[{"blips":[{"name":"Android","id":"9007","quadrant":"platforms","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"ASP.NET MVC","id":"9016","quadrant":"tools","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Build pipelines","id":"9029","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"C# 4.0","id":"9032","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Chrome","id":"9040","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"Web browsers continue to evolve as they strive to keep pace with new specifications in HTML, CSS and JavaScript. Alas, many enterprises have yet to embrace the end of life for IE6 and move to a newer and more standards compliant option. Of the browsers available today, Firefox and Opera provide support for the widest range of platforms. The Google browser, Chrome, brings new innovation to the browser space by splitting browser tabs into separate processes while providing a new implementation of JavaScript. These changes appear to give Chrome a significant performance boost over other browsers and have influenced the creation of a netbook OS called Chrome OS. While enterprises may look to move off IE6 and onto Microsoft’s IE8, we remain concerned about IE8’s current level of compliance to web standards.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Chrome OS","id":"9041","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"Web browsers continue to evolve as they strive to keep pace with new specifications in HTML, CSS and JavaScript. Alas, many enterprises have yet to embrace the end of life for IE6 and move to a newer and more standards compliant option. Of the browsers available today, Firefox and Opera provide support for the widest range of platforms. The Google browser, Chrome, brings new innovation to the browser space by splitting browser tabs into separate processes while providing a new implementation of JavaScript. These changes appear to give Chrome a significant performance boost over other browsers and have influenced the creation of a netbook OS called Chrome OS. While enterprises may look to move off IE6 and onto Microsoft’s IE8, we remain concerned about IE8’s current level of compliance to web standards.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Cloud","id":"9045","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Concurrent languages","id":"9055","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"The remaining two language types included on the radar are often grouped together. While functional and concurrent languages may be adopted in similar environments, their approaches are different. Functional programming focuses on expressing code in the form of mathematical functions that avoid maintaining state across multiple invocations. While functional languages such as Haskell have been around for a number of years, new functional (themed) languages such as Scala, F# and Clojure have sparked some interest in this paradigm. Due to the way in which functional languages manage state, interest in these languages has increased by many developers seeking to make the most out of multi-core processors. Many concurrent languages are also functional languages. The distinction lies in the emphasis on running operations in parallel. A number of such languages exist; Erlang is currently the most popular of these languages. Concurrent languages commonly provide some means for handling concurrency by using messages to communicate across multiple threads.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Continuous deployment","id":"9059","quadrant":"techniques","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Distributed version control","id":"9078","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"Distributed version control systems such as Git and Mercurial have had significant exposure in the past year or more as open source projects move to this toolset en masse. The social networking aspect that GitHub and Bitbucket have brought to distributed version control has helped to propel these tools forward and into enterprises looking for ways to develop across multiple geographies. The move for many to a distributed version control system has resulted in a move away from tools such as Subversion and other centralized version control systems. As organizations assess and choose between these two different toolsets, we suggest that you evaluate both in relation to your team’s specific needs. While we have seen widespread adoption of distributed version control tools within Thoughtworks and beyond, we still advocate the use of continuous integration and limits to the amount of time that code is spent outside of the main branch.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Domain-Specific Languages","id":"9079","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Emergent design","id":"9086","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Evolutionary architecture","id":"9092","quadrant":"techniques","ring":"Assess","movement":"c","radius":"","description":"We assist many of our clients in adapting enterprise software architecture practices to fit within an Agile software delivery approach. In the past year we have seen increased interest in evolutionary enterprise architecture and how service oriented architectures shape the boundaries between enterprise units. The value of an evolutionary approach to enterprise architecture is the creation of lighter weight systems that ease integration between disparate parts. By embracing this approach and the notion of the web as an enterprise application platform, we have reduced overall complexity of application architectures, increased quality and scalability, and reduced development costs.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Evolutionary database","id":"9093","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Firefox","id":"9101","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"Web browsers continue to evolve as they strive to keep pace with new specifications in HTML, CSS and JavaScript. Alas, many enterprises have yet to embrace the end of life for IE6 and move to a newer and more standards compliant option. Of the browsers available today, Firefox and Opera provide support for the widest range of platforms. The Google browser, Chrome, brings new innovation to the browser space by splitting browser tabs into separate processes while providing a new implementation of JavaScript. These changes appear to give Chrome a significant performance boost over other browsers and have influenced the creation of a netbook OS called Chrome OS. While enterprises may look to move off IE6 and onto Microsoft’s IE8, we remain concerned about IE8’s current level of compliance to web standards.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Functional languages","id":"9106","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"The remaining two language types included on the radar are often grouped together. While functional and concurrent languages may be adopted in similar environments, their approaches are different. Functional programming focuses on expressing code in the form of mathematical functions that avoid maintaining state across multiple invocations. While functional languages such as Haskell have been around for a number of years, new functional (themed) languages such as Scala, F# and Clojure have sparked some interest in this paradigm. Due to the way in which functional languages manage state, interest in these languages has increased by many developers seeking to make the most out of multi-core processors. Many concurrent languages are also functional languages. The distinction lies in the emphasis on running operations in parallel. A number of such languages exist; Erlang is currently the most popular of these languages. Concurrent languages commonly provide some means for handling concurrency by using messages to communicate across multiple threads.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Google as corporate platform","id":"9113","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Google Wave","id":"9115","quadrant":"tools","ring":"Hold","movement":"c","radius":"","description":"Google Wave has sprung up over the past few months and looks to be a promising platform for collaboration over the Internet. The platform is still in early beta and suffers from some stability issues. Some early developers have integrated with the Google Wave platform but commercial releases of software that utilize Google Wave will likely wait until the beta tag has been lifted from the product.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"HTML 5","id":"521521","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"This platform was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"IE6 End of Life","id":"9137","quadrant":"tools","ring":"Adopt","movement":"c","radius":"","description":"Web browsers continue to evolve as they strive to keep pace with new specifications in HTML, CSS and JavaScript. Alas, many enterprises have yet to embrace the end of life for IE6 and move to a newer and more standards compliant option. Of the browsers available today, Firefox and Opera provide support for the widest range of platforms. The Google browser, Chrome, brings new innovation to the browser space by splitting browser tabs into separate processes while providing a new implementation of JavaScript. These changes appear to give Chrome a significant performance boost over other browsers and have influenced the creation of a netbook OS called Chrome OS. While enterprises may look to move off IE6 and onto Microsoft’s IE8, we remain concerned about IE8’s current level of compliance to web standards.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"IE8","id":"9138","quadrant":"platforms","ring":"Hold","movement":"c","radius":"","description":"Web browsers continue to evolve as they strive to keep pace with new specifications in HTML, CSS and JavaScript. Alas, many enterprises have yet to embrace the end of life for IE6 and move to a newer and more standards compliant option. Of the browsers available today, Firefox and Opera provide support for the widest range of platforms. The Google browser, Chrome, brings new innovation to the browser space by splitting browser tabs into separate processes while providing a new implementation of JavaScript. These changes appear to give Chrome a significant performance boost over other browsers and have influenced the creation of a netbook OS called Chrome OS. While enterprises may look to move off IE6 and onto Microsoft’s IE8, we remain concerned about IE8’s current level of compliance to web standards.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Incremental data warehousing","id":"9141","quadrant":"techniques","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"iPhone","id":"9146","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Java language end of life","id":"9150","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"As C# continues to surge ahead, the Java language appears to be moving slowly as the Java community waits for Java 7. Having waited for new language features to surface for almost 3 years, the Java community has begun to innovate in new languages that run on the Java Virtual Machine, languages such as Groovy, JRuby, Scala and Clojure. With the increase in number of languages available on the JVM, we expect enterprises to begin to assess the suitability of reducing the amount of Java specific code developed in their enterprise applications in favor of these newer languages.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"JavaScript as a first class language","id":"9152","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"JVM as platform","id":"9160","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Language workbenches","id":"9162","quadrant":"tools","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Lean software development","id":"9164","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Location based services","id":"9167","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Next-generation test tools","id":"9192","quadrant":"tools","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Non-relational databases","id":"9194","quadrant":"platforms","ring":"Trial","movement":"c","radius":"","description":"The semantic web and its underlying technologies, including RDF \u0026 SPARQL, have been around for 8 years or more. Broader uptake of the Cloud and non-relational databases such Neo4j have helped move the semantic web into the reach of enterprise developers. Outside of the semantic web, nonrelational databases are being adopted as alternatives to relational databases in a number of situations. Leveraging these technologies will require new approaches to architecture and development that suggest widespread adoption will only occur over a number of years.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Polyglot development environments","id":"9213","quadrant":"tools","ring":"Hold","movement":"c","radius":"","description":"Polyglot programming continues to gain widespread acceptance across the industry reflecting the reality that software developers have many languages and tools at their disposal. One area that we have yet to see take off is the creation of polyglot development environments, capable of satisfying multiple language needs of development teams. While Eclipse, IntelliJ, Visual Studio and others have some cross-language capabilities, their support for a wide range of languages is limited at best.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"RDF \u0026 SPARQL","id":"9228","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"The semantic web and its underlying technologies, including RDF \u0026 SPARQL, have been around for 8 years or more. Broader uptake of the Cloud and non-relational databases such Neo4j have helped move the semantic web into the reach of enterprise developers. Outside of the semantic web, nonrelational databases are being adopted as alternatives to relational databases in a number of situations. Leveraging these technologies will require new approaches to architecture and development that suggest widespread adoption will only occur over a number of years.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Rich Internet applications","id":"9239","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"Our position on Rich Internet Applications has changed over the past year. Experience has shown that platforms such as Silverlight, Flex and JavaFX may be useful for rich visualizations of data but provide few benefits over simpler web applications. Given that these toolsets have limited support for automated testing, it would suggest that a more traditional web application stack provides greater value for enterprise development. We recommend only using RIA platforms for rich visualizations incorporated into web applications, not as comprehensive development targets.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Subversion","id":"9268","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"Distributed version control systems such as Git and Mercurial have had significant exposure in the past year or more as open source projects move to this toolset en masse. The social networking aspect that GitHub and Bitbucket have brought to distributed version control has helped to propel these tools forward and into enterprises looking for ways to develop across multiple geographies. The move for many to a distributed version control system has resulted in a move away from tools such as Subversion and other centralized version control systems. As organizations assess and choose between these two different toolsets, we suggest that you evaluate both in relation to your team’s specific needs. While we have seen widespread adoption of distributed version control tools within Thoughtworks and beyond, we still advocate the use of continuous integration and limits to the amount of time that code is spent outside of the main branch.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"User centered design","id":"9281","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"The benefits of user-centered design are often understated. Gaining a broader understanding of data flows and users’ goals simplify the overall architecture of a system while optimizing user interaction. In the past year we have seen a greater uptake of user-centered design in Agile software development practices as experts in both fields have established new ways of working together.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Visualization and metrics","id":"9286","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-01"},{"name":"Web as platform","id":"9290","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"We assist many of our clients in adapting enterprise software architecture practices to fit within an Agile software delivery approach. In the past year we have seen increased interest in evolutionary enterprise architecture and how service oriented architectures shape the boundaries between enterprise units. The value of an evolutionary approach to enterprise architecture is the creation of lighter weight systems that ease integration between disparate parts. By embracing this approach and the notion of the web as an enterprise application platform, we have reduced overall complexity of application architectures, increased quality and scalability, and reduced development costs.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-01"}],"date":"2010-01"},{"blips":[{"name":"ALT.NET","id":"9005","quadrant":"platforms","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Android","id":"9007","quadrant":"platforms","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Application appliances","id":"9015","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"This platform was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"ASP.NET MVC","id":"9016","quadrant":"tools","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Automation of technical tests","id":"9021","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"Significant advances in the tools for automating functional testing haven’t been replicated in the technical testing space. Data management for performance, load and soak testing is a particular issue. However, the tools are improving and increased visibility for these tools supports the early and often technical testing that we advocate.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Azure","id":"473","quadrant":"platforms","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Build pipelines","id":"9029","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"C# 4.0","id":"9032","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Clojure","id":"258","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"In the previous radar, we lumped functional languages together in a group. For this version, we’ve exploded that group and started calling out the ones interesting to us. Of the current crop of functional languages, the one we like the most is Clojure: a simple, elegant implementation of Lisp on the JVM. The other two that we fi nd interesting are Scala (a re-thinking of Java in functional form) and F#, the OCaml derivative from Microsoft that now appears “in the box” in Visual Studio 2010.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Cloud","id":"9045","quadrant":"platforms","ring":"Adopt","movement":"s","radius":"","description":"The Cloud continues to be of interest to us, with Software as a Service the most mature cloud component. Platform and Infrastructure as service offerings have reached different levels of maturity, and we reflect that in our placement of EC2, Google App Engine and Azure.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Continuous deployment","id":"9059","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Cross mobile platforms","id":"9063","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Distributed version control","id":"9078","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"Subversion moves back into the Adopt section of the radar because it is a solid version control tool suitable for most teams. We consider Subversion’s features to be the basic standard for a modern version control tool. Thoughtworkers continue to embrace and recommend Distributed Version Control tools such as Git and Mercurial, but we caution that these systems often require deeper understanding to get the most out of them. New to the radar is GitHub, a “social coding” tool supporting both source code hosting and social networking. GitHub is arguably one of the main reasons Git has become the leading DVCS tool, and GitHub’s collaboration features are often used by enterprises that need to support distributed teams.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Domain-Specific Languages","id":"9079","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"EC2 \u0026 S3","id":"9082","quadrant":"platforms","ring":"Trial","movement":"c","radius":"","description":"The Cloud continues to be of interest to us, with Software as a Service the most mature cloud component. Platform and Infrastructure as service offerings have reached different levels of maturity, and we reflect that in our placement of EC2, Google App Engine and Azure.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Emergent design","id":"9086","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"ESB","id":"9088","quadrant":"tools","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Evolutionary database","id":"9093","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"F#","id":"9097","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"In the previous radar, we lumped functional languages together in a group. For this version, we’ve exploded that group and started calling out the ones interesting to us. Of the current crop of functional languages, the one we like the most is Clojure: a simple, elegant implementation of Lisp on the JVM. The other two that we fi nd interesting are Scala (a re-thinking of Java in functional form) and F#, the OCaml derivative from Microsoft that now appears “in the box” in Visual Studio 2010.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Facebook as business platform","id":"9098","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"GitHub","id":"9111","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Google App Engine","id":"9112","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"The Cloud continues to be of interest to us, with Software as a Service the most mature cloud component. Platform and Infrastructure as service offerings have reached different levels of maturity, and we reflect that in our placement of EC2, Google App Engine and Azure.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Google as corporate platform","id":"9113","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Groovy","id":"9120","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"GWT","id":"9122","quadrant":"platforms","ring":"Hold","movement":"t","radius":"","description":"Google Web Toolkit (GWT) offers an interesting premise: write Swing-like Java code and generate unit testable JavaScript widgets and user interfaces. From a practical standpoint this doesn’t work well. First, using code-gen to produce the artifacts is time consuming, artificially extending build times and requiring manual changes to obtain optimal package layout. Second, if the JavaScript doesn’t behave exactly as you want you will have to hack the generated code. Third, using Java to generate JavaScript means that you can’t take direct advantage of the powerful features of JavaScript or numerous libraries such as JQuery. Finally, the JUnit support is quite limited, for example code using reflection cannot be tested.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"HTML 5","id":"521521","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"HTML 5 offers a large number of improvements over HTML 4 and XHTML 1.0. Many of these improvements are focused on providing support for developing complex web applications, and improving integration of rich content such as audio and video in standard ways. Features such as client-side storage, web sockets and offline use will further establish the position of the web browser as a viable enterprise application platform.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"IE6 End of Life","id":"9137","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"IE8","id":"9138","quadrant":"platforms","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Incremental data warehousing","id":"9141","quadrant":"techniques","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"iPhone","id":"9146","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"The iPhone and android operating systems have rapidly become key players in the mobile platform marketplace. Apple’s app store and Google’s open source operating system have helped both companies leapfrog the competition in capturing developer mindshare.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Java language end of life","id":"9150","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"JavaScript as a first class language","id":"9152","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"JVM as platform","id":"9160","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Language workbenches","id":"9162","quadrant":"tools","ring":"Hold","movement":"c","radius":"","description":"It is likely that test languages will continue to evolve with the assistance of language workbenches, tools that assist in the creation of domain specific languages. Tools such as Jetbrains’ MPS and Intentional Software’s offering are leading the industry in this area. Both provide ways of creating new languages to map business software more closely to the end user’s domain language.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Large format mobile devices","id":"9163","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"Large format mobile devices, such as the Apple iPad and Amazon Kindle, provide a new model of ubiquitous computing. Their long battery life, simple interfaces and easy connectivity have the potential to change the way we interact with computers. Apple’s new user interfaces discard the familiar desktop metaphors of files and folders that have been standard since the introduction of the Macintosh in 1984.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Lean software development","id":"9164","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"As Agile practices move further toward mainstream adoption, we see significant benefits from the adoption of Lean software development practices as well. These practices have their roots in the Toyota Production System and complement much of our understanding of Agile software development to date. One topic that Lean has also given us greater insight into is that of set-based design. Set-based design leads us to implement similar solutions at the same time while the cost of doing so is constrained. This leads us into the area of emergent design and the ability to let experience shape our design decisions and defer key decisions until the last responsible moment.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Location based services","id":"9167","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Message buses without smarts","id":"9180","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Mobile Web","id":"9187","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"MongoDB","id":"508","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Neo4J","id":"460","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Next-generation test tools","id":"9192","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"NoSQL","id":"9195","quadrant":"tools","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"OAuth","id":"9197","quadrant":"techniques","ring":"Assess","movement":"t","radius":"","description":"The Web is a global data structure that enables us to share information. However not all data is meant to be shared by everyone and it’s important to be able to share information on the Web in a disciplined and governable manner without requiring massive centralized infrastructure. OAuth provides a way of sharing resources on the Web responsibly and securely. It is a Web protocol (for Web browsers or machine-to-machine interactions), which allows federated authorization of access to Web resources. What’s interesting is that OAuth is a simple protocol to implement and utilize and yet its design goals match many common enterprise authorization problems. OAuth remains in the assessment category, however, because it has fragmented, and the IETF has not yet drawn the community back together under an Internet RFC.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Platform roadmaps","id":"9211","quadrant":"platforms","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Polyglot programming","id":"9215","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"This technique was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"RDF triple stores","id":"9228","quadrant":"tools","ring":"Assess","movement":"c","radius":"","description":"Semantic Web W3C standards, and the tools implementing them, are at last worthy of real attention. RDF and RDFa allow anyone to say anything about anything in a sharable, structured format. This proves a much more powerful means of linking and structuring data from disparate sources than the strictness of RDBMS, or the mess that is unstructured Web data. Correspondingly SPARQL is the query standard that allows information to be mined from RDF marked-up data.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Restfulie","id":"9238","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Rich Internet Applications","id":"9239","quadrant":"platforms","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Ruby/Jruby","id":"9244","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Scala","id":"257","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"In the previous radar, we lumped functional languages together in a group. For this version, we’ve exploded that group and started calling out the ones interesting to us. Of the current crop of functional languages, the one we like the most is Clojure: a simple, elegant implementation of Lisp on the JVM. The other two that we fi nd interesting are Scala (a re-thinking of Java in functional form) and F#, the OCaml derivative from Microsoft that now appears “in the box” in Visual Studio 2010.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Scrum certification","id":"9251","quadrant":"techniques","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Service choreography","id":"9255","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Squid","id":"9267","quadrant":"tools","ring":"Adopt","movement":"t","radius":"","description":"This tool was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Subversion","id":"9268","quadrant":"tools","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Visualization and metrics","id":"9286","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Visualizations for business data","id":"9287","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"This tool was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"Web as platform","id":"9290","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-04"},{"name":"WS-* beyond basic profile","id":"234","quadrant":"platforms","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2010-04"}],"date":"2010-04"},{"blips":[{"name":"ALT.NET","id":"9005","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"While .NET has proven itself as a solid platform, many practitioners are dissatisfied with many of the default Microsoft tools and practices. This has led to the growth of the Alt.NET community, which champions techniques that we find more effective along with (usually opensource) tools that better support them.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Android","id":"9007","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Apache camel","id":"9009","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"App containers","id":"9012","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"This platform was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Application appliances","id":"9015","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"This platform was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"ASP","id":"9016","quadrant":"tools","ring":"Adopt","movement":"c","radius":"","description":"We have been tracking ASP.NET MVC since its early release candidates. This is an exciting development in the .NET space from Microsoft, both in the programming model and in the open source license under which Microsoft has released the library. ASP.NET MVC is similar to MVC frameworks on the Java platform and is a move away from the ASP.NET Web Forms approach to one that supports greater levels of automated testing.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"ATOM","id":"9018","quadrant":"platforms","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Automation of technical tests","id":"9021","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Azure","id":"473","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Build pipelines","id":"9029","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"C# 4.0","id":"9032","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Capability modeling","id":"9035","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Clojure","id":"258","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Coding architects","id":"9049","quadrant":"techniques","ring":"Adopt","movement":"t","radius":"","description":"This technique was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Continuous deployment","id":"9059","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Cross mobile platforms","id":"9063","quadrant":"tools","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Database based integration","id":"9068","quadrant":"techniques","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"DevOps","id":"9077","quadrant":"techniques","ring":"Assess","movement":"t","radius":"","description":"DevOps is a new movement seeking to achieve the business need for rapid delivery of software products while maintaining the stability of live environments. It uses two approaches: first, promoting closer collaboration between development and operations; second, applying practices shared with agile (collaboration, automation, simplicity, etc) to operations processes such as provisioning, change management, and production monitoring. It encompasses culture, processes, and tools - all supporting better communication, faster feedback and delivery, and more predictable outcomes.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Domain-Specific Languages","id":"9079","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radius":"","description":"A significant amount of innovation occurred in the JavaScript space thanks to the Ruby on Rails community. This same community has helped to move both internal and external DSLs forward as a means for more closely mapping business requirements in code. Ruby’s syntax lends itself easily to the creation of easily readable DSLs, while language tools such as ANTLR help to make the creation of new domain specific languages more accessible to interested developers.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"EC2 \u0026 S3","id":"9082","quadrant":"platforms","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Emergent design","id":"9086","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"ESB","id":"9088","quadrant":"tools","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Evolutionary architecture","id":"9092","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Evolutionary database","id":"9093","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"F#","id":"9097","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Facebook as business platform","id":"9098","quadrant":"platforms","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Git","id":"9110","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Github","id":"9111","quadrant":"tools","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Google App Engine","id":"9112","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"This platform was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Google as corporate platform","id":"9113","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"At the start of October 2009, Thoughtworks became a customer of Google Apps. Although we have heard a wide range of opinions about the user experience offered by Google Mail, Calendar and Documents, the general consensus is that our largely consultant workforce is happy with the move. The next step that we as a company are looking to embrace is Google as a corporate platform beyond the standard Google Apps; in particular we are evaluating the use of Google App Engine for a number of internal systems initiatives. Google App Engine, Amazon EC2 and Salesforce.com all claim to be Cloud providers, yet each of their offerings differ. The Cloud fits into a broad categorization of service offerings split out into Infrastructure as a Service (e.g. Amazon EC2 and Rackspace), Platform as a Service (e.g. App Engine) and Software as a Service (e.g. Salesforce.com). In some cases, providers may span multiple service categories, further diluting the Cloud as a label. Regardless, the value of infrastructure, platform and software in the cloud is difficult to question and although many offerings have hit bumps in the road, they certainly have earned their position on the radar.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"GPGPU","id":"9116","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Groovy","id":"9120","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"GWT","id":"9122","quadrant":"platforms","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"HTML 5","id":"521521","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"IE6 End of Life","id":"9137","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"IE6 is a significantly deficient browser with many documented security holes and should be phased out as soon as possible. Browsers such as Firefox and Chrome can be installed alongside IE, allowing the user to choose which one to use. We recommend that organizations with intranet applications that require IE6 consider using it only for those specific applications, and install one of these alongside for general use.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"IE8","id":"9138","quadrant":"platforms","ring":"Hold","movement":"c","radius":"","description":"Internet browsers such as Google Chrome, Safari, Opera and Firefox, have made serious inroads in the implementation of the HTML 5 specification. With these advances it is now possible to experience many of the improvements that HTML brings. Unfortunately so far Microsoft has lagged on implementing these new standards. We recommend that organizations favor standards compliant browsers over IE8.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Incremental data warehousing","id":"9141","quadrant":"techniques","ring":"Assess","movement":"c","radius":"","description":"The industry has seen significant changes to the way we use and store data over the past few years. Agile development practices have lead to greater emphasis on evolutionary database design, requiring new tools that support migration of schemas in line with changes to the domain model of an application. As storage space consistently becomes cheaper and data access speeds increase, many organizations are investigating the use of multiple schemas to hold data for different purposes, e.g. transactional and analysis schemas. Incremental data warehousing is becoming increasingly popular as the cost of moving data between a transactional data store and an analysis environment is less than the value of having access to near real-time reporting of critical business data.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Intentional Software","id":"9144","quadrant":"tools","ring":"Hold","movement":"t","radius":"","description":"Thoughtworks has been working with Intentional Software for the past several years, and we are thrilled at the recent limited availability and production use of the Intentional Domain Workbench. We believe this technology represents a radical departure from the traditional software development approach. We place this technology in the assess ring, since we believe that it is time to begin exploring the application of Intentional’s technology in proofs of concept.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"iPad","id":"9145","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"iPhone","id":"9146","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"The iPhone changed the face of the mobile phone. The iPad has the potential to radically alter the way users interact with and consume Web-based resources and applications and will spawn a plethora of similar tablet devices. The addition of wireless application distribution in IOS4 allows organizations to securely host and distribute in-house applications without using the App Store, overcoming one of the main barriers to corporate adoption. IOS4’s introduction of multitasking with applications running in the background has opened up new possibilities for enterprise applications, at the cost of extra battery usage.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Java language end of life","id":"9150","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"As we have discussed previously, the Java language appears to be moving slowly as the Java community waits for Java 7. Having waited for new language features to surface for almost 3 years, the Java community has begun to innovate in new languages that run on the Java Virtual Machine, languages such as Groovy, JRuby, Scala and Clojure. With the increase in number of languages available on the JVM, we expect enterprises to begin to assess the suitability of reducing the amount of Java specific code developed in their enterprise applications in favor of these newer languages. This is not to say that enterprises should outright abandon Java as a programming language, we do however suggest that you look for alternatives that may be more fi t for purpose in the area that new development is taking place.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"JavaScript as a first class language","id":"9152","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"JRuby","id":"9244","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"JVM as platform","id":"9160","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"While the radar has called out the possibility of the Java language nearing its end of life, the JVM is demonstrating its resilience as a general-purpose virtual machine for other languages such as Ruby, Groovy, Scala and Clojure.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"KVM","id":"9161","quadrant":"platforms","ring":"Adopt","movement":"t","radius":"","description":"This platform was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Location based services","id":"9167","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"Google maps has led the way in bringing mapping mainstream. But businesses, governments and non-profit organizations are now learning to use these location based services to communicate more effectively with customers. With other mapping services providers getting into the act, there is going to be a proliferation of applications built around mapping targeted at customers who are now much more map-savvy.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Mercurial","id":"9179","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Message buses without smarts","id":"9180","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Mobile Web","id":"9187","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"MongoDB","id":"508","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"Document-oriented databases treat each record as a document with the ability to add any number of fields of arbitrary size. A relatively large amount of the attention that has been directed at document databases has landed on mongoDB, a highly scalable option with support for querying, indexing, replication and sharding. Beyond its enterprise feature set, its popularity is aided by its driver support for Java, Ruby, PHP, C#, Python and a number of other languages.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Neo4J","id":"460","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"Graph databases store information as interconnected nodes with arbitrary relations rather than tables and nameless relations. Graph databases are an excellent choice for complex domains with semi-structured data since they’re schema-less and highly extensible. Neo4j is the front-runner in the graph database space being an embedded Java component, which supports fast storage and search of graphs for Java solutions (including server applications). The Neo4j community is highly active and now has a basic REST API enabling it as more general purpose database engine. Neo4j moving into the trial category is representative of our experience trialling it in real-world scenarios and the early successes we’ve achieved.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Next-generation test tools","id":"9192","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"NoSQL","id":"9195","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"OAuth","id":"9197","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Platform roadmaps","id":"9211","quadrant":"techniques","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Polyglot programming","id":"9215","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"This technique was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Puppet","id":"9224","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"Puppet is a free, open source data center automation tool for managing changes to your production and production-like environments. Using Puppet, you can keep the configuration of your environments in version control and push changes out to your systems in a controlled, automated fashion. Infrastructure automation tools like puppet have the benefits of reducing manual effort allowing ops to focus on higher priorities, providing consistency and repeatability by reducing waste eliminating environmental differences between test and production environments.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"RDF triple stores","id":"92281","quadrant":"tools","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"RDFa","id":"9228","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Restfulie","id":"9238","quadrant":"tools","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Rich Internet Applications","id":"9239","quadrant":"platforms","ring":"Hold","movement":"c","radius":"","description":"Rich Internet Applications (RIA) are a popular topic, driven by the effort and marketing of big vendors pushing their offerings. RIA is useful for complex visualizations but ill-suited for other programming tasks because it doesn’t fully support the engineering hygiene we require for our tools: testing is difficult and application partitioning is cumbersome. These frameworks also don’t support common elements we take for granted in applications hosted in a browser: bookmarking, addressability, browser controls, and other aspects. We’re not entirely critical of these tools, but think that their sweet spot is rich visualizations, not building traditional data entry CRUD applications.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Ruby","id":"9243","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radius":"","description":"This language/framework was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Scala","id":"257","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"The functional languages F#, Clojure and Scala still reside in the assess ring of the radar. Interest in functional languages continues to grow. Two characteristics of functional languages in particular are driving this interest, immutability with its implications for parallelism and functions as first class objects. While the introduction of closures to C# brings some of the latter capability, functional languages are almost synonymous with immutability. The placement of these languages within the assess ring indicates our view of their relative maturity and appropriateness. F#, based on OCaml, is fully supported within the Visual Studio toolset. F# includes support for objects and imperative constructs in addition to functional language constructs in a natural way. Scala, like F#, combines the object and functional paradigms, although the syntax of Scala is more Java-like. Clojure began as a JVM language and is now available on the .NET CLR. Clojure does allow for mutable state although it has an extensive set of immutable persistent data structures, all supporting multi-threaded applications. There are many similarities between these three languages, but at the moment we believe F# and Clojure to be better suited to most organizations for assessing than Scala. More work clearly needs to be done to validate this assertion.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Scrum certification","id":"9251","quadrant":"techniques","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Service choreography","id":"9255","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Squid","id":"9267","quadrant":"tools","ring":"Adopt","movement":"c","radius":"","description":"This tool was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Subversion","id":"9268","quadrant":"tools","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Visualization and metrics","id":"9286","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"Web as platform","id":"9290","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2010-08"},{"name":"WS-* beyond basic profile","id":"234","quadrant":"platforms","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-04","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2010-08"}],"date":"2010-08"},{"blips":[{"name":"Acceptance test of journeys","id":"9001","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Android","id":"9007","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"The iPhone and android operating systems have rapidly become key players in the mobile platform marketplace. Apple’s app store and Google’s open source operating system have helped both companies leapfrog the competition in capturing developer mindshare.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Apache camel","id":"9009","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"In today’s connected systems environments almost all new development needs to integrate with existing applications and services. In conjunction with our adoption of simple message buses and integration techniques at the edges of a system, we have successfully used small libraries such as Apache Camel to perform the protocol bridging, message transformation and message routing tasks common to such integrations. Camel’s fluent Java interface, unit testing support and connectors for many different transports and message formats provide for an effective anti-corruption layer when implementing distributed applications.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"API management services","id":"9011","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"App containers","id":"9012","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"This platform was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Application appliances","id":"9015","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"This platform was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"ATOM","id":"9018","quadrant":"platforms","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Automate database deployment","id":"9019","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"When moving to continuous delivery, deployment of database changes should also be automated so that the application release that relies on those changes does not have to wait for manual deployment of the database changes. Automated database deployment ensures that the full cycle of deploying application and database changes is automated.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Automation of technical tests","id":"9021","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"We strongly believe that all software delivery organizations need to be making use of automated technical tests. This sort of test spans failover testing, performance testing and soak testing among others; these activities can start early in a project’s life-cycle and continue through to maintenance. The common practice of waiting until near the end of a project is fraught with risk with little time available to find and fix problems. For example the requirement for a comprehensive production-like environment before the start of performance testing is a dangerous fallacy, we can discover bottlenecks, track performance trends and test our performance tests, without waiting for a perfect environment.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Azure","id":"473","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"The Cloud continues to be of interest to us, with Software as a Service the most mature cloud component. Platform and Infrastructure as service offerings have reached different levels of maturity, and we reflect that in our placement of EC2, Google App Engine and Azure.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Build pipelines","id":"9029","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"The past 2 years or more has seen a proliferation of continuous integration tools and platforms leading to substantial innovation in the build and release space. Distribution of builds is one such innovation and yet another is the way in which builds are now structured to make greater use of automation in various stages of the build. Build pipelines help to provide greater insight into the quality of each build and the environments to which they have been deployed. A natural expansion of the build pipeline meme is the adoption of continuous deployment techniques, where the intention is to extend the build pipeline into the production environment. This relies on automated deployment techniques and authorization mechanisms built into the continuous integration toolset. One of the key benefits is the ability to move new functionality into production rapidly and reliably.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"C# 4.0","id":"9032","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radius":"","description":"When C# first appeared, many saw it as a direct competitor to the Java language’s dominance in enterprise application development. This was often attributed to the syntactical similarities that the two languages shared. Since its introduction, however, C# has continued to move forward with the adoption of language features such as lambda expressions, extension methods, object initializers and automatic property setters and getters, all of which are available in the 3.5 release of the language. With the 4.0 release of C#, we will see the introduction of a dynamic keyword and named and optional parameters, which will continue to bring C# more in line with languages such as Ruby and well ahead of the Java language.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Capability modeling","id":"9035","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Categorization \u0026 prioritization of technical debt","id":"9039","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Clojure","id":"258","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Coding architects","id":"9049","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"This technique was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Concurrency abstractions and patterns","id":"9054","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Continuous deployment","id":"9059","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"The past 2 years or more has seen a proliferation of continuous integration tools and platforms leading to substantial innovation in the build and release space. Distribution of builds is one such innovation and yet another is the way in which builds are now structured to make greater use of automation in various stages of the build. Build pipelines help to provide greater insight into the quality of each build and the environments to which they have been deployed. A natural expansion of the build pipeline meme is the adoption of continuous deployment techniques, where the intention is to extend the build pipeline into the production environment. This relies on automated deployment techniques and authorization mechanisms built into the continuous integration toolset. One of the key benefits is the ability to move new functionality into production rapidly and reliably.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Cross mobile platforms","id":"9063","quadrant":"tools","ring":"Assess","movement":"c","radius":"","description":"While there has been much publicity around Apple’s squashing cross-platform development options for the iPhone and iPad, there are still perfectly valid options. PhoneGap and Appcelerator Titanium’s approach is to provide a native compatibility layer for all the major mobile platforms to your Web standard HTML+CSS+JS application.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Database based integration","id":"9068","quadrant":"techniques","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Deltacloud","id":"9073","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"DevOps","id":"9077","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"The DevOps movement continues to gain traction as people pay more attention to the often-broken relationship between development and operations. DevOps promotes closer collaboration and joint responsibility between development and operations. DevOps applies agile practices to operations processes such as provisioning, change management and production monitoring and also brings productionlike thinking, tools and environments to development. DevOps is a key underpinning for organizations wanting to achieve continuous delivery of application releases into production.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Domain-Specific Languages","id":"9079","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"EC2 \u0026 S3","id":"9082","quadrant":"platforms","ring":"Trial","movement":"c","radius":"","description":"AWS is the most mature and broadest of the current cloud offerings providing scalable services for computation (EC2), storage (S3 \u0026 SBS), databases (SimpleDB \u0026 RDS), messaging (SQS \u0026 SNS), etc. The list of services provided by AWS continues to expand rapidly with new services being added on an almost monthly basis, (http://bit.ly/90887v). While existing applications can be deployed on AWS through the use of Amazon Machine Images the full benefits of this platform will come from applications that are developed to take advantage of AWS. The usage based billing model adopted by AWS allows organizations to scale applications without large upfront investment and avoid the overhead cost of under utilized hardware.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Emergent design","id":"9086","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"ESB","id":"9088","quadrant":"tools","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Evolutionary architecture","id":"9092","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"One principle of agile software development is the notion of the last responsible moment. This notion applied to architectural considerations is controversial among traditional architects. We believe that, given properly articulated principles and appropriate test suites, architectures can evolve to meet the changing needs of a system, allowing for architectural decisions to be made at the last responsible moment without compromising the integrity of the system. We call this approach evolutionary architecture, in that we allow the architecture to evolve over time, always respecting the architectural guiding principles.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Evolutionary database","id":"9093","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"The industry has seen significant changes to the way we use and store data over the past few years. Agile development practices have lead to greater emphasis on evolutionary database design, requiring new tools that support migration of schemas in line with changes to the domain model of an application. As storage space consistently becomes cheaper and data access speeds increase, many organizations are investigating the use of multiple schemas to hold data for different purposes, e.g. transactional and analysis schemas. Incremental data warehousing is becoming increasingly popular as the cost of moving data between a transactional data store and an analysis environment is less than the value of having access to near real-time reporting of critical business data.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"F#","id":"9097","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Facebook as business platform","id":"9098","quadrant":"platforms","ring":"Trial","movement":"c","radius":"","description":"Facebook has become popular in part due to its rich API and explosion of third-party applications. Thoughtworks is now starting to see our clients consider Facebook as a business platform. In addition to having a Facebook presence, businesses are building Facebook applications that are tightly integrated with their own services and offer useful functionality to Facebook users.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Git","id":"9110","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"In previous radars we recommended Distributed Version Control (DVCS) tools in general while mentioning Git and Mercurial in particular. In this edition we narrow our recommendation to only Mercurial and Git as these two have become the clear front-runners. Due to its success and the associated network effect GitHub remains the recommended option for enterprises that want to interact with the open source community.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Github","id":"9111","quadrant":"tools","ring":"Assess","movement":"c","radius":"","description":"Subversion moves back into the Adopt section of the radar because it is a solid version control tool suitable for most teams. We consider Subversion’s features to be the basic standard for a modern version control tool. Thoughtworkers continue to embrace and recommend Distributed Version Control tools such as Git and Mercurial, but we caution that these systems often require deeper understanding to get the most out of them. New to the radar is GitHub, a “social coding” tool supporting both source code hosting and social networking. GitHub is arguably one of the main reasons Git has become the leading DVCS tool, and GitHub’s collaboration features are often used by enterprises that need to support distributed teams.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"GPGPU","id":"9116","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Groovy","id":"9120","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radius":"","description":"Functional languages have a wide range of practical uses, including simulation, computational fi nance, computational science, large scale data processing and parsing. These fields benefit from functional programming techniques that simplify concurrent execution and the expression of complex mathematical functions concisely. Functional programming requires a shift in thinking for enterprise developers experienced in object oriented development. Moving to an often terse syntax for solving complex problems may initially be intimidating to many. As with all forms of programming languages, syntax is just one aspect of the language itself. In functional programming another significant aspect is the use of common idioms. These idioms speed code comprehension and increase overall maintainability. This might not be news to all, but it is worth noting that dynamic languages are long ready for adoption and trial. Ruby, particularly when deployed on JRuby, is ready for adoption. Thoughtworks uses Ruby and JRuby extensively in both its Services and Product work. Groovy is ready for trial and could prove more accessible than Ruby/JRuby in a Java shop. For the right type of applications, Ruby, JRuby, and Groovy prove far more effective, expressive, and productive than Java and C#.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"GWT","id":"9122","quadrant":"platforms","ring":"Hold","movement":"c","radius":"","description":"In the last radar we placed the Google Web Toolkit (GWT) on hold and tried to provide a few reasons for that decision. As it turned out the conciseness of the text didn’t allow us to adequately make our points so that they were not misunderstood. We are interested in a discussion but our opinion about the suitability and usability of GWT has still not changed.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"HAML","id":"9124","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Heroku","id":"9128","quadrant":"platforms","ring":"Trial","movement":"t","radius":"","description":"Heroku is a beautifully simple Platform as a Service (PaaS) for Rack-compatible frameworks such as Ruby on Rails. In contrast to similar offerings for other languages, which often limit development to a programming model specific to the service platform, Heroku uses the standard Rails stack and even allows deployment with a plain Git push. Heroku was recently acquired by Salesforce.com and so has significant backing behind their service.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"HTML 5","id":"521521","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radius":"","description":"HTML 5 continues to be the preferred choice for developing complex Web-based applications, with features including improved integration of rich audio and video content, clientside storage, better document structure, Web sockets and offline use. Safari, Chrome, Firefox and Opera each support significant subsets of the proposed standards, with support coming in Internet Explorer 9. HTML 5 is likely to remain in draft for some time to come, however; early adopters may wish to reflect on the bleakly comedic saga of two separate groups attempting to drive its evolution.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Infrastructure as code","id":"9142","quadrant":"tools","ring":"Adopt","movement":"t","radius":"","description":"The large number of hosts and devices in a modern datacenter or cloud deployment have made manually installing and configuring infrastructure unwise. Infrastructure as code is an approach whereby infrastructure configuration is scripted or described by files that are stored in version control, and changes are pushed out to the datacenter in a controlled manner. This parallels the discipline of source control and build promotion used in software development, hence ‘as code’. The two front-running open source tools for infrastructure automation are Chef and Puppet. They both use a textual DSL to script automation. Using this approach provides consistent and repeatable environment changes, reducing the manual effort involved, especially in troubleshooting environmental differences.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"iPad","id":"9145","quadrant":"platforms","ring":"Trial","movement":"t","radius":"","description":"The iPhone changed the face of the mobile phone. The iPad has the potential to radically alter the way users interact with and consume Web-based resources and applications and will spawn a plethora of similar tablet devices. The addition of wireless application distribution in IOS4 allows organizations to securely host and distribute in-house applications without using the App Store, overcoming one of the main barriers to corporate adoption. IOS4’s introduction of multitasking with applications running in the background has opened up new possibilities for enterprise applications, at the cost of extra battery usage.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Java language end of life","id":"9150","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"The purchase of Sun, and thus their Java assets, by Oracle introduced uncertainty regarding the future of Java. This uncertainty continues despite the recent announcements of Oracle’s Java roadmap, which had both encouraging and worrying aspects. As a result we continue to highlight the issue. We recommend monitoring the situation rather than any immediate actions to move off the platform.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"JavaScript as a first class language","id":"9152","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"JRuby","id":"9244","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radius":"","description":"Functional languages have a wide range of practical uses, including simulation, computational fi nance, computational science, large scale data processing and parsing. These fields benefit from functional programming techniques that simplify concurrent execution and the expression of complex mathematical functions concisely. Functional programming requires a shift in thinking for enterprise developers experienced in object oriented development. Moving to an often terse syntax for solving complex problems may initially be intimidating to many. As with all forms of programming languages, syntax is just one aspect of the language itself. In functional programming another significant aspect is the use of common idioms. These idioms speed code comprehension and increase overall maintainability. This might not be news to all, but it is worth noting that dynamic languages are long ready for adoption and trial. Ruby, particularly when deployed on JRuby, is ready for adoption. Thoughtworks uses Ruby and JRuby extensively in both its Services and Product work. Groovy is ready for trial and could prove more accessible than Ruby/JRuby in a Java shop. For the right type of applications, Ruby, JRuby, and Groovy prove far more effective, expressive, and productive than Java and C#.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"KVM","id":"9161","quadrant":"platforms","ring":"Adopt","movement":"t","radius":"","description":"This platform was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Mercurial","id":"9179","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Message buses without smarts","id":"9180","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Mobile Web","id":"9187","quadrant":"platforms","ring":"Trial","movement":"t","radius":"","description":"Mobile Web was in our Assess category on previous radars, but we’ve moved it into Trial in recognition of the fact that the Web is increasingly consumed through iPhone, Android and tablet devices. Many devices can render a fair approximation of a desktop browser experience, but to present the user with a truly optimal experience we recommend adapting a site to the screen size, display and control behaviors particular to the device. Techniques such as progressive enhancement can allow a single site to adapt to both desktop and mobile browsers. Large format mobile devices, such as the Apple iPad and Amazon Kindle, provide a new model of ubiquitous computing. Their long battery life, simple interfaces and easy connectivity have the potential to change the way we interact with computers. Apple’s new user interfaces discard the familiar desktop metaphors of files and folders that have been standard since the introduction of the Macintosh in 1984.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Next-generation test tools","id":"9192","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Node.js","id":"280","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"NoSQL","id":"9195","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"NoSQL is about scale, massive datasets, cloud data, social network data, data in buckets, data in graphs i.e. a range of use cases for which “traditional” SQL databases may not be the optimal choice. Unravelling NoSQL and trying to explain what it is and why you should or should not be interested in it is difficult as the term covers a wide range of technologies, data architectures and priorities and represents as much a movement or a school of thought as it does any particular technology. Types of NoSQL technologies include key-value, column and object stores as well as document, graph and XML databases.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"OAuth","id":"9197","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"OAuth is a Web-based authorization protocol that allows applications to access a user’s secured resources in another application without the user having to share their private security credentials. Now an RFC, OAuth represents a significant standards-based attempt to improve privacy and security for Web browser and machine-based access to distributed Web resources. Library support is patchy and adopters can expect to spend some time wrangling their code to achieve true interoperability. OAuth 2.0 is due towards the end of 2010, with specific flows for Web applications, desktop applications, mobile phones, and household devices. Because OAuth 2.0 is not backwardly compatible with version 1 and the implementation challenges around the current version, OAuth is still in the assess ring.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"OpenStack","id":"604","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Platform roadmaps","id":"9211","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Progressive Enhancement","id":"9221","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"RDF triple stores","id":"92281","quadrant":"tools","ring":"Assess","movement":"c","radius":"","description":"While we are bullish on RDFa, we remain highly guarded on native RDF triple stores as a persistence mechanism. The leading available triple stores vary greatly in their capabilities, capacity, and performance characteristics. If you are exploring the use of a triple store, you must do extensive testing to make sure the triple store fits your needs.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"RDFa","id":"9228","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"RDFa, a mechanism for attaching meaningful vocabularies to HTML content that is being quickly and widely adopted by content providers, is the first mainstream success to arise from the Semantic Web stack. RDFa enables tools ranging from custom point integrations to Google spiders to more richly understand your Web content. If you would like to quickly open up your content to a multitude of integration possibilities in a simple, cheap, standards-based fashion, we recommend you try RDFa.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Real-time business intelligence","id":"9232","quadrant":"techniques","ring":"Assess","movement":"c","radius":"","description":"Business are running 24x7, but the information needed to make business decisions is being provided by outdated methods using ETL jobs in batch mode. The batch window is shrinking as businesses move to global markets and are open for longer durations. The data provided by these jobs is out of date by the time the business needs to make a decision. There is substantial value in taking the event as it happens in the transactional system and feeding it to the data warehouse so that the business can get near real-time business intelligence.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Restfulie","id":"9238","quadrant":"tools","ring":"Assess","movement":"c","radius":"","description":"The hypermedia constraint from REST is now understood as critical in sharing business protocols over the Web. Unfortunately many frameworks for building computer to- computer systems on the Web are ignorant of this constraint and tend towards simple CRUD systems. Restfulie is the first of a new generation of frameworks that natively support hypermedia, for Ruby, Java, and .NET. In Restfulie, business protocols are implemented using DSLs and exposed across the Web through hypermedia representations; clients drive those protocols through a similar declarative mechanism, consuming server-generated representations as they work towards a business goal. As the fi rst framework of its kind, Restfulie is opinionated and provides strict “training wheels” in order to bootstrap newcomers. However, it is an empirical proof that the Web and hypermedia can be used to orchestrate complex business activities.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"RIA","id":"9239","quadrant":"platforms","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Ruby","id":"9243","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radius":"","description":"This language/framework was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"SASS, SCSS, and LESS","id":"9247","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Scala","id":"257","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Scrum certification","id":"9251","quadrant":"techniques","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Service choreography","id":"9255","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"Integrated business processes now routinely span multiple systems and even enterprises. This raises the question of how these processes should be coordinated. In our experience centralized orchestration solutions often fail to deliver the promised benefits. They are costly to implement, and because they maintain application state on behalf of many consumers, they are often difficult to scale. This has lead us to prefer service choreography, where independently distributed participants collaborate according to an application protocol. Using the Web as platform, hypermedia-driven application protocols allow us to implement integrated business processes that are easy to evolve and easy to scale.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Smart Systems","id":"9262","quadrant":"techniques","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Splunk","id":"9266","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Squid","id":"9267","quadrant":"tools","ring":"Adopt","movement":"c","radius":"","description":"This tool was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Subversion","id":"9268","quadrant":"tools","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Vagrant","id":"9282","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"vFabric","id":"9285","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Visualization and metrics","id":"9286","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"Evolutionary and emergent design of enterprise systems requires significant vigilance by development and architecture teams. Collecting metrics to capture development trends is a key part of understanding the stress points for a system under development. Assessing this information in its raw form is even more difficult than taking stock of a system at the source code level. To address this concern we have found a number of visualization tools and techniques to get what we refer to as the 1000ft view of the system and its internal quality. This 1000ft view allows us to identify visual patterns that help find and address issues more quickly.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"WCF HTTP","id":"9289","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"Microsoft’s WCF HTTP API, though currently in the early stages of development, is evolving rapidly, and we’re already impressed by its support for HTTP primitives as well as idioms such as content negotiation and conditional requests. The API encourages the development of highly testable solutions with a clear separation of concerns. What is of particular interest to us is the way in which the project is being developed in Codeplex’s open source community. The ability for the community to steer the development of this part of the .NET platform merits this project’s early inclusion in the radar. While the license does allow for using the library in production today, given the current volatility of the API, we caution against taking a dependency at this early stage; many of the features we’ve admired in recent releases, such as its use of an attributelight programming model based on convention over configuration, may not make it into the first version.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"Web as platform","id":"9290","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"Our understanding of the Web has matured to the point where we believe it is a viable platform for building distributed systems. RESTful techniques have advanced past pretty URIs + JSON towards hypermedia systems that project business protocols over the Internet and support seamless business process and service composition. The Web provides a powerful capability for scale, resiliency, and ease of implementation with commodity infrastructure like caches and Web servers with commodity protocols (like HTTP, AtomPub, and OAuth). Moving from trial to adopt is indicative of our position that the Web is ready for primetime, not just for Internet-facing systems but as a practical base for enterprise systems delivery.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-01"},{"name":"WS-* beyond basic profile","id":"234","quadrant":"platforms","ring":"Hold","movement":"c","radius":"","description":"Web services are now widely used as an enabler for service oriented architectures as well as for the integration of existing applications. We see mature tools and largely interoperable implementations for web service standards covered by WS-I Basic Profile, but we remain skeptical about the proliferation and value of WS-* standards beyond Basic Profile.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2011-01"}],"date":"2011-01"},{"blips":[{"name":"Acceptance test of journeys","id":"9001","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"API management services","id":"9011","quadrant":"tools","ring":"Assess","movement":"c","radius":"","description":"Exposing APIs to a large developer community creates nonfunctional requirements that are often the same from one business to another. Key management, authentication, access control, traffic management, caching, tracking and reporting are often implemented as commodity functions that can be reused across applications and businesses without modification. Some service providers have spotted this trend and are offering API management via software as a service. Prominent vendors in this space include Mashery and Apigee, who both offer the option of hosting the service on a customer’s own infrastructure. API management services may also be interesting to enterprise customers who are using Web as platform techniques for their internal SOA, providing a lighter weight alternative to traditional SOA management tools.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"ATOM","id":"9018","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Automate database deployment","id":"9019","quadrant":"techniques","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"AWS","id":"9022","quadrant":"platforms","ring":"Adopt","movement":"t","radius":"","description":"Amazon continues to evolve the AWS cloud with services such as RDB, making it even easier to engineer and deploy cloud-based applications. Not every AWS feature is as mature as EC2 and S3, so you should carefully evaluate which AWS components to use. We feel comfortable recommending AWS where elasticity or on-demand computing are required.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Backbone.js","id":"304","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"Even though JavaScript increasingly plays a more important role in today’s world of software development, it is still troublesome to organize in a clean structure. Backbone.js is a library which provides an MVC (model view controller) framework for JavaScript heavy applications. It allows developers to write JavaScript code in a more manageable and testable way.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Build your own radar","id":"9030","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Caching reverse proxies","id":"9033","quadrant":"tools","ring":"Adopt","movement":"t","radius":"","description":"Application designs that incorporate caching reverse proxies as first class design elements are simpler and more resilient to infrastructure failures. Placing a caching reverse proxy between an application and a web service it consumes reduces the risk of service failures affecting the application while improving overall system performance.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Capability modeling","id":"9035","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"Initiatives that span multiple projects require shared understanding of the business context, operating model, and strategic goals of an organization, as well as any existing technical, organizational and process constraints impinging on planning and design activities. As part of our evolutionary approach to enterprise architecture, we use business capability modelling to create lightweight hierarchical models of the business functions that are an essential part of an organization’s needs and goals. Capabilities describe an organization’s operating model in terms of goals and competencies (what is to be done), rather than implementation specifics (how things are done). Whereas business architecture models based on people, process or technology are contingent, volatile and often short lived, and therefore ill-suited to the long-term planning needs of the organization, capability models provide a description of the business context that is stable enough to serve as a basis for identifying and prioritising technology and process initiatives.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Categorization \u0026 prioritization of technical debt","id":"9039","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Clojure","id":"258","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radius":"","description":"The functional languages F#, Clojure and Scala still reside in the assess ring of the radar. Interest in functional languages continues to grow. Two characteristics of functional languages in particular are driving this interest, immutability with its implications for parallelism and functions as first class objects. While the introduction of closures to C# brings some of the latter capability, functional languages are almost synonymous with immutability. The placement of these languages within the assess ring indicates our view of their relative maturity and appropriateness. F#, based on OCaml, is fully supported within the Visual Studio toolset. F# includes support for objects and imperative constructs in addition to functional language constructs in a natural way. Scala, like F#, combines the object and functional paradigms, although the syntax of Scala is more Java-like. Clojure began as a JVM language and is now available on the .NET CLR. Clojure does allow for mutable state although it has an extensive set of immutable persistent data structures, all supporting multi-threaded applications. There are many similarities between these three languages, but at the moment we believe F# and Clojure to be better suited to most organizations for assessing than Scala. More work clearly needs to be done to validate this assertion.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Cloud Foundry","id":"9046","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Code in configuration","id":"9048","quadrant":"tools","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Coding architects","id":"9049","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"This technique was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"CoffeeScript","id":"648","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Concurrency abstractions and patterns","id":"9054","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"Concurrency is a difficult problem and increasingly difficult to avoid. Hardware isn’t getting faster but multicore platforms are becoming the norm, with even mobile phones containing two or more processors. Concurrency abstractions and patterns -- which are not new, but less widely known -- are helping address many of the challenges seen in this space. In particular the models seen in Clojure, Erlang, Retlang and Event Patterns offer a more testable and reliable approach than the better known threads, locks and semaphores.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Continuous Delivery (CD)","id":"9057","quadrant":"techniques","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Continuous deployment","id":"9059","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"If you are wondering “What comes after agile?,” you should look towards continuous delivery. While your development processes may be fully optimized, it still might take your organization weeks or months to get a single change into production. Continuous delivery focuses on maximizing automation including infrastructure as code, environment management and deployment automation to ensure your system is always ready for production. It is about tightening your feedback loops and not putting off anything until the end. Continuous delivery is not the same as continuous deployment, which means deploying every change to production. Continuous delivery is not a cowboy show. It puts you in charge of your production environment. The business can pick and choose what and when to deploy. If you think you’ve nailed agile development, but aren’t considering how to achieve continuous delivery, you really haven’t even started.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Cross-platform mobile toolkits","id":"9064","quadrant":"tools","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Database based integration","id":"9068","quadrant":"techniques","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Decision driven BI","id":"9071","quadrant":"techniques","ring":"Assess","movement":"t","radius":"","description":"Traditional approaches to implementing data warehouses and business intelligence work from the bottom up in horizontal tiers, assembling and cleansing data sources from across the enterprise then aggregating them into a comprehensive data mart before reports can be generated. Some people are now employing an alternative approach that starts with the real outcome--a business decision--and pulls work items through the process as needed to support that decision. Decision driven business intelligence allows a more incremental approach to BI and facilitates rapid feedback to the decision makers who are the ultimate consumers of business intelligence.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Deltacloud","id":"9073","quadrant":"tools","ring":"Assess","movement":"c","radius":"","description":"Every Infrastructure as a Service (IaaS) cloud offering provides their own API for performing common tasks. Deltacloud aims to abstract those APIs and provide a RESTful interface for performing common cloud management functions, making it possible to migrate virtual infrastructure between clouds.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"DevOps","id":"9077","quadrant":"techniques","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Domain-Specific Languages","id":"9079","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Emergent design","id":"9086","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"As Agile practices move further toward mainstream adoption, we see significant benefits from the adoption of Lean software development practices as well. These practices have their roots in the Toyota Production System and complement much of our understanding of Agile software development to date. One topic that Lean has also given us greater insight into is that of set-based design. Set-based design leads us to implement similar solutions at the same time while the cost of doing so is constrained. This leads us into the area of emergent design and the ability to let experience shape our design decisions and defer key decisions until the last responsible moment.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"ESB","id":"9088","quadrant":"tools","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Event API’s","id":"9089","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Event driven business intelligence","id":"9090","quadrant":"techniques","ring":"Assess","movement":"t","radius":"","description":"This technique was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Event sourcing","id":"738","quadrant":"techniques","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Evolutionary architecture","id":"9092","quadrant":"techniques","ring":"Adopt","movement":"t","radius":"","description":"In contrast to traditional up-front, heavy-weight enterprise architectural designs, we recommend adopting evolutionary architecture. It provides the benefits of enterprise architecture without the problems caused by trying to accurately predict the future. Instead of guessing how components will be re-used, evolutionary architecture supports adaptability, using proper abstractions, database migrations, test suites, continuous integration and refactoring to harvest re-use as it occurs within a system. The driving technical requirements for a system should be identified early to ensure they are properly handled in subsequent designs and implementations. We advocate delaying decisions to the latest responsible moment, which might in fact be up-front for some decisions.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Evolutionary database","id":"9093","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"F#","id":"9097","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"The functional languages F#, Clojure and Scala still reside in the assess ring of the radar. Interest in functional languages continues to grow. Two characteristics of functional languages in particular are driving this interest, immutability with its implications for parallelism and functions as first class objects. While the introduction of closures to C# brings some of the latter capability, functional languages are almost synonymous with immutability. The placement of these languages within the assess ring indicates our view of their relative maturity and appropriateness. F#, based on OCaml, is fully supported within the Visual Studio toolset. F# includes support for objects and imperative constructs in addition to functional language constructs in a natural way. Scala, like F#, combines the object and functional paradigms, although the syntax of Scala is more Java-like. Clojure began as a JVM language and is now available on the .NET CLR. Clojure does allow for mutable state although it has an extensive set of immutable persistent data structures, all supporting multi-threaded applications. There are many similarities between these three languages, but at the moment we believe F# and Clojure to be better suited to most organizations for assessing than Scala. More work clearly needs to be done to validate this assertion.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Feature branching","id":"9100","quadrant":"techniques","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Future of Java","id":"9107","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"This language/framework was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Git","id":"9110","quadrant":"tools","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Github","id":"9111","quadrant":"tools","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"GPGPU","id":"9116","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Gradle","id":"315","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"Gradle is an attempt to bring sanity to the enterprise build space by marrying best-of-breed tools with cutting edge techniques. Gradle allows you to interact with your existing Maven repositories, but adds scriptability to your builds with a clean domain specific language.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"GWT","id":"9122","quadrant":"platforms","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"HAML","id":"9124","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radius":"","description":"HAML is a language that allows you to use indentation to lay out the structure of HTML. While not a general replacement for HTML, it is effective for focusing on the hierarchical structure of tags.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Heroku","id":"9128","quadrant":"platforms","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"HTML 5","id":"521521","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Infrastructure as code","id":"9142","quadrant":"tools","ring":"Adopt","movement":"c","radius":"","description":"The DevOps movement continues to grow, with developers and operations staff working closely together to solve the “software last mile” problem. Infrastructure as code is a technique for treating infrastructure configuration in the same way as code; checking it into source control, then using it to push changes out to the data center. In addition to web server, application server and application configuration, we are seeing network configuration treated in the same way. Network switch, firewall and load balancer configuration can be infrastructure as code, and even changed at runtime.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Iterative data warehousing","id":"9141","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"Like iterative software development, there is lot of value to be gained by delivering data warehousing projects using iterative techniques. Iterative data warehousing techniques allow the end users of the data warehouse to determine what reports they want and the ETL developers and data modelers to deliver those features without wasting time with data modeling and ETL jobs that do not provide immediate value to the business.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Java portal servers","id":"9151","quadrant":"platforms","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"JavaScript as a first class language","id":"9152","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radius":"","description":"The maintainability, testability and readability of JavaScript is a very significant contributor to the productivity of teams producing Web-based applications and sites. Thoughtworks believes JavaScript deserves to be treated as a first class language, viewing it as second class citizen has become an excuse for a whole series of bad practice we would not tolerate in Java or C#. We need to use the same kind of tools (e.g. unit testing) and approaches (e.g. refactoring) as we’d use for any other production language. V8 and other JavaScript engines are raising the bar on performance, while Flash \u0026 Silverlight seem to be losing momentum to HTML5 + JavaScript in areas where a rich client-like experience is required. This is good news for all interested in open standards on the Web.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"jQuery Mobile","id":"9158","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"JRuby","id":"9244","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"Charles Nutter and the JRuby team continue to improve JRuby at a frantic pace. It is fast and they place massive importance on keeping their ecosystem up-to-date, including DB adapters, gem management, and modern Rails deployment. Rails 3 + JRuby is an awesome platform. There really is no reason to not be using Ruby, one of our favorite languages, in the enterprise.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"KVM","id":"9161","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"This platform was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Logic in stored procedures","id":"314","quadrant":"languages-and-frameworks","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Manual infrastructure management","id":"9176","quadrant":"techniques","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Mercurial","id":"9179","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"In previous radars we recommended Distributed Version Control (DVCS) tools in general while mentioning Git and Mercurial in particular. In this edition we narrow our recommendation to only Mercurial and Git as these two have become the clear front-runners. Due to its success and the associated network effect GitHub remains the recommended option for enterprises that want to interact with the open source community.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Message buses without smarts","id":"9180","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Mobile web","id":"9187","quadrant":"platforms","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"New Relic beyond Rails","id":"9191","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"We have regularly used New Relic hosted performance monitoring with Ruby on Rails systems in development and production. The combination of fast setup and comprehensive reporting has proven extremely valuable in troubleshooting performance. We are now seeing good results from the New Relic monitoring services for Java and .NET systems.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Next-generation test tools","id":"9192","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"The Ruby language community is responsible for a number of innovations in the area of testing. The next generation of testing tools such as rspec and Cucumber are two such tools that have come out of this community. These tools, along with Thoughtworks’ Twist, provide a way to express tests in a more natural language syntax that captures the intent of the system in a way that end users can quickly grasp.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Node.js","id":"280","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"NoSQL","id":"9195","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"NoSQL technologies are maturing daily, allowing for innovative solutions as businesses need to scale massively or ask intelligent questions of existing data. Technologies like MongoDB, Riak, Neo4J, Cassandra and many others are helping power the NoSQL space.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"OAuth","id":"9197","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"OAuth is a web-friendly, lightweight standard for authorization that allows a user to share private resources between internet services, e.g., allowing your favorite social networking site to access your photos from your favorite photo sharing site. OAuth is simple, avoids password proliferation, and allows a service to grant bare minimum privileges. If you are exposing your application’s data in a lightweight, web-friendly manner you should strongly consider using OAuth as your standard for authorization.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Offline mobile webapps (just HTML5)","id":"521","quadrant":"platforms","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Open source BI/ETL tools","id":"9201","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"OpenStack","id":"604","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"OpenStack is a new cloud operating system that promises a complete open-source solution. OpenStack is a fabric cloud controller which leverages existing virtualization technologies such as KVM and will integrate with other virtualisation tools such as Xen and OpenVZ. Currently under heavy development, OpenStack is expected to provide a stable production-ready solution by the end of Q2 2011.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Platform roadmaps","id":"9211","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"Almost every enterprise has “legacy systems” that are expensive to operate and upgrade. Often a system will become legacy over the course of several years, through neglect or atrophy. We recommend using platform roadmaps to maximize the value of a systems portfolio and plan for the upgrade and eventual retirement of systems.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Powershell","id":"9217","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Procedure oriented integration","id":"9219","quadrant":"techniques","ring":"Hold","movement":"t","radius":"","description":"One of the goals of SOA has been to decouple services by exchanging human-readable business documents instead of programming parameters. However, in implementing SOA, many businesses have simply used web services to expose the underlying programming models of back-end systems. Procedure oriented integration is nothing more than remote procedure calls implemented via a different protocol. The consequences of this are additional layers of complexity with no improvement in business flexibility. To avoid this, implementers of SOA should first understand the business meaning of their services, then implement human-readable contracts that are independent of legacy system implementation.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Progressive Enhancement","id":"9221","quadrant":"techniques","ring":"Adopt","movement":"t","radius":"","description":"Recent use of progressive enhancement with mobile applications has been very effective and demonstrates the universal nature of this web design strategy. We encourage people to adopt this strategy to keep their code clean and give each user the optimal experience for their device.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"SASS, SCSS, and LESS","id":"9247","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Scala","id":"257","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Scrum certification","id":"9251","quadrant":"techniques","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Selenium 2 testing of mobile websites","id":"9252","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"When building mobile web applications we can now use Selenium 2 mobile tests to run the same acceptance tests on iOS, Android and Blackberry. This works on emulators, simulators and physical devices. We have successfully used this approach on production software for all 3 platforms. While the Blackberry driver is still in beta, we found it stable enough for use. The key challenge is the different ways to install the driver and start the browser, but this only needs to be solved once. We suggest that companies doing mobile web for these devices try this approach. We see no reason why this approach cannot be extended to Windows Phone in the future.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Simple performance trending","id":"9257","quadrant":"techniques","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Smart systems","id":"9262","quadrant":"techniques","ring":"Assess","movement":"c","radius":"","description":"Smart Phones with a GPS, cameras and a screen are but one example of smart systems which are proliferating around us, fusing the real and the digital world. Augmented reality apps like Google Goggles, geolocation services \u0026 smart grids are just some of the possible applications.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Sonar","id":"9265","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Splunk","id":"9266","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"Application logs are both a blessing and a curse. They are comforting to have when a production issue arises, but actually digging out the data we need usually requires cobbling together scripts written in tools such as AWK and sed. Splunk is an elegant solution that quickly analyzes many standard log file formats like IIS, Log4J and syslog, and is extensible to custom formats. It indexes files, statically or in real time, to generate canned or custom reports. If the raw log fields do not provide what you need, simply use a regular expression, either inline or to define a new field, to get the desired level of detail. Splunk’s full power is difficult to describe, so we recommend downloading and trying it.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Subversion","id":"9268","quadrant":"tools","ring":"Adopt","movement":"c","radius":"","description":"Subversion moves back into the Adopt section of the radar because it is a solid version control tool suitable for most teams. We consider Subversion’s features to be the basic standard for a modern version control tool. Thoughtworkers continue to embrace and recommend Distributed Version Control tools such as Git and Mercurial, but we caution that these systems often require deeper understanding to get the most out of them. New to the radar is GitHub, a “social coding” tool supporting both source code hosting and social networking. GitHub is arguably one of the main reasons Git has become the leading DVCS tool, and GitHub’s collaboration features are often used by enterprises that need to support distributed teams.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Tablet (formerly iPad)","id":"9145","quadrant":"platforms","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Thoughtful caching","id":"9275","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"TLB","id":"9276","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"If your test suites are growing slower and you have already verified that it is not a serious problem with your application, first make your tests faster, then look at parallelization. The Test Load Balancer (TLB) project is a big development in the world of parallel test execution. It removes the inefficiencies of manual work distribution using smart algorithms and historical test execution data to optimize workload distribution and minimize elapsed time. Further, it orders the tests in intelligent ways like executing the test that failed in the previous execution first to get quicker feedback. Parallel execution can occur across a grid of machines or across multiple processes on a single machine. JUnit, RSpec, Test::Unit, Twist and Cucumber are currently supported and NUnit is under development.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Ubiquitous computing","id":"9279","quadrant":"platforms","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Vagrant","id":"9282","quadrant":"tools","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"VCS with “implicit workflow”","id":"9283","quadrant":"tools","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"vFabric","id":"9285","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"Visualization and metrics","id":"9286","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"Data visualizations have been effective in business and IT decision making. Organizations are making effective use of real time data through visualizations. These visualizations include point in time data as well as trends plotted over time. We are seeing increased adoption of these techniques in optimizing operations and software development.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2011-07"},{"name":"WS-*","id":"234","quadrant":"platforms","ring":"Hold","movement":"t","radius":"","description":"Previously our advice has been to tread carefully when using the WS-* stack beyond the basic profile. Given the progress and acceptance of simpler web-as-platform techniques such as REST and OAuth and the known issues with the WS-*, it should only be used cautiously.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2011-07"}],"date":"2011-07"},{"blips":[{"name":"Acceptance test of journeys","id":"9001","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"Many teams focus acceptance testing at the story level, but this can lead to a large number of hard to maintain tests, and a focus on completing individual stories instead of coherent functionality needed to go live. A more holistic approach is to group user stories into journeys for which we create acceptance tests. Journeys through a system are a set of user interactions that provide value for both users and the business. At the outset a journey acceptance test will cover only one step, but as stories are completed the journey is expanded to encompass each stage in the user’s progress. Once the acceptance test of journeys passes, this tells us we have delivered real value.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Agile analytics","id":"9004","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"AppHarbor","id":"9014","quadrant":"platforms","ring":"Trial","movement":"t","radius":"","description":"AppHarbor is a Platform as a Service (PaaS) offering for the .NET Platform using the same pricing model and structure pioneered by Heroku. It is a promising take on the deployment of .NET applications as it abstracts away most of the underlying configuration needs that come with the platform. It is maturing quickly and we expect it will see growing interest in time to come.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"ATOM","id":"9018","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Automate database deployment","id":"9019","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"If the rate at which business is changing is an indicator of change in requirements, then the days of doing upfront database design are gone. Instead, projects should follow evolutionary database techniques and continue to change their database schemas as new requirements are implemented over the course of the project. Deployment of database changes should also be automated so that the application release that relies on those changes does not have to wait for manual deployment of the database changes. Automated database deployment ensures that application and database changes can be deployed automatically. Evolutionary database and automated database deployments ensure highly productive teams a path to continuous delivery.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"AWS","id":"9022","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"While it can be all too easy to ignore geographical location of cloud-based services, for legal and technical reasons it can be a serious constraint when considering appropriate platforms. With the recently announced Brazil and Singapore regions, Amazon has made AWSbased systems more viable for people in areas previously poorly served by IaaS providers. In addition, they continue to add features to existing services, such as VPC. We remain confident in recommending AWS for those situations where flexibility in provisioning resources is key.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Build your own radar","id":"9030","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"Building your own technology radar helps you decide, normalize, and publicize consensus technology views for all interested parties. Thoughtworks produces a technology radar for clients and friends, telling the world our opinions about upcoming technology trends. You should do this for your own company as well. Too many decisions in large companies happen in a vacuum, with no input from the technologists who have to live with them every day.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Buying solutions you can only afford one of","id":"9031","quadrant":"platforms","ring":"Hold","movement":"t","radius":"","description":"Many teams encounter problems that are caused by their test environment missing an expensive hardware component that is only present in production. While a pre-production environment in many cases cannot approach the scale of a production environment, all of its components should be present. We recommend not buying solutions you can only afford one of, such as SAN, firewalls or load balancers, as this prevents realistic testing anywhere but in production.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Care about hardware","id":"9037","quadrant":"platforms","ring":"Adopt","movement":"t","radius":"","description":"This platform was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Care about languages","id":"9038","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Categorization \u0026 prioritization of technical debt","id":"9039","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"Technical debt is a powerful and useful metaphor for dealing with the compromises we make when building software. Unfortunately it has become a catch-all term for many different kinds of issues and problems, leading to confusion and “devaluation” of the term. A very useful approach for dealing with this is catagorization of technical debt, assigning value and prioritizing debt payback in an analogous way to user stories. This helps the team focus on the most important areas and keeps issues transparent and measurable.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Client-side MVC","id":"9042","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"This tool was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Clojure","id":"258","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"ClojureScript","id":"478","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Cloud Foundry","id":"9046","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"Cloud Foundry is an open source Platform as a Service that can be deployed in your own data center or hosted by VMWare. At present Cloud Foundry supports Java/ Spring applications, Rails, Sinatra, Grails and Node.js. Additional services include MongoDB, MySQL and Redis. The platform seems to be enjoying active development with the recent addition of Scala and Lift support. Cloud Foundry is an interesting addition to the growing list of PaaS solutions. It is not clear what the relationship between vFabric and Cloud Foundry will be going forward.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Code in configuration","id":"9048","quadrant":"tools","ring":"Hold","movement":"c","radius":"","description":"Many organizations try to minimize change in production IT environments. This frequently leads to behavioral anti-patterns. One example of this is over use of code in configuration to affect the behavior of production systems. Changes that really belong in code end up in configuration files which don’t necessarily pass through the same levels of testing as the application. Streamlining the path to production and focusing on quality simplifies rather than complicate things.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Coding architects","id":"9049","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"This technique was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"CoffeeScript","id":"648","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radius":"","description":"JavaScript is a powerful, ubiquitous programming language with tricky and error prone syntax. Coffeescript fixes many of the warts of JavaScript in a clean, simple syntax that generates readable JavaScript. For example, creating true private variables in JavaScript is a syntactic nightmare; CoffeeScript generates the technically correct but hideous syntax. Some readers may be confused by our advocacy of Coffeescript given our general dislike for GWT, because on the surface they seem similar: tools that generate JavaScript. However, it is the level of abstraction that differs. GWT has an elaborate component model, which tries to hide details about the underlying language (JavaScript) and platform (the web). Coffeescript tries to make it easier to write proper JavaScript, avoiding pathological but default “features” of JavaScript, and does not build a layer that tries to insulate you from the platform.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Communication between those responsible for hardware and software","id":"9052","quadrant":"platforms","ring":"Adopt","movement":"t","radius":"","description":"One of the principal mechanisms that allows agile software development to work is feedback loops. One common yet expensive broken feedback loop we have observed is the lack of communication between those responsible for hardware and software. The end result creates cost but not worth. You must view architecture holistically; neither hardware nor software has a full enough perspective to be successful alone.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Continuous Delivery (CD)","id":"9057","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"If you are wondering “What comes after agile?,” you should look towards continuous delivery. While your development processes may be fully optimized, it still might take your organization weeks or months to get a single change into production. Continuous delivery focuses on maximizing automation including infrastructure as code, environment management and deployment automation to ensure your system is always ready for production. It is about tightening your feedback loops and not putting off anything until the end. Continuous delivery is not the same as continuous deployment, which means deploying every change to production. Continuous delivery is not a cowboy show. It puts you in charge of your production environment. The business can pick and choose what and when to deploy. If you think you’ve nailed agile development, but aren’t considering how to achieve continuous delivery, you really haven’t even started.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Cross-platform mobile toolkits","id":"9064","quadrant":"tools","ring":"Hold","movement":"c","radius":"","description":"With very few exceptions, tools that claimed to create seamless user experiences across Windows, Linux and OSX did not deliver. We ended up with compromised experiences on one or more of the operating systems. Mobile adds complexity to this problem with different hardware form factors and conventions for user interactions. We have made several attempts to use cross platform mobile toolkits on our projects with varying degrees of success. We saw issues like having to create a project for each platform or invoking specific native UI widgets to get things working. For these reasons we have put cross platform mobile toolkits in hold. While this may change in the future, we remain skeptical especially given past experiences on hardware that was far more homogeneous.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Data visualizations of development and operations","id":"9067","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"We have long advocated for both static and dynamic code analysis tools to help glean information about your code base. As the focus of software development broadens because of the Continuous Delivery movement, data visualizations of development and operations with effective, actionable profiling and monitoring should be part of your technical stack as well.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Database based integration","id":"9068","quadrant":"techniques","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"DevOps","id":"9077","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"Improving the interactions and relationship between development and IT operations gives us more effective delivery and production systems that are more stable and maintainable. Creating a DevOps culture requires attention to team organization, work practices, reporting lines, and incentives - leading to joint responsibility for faster and safer delivery. We recommend adopting DevOps because we cannot see any situation where attention in this area will not have a positive benefit.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Domain-Specific Languages","id":"9079","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Domain-specific PaaS","id":"9080","quadrant":"platforms","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Embedded servlet containers","id":"394","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"Embedding a servlet container, such as Jetty, inside a Java application has many advantages over running the application inside a container. Testing is relatively painless because of the simple startup, and the development environment is closer to production. Nasty surprises like mismatched versions of libraries or drivers are eliminated by not sharing across multiple applications. While you will have to manage and monitor multiple Java Virtual Machines in production using this model, we feel the advantages offered by the simplicity and isolation are significant.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Emergent design","id":"9086","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"Emergent design is one of the more advanced aspects of agile engineering practices, and therefore an area of active research \u0026 development. Such architectures should be driven by the underlying technical requirements of the system, rather than speculative planning for a future that may change. We have identified at least two facets of emergent design: the Lean software principle of last responsible moment, which mostly applies to greenfield projects, and finding \u0026 harvesting idiomatic patterns, which is more applicable to existing projects.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"ESB","id":"9088","quadrant":"tools","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Event API’s","id":"9089","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"RESTful APIs have become standard in our industry. A good REST API provides a simple, lightweight means of building customizations and integrations. However, many of the quick, high value integrations we’d like to build require knowing when something happened. Consider building an event API, which, when used in conjunction with a REST API, facilitates simple workflow, notification, and synchronization integrations. These integrations often require no more than 20 or 30 lines of code. Often event APIs take the form of a “web hook” or callback mechanism, but don’t be afraid of using a poll-based Atom style either. An Atom event API scales cheaply and gives the client the power to guarantee delivery.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Event sourcing","id":"738","quadrant":"techniques","ring":"Assess","movement":"c","radius":"","description":"Event sourcing is an approach to thinking about persistent data where the primary record is a log of all events that make updates. A traditional representation of database state can be entirely recreated by reprocessing this event log. Event sourcing’s benefits include strong auditing, creation of historic state, and replaying of events for debugging and analysis. Event sourcing has been around for a while, but we think it is used much less than it should be.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Evolutionary architecture","id":"9092","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"We recommend adopting evolutionary architecture as an alternative to traditional up-front, heavy-weight enterprise architectural designs.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Evolutionary database","id":"9093","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"If the rate at which business is changing is an indicator of change in requirements, then the days of doing upfront database design are gone. Instead, projects should follow evolutionary database techniques and continue to change their database schemas as new requirements are implemented over the course of the project. Deployment of database changes should also be automated so that the application release that relies on those changes does not have to wait for manual deployment of the database changes. Automated database deployment ensures that application and database changes can be deployed automatically. Evolutionary database and automated database deployments ensure highly productive teams a path to continuous delivery.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Experience Design (XD)","id":"9096","quadrant":"techniques","ring":"Assess","movement":"t","radius":"","description":"Experience Design (XD) is an example of ways in which agility must evolve to accommodate real-world constraints. We are always interested in finding innovative ways to incorporate what have traditionally been up-front exercises into practices like Continuous Delivery. XD is a ripe field for study.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"F#","id":"9097","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Feature branching","id":"9100","quadrant":"techniques","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"FPM","id":"9103","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"There are many advantages to using OS-native packages to deploy components and dependencies, however the tools which build native packages for Linux are not trivial. FPM is a useful tool which makes it easy to create RPM, DEB, or Solaris packages with a minimum of fuss.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Frank","id":"407","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Functional Java","id":"9105","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radius":"","description":"Functional programming continues its slow but steady ascent into developer mind share and, increasingly, code bases. New languages like Clojure, Scala, and F# offer great new features. Now libraries such as Functional Java, TotallyLazy and LambdaJ are back porting some functional language capabilities, particularly around higher-order functions and collections, into Java. We like this trend because it previews common capabilities of future languages yet allows developers to stay in their comfort zone.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Future of Java","id":"9107","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"This language/framework was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Git","id":"9110","quadrant":"tools","ring":"Adopt","movement":"c","radius":"","description":"Starting from a challenge posed to the Linux community to stop using commercial version control, Git has proved itself. Git embodies a well architected, high performance implementation of distributed version control. Git is powerful, so it should be used with respect, but that power enables agile engineering workflows that simply cannot exist with other tools. Git’s popularity is supported by the existence of GitHub. GitHub combines public and private Git repositories, social networking, and a host of other innovative tools and approaches.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"GitHub","id":"9111","quadrant":"tools","ring":"Adopt","movement":"c","radius":"","description":"Starting from a challenge posed to the Linux community to stop using commercial version control, Git has proved itself. Git embodies a well architected, high performance implementation of distributed version control. Git is powerful, so it should be used with respect, but that power enables agile engineering workflows that simply cannot exist with other tools. Git’s popularity is supported by the existence of GitHub. GitHub combines public and private Git repositories, social networking, and a host of other innovative tools and approaches.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Google Dart","id":"9114","quadrant":"languages-and-frameworks","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"GPGPU","id":"9116","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"The use of GPUs for computing offers efficiencies and performance for certain classes of problems that would be prohibitively expensive for more traditional hardware. Problems that fit Single Instruction Multiple Data (SIMD) processing models can gain significant advantages at the cost of difficult learning curves using specialized APIs. OpenCL, CUDA from NVidia and DirectCompute from Microsoft offer developers access to General-purpose computing on graphics processing units (GPGPU).","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Gradle","id":"315","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"This tool was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"GWT","id":"9122","quadrant":"platforms","ring":"Hold","movement":"c","radius":"","description":"GWT is a reasonable implementation of a poor architectural choice. GWT attempts to hide many of the details of the web as a platform by creating desktop metaphors in Java and generating JavaScript code to implement them. First, in many ways, JavaScript is more powerful and expressive than Java, so we suspect that the generation is going in the wrong direction. Secondly, it is impossible to hide a complex abstraction difference like that from event-driven desktop to stateless-web without leaky abstraction headaches eventually popping up. Third, it suffers from the same shortcomings of many elaborate frameworks, where building simple, aligned applications is quick and easy, building more sophisticated but not supported functionality is possible but difficult, and building the level of sophistication required by any non-trivial application becomes either impossible or so difficult it isn’t reasonable.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Health check pages","id":"9126","quadrant":"techniques","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Heroku","id":"9128","quadrant":"platforms","ring":"Trial","movement":"c","radius":"","description":"Heroku is a beautifully simple Platform as a Service (PaaS). Although Heroku began as a Ruby on Rails platform, it is evolving to support a variety of languages and web frameworks, most recently Clojure. Heroku uses a standard stack and deploys applications with a simple Git push. Heroku’s recent acquisition by Salesforce.com has not diminished its service quality.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"HTML 5","id":"521521","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radius":"","description":"While HTML5 is an evolving standard, many elements have reached the stage where they can be safely used in production to create both on and offline mobile web applications. Based on our projects we think HTML5 is ready to be adopted for mobile web applications. As the standard continues to evolve we expect HTML5 will become an increasingly viable alternative to native applications with the distinct advantage of being inherently cross platform.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Hybrid clouds","id":"9134","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"Hybrid clouds describe a set of patterns that combine the best features of public clouds and private data centers. They allow applications to run in a private data center during normal periods then use rented space in a public cloud for overflow capacity during peak traffic periods. Another way to combine public and private clouds in an agile way is to use the elasticity and malleability of public clouds for developing and understanding an application’s production characteristics, then moving it into permanent infrastructure in a private data center when it is stable.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Infrastructure as code","id":"9142","quadrant":"tools","ring":"Adopt","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Infrastructure automation of development workstations","id":"9143","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Jade","id":"9148","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"This tool was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Java portal servers","id":"9151","quadrant":"platforms","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"JavaScript as a first class language","id":"9152","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radius":"","description":"Rich experiences delivered via the web to desktops, tablets and mobile devices rely heavily on JavaScript, and we continue to recommend treating JavaScript as a “first class” language within your application. Developers should carefully consider how they structure, test, refactor and maintain JavaScript code, applying the same rigor as they would with any other programming language.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"JavaScript micro frameworks","id":"9154","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"JavaScript tooling","id":"9156","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"JavaScript is now established as a powerful, mainstream language that can be used in a variety environments both on client and server sides. As JavaScript codebases expand, more JavaScript tooling support becomes necessary, especially in the continuous integration and testing spaces. Tools like Backbone.js, SpineJS, JavaScriptMVC, Jasmine, JSTestDriver and HRcov are coming to the forefront. They are created by a vibrant community that continues to grow.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"jQuery Mobile","id":"9158","quadrant":"tools","ring":"Assess","movement":"c","radius":"","description":"Thoughtworks has used jQuery Mobile on two projects with mobile websites and had mixed experiences. One project found the library very useful for dealing with device differences and graceful degradation on older browsers. On this project we were working in a way that fit with the jQuery Mobile approach. Our other project found the tool less useful and felt to some extent it was trying to force them to work a particular way that did not fit their application well. For these reasons we have decided to leave this tool in assess. If you are doing mobile web it is definitely worth spiking but it may not fit every application.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"KVM","id":"9161","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"This platform was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Linux containers","id":"9166","quadrant":"platforms","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Log aggregation \u0026 indexing","id":"9169","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"This tool was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Logic in stored procedures","id":"314","quadrant":"languages-and-frameworks","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"4","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Logic-free markup","id":"9171","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Manual infrastructure management","id":"9176","quadrant":"techniques","ring":"Hold","movement":"c","radius":"","description":"Despite advances in automation, many people fall back on manual infrastructure management. We often see problems caused by manual configuration of firewalls and load balancers, and especially by DBAs cutting and pasting SQL scripts to run against production databases. All of these activities, if not fully automated, should at least be scripted and repeatable across environments.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Maven","id":"419","quadrant":"tools","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Mechanical sympathy","id":"9178","quadrant":"techniques","ring":"Assess","movement":"t","radius":"","description":"There is a worrying trend that developers are becoming too distant from the hardware on which their code runs. Increasing virtualization and separation between development and operations makes this worse. In stark contrast some teams are writing code that leverages mechanical sympathy to get incredibly high performance from their software. The LMAX Disruptor is an open-source example in Java. For high performance cases like finance and Big data, getting closer to the metal can yield big returns.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Message buses without smarts","id":"9180","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"In contrast we have seen considerable success with Simple Message Buses where the integration problems are solved at the end points, rather than inside a vendor ESB system. The most well known Simple Message Bus approach is one based on the principles of REST and leveraging the proven scalability of the web. However organizations that have already invested in ESB infrastructure can leverage the useful parts of that infrastructure (reliable messaging etc) while still using a Simple Message Bus approach and performing integrations at the edges of the system.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Microservices","id":"395","quadrant":"techniques","ring":"Assess","movement":"t","radius":"","description":"Microservices, often deployed out-of-container or using an embedded HTTP server, are a move away from traditional large technical services. This approach trades benefits such as maintainability for additional operational complexity. These drawbacks are typically addressed using infrastructure automation and continuous deployment techniques. On balance, microservices are an effective way of managing technical debt and handling different scaling characteristics especially when deployed in a service oriented architecture built around business capabilities.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Mobile web","id":"9187","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"Mobile web was in our trial ring on previous radars, but we’ve moved it into adopt in recognition of the fact we have created many mobile web applications. We believe this is the right way to create web content for mobile devices.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Node.js","id":"280","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"NuGet","id":"416","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Offline mobile webapps (just HTML5)","id":"521","quadrant":"platforms","ring":"Trial","movement":"c","radius":"","description":"HTML5 includes features that allow control and storage of offline data within the browser using client side JavaScript. These features allows creation of offline mobile web applications in a cross platform way that would have previously required installed applications. For instance an application that can download articles for reading later or a data capture application that can work offline and upload when you are online. While the standard is not finalized yet, support for these offline features is available and ready for use in the WebKit based browsers found on iOS, Android and newer Blackberry phones.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Open source BI/ETL tools","id":"9201","quadrant":"tools","ring":"Assess","movement":"c","radius":"","description":"Open source BI tools such as Pentaho, JasperSoft, CloverETL, Talend, BIRT and SpagoBI are matching features with the proprietary tools and allowing for easy entry into the BI space. We recommend that you assess them.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"OpenSocial","id":"9203","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"OpenSocial is a specification that provides a standard way to share content between semi-trusted applications. While initially proposed for public facing social networking sites, it has possibly more potential within the corporate firewall, where the benefits of being able to share data and content between applications in a standard manner frequently outweigh the requirements of scale and security.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Out-of-container functional testing","id":"9205","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Performance testing as a first-class citizen","id":"390","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Polyglot Persistence","id":"9214","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"PowerShell","id":"9217","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"Powershell is as important tool for managing Windows servers and applications. Built into Windows 2008 and Windows 7, Powershell allows Unix-like scripting and automation across a server farm. Scripts can be executed on remote machines, and a single command can manage hundreds of machines at once. Powershell scripts can deploy and configure applications and operating system components, and can be extended by writing .NET “commandlets.”","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Private Clouds","id":"691","quadrant":"platforms","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Production immune system","id":"9220","quadrant":"techniques","ring":"Assess","movement":"t","radius":"","description":"Continuous Delivery techniques are shortening the “last mile” to get changes into production, allowing more frequent feature releases. A production immune system tracks changes as they are put into production, and automatically rolls back changes that have a negative effect on key metrics, such as revenue. Solid metrics, as well as automated A/B deployment, are required for this kind of aggressive rollback to be successful.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"PSake","id":"406","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"RIA","id":"9239","quadrant":"platforms","ring":"Hold","movement":"t","radius":"","description":"We have long been less than enthusiastic about RIA technologies such as Flash and Silverlight because of vendor lock in potential, anemic support for agile engineering practices, and potential for overuse. It seems even the large vendors are starting to agree with us. Now that modern versions of HTML handle most of the common cases that formerly required RIA, we feel that new projects must have enormous justification and careful strategic thought before using any of these technologies.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Riak","id":"418","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"Riak is a distributed key-value store that is schemaless and data-type agnostic. It can be put to good use in write heavy projects to store data such as sessions, shopping carts and streaming logs. The ability of the distributed cluster to self recover, distribute data across the cluster with tunable consistency and availability settings, do collision detection and resolve those if needed can be helpful in high availability environments and provide interesting solutions in the architecture.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"SASS, SCSS, and LESS","id":"9247","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Scala","id":"257","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Scrum certification","id":"9251","quadrant":"techniques","ring":"Hold","movement":"c","radius":"","description":"Scrum was one of the founding approaches to Agile software development, and continues to provide a worthwhile core for the management side of software development. Scrum Certification schemes have proven counterproductive, granting only a veneer of competence, which often misleads teams into a distorted experience of agility.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Server / application container end-of-life","id":"9254","quadrant":"techniques","ring":"Hold","movement":"t","radius":"","description":"A decade ago when memory was at a premium, application servers made a lot of sense. They were popular and useful as a mechanism to run and manage multiple applications on a shared server or cluster. These days applications are more often run on separate physical or virtual servers and the need for an application server is reduced. Consider evaluating server / application container end-of-life within your organization, and only use one if you benefit from the added complexity.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Simple performance trending","id":"9257","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"Starting performance tests late in a project is risky and costly. Very simple performance tests that exercise key parts of the system, run on a regular basis, are good enough to track trends, so we can react if we see a change in performance. Run these tests with your build or as an overnight job and graph the results to create simple performance trending. Complex performance tests in a truly representative environment are still useful, but don’t wait for them to start understanding how the performance of your code is changing.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Single command deploy","id":"9259","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"A key step in the Continuous Delivery process is the ability to release software arbitrarily close to when the business wants it. The ability to do single command deploy relies on a complete set of activities that fall under the umbrella of Continuous Delivery including extensive automation of everything from build/test to scripted environment provisioning and deployment. We have found that adopting this as a goal tends to drive the automation and testing pre-requisites upstream into the rest of your organization.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Single threaded servers with asynchronous I/O","id":"9260","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Sonar","id":"9265","quadrant":"tools","ring":"Assess","movement":"c","radius":"","description":"Measuring software internal quality is still a mystery, even though many source code metrics have been around for years. The problem with those metrics is they usually only capture one aspect of quality. We must consult many metrics to come to a conclusion about the overall quality of our code. Sonar is an integrated tool for checking, tracking and visualizing those metrics. It not only combines metrics together, but also mixes them with historical measures, giving us a better insight into the internal quality of the codebase.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Tablet","id":"9145","quadrant":"platforms","ring":"Trial","movement":"c","radius":"","description":"Tablet devices provide a new model of computing. The next generation of tablets show the potential for new interaction paradigms, and we expect interest and innovation to continue to escalate.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Test at the appropriate level","id":"9271","quadrant":"techniques","ring":"Adopt","movement":"t","radius":"","description":"The advent of behavior-driven design (BDD) testing frameworks like Cucumber, combined with browser automation tools like Selenium, has encouraged widespread use of acceptance testing at the browser level. This unfortunately encouraged doing the bulk of testing where the cost to run the tests is the greatest. Instead, we should test at the appropriate level, as close to the code as possible, so that tests can be run with maximum efficiency. Browser-level tests should be the icing on the cake, supported by acceptance and unit tests executed at appropriate layers.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Test recorders","id":"9272","quadrant":"techniques","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Thoughtful caching","id":"9275","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"All too often caching is an afterthought used to address performance problems with a blanket approach and common cache lifetime. This leads to issues and workarounds. The “time value” of information is inherently linked to the business purpose and hence needs to be captured at the same time as other requirements. We believe thoughtful caching should be addressed early in the project and not just treated as a last minute performance fix.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Treating VMs like physical infrastructure","id":"9277","quadrant":"platforms","ring":"Hold","movement":"t","radius":"","description":"While virtualization is on the rise, some organizations are treating virtual machines like physical infrastructure. We frown on doing a full operating system install for each VM or using VMs for load testing. Virtual machines can be cloned, snapshotted, and manipulated in ways physical machines cannot, and also have vastly different performance characteristics than physical hardware. VMs should be used with full understanding of their benefits and limitations, otherwise you can really get into trouble with them.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Ubiquitous computing","id":"9279","quadrant":"platforms","ring":"Trial","movement":"c","radius":"","description":"Ubiquitous computing is tricky term as it covers many different ideas. What we find interesting and exciting at the moment is that both consumer and specialist mobile devices are increasingly based on commodity operating systems such as Android or iOS. This means that in many cases, software can be developed by organizations themselves, opening the door to innovative new applications without requiring expensive niche skills. Lower price points for the hardware also make this area more accessible, especially with peripherals like payment card readers, PIN key pads and high quality bar code scanners becoming available for both Android and iOS devices. When combined with features already available on these consumer devices, whole new ways of working open up.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Vagrant","id":"9282","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"VCS with “implicit workflow”","id":"9283","quadrant":"tools","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"vFabric","id":"9285","quadrant":"platforms","ring":"Assess","movement":"c","radius":"","description":"vFabric is a new Platform as a Service (PaaS) offering from VMWare. Based on enhanced versions of opensource web and messaging platforms Tomcat, Apache, and RabbitMQ, vFabric aims to deliver a Java based PaaS on a variety of cloud platforms. Currently supported platforms include VMForce, a collaboration between VMWare and force.com, Google App Engine and Amazon EC2. The addition of the GemFire in-memory distributed data management platform and Hyperic monitoring and management tool make vFabric an interesting set of technologies for Java developers looking to move to the cloud.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Windows infrastructure automation","id":"401","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Windows Phone 7","id":"9292","quadrant":"platforms","ring":"Trial","movement":"t","radius":"","description":"Windows Phone 7 has surprised even some of the long time critics of Windows platforms. After many failed attempts, Microsoft has managed not only to produce a mobile operating system that provides a user experience on par with the other major contenders in the space but also the development support to go with it. Microsoft is making Windows Phone 7 a viable competitor and another choice for a more integrated experience in the corporate arena. Whether it will be able to change adoption trends remains to be seen.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"WS-*","id":"234","quadrant":"platforms","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"},{"name":"Zero-code packages","id":"9298","quadrant":"platforms","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-03"}],"date":"2012-03"},{"blips":[{"name":"Advanced analytics","id":"9002","quadrant":"techniques","ring":"Adopt","movement":"t","radius":"","description":"Machine learning, semantic analysis, text mining, quantitative analytics, and other advanced analytics techniques have steadily matured over the past 15 years. They offer incredible potential for prediction, forecasting, identifying repeatable patterns, and providing insight into unstructured data. Historically, our ability to store and rapidly analyze large amounts of audio, video and image data has been severely limited. This placed constraints on sample size, as well as the time it would take to validate analytical models and put them into production. Now, using a spectrum of new technologies like NoSQL, data harvesters, MapReduce frameworks, and clusters of shared-nothing commodity servers, we have the power necessary to make truly effective use of these techniques. Combined with the massive increase in global data available from sensors, mobile devices and social media and we see this as a field with tremendous opportunity.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Aggregates as documents","id":"452","quadrant":"techniques","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Agile analytics","id":"9004","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"Applying agile methods to data warehousing, business intelligence and agile analytics provides better return and improved business responsiveness. This is done by applying lightweight technologies like REST services to move data around in near real-time instead of batch updates. This allows information about customer behavior and application usage to be derived and responses incorporated within the applications for better user experience and data visualization.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"AngularJS and Knockout","id":"9008","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radius":"","description":"We are seeing a common pattern of creating single-page web applications. Rather than requiring full page refresh, these request smaller sets of data from the server, and change the displayed content of their page through modifying the DOM. To make this more manageable, JavaScript MV* frameworks have been developed that support data binding, client-side templates, and validation. While lightweight applications may not need a framework, for more complex scenarios, AngularJS and Knockout should be considered as the current front-runners in this field.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Apache Pig","id":"502","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"AppCode","id":"9013","quadrant":"tools","ring":"Adopt","movement":"t","radius":"","description":"Apple’s mobile devices are going strong and native apps are a cornerstone of their success. Writing these native apps has become much more pleasant and productive since JetBrains launched AppCode, an IDE for iOS and OS X development that replicates the strengths of their IDEs for other platforms.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"ATOM","id":"9018","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"One of the foundational technologies of the Web as platform, Atom is an extensible data syndication format with broad tool support in almost all languages. In conjunction with the Atom Publication Protocol, Atom comprises a lightweight platform for publishing and consuming data with high quality-of-service guarantees. Atom-based solutions trade scalability for latency, however, making Atom often inappropriate for very low-latency scenarios.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Automated deployment pipeline","id":"448","quadrant":"techniques","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Azure","id":"473","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Backbone.js","id":"304","quadrant":"languages-and-frameworks","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"4","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"BigQuery","id":"475","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"Google’s BigQuery brings data analytics to the cloud. Rather than loading data into an expensive data-warehouse with predefined indexes, BigQuery allows you to upload and investigate a data set through ad-hoc SQL-like queries. This is a great way to create a cheap proof-of-concept or even a complete application, as processing of hundreds of gigabytes of data by thousands of servers happens in seconds.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Calatrava","id":"477","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Care about hardware","id":"9037","quadrant":"platforms","ring":"Adopt","movement":"c","radius":"","description":"This platform was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Care about languages","id":"9038","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radius":"","description":"The industry is experiencing something of a renaissance in programming languages. Thoughtworks thinks it is time to start assessing which other languages will help your organization while taking stock of the useful lifetime remaining for your current choices. You need to care about languages. Traditionally structured organizations with separate support teams may find skills constrain choice, DevOps offers a path forwards here.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Clojure","id":"258","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"ClojureScript","id":"478","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Component-based frameworks","id":"486","quadrant":"languages-and-frameworks","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Configuration in DNS","id":"9056","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"Application deployments often suffer from an excess of environment-specific configuration settings, including the hostnames of dependent services. Configuration in DNS is a valuable technique to reduce this complexity by using standard hostnames like ‘mail’ or ‘db’ and have DNS resolve to the correct host for that environment. This can be achieved in multiple ways, including split-horizon DNS or configuring search subdomains. Collaboration between development teams and IT operations is essential to achieve this, but that is unfortunately still difficult in some organizations.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Continuous integration in the cloud","id":"510","quadrant":"platforms","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Couchbase","id":"513","quadrant":"platforms","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Crazy Egg","id":"9062","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"There are a couple of usability testing tools that match our preferred ‘guerrilla’ approach. Eye-tracking has long been a useful technique when designing compelling user interfaces, however the equipment and software associated with it is expensive and typically requires the use of specialist firms. Crazy Egg is a cheaper, software-only solution that produces heat maps based on mouse movement. This movement has a strong correlation with gaze, and can be used as a reasonable approximation. Silverback captures not only the screen during a test, but also records the face and voice of the user. This can be invaluable in sharing rich test experiences with the wider development team.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"D3","id":"500","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"D3 is a JavaScript library for binding datasets into the DOM, and then declaratively transforming the document to create rich visualizations - ranging from graphs to heatmaps. With support for HTML, CSS and SVG, and an extensible plug-in model, we like the fact that this library allows us to deliver information in more intuitive ways.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Database based integration","id":"9068","quadrant":"techniques","ring":"Hold","movement":"c","radius":"","description":"For those organizations that are required to integrate systems, many continue to use a common database, sharing data between applications through the database tier. In many cases this has become an established and accepted architectural pattern: database based integration. The side affect of such an approach is greater coupling of database schemas, release schedules, performance and quality of service across applications.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Datomic","id":"471","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Declarative provisioning","id":"9072","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"Tools such as Pallet offer a compelling approach to environment creation and management through declarative provisioning. Usually, this is accomplished by declaring your environment topology - a number of instances, OS, network configuration and applications - using a DSL, and then creating the entire environment automatically via a commandline tool. This approach differs in the decoupling of instance creation and application provision, and in the addition of the ability to declare dependencies between domain-specific application-level services over multiple boxes.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Dependency Structure Matrices","id":"9074","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"We strongly favor code-base visualization techniques. In particular, Dependency Structure Matrices (DSM) have proven to be extremely useful, especially in support of an evolutionary architecture and emergent design. Tools support for DSM is widespread.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Deployment and scripting test tools","id":"9075","quadrant":"techniques","ring":"Assess","movement":"t","radius":"","description":"With deployment automation tools maturing, including PowerShell on Windows, scripts are increasingly sophisticated and contain a lot of logic. We recommend deployment and scripting test tools, such as Pester for PowerShell and TOFT for Chef and Puppet. It is critical to have good test coverage around the most important aspects of your deployment automation.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Domain-Specific Languages","id":"9079","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radius":"","description":"Domain-Specific Languages is an old technique that we think is significantly under-used. We hope that the publication of Martin Fowler’s latest book will encourage more people to utilize them.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Domain-specific PaaS","id":"9080","quadrant":"platforms","ring":"Trial","movement":"c","radius":"","description":"We find that many businesses are starting to build their own internal cloud deployment environments that can be easily replicated for development and testing environments. In many cases, provisioning is selfservice, and with a single keystroke, developers can create a set of hosts that implement core enterprise assets and collaborating systems. In a sense, this is a domain-specific PaaS offered to internal customers.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Dropwizard","id":"519","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Edge Side Includes for page composition","id":"495","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Embedded servlet containers","id":"394","quadrant":"tools","ring":"Adopt","movement":"t","radius":"","description":"We have talked much already about embedded servlet containers - and these are now widely adopted on our projects. Tools such as SimpleWeb and Webbit take the simple, embedded approach further and offer raw HTTP server functionality without implementing the Java Servlet specification. We are pleased to see a corresponding reduction in the complexity of test code that takes advantage of this.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"ESB","id":"9088","quadrant":"tools","ring":"Hold","movement":"c","radius":"","description":"IT departments are increasingly striving to liberate data from disparate systems. A broad set of approaches have been promoted under the generic term Service Oriented Architecture (SOA). This has led to confusion about what the term and approach actually means. We believe businesses do not need the complex enterprise service bus products advocated by vendors. ESBs actively undermine the reasons for choosing the bus approach: low latency, loose coupling, and transparency.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Exhaustive browser-based testing","id":"483","quadrant":"techniques","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"F#","id":"9097","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radius":"","description":"Microsoft’s F# continues to evolve, with the recent release of F# 3.0 beta. F# is excellent at concisely expressing business and domain logic. Developers trying to achieve explicit business logic within an application may opt to express their domain in F# with the majority of plumbing code in C#.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Feature branching","id":"9100","quadrant":"techniques","ring":"Hold","movement":"c","radius":"","description":"Disappointingly, we continue to see development teams embrace the practice of feature branching to isolate work and defer integration. Feature branches commonly cause significant pain and unpredictability during late merges, but more importantly prevent the continual design improvement necessary to maintain high quality software. We recommend continuous integration and branch by abstraction as an alternative to feature branching.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Frank","id":"407","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"GemJars","id":"9109","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"In a mixed Ruby/Java application, running on the JVM, there are differences in package format and dependency resolution that need to be dealt with. By providing an Ivy compatible proxy that packages RubyGems as JARs and uses Ivy to resolve Gem dependencies, GemJars consolidates and simplifies the building of truly polyglot codebases.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Google Dart","id":"9114","quadrant":"languages-and-frameworks","ring":"Hold","movement":"c","radius":"","description":"Dart is Google’s attempt at creating a programming language to replace JavaScript due to JavaScript’s perceived flaws and inherent performance issues. Dart, in line with previous Google languages, provides Java-like syntax and semantics that are intended to be more appealing than JavaScript’s prototype-based nature. Reception within the browser-development community has been understandably cool and it remains to be seen if the language will become more widely accepted, though Chrome’s continued rise and the search for alternatives like CoffeeScript may yet shift that balance.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"4","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Gradle","id":"315","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"Two things have caused fatigue with XML-based build tools like Ant and Maven: too many angry pointy braces and the coarseness of plug-in architectures. While syntax issues can be dealt with through generation, plug-in architectures severely limit the ability for build tools to grow gracefully as projects become more complex. We have come to feel that plug-ins are the wrong level of abstraction, and prefer language-based tools like Gradle and Rake instead, because they offer finer-grained abstractions and more flexibility long term.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Graphite","id":"458","quadrant":"tools","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Gremlin","id":"481","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radius":"","description":"Gremlin is an imperative graph traversal language supported by multiple graph databases. Its concise constructs can be used in place of the native language of the database, leading to faster development times and, in some cases, faster execution. We recommend its use as a good alternative in simple scenarios.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Guerrilla user testing","id":"446","quadrant":"techniques","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Health check pages","id":"9126","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"We have found adding simple health check pages to applications is incredibly useful. This allows people to quickly understand the health of an individual node. We often extend them to add metrics like the number of orders placed, error rates, or similar information. Using simple embedded web servers, even non-web based services can easily expose internal information over HTTP. By using microformats, these web pages can easily be scraped by other monitoring tools to become part of holistic monitoring.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Highcharts","id":"9129","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"Increasingly performant JavaScript engines, combined with widespread support for embedded SVG documents in HTML, has lead to pure JavaScript-based client-side graphing and visualization solutions gaining a lot of traction. Highcharts is one of the best ones we have come across, with out-of-the-box support for multiple highly-configurable interactive chart types, and the ability to easily render large data sets.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"HTML 5 for offline applications","id":"521","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Hybrid clouds","id":"9134","quadrant":"platforms","ring":"Trial","movement":"t","radius":"","description":"Hybrid clouds combine the best features of public clouds and private data centers. They allow applications to run in a private data center during normal periods, and then use rented space in a public cloud for overflow capacity during peak traffic periods. There are now a number of infrastructure solutions that allow automatic and consistent deployment across a hybrid cloud, such as Palette and RightScale. With robust offerings from Amazon, Rackspace and others, we are moving hybrid clouds to “Trial” on this edition of the radar.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Immutable servers","id":"457","quadrant":"tools","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"In-process acceptance testing","id":"449","quadrant":"techniques","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Infrastructure as code","id":"9142","quadrant":"tools","ring":"Adopt","movement":"c","radius":"","description":"We continue to highlight infrastructure as code. This technique treats infrastructure configuration in the same way as code; checking configuration into source control, then carefully pushing changes out to the data center.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Infrastructure automation of development workstations","id":"9143","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"Automation is one of the core practices of Continuous Delivery. While companies are getting better at automating the management of infrastructure and environments, one commonly forgotten aspect is infrastructure automation of development workstations. This leads to huge gains in productivity by avoiding manually building specific environments and allows a seamless pairing environment. As with other parts of the environment, tools like Puppet and Chef can be used though they are not entirely necessary as the judicious use of platform packaging and language build tools can be sufficient.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Jade","id":"9148","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"This tool was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Jasmine paired with Node.js","id":"456","quadrant":"tools","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Java portal servers","id":"9151","quadrant":"platforms","ring":"Hold","movement":"c","radius":"","description":"A continuing cause of delivery problems lies in the use of Java Portal Server packages. These problems occur in both open source and commercial portal platforms. The promised productivity of these platforms is hindered by their complex and unwieldy programming models and difficulty in automating deployment, data migration, and tests. Although product demos are compelling, the base features of portal products are often a poor fit for real web applications, while the extra advertised features such as single sign-on or search are usually already served by existing, targeted, enterprise assets.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"JavaScript as a platform","id":"482","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"JavaScript micro frameworks","id":"9154","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"With mobile applications on the rise, JavaScript size and performance is even more critical. JavaScript micro frameworks have emerged as a direct response to ‘bloat’ in some of the larger libraries. These small libraries do exactly one thing, such as DOM selection or MVC, and can be under one kilobyte in size. By combining a number of micro frameworks, developers can get exactly the functionality they need without the overhead of a larger library. Microjs.com hosts a collection of these micro frameworks, as well as a tool that can bundle them into a single library.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Jekyll","id":"520","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Light Table","id":"469","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Linux containers","id":"9166","quadrant":"platforms","ring":"Trial","movement":"c","radius":"","description":"One style of virtualization that is particularly attractive for SaaS and PaaS implementations is the virtual container. Linux containers such as OpenVZ provide the isolation and management benefits of a virtual machine without the overhead usually associated with general-purpose virtualization. In the container model, the guest OS is limited to being the same as the underlying host OS, but that is not a serious limitation for many cloud applications.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Locust","id":"505","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Logic in stored procedures","id":"314","quadrant":"languages-and-frameworks","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"4","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Logic-free markup","id":"9171","quadrant":"tools","ring":"Assess","movement":"c","radius":"","description":"While MVC has been a staple of web development for the past few years, most libraries and frameworks fail to adhere to one of its most important principles: keeping logic out of the view layer. The consequences of not having logicfree markup include complex dependencies, difficulty testing and inability to reuse code. Recent DSLs like Mustache are available for many languages and platforms and have started to turn the trend. They allow editing in any tool, without extra requirements for language support and provide huge gains for UI development and overall application design.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Logs as data","id":"488","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Lua","id":"479","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Maven","id":"419","quadrant":"tools","ring":"Hold","movement":"c","radius":"","description":"Maven has long been a staple of build automation in the Java space. However, given its lack of flexibility and support for automation best practices, especially in the Continuous Delivery domain, the use of alternatives such as Gradle should be considered.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Meteor.js","id":"9181","quadrant":"platforms","ring":"Hold","movement":"t","radius":"","description":"Meteor.js is a client- and server-side JavaScript application framework, run inside a web browser, or in a Node.js container, and backed by MongoDB for persistence. It uses “Smart Packages” - little bundles of code that can run in the browser or as part of a cloud service. It allows hot code deploys and live in-browser updates. We think the idea is great, even if the framework is not yet ready for primetime.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Microservices","id":"395","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Mobile first","id":"490","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Mobile payment systems","id":"9185","quadrant":"platforms","ring":"Adopt","movement":"t","radius":"","description":"Despite apparent resistance in the Global North, mobile payment systems such as Kenya’s M-Pesa are providing secure cashless monetary transactions. With the service rolling out across Africa, the system opens up the market for the millions of people with mobile phones but lacking access to traditional banking outlets. Providers such as Square are slowly improving the situation, but the North continues to lag.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"MongoDB","id":"508","quadrant":"platforms","ring":"Trial","movement":"t","radius":"","description":"For problems that fit the document databases model, MongoDB provides easy programmability, a query interface, high availability with automated failover, and automated sharding capabilities. It allows for a smooth transition to NoSQL data stores from the RDBMS model, with the inclusion of familiar concepts, such as the ability to define indexes.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Neo4J","id":"460","quadrant":"platforms","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2010-08","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Node.js","id":"280","quadrant":"platforms","ring":"Trial","movement":"t","radius":"","description":"For many years JavaScript was predominantly used as a client side Web programming language, but a lightweight language such as JavaScript can easily be embedded in different environments, including the server side. Node.js allows developers to write applications in JavaScript on both client and server sides. Since most servers spend the majority of their time waiting for I/O operations, Node.js’ event driven non-blocking architecture is very efficient. Unlike threadbased solutions, Node.js does not need to wait for I/O operations to complete while processing incoming requests, making it a good choice when implementing high performance services.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"NuGet","id":"416","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"Package management systems are a widely accepted practice for incorporating third party libraries. Tools such as RubyGems, Maven, APT, are available at both language and system level. NuGet is such a system for .Net platform. It consists of a Visual Studio IDE extension and a PowerShell module that opens the possibility for further improving build automation on the .Net platform.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Open source IaaS","id":"9202","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"Selecting the right cloud provider from an almost bewildering array of options continues to be difficult. One strategy is to adopt an open source IaaS platform such as OpenStack or CloudStack. This allows you to run a private cloud that is consistent with a public cloud, and to migrate from one cloud provider to another should the need arise. Going one step further, Apache’s Deltacloud abstracts away from specific provider APIs to give a consistent experience across cloud platforms.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Out-of-container functional testing","id":"9205","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"With the popularity of embedded HTTP servers increasing, so has the technique of out-of-container functional testing. That is writing tests at the boundary of the system, using a mock container to provide both fast feedback and high coverage. Servers such as Jetty and tools like Plasma for the .Net platform can provide a significant reduction in the time it takes to run your test suite.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Performance testing as a first-class citizen","id":"390","quadrant":"techniques","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Polyglot Persistence","id":"9214","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"Polyglot persistence is the technique of storing data in various data stores based on efficiency and how that data is going to be used. Do not just use the default database, often an RDBMS, for all the needs of the application. Instead, ask questions like: Does session management data belong in the database or does it belong in a key-value store? Do relationships between customers and products belong in a graph database? Using NoSQL databases like MongoDB, Riak and Neo4J allows us to reconsider how data is treated, even with-in a single application.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Private Clouds","id":"691","quadrant":"platforms","ring":"Trial","movement":"c","radius":"","description":"Because of concerns over privacy and security, or a need to repurpose existing hardware investments, many businesses are choosing to implement their own private cloud. There are are a variety of products, both open source and commercial for this purpose, but it should be noted that compute, storage, and network management are only the starting points for a useful private cloud. There are many services and processes that must be custom implemented to provide a cloud facility that rivals the public offerings from Amazon, Rackspace, or others.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"PSake","id":"406","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Rake for Java \u0026 .NET","id":"9227","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"Of all the build tools and languages we use across our projects, the one we keep coming back to is Rake. Rake is a beautiful, simple and powerful build language implemented as an internal Domain-Specific Language on Ruby. Ruby’s ability to run across several virtual-machine platforms means that Rake is equally available - while leaving open the option to utilize more language-specific tools for some tasks. Finding a similar combination of elegance and flexibility is difficult regardless of your platform, so we recommend trying Rake for Java and .Net projects.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Remote usability testing","id":"9234","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"Bringing users in to a controlled environment for formal testing can be a slow and expensive proposition. Much useful, qualitative feedback can be gathered quickly and cheaply through guerrilla user testing - by going out into the world and testing with small samples of the general public. Another alternative is remote usability testing, where you can send out everything from wireframes to final applications for testing by people all over the world. Usabila, Loop11 and Treejack all provide tools where you can ask users to carry out specific tasks, and capture everything from the time taken to complete a task, to the user’s thoughts and feelings while doing so.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Require.js","id":"9235","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radius":"","description":"As adoption continues to expand, so does the size of many JavaScript codebases. To improve modularity of code and help manage this, we are seeing teams embrace libraries such as Require.js. Using the Asynchronous Module Definition (AMD) format, code is split into modules, easing development and maintenance, and an optimization tool then combines and minifies scripts for production deployment.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Responsive web design","id":"489","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Riak","id":"418","quadrant":"platforms","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Riemann","id":"470","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"RubyMotion","id":"480","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"SaaS performance testing tools","id":"9246","quadrant":"tools","ring":"Trial","movement":"t","radius":"","description":"Rather than wrestling with licenses and setting up clusters of machines for performance testing, we’re seeing a rise in SaaS performance testing tools such as Blitz.io and Tealeaf. These services make it easy to run performance tests with a huge number of geographically diverse clients, without investing heavily in infrastructure.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"SASS, SCSS, LESS, and Stylus","id":"9247","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radius":"","description":"CSS has been an extremely popular and effective DSL for styling web pages. It does, however, have some annoying limitations which have led to a number of languages that build on CSS to make it easier to write and modify. We’ve had good experiences with SASS, SCSS, and LESS.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Scala","id":"257","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Scratch, Alice, and Kodu","id":"514","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Semantic monitoring","id":"494","quadrant":"techniques","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Silverback","id":"9256","quadrant":"tools","ring":"Adopt","movement":"t","radius":"","description":"There are a couple of usability testing tools that match our preferred ‘guerrilla’ approach. Eye-tracking has long been a useful technique when designing compelling user interfaces, however the equipment and software associated with it is expensive and typically requires the use of specialist firms. Crazy Egg is a cheaper, software-only solution that produces heat maps based on mouse movement. This movement has a strong correlation with gaze, and can be used as a reasonable approximation. Silverback captures not only the screen during a test, but also records the face and voice of the user. This can be invaluable in sharing rich test experiences with the wider development team.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Sinatra","id":"516","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radius":"","description":"Micro-frameworks are emerging as a way to handle increasing complexity in applications both on client- and server-side. Sinatra was one of the early precursors of that trend in server-side space, exposing a lightweight DSL to build fast services that can be easily composed. Flask, Scalatra and Compojure are similar offerings for Python, Scala and Clojure respectively.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Single threaded servers with asynchronous I/O","id":"9260","quadrant":"platforms","ring":"Trial","movement":"t","radius":"","description":"Node.js is just one example of a class of single threaded servers with asynchronous I/O that are seeing increased popularity. A traditional web or application server associates each incoming request with a thread until all the processing tasks associated with that request are complete and the response has been sent back. If any of those tasks involve I/O, the thread blocks while that I/O takes place. This approach can waste finite resources such as file descriptors and memory since each connection occupies a thread whether or not that thread is actually consuming CPU cycles. An alternative architecture is starting to emerge in implementations like Node.js (a JavaScript server running on Google V8), Nginx (an open source web server and proxy), and Webbit (a Java application server), that uses a single thread to serve many connections, processing all I/O asynchronously. These servers support orders of magnitude more simultaneous connections because each one consumes far fewer resources.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Singleton infrastructure","id":"436","quadrant":"platforms","ring":"Hold","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Test recorders","id":"9272","quadrant":"techniques","ring":"Hold","movement":"c","radius":"","description":"Test recorders seem invaluable as they provide a quick way to capture navigation through an application. However, we strongly advise against their regular use, as it tends to result in brittle tests which break with small changes to the UI. The test code they produce tends to be relatively poor and riddled with unnecessary duplication. Most importantly, test recorders tend to cut channels of communication between the test automation and development teams. When faced with an application that is difficult to test through the user interface, the solution is to have a critical conversation between the teams to build a more testable UI.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Twitter Bootstrap","id":"515","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Vagrant","id":"9282","quadrant":"tools","ring":"Trial","movement":"c","radius":"","description":"The tool Vagrant makes it simple for teams to distribute virtualized development environments constructed using version-control friendly descriptors. Vagrant helps eliminate environmental differences in development and reduce troubleshooting waste.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"VCS with “implicit workflow”","id":"9283","quadrant":"tools","ring":"Hold","movement":"c","radius":"","description":"Some tools seek to enable and facilitate different ways of working. Unfortunately other tools are created using a different premise, one of low trust in users and the need to enforce a predefined process. ClearCase and TFS do this. This makes version control systems with “implicit workflow” unsuitable tools for modern agile software development. Project methodologies and the best ways of working on a project need to emerge. Tools that enforce high ceremony around things like check in just get in the way and kill productivity.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Vert.x","id":"9284","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"Representing yet another evolution away from traditional, free-standing application containers, Vert.x is an application framework that bridges synchronous and asynchronous programming styles. This gives the programmer the option to trade off scalability and performance for simplicity. Unlike Node.js, Vert.x is a library that can be called from a variety of languages supported on the JVM, including Java, Ruby and JavaScript.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Windows infrastructure automation","id":"401","quadrant":"techniques","ring":"Adopt","movement":"c","radius":"","description":"Mature tools such as PowerShell, together with newer options such as Chef and Puppet, lead us to highlight Windows infrastructure automation on this edition of the technology radar. Manual configuration using a mouse and menu options is slow and leads to misconfiguration and “snowflake” machines in an unknown state. We recommend command-line tools for their clarity and scriptability.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Windows Phone","id":"9292","quadrant":"platforms","ring":"Assess","movement":"t","radius":"","description":"Despite a promising start to Windows Phone, a well thought-out user interface, and probably the best development experience of any mobile platform, we have seen several stumbles in the execution of the platform strategy by Microsoft and its partners. This makes us less optimistic about the future of the platform than we were in the last radar.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Work-in-Progress limits","id":"9294","quadrant":"techniques","ring":"Adopt","movement":"t","radius":"","description":"It might sound odd for us to mention this, given how mainstream Agile development has become, but we are noticing teams rediscover and embrace work-in-progress limits. Methods such as Kanban limit the amount of in-flight work, forcing better workflow into the team and more visibility into bottlenecks.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"WS-*","id":"234","quadrant":"platforms","ring":"Hold","movement":"c","radius":"","description":"","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Zero-code packages","id":"9298","quadrant":"platforms","ring":"Hold","movement":"c","radius":"","description":"There are a number of enterprise software packages on the market that purport to offer flexible functionality with zero coding. This is certainly an appealing notion – that a non-technical business user could configure software to the unique requirements of any business without learning a programming language or hiring a professional software developer. However, it should be kept in mind that any change that affects the behavior of software in production, whether it is code, configuration, data or environments, could cause defects or failures in the business system. Writing code is only one step in a professional software production lifecycle. The need for repeatable analysis, testing, build, and deployment does not go away because the system is modified via a dragand- drop interface instead of a high-level programming language. When evaluating a zero-code package, ensure that the the product supports these processes and that you have the necessary IT support structures in place to implement them.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-03","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Zipkin","id":"466","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"When building distributed applications to address web-scale or big data requirements, setting up appropriate monitoring tools becomes a non-trivial exercise. Zipkin is a tool that instruments the different components of a service-based system and visualizes the breakdown of logical requests passing through multiple services using a ‘firebug-like’ view. The raw data can be stored in Hadoop for more advanced reporting and data mining.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"},{"name":"Zucchini","id":"9300","quadrant":"tools","ring":"Assess","movement":"t","radius":"","description":"Zucchini is a testing framework that provides Cucumber-style BDD testing for iOS apps. It uses CoffeeScript for feature definitions, takes screenshots as tests are run, and we’ve been very happy with it.","theta":"","editStatus":"Include w/o Write Up","faded":"","lastModified":"","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2012-10"}],"date":"2012-10"},{"blips":[{"name":"Aggregates as documents","id":"452","quadrant":"techniques","ring":"Adopt","movement":"c","radarId":"1","radius":"55","description":"When designing a domain model, the aggregate pattern helps to add structure and modularity. Mapped to a relational database the aggregate is not visible in the table structure. Document databases, like MongoDB, allow you to model aggregates as documents. This 1:1 mapping means that the aggregate root should be the object that is loaded from the collection.","theta":"125","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Analyzing test runs","id":"576","quadrant":"techniques","ring":"Trial","movement":"t","radarId":"2","radius":"230","description":"Failing tests reveal bugs in production code. However, analyzing test runs for other properties can reveal interesting information. A simple example would be to monitor which tests fail frequently and run them earlier in your build pipeline to get fast feedback. Similarly, tracking other properties such as test execution times and ratios of long-running tests to fast-tests can provide actionable metrics.","theta":"160","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Apache Pig","id":"502","quadrant":"tools","ring":"Trial","movement":"c","radarId":"3","radius":"225","description":"Hadoop continues to be the most popular framework to develop distributed data-processing applications. Although programming Hadoop applications in Java is not particularly difficult, designing efficient MapReduce pipelines does require a good amount of experience. Apache Pig simplifies Hadoop development by offering a high level language, called Pig Latin, and an execution runtime. Pig Latin is procedural and provides a SQL-like interface to work with large datasets. The execution infrastructure compiles Pig Latin into an optimized sequence of MapReduce programs that run on the cluster. Pig Latin is extensible through user-defined functions in different languages such as Ruby, JavaScript, Python and Java.","theta":"80","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Automated deployment pipeline","id":"448","quadrant":"techniques","ring":"Adopt","movement":"c","radarId":"4","radius":"25","description":"The adoption of Continuous Delivery means many teams are creating an automated deployment pipeline that carries their code all the way to production. Pipelines allow the visualization of otherwise complex chains of build and deployment activities. Further, they provide the ability to reliably trace build artifacts as they progress through each stage on their path to production. Several vendors are now building CI servers that support the pipeline as a first-class feature and not just a visual element. We recommend teams look closely at these products to avoid wasting time trying to shoehorn a pipeline into a tool without adequate support.","theta":"135","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Azure","id":"473","quadrant":"platforms","ring":"Assess","movement":"c","radarId":"5","radius":"300","description":"Microsoft’s Azure cloud platform continues to play catchup with more mature clouds such as AWS, but we’ve been impressed with how Microsoft has responded to market demands. As with most Microsoft solutions it continues to be a contender and worth evaluating.","theta":"215","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Backbone.js","id":"304","quadrant":"languages-and-frameworks","ring":"Hold","movement":"c","radarId":"6","radius":"360","description":"Backbone.js is a great example of an abstraction pushed too far. While we initially liked the ease of wire-up, in practice it suffers from the same issues as all such databound frameworks from WebForms to client/server tools. We find that it blurs the framework and model too much, forcing either bad architectural decisions or elaborate framework hackery in order to preserve sanity.","theta":"280","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"4","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Big enterprise solutions","id":"600","quadrant":"platforms","ring":"Hold","movement":"t","radarId":"7","radius":"375","description":"","theta":"210","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"BigQuery","id":"475","quadrant":"platforms","ring":"Trial","movement":"t","radarId":"8","radius":"250","description":"The amount of data that even a relatively low volume website can generate is huge. Once you add in analytics, business metrics, demographics, user profiles and multiple devices, it can become overwhelming. Many organizations use data warehouses as a repository with data being sucked in from all parts of the organization. The challenge here is that these often turn into “Data Fortresses.” Even getting timely business metrics becomes a challenge, let alone running exploratory queries across the entire data set. Technologies like the cloud based BigQuery help. The pay-as-you-go model and the ability to do ad hoc queries lets you gain insight without buying specialist hardware and software. A data-driven business should put data in the hands of the decision makers, not hidden behind technological barriers and bureaucracy.","theta":"225","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Blue-green deployment","id":"658","quadrant":"techniques","ring":"Trial","movement":"t","radarId":"9","radius":"180","description":"Blue-green deployment is a pattern for performing software upgrades. By setting up the latest version of your application on an identical clone of your production application stack, traffic can be switched, near instantaneously, from the current production stack to the new one as soon as the test suite and the business determine it is appropriate. Though this is an old technique, infrastructure automation and resources in the cloud make it worth reconsidering.","theta":"100","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Browser-based templating","id":"663","quadrant":"tools","ring":"Assess","movement":"t","radarId":"10","radius":"312","description":"We see several JavaScript frameworks embrace browser-based templating, moving more layout work to the client. While this approach is useful in many cases, it does introduce operational issues involving caching, performance, and search. We believe these tools should be assessed carefully to ensure suitability for the target deployment environment.","theta":"53","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Calatrava","id":"477","quadrant":"platforms","ring":"Assess","movement":"c","radarId":"11","radius":"300","description":"We have previously been skeptical of claims of reusable code working across platforms. Our experience with many tools in the market has been mixed and we advise caution to our clients who are looking at these types of solutions. Taking an approach that carefully navigates these dangerous waters, we feel Calatrava is worth evaluating for mobile application development. The framework neatly follows the separation of business and presentation logic, maximising reuse where there is commonality, and providing native access where speed or device-specific idioms are to be followed.","theta":"185","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Capturing client-side JavaScript errors","id":"545","quadrant":"techniques","ring":"Assess","movement":"t","radarId":"12","radius":"320","description":"","theta":"100","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Clojure","id":"258","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radarId":"13","radius":"110","description":"","theta":"280","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"ClojureScript","id":"478","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"14","radius":"290","description":"ClojureScript illustrates just how cross-platform the core of Clojure really is: they ported the primary parts to run on JavaScript. It is missing some of the whizzbang features of Clojure on the JVM and CLR, like software transactional memory, but has a surprisingly high fidelity with its more sophisticated cousins. One interesting option afforded by ClojureScript is the ability to send data structures à la JSON using ClojureScript as the data structure. Because Clojure is a Lisp, this means that you can also send “real” code.","theta":"290","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Co-location by telepresence","id":"564","quadrant":"techniques","ring":"Trial","movement":"t","radarId":"15","radius":"240","description":"Increasing quality and range of choices for inexpensive or free video conferencing is leading to a new way of working for distributed teams. Always-on video connections can help create a sense of co-location by telepresence, even when the team is distributed geographically. This is becoming the defacto standard in some of our offshore delivery centers. We are also seeing increased use of screen-sharing tools like ScreenHero for remote pairing. We would caution those looking for a silver bullet to eliminate the need for physical co-location. There is no substitute for the understanding and empathy created by faceto- face communication.","theta":"115","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"CoffeeScript","id":"648","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"16","radius":"225","description":"","theta":"337","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"Dropbox dives into CoffeeScript, CoffeeScript Source Maps, Source Map Revision 3 Proposal, CoffeeScript is not a language worth learning","volume":"2013-05"},{"name":"Collaborative analytics and data science","id":"628","quadrant":"techniques","ring":"Assess","movement":"t","radarId":"17","radius":"290","description":"","theta":"115","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Component-based frameworks","id":"486","quadrant":"languages-and-frameworks","ring":"Hold","movement":"c","radarId":"18","radius":"375","description":"As the industry shifted from desktop GUI development to the web, it seemed natural to port the most successful patterns and designs to the new paradigm. After 15 years of trying, we feel that there are still no component-based frameworks that have successfully achieved this. We recommend not attempting to make web development into something that it fundamentally is not. It is time to accept the page and request-based nature of the web, and focus on the frameworks that support - rather than work against - these concepts.","theta":"310","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"4","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Continuous delivery for mobile devices","id":"528","quadrant":"techniques","ring":"Trial","movement":"t","radarId":"19","radius":"240","description":"With HTML5 blurring the line between traditional native apps and web apps, we are beginning to experiment with continuous delivery for mobile devices. Services such as TestFlight allow you to deploy native apps to real devices multiple times per day. With a wholly or partially HTML5-based application changes can be deployed without submitting a new app to an app store. If your organization has an enterprise app store, you may be able to easily push builds to it. While the techniques for implementing CD to mobile devices are improving, we note that testing practices are lagging behind. To be successful you will need to increase your focus on automated testing to ensure that everything actually works once it gets to the device.","theta":"110","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Continuous integration in the cloud","id":"510","quadrant":"platforms","ring":"Trial","movement":"c","radarId":"20","radius":"170","description":"Continuous integration in the cloud is one of those obvious-in-hindsight infrastructure offerings that supports agile development. With no local software and minimal configuration, it just works. With mature offerings now in place, serious developers are left with no excuse for avoiding this important practice.","theta":"230","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Couchbase","id":"513","quadrant":"platforms","ring":"Trial","movement":"c","radarId":"21","radius":"180","description":"Couchbase is a persistent cache with auto-sharding features, master-less clusters and replicated data to avoid cachemisses. Because it supports the Memcached protocol, it allows drop-in replacement for Memcached based systems.","theta":"190","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"CSS frameworks","id":"284","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"22","radius":"75","description":"This language/framework was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"350","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"D3","id":"500","quadrant":"tools","ring":"Adopt","movement":"t","radarId":"23","radius":"100","description":"","theta":"60","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Database migrations for NoSQL","id":"632","quadrant":"techniques","ring":"Trial","movement":"t","radarId":"24","radius":"170","description":"NoSQL data stores continue to become mainstream, and teams should acknowledge the need for database migrations for NoSQL. Especially with an implicit or dynamic schema you are likely to want to reconfigure data over time. There are several approaches such as running an explicit migration when deploying a new build of your application, or using dynamic migrations in code as documents are loaded and processed.","theta":"115","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Datomic","id":"471","quadrant":"platforms","ring":"Assess","movement":"c","radarId":"25","radius":"300","description":"A fundamental rethinking of how databases work, Datomic is an immutable database server with fascinating transactional and deployment characteristics. One of the common headaches on agile projects is managing database migrations, especially restoring previous states. Datomic makes the need for migrations go away - every version of the data (and schema) is preserved by the database. While still evolving, we appreciate Datomic’s boldness of vision.","theta":"225","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Development environments in the cloud","id":"633","quadrant":"techniques","ring":"Assess","movement":"t","radarId":"26","radius":"320","description":"","theta":"125","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Dropwizard","id":"519","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"27","radius":"210","description":"","theta":"290","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Edge Side Includes for page composition","id":"495","quadrant":"techniques","ring":"Trial","movement":"c","radarId":"28","radius":"230","description":"Breaking up monolithic applications and building systems from microservices requires a solid strategy to integrate output from disparate systems into a coherent experience for the end-user. Integrating at the presentation layer using Edge Side Includes (ESI) for page composition is a practical and elegant solution. This can occur within your environment using a reverse proxy like Varnish or closer to the user in a Content Delivery Network (CDN).","theta":"170","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Elastic Search","id":"667","quadrant":"platforms","ring":"Adopt","movement":"t","radarId":"29","radius":"115","description":"","theta":"225","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Embedded servlet containers","id":"394","quadrant":"tools","ring":"Adopt","movement":"t","radarId":"30","radius":"60","description":"In previous radars we have talked about embedded servlet containers, and these are now widely adopted on our projects. Tools such as SimpleWeb and Webbit take the simple, embedded approach further and offer raw HTTP server functionality without implementing the Java Servlet specification. At the same time, Tomcat, the most popular Java application server, is increasingly used in embedded setups and Microsoft provides self-hosted servers for the .NET framework, lending further weight to this Trend.","theta":"65","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Exhaustive browser based testing","id":"483","quadrant":"techniques","ring":"Hold","movement":"c","radarId":"31","radius":"385","description":"We have previously spoken about executing automated tests at the appropriate layer of your application. In this radar, we want to be very specific - we recommend against exhaustive browser based testing. Web browser automation tools like Selenium have encouraged widespread automated testing through the browser. While these tests continue to have their place in a test portfolio, most teams find that executing the bulk of tests through the browser creates a slow and fragile test suite.","theta":"100","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Faraday","id":"549","quadrant":"tools","ring":"Assess","movement":"t","radarId":"32","radius":"312","description":"Several Thoughtworks teams called out the usefulness of Faraday, a Ruby HTTP client library that provides a common interface over a variety of adapters and integrates nicely with Rack middleware.","theta":"25","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Focus on mean time to recovery","id":"623","quadrant":"techniques","ring":"Assess","movement":"t","radarId":"33","radius":"310","description":"","theta":"165","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Frank","id":"407","quadrant":"tools","ring":"Adopt","movement":"t","radarId":"34","radius":"140","description":"Frank is an open source library that allows functional tests for iOS written in Cucumber and executed on a remote device. This fills an important niche where acceptance test-driven development was previously cumbersome and awkward.","theta":"12","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Gatling","id":"655","quadrant":"tools","ring":"Trial","movement":"t","radarId":"35","radius":"240","description":"","theta":"38","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Gradle","id":"315","quadrant":"tools","ring":"Adopt","movement":"t","radarId":"36","radius":"135","description":"Language-based build tools like Gradle and Rake continue to offer finer-grained abstractions and more flexibility long term than XML and plug-in based tools like Ant and Maven. This allows them to grow gracefully as projects become more complex.","theta":"80","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"Why Everyone Either Hates or Leaves Maven","volume":"2013-05"},{"name":"Graphite","id":"458","quadrant":"tools","ring":"Adopt","movement":"c","radarId":"37","radius":"75","description":"While many tools exist for displaying graphs for system monitoring purposes, Graphite has emerged recently as the clear leader in this space. Capable of charting metrics in realtime, it features a round-robin database that is able to store long periods of historic data, while still providing more recent information at a higher fidelity. Numerous configuration options exist on the dashboard, and the resulting graphs can then be embedded in webpages to increase visibility.","theta":"25","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Gremlin","id":"481","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"38","radius":"330","description":"This language/framework was included in this edition of the Radar for visibility. We felt that there wasn\u0027t anything substantial to add to the discourse around it, but that it was important to keep this in view.","theta":"280","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Guerrilla user testing","id":"446","quadrant":"techniques","ring":"Adopt","movement":"c","radarId":"39","radius":"120","description":"Bringing users in to a controlled environment for formal testing can be a slow and expensive proposition. Much useful, qualitative feedback can be gathered quickly and cheaply through guerrilla user testing - by going out into the world and testing with small samples of the general public. Another alternative is remote usability testing, where you can send out everything from wireframes to final applications for testing by people all over the world. Usabila, Loop11 and Treejack all provide tools where you can ask users to carry out specific tasks, and capture everything from the time taken to complete a task, to the user’s thoughts and feelings while doing so.","theta":"120","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Hadoop 2.0","id":"674","quadrant":"platforms","ring":"Trial","movement":"t","radarId":"40","radius":"165","description":"","theta":"260","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Handwritten CSS","id":"594","quadrant":"languages-and-frameworks","ring":"Hold","movement":"t","radarId":"41","radius":"375","description":"","theta":"330","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"4","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Heavyweight test tools","id":"579","quadrant":"tools","ring":"Hold","movement":"t","radarId":"42","radius":"375","description":"","theta":"59","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"HTML5 for offline applications","id":"521","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"43","radius":"190","description":"There is a tendency to equate the need for offline functionality with the need to build an app. Despite the slow standardization process, most HTML5 features have now been implemented across all major browsers. Its local storage capabilities, comprehensively supported across mobile and tablet browsers - makes HTML5 for offline applications a very suitable option.","theta":"315","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"HTML5 storage instead of cookies","id":"660","quadrant":"techniques","ring":"Trial","movement":"t","radarId":"44","radius":"180","description":"","theta":"155","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Hystrix","id":"554","quadrant":"tools","ring":"Assess","movement":"t","radarId":"45","radius":"312","description":"Managing dependencies in distributed systems can become complicated, and is a problem more people are facing with the move to finer-grained micro services. Hystrix is a library for  the JVM from Netflix that implements patterns for dealing with downstream failure, offers real-time monitoring of connections,and caching and batching mechanisms to make inter-servicedependencies more efficient.","theta":"30","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Icon fonts","id":"622","quadrant":"tools","ring":"Assess","movement":"t","radarId":"46","radius":"312","description":"","theta":"35","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Immutable servers","id":"457","quadrant":"tools","ring":"Adopt","movement":"c","radarId":"47","radius":"115","description":"Precedents set by cloud providers are now changing expectations within the corporate datacenter. In the cloud, many systems scale automatically, either to provide additional availability or in response to increased demand. Crucial to managing a growing estate, immutable servers, or ‘phoenix servers’, are a sensible approach for enterprises looking at IaaS and PaaS. In contrast, custom-configured ‘snowflake servers’ increase the load on the operations group and encourage a “works on my machine” mentality. Being able to re-provision machines - hard or virtual - from scratch using tools such as Chef or Puppet can drastically reduce the complexity of managing large server farms. Coupled with software that is designed to withstand failure, this will lead to more scalable and reliable systems.","theta":"45","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"In-process acceptance testing","id":"449","quadrant":"techniques","ring":"Adopt","movement":"c","radarId":"48","radius":"100","description":"Acceptance tests generally exercise the system from the ‘outside’, traversing an entire network stack for the security of exercising the complete application. In-process acceptance testing challenges the notion that test code and application under- test must run in different processes in order to achieve these benefits. When using an embedded container, it is easy to set up the system, run the tests over HTTP and to verify the final state without the setup costs associated with deploying to and communicating with a separate container.","theta":"135","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Jasmine paired with Node.js","id":"456","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radarId":"49","radius":"75","description":"We have long thought of JavaScript as a first class language, and have been keenly following the development of testing tools in that space. The cream of the crop for out-of-browser testing is currently Jasmine. Jasmine paired with Node.js is the go-to choice for robust testing of both client- and serverside JavaScript.","theta":"330","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"JavaScript as a platform","id":"482","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"50","radius":"260","description":"JavaScript is moving outside of the browser, emerging as an important technology for cross-platform development. It is front-and-center in the approach to code reuse taken by Node.js, Meteor.js and mobile frameworks like Calatrava. Along with the recent proliferation of other languages that compile to JavaScript, this makes us wonder if we should start to consider JavaScript as a platform and not just a language.","theta":"320","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"JavaScript MV* frameworks","id":"517","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"51","radius":"225","description":"Single-page web application development continues to flourish along with the frameworks supporting data binding, client-side templates, validation, and other capabilities. The JavaScript MV* frameworks in active use on Thoughtworks projects include AngularJS, Knockout, and Ember.js. Each has advocates and a few detractors. We expect continuing innovative churn in this vibrant space.","theta":"345","editStatus":"In Editing","faded":"","lastModified":"2012-10","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Jekyll","id":"520","quadrant":"tools","ring":"Trial","movement":"c","radarId":"52","radius":"225","description":"Jekyll represents the “microization” of frameworks in the web publishing space. While the focus is maintained on doing one thing - sites that feature blogs - as transparently as possible, it also shows the path to a more lightweight future. One example of this that we like is that it is now trivially easy to publish useful documentation for your software project.","theta":"73","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Light Table","id":"469","quadrant":"tools","ring":"Assess","movement":"c","radarId":"53","radius":"300","description":"Like most good software developers, we choose our tools with care. We are especially keen on interesting departures from the norm, which is why we helped back the Light Table Kickstarter project. While still very early in development, the promised interactivity rivals the best of the Smalltalk world, with a modern twist; we are anxious to see what will come of this ambitious project.","theta":"45","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Locust","id":"505","quadrant":"tools","ring":"Trial","movement":"c","radarId":"54","radius":"220","description":"We are strong believers in in-line automated performance testing, although open source tools in this space have been somewhat limited to date. Locust is a firm favorite that provides the ability to write tests in Python, with good support for running multiple injectors, basic statistics generation, and a useful web dashboard. Its approach to web load testing focuses more on the simulation of users than just generating hits per second. We would typically recommend Locust over and above older tools such as JMeter or Grinder.","theta":"25","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Logic in stored procedures","id":"314","quadrant":"languages-and-frameworks","ring":"Hold","movement":"c","radarId":"55","radius":"375","description":"It is startling to us that we continue to find new systems in 2011 that implement significant business logic in stored procedures. Programming languages commonly used to implement stored procedures lack expressiveness, are difficult to test, and discourage clean modular design. You should only consider stored procedures executing within the database engine in exceptional circumstances, where there is a proven performance issue.","theta":"350","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"4","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Logs as data","id":"488","quadrant":"techniques","ring":"Trial","movement":"c","radarId":"56","radius":"190","description":"Log files generated by web servers, databases, networking infrastructure, and back-end systems are a valuable source of operational and behavioral data for a business. In the past, these files were mostly viewed as a source of diagnostic information in the case of failure, but with lowered cost of storage, and availability of tools such as Splunk for indexing and retrieving millions of events, they can also be a source of customer insights. Treating logs as data and storing complete logs instead of just collecting predefined metrics provides a means to answer novel questions that a business could not have previously anticipated.","theta":"125","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Logstash \u0026 Graylog2","id":"638","quadrant":"tools","ring":"Trial","movement":"t","radarId":"57","radius":"170","description":"","theta":"62","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Lua","id":"479","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"58","radius":"320","description":"An unlikely contender in the programming languages space, Lua has seen massive adoption across a variety of industries. It is used as a scripting platform in game development and music composition; embedded in point-of-sale appliances and network devices; and in extending NoSQL databases with safe execution semantics. We expect further growth in time to come.","theta":"300","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Machine image as a build artifact","id":"625","quadrant":"techniques","ring":"Assess","movement":"t","radarId":"59","radius":"310","description":"","theta":"135","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Maven","id":"419","quadrant":"tools","ring":"Hold","movement":"c","radarId":"60","radius":"375","description":"Language-based build tools like Gradle and Rake continue to offer finer-grained abstractions and more flexibility long term than XML and plug-in based tools like Ant and Maven. This allows them to grow gracefully as projects become more complex.","theta":"29","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-01","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Microservices","id":"395","quadrant":"techniques","ring":"Trial","movement":"c","radarId":"61","radius":"230","description":"","theta":"130","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Minimizing application configuration","id":"629","quadrant":"techniques","ring":"Assess","movement":"t","radarId":"62","radius":"330","description":"Application configuration can be a source of pain when getting started with a new tool, managing deployments to different environments, or trying to understand why applications behave differently in different places. We are a big fan of minimizing application configuration, trying to ensure that applications work sensibly out of the box with the bare minimum of Configuration.","theta":"145","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Mobile first","id":"490","quadrant":"techniques","ring":"Trial","movement":"c","radarId":"63","radius":"250","description":"We are rapidly heading towards a world where the majority of consumer interactions are from mobile devices. Mobile first embraces this trend by designing user interfaces and server interactions that target mobile devices in the first instance. The mobile first strategy contrasts with approaches that assume a highly capable client device connected to a fast and reliable network and then degrade the experience to fit the limitations of the device.","theta":"140","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Mobile testing on mobile networks","id":"526","quadrant":"techniques","ring":"Adopt","movement":"t","radarId":"64","radius":"125","description":"","theta":"150","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"MongoDB","id":"508","quadrant":"platforms","ring":"Adopt","movement":"t","radarId":"65","radius":"40","description":"","theta":"205","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Nancy","id":"630","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"66","radius":"285","description":"","theta":"331","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Neo4J","id":"460","quadrant":"platforms","ring":"Adopt","movement":"c","radarId":"67","radius":"75","description":"","theta":"225","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Node.js","id":"280","quadrant":"platforms","ring":"Trial","movement":"t","radarId":"68","radius":"170","description":"","theta":"205","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"NuGet","id":"416","quadrant":"tools","ring":"Adopt","movement":"t","radarId":"69","radius":"135","description":"Package systems for third-party library management continue to gain acceptance and features across all platforms. We called out NuGet as a recent entry, and the addition of Chocolatey NuGet exemplifies the advances and capabilities springing up around this essential agile engineering practice.","theta":"27","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Octopus","id":"560","quadrant":"tools","ring":"Assess","movement":"t","radarId":"70","radius":"312","description":"","theta":"75","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"OpenStack","id":"604","quadrant":"platforms","ring":"Trial","movement":"t","radarId":"71","radius":"200","description":"","theta":"250","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"OWIN","id":"637","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"72","radius":"285","description":"","theta":"354","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Performance testing as a first-class citizen","id":"390","quadrant":"techniques","ring":"Adopt","movement":"t","radarId":"73","radius":"100","description":"While unit and acceptance testing are widely embraced as standard development practices, this trend has not continued into the realm of performance testing. Currently, the common tooling drives testers towards creating throw away code and a click-and-script mentality. Treating performance testing as a first-class citizen enables the creation of better tests that cover more functionality, leading to better tooling to create and run performance tests, resulting in a test suite that is maintainable and can itself be tested.","theta":"95","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Perimeterless enterprise","id":"574","quadrant":"techniques","ring":"Trial","movement":"t","radarId":"74","radius":"250","description":"","theta":"150","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"PhantomJS","id":"583","quadrant":"tools","ring":"Trial","movement":"t","radarId":"75","radius":"240","description":"","theta":"50","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"PhoneGap/Apache Cordova","id":"532","quadrant":"platforms","ring":"Assess","movement":"t","radarId":"76","radius":"300","description":"","theta":"200","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Play Framework 2","id":"669","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"77","radius":"225","description":"The recent release of Play Framework 2.1.1 with support for controller dependency injection, asynchronous, non-blocking I/O, a code-reload workflow, database migrations, asset pipelining, and flexible deployment options has made it more attractive to developers. For this reason Play re-appears on the radar as something for teams to seriously consider when building web applications and services on the JVM. A word of caution however, Play embraces a functional programming style which, when working with the Java language, still translates into a plethora of static methods that may be difficult to unit test outside a running server.","theta":"328","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"PostgreSQL for NoSQL","id":"643","quadrant":"platforms","ring":"Assess","movement":"t","radarId":"78","radius":"305","description":"","theta":"256","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Promises for asynchronous programming","id":"617","quadrant":"techniques","ring":"Adopt","movement":"t","radarId":"79","radius":"120","description":"The use of promises for asynchronous programming is an old technique that is also known as futures. It is gaining renewed interest in light of the extensive use of JavaScript on both the client and server side. This technique eliminates the use of deeply nested callbacks, flags and pollers and has first-class support from libraries such as jQuery. Teams developing JavaScript codebases of significant complexity should take advantage of this.","theta":"110","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"PSake","id":"406","quadrant":"tools","ring":"Adopt","movement":"c","radarId":"80","radius":"140","description":"PSake (pronounced ‘sake’ like the Japanese rice wine) is a build automation tool implemented in PowerShell. PSake provides a tidy syntax for declaring build tasks and dependencies without programming in XML. You also have access to all the features of PowerShell and the .NET framework from within your build scripts.","theta":"40","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-01","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Puppet-librarian and Chef-librarian","id":"557","quadrant":"tools","ring":"Trial","movement":"t","radarId":"81","radius":"212","description":"","theta":"7","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Rackspace Cloud","id":"605","quadrant":"platforms","ring":"Trial","movement":"t","radarId":"82","radius":"205","description":"While AWS continues to add more features, Rackspace Cloud has become a viable competition in the storage and compute space. Some users may value the more thorough customer support available for Rackspace, as well as the ability to mix in more traditional hosting models. We are not excited about this just because Rackspace is a client of ours and we have had the pleasure developing the platform. We have successfully used Rackspace Cloud with several other clients, and would look forward to it being offered in more geographical locations.","theta":"262","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Reactive Extensions for .Net","id":"541","quadrant":"tools","ring":"Assess","movement":"t","radarId":"83","radius":"312","description":"By putting IObservables and IObservers on an equal footing with IEnumerables and IEnumerators, Rx for .NET allows developers to use their existing knowledge of LINQ (Language Integrated Query) operators to query and compose asynchronous operations and event-based code using a common underlying abstraction of observable event streams. Microsoft has also released RxJS to bring the benefits of reactive programming to JavaScript. They open sourced the entire Rx framework, making it useful for Windows rich client applications and single-page JavaScript applications.","theta":"70","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Redis","id":"534","quadrant":"platforms","ring":"Adopt","movement":"t","radarId":"84","radius":"75","description":"","theta":"200","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Require.js \u0026 NPM","id":"518","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"85","radius":"250","description":"Our continued use of node.js on new production applications has re-enforced our need for reliable packaging of JavaScript code and libraries. The Node Package Manager (npm) is an important part of the node.js ecosystem and a useful tool for packaging node.js applications. Developers of browser applications with large amounts of JavaScript or CoffeeScript should consider Require.js to help with structuring their code and loading dependencies at run time","theta":"290","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Responsive web design","id":"489","quadrant":"techniques","ring":"Trial","movement":"c","radarId":"86","radius":"240","description":"One such technique for achieving this is responsive web design. Starting with a basic presentation of content - and typically keeping the essential information constant - the experience is enhanced to suit the features detected on more capable browsers. This commonly takes the form of layout and format changes based on screen size.","theta":"95","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Riak","id":"418","quadrant":"platforms","ring":"Trial","movement":"c","radarId":"87","radius":"220","description":"Riak is a distributed key-value store that is schema-less and data-type agnostic. It can be put to good use in write-heavy projects to store data such as sessions, shopping carts and streaming logs - whilst it retains the ability to perform complex queries in a full-text search. The distributed cluster can self-recover without a single master, has tuneable consistency and availability settings and can do collision detection and resolution if needed - all of which can be particularly helpful in high availability environments.","theta":"190","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Riemann","id":"470","quadrant":"tools","ring":"Assess","movement":"c","radarId":"88","radius":"312","description":"Riemann is an open source server that aggregates and relays events in real time. Written in Clojure, and based on Netty, it is capable of handling thousands of concurrent connections per node. Riemann uses a simple Protobuf protocol for events, which allows it to aggregate everything from CPU and memory use to orders placed to error rates. It forwards to systems like Graphite, triggers email alerts, and provides a dashboard for monitoring these metrics. Riemann is an important part of the movement towards handling data as generic streams of events in real-time, as opposed to using specialized systems for different types of data.","theta":"65","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"RubyMotion","id":"480","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"89","radius":"300","description":"Introducing a Ruby compiler and toolchain for developing iOS applications, RubyMotion has unsurprisingly caused quite a stir in the Thoughtworks development community. There continues to be a need to understand the underlying iOS APIs and some Objective-C when building applications, but there are clear benefits for those who find working with the Ruby language and tools more comfortable.","theta":"350","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Scala","id":"257","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radarId":"90","radius":"100","description":"In the previous radar we had two JVMbased functional programming languages, Clojure and Scala, in our Assess category. We had expressed a slight preference for Clojure because it is the smaller and more focused language. Since the last radar we have realized that the wider applicability of Scala makes it more approachable for enterprise developers, and we have witnessed great successes in the adoption of Scala. Consequently we have moved Scala into our Trial category. Pay careful attention to the idiomatic use of Scala if it is introduced to a new team to avoid \u0026quot;Java without semicolons\u0026quot; or Perl styles.","theta":"300","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-01","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Scratch, Alice, and Kodu","id":"514","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"91","radius":"240","description":"We think it is essential to inspire the next generation of technologists. Scratch, Alice, and Kodu are programming languages that rely on visual environments and building blocks as teaching devices. They offer exciting possibilities for educational programs and organizations intending to foster programming knowledge in environments beyond academia.","theta":"300","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Semantic monitoring","id":"494","quadrant":"techniques","ring":"Trial","movement":"c","radarId":"92","radius":"220","description":"Development teams typically produce tests that specify and validate application behavior, but stop running them once the application goes into production. This is a missed opportunity. Semantic monitoring uses your tests to continuously evaluate your application, combining test-execution and realtime monitoring. With microservices, and similar fine-grained architectural approaches, it is increasingly important to test their interaction at run-time. Incorporating the validation of consumer-driven contracts into a monitoring facility is one way to approach this. While still evolving, we see great promise in the merging of two separate but important verification schemes.","theta":"150","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Sinatra","id":"516","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"93","radius":"125","description":"","theta":"315","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Singleton infrastructure","id":"436","quadrant":"platforms","ring":"Hold","movement":"c","radarId":"94","radius":"375","description":"Sometimes, architectural decisions lead you to incorporate infrastructure items that you can only afford one of, such as mainframes or search appliances. This is a terrible idea. It severely restricts testing and deployment flexibility. We strongly favor infrastructure you can easily set up and tear down. Singleton infrastructure belongs to misguided vendor-driven architectures of the past.","theta":"232","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-01","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"SMS and USSD as a UI","id":"562","quadrant":"platforms","ring":"Adopt","movement":"t","radarId":"95","radius":"100","description":"","theta":"260","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Snowplow Analytics","id":"646","quadrant":"tools","ring":"Assess","movement":"t","radarId":"96","radius":"312","description":"We see great promise in Snowplow Analytics, an open source web analytics platform that derives intelligent information from regular web analytics, based on open data principles and cloud Storage.","theta":"60","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"TestFlight \u0026 HockeyApp","id":"666","quadrant":"tools","ring":"Trial","movement":"t","radarId":"97","radius":"210","description":"Both TestFlight and HockeyApp allow you to manage the deployment of mobile applications without an app store, makinguser testing easier. They offer crash reporting and analytic capabilities to gather data in the field. HockeyApp supports IOS, Android, \u0026 Windows Phone, while TestFlight supports iOS and Android. We have used both tools successfully to help deliver mobile applications. This is clearly a fast evolving space.","theta":"55","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"TFS","id":"307","quadrant":"tools","ring":"Hold","movement":"t","radarId":"98","radius":"375","description":"","theta":"54","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Twitter Bootstrap","id":"515","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"99","radius":"285","description":"With JavaScript development on the rise, there is a growing need for reusable, extensible UI tooling. Twitter Bootstrap builds on the best offerings in the space, to provide a powerful set of patterns and components that help developers create responsive and adaptive applications with pleasant aesthetics.","theta":"310","editStatus":"In Editing","faded":"","lastModified":"2012-10","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"UIAutomator","id":"524","quadrant":"tools","ring":"Assess","movement":"t","radarId":"101","radius":"312","description":"UIAutomator looks like the most promising tool for testing Android user interfaces by allowing fine-grained control over components during test and facilitating testing on multiple Devices.","theta":"40","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Vumi","id":"570","quadrant":"platforms","ring":"Assess","movement":"t","radarId":"100","radius":"305","description":"","theta":"236","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Windows infrastructure automation","id":"401","quadrant":"techniques","ring":"Adopt","movement":"t","radarId":"102","radius":"130","description":"","theta":"95","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"WS-*","id":"234","quadrant":"platforms","ring":"Hold","movement":"c","radarId":"103","radius":"375","description":"We are reiterating our advice that given the progress and acceptance of simpler web-as-platform techniques such as REST and OAuth and the known issues with WS-*, it should only be used cautiously.","theta":"190","editStatus":"Include w/o Write Up","faded":"","lastModified":"2011-07","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2013-05"},{"name":"Zepto.js","id":"668","quadrant":"platforms","ring":"Assess","movement":"t","radarId":"104","radius":"312","description":"Zepto.js is a lightweight JavaScript library that is largely based on JQuery. The API is identical to JQuery although it does not offer full compatibility with it. With a vastly compressed file size, Zepto is a compelling option when building responsive web Applications.","theta":"268","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2013-05"}],"date":"2013-05"},{"blips":[{"name":"Capturing client-side JavaScript errors","id":"545","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"1","radius":"50","description":"Capturing client-side JavaScript errors has helped our delivery teams identify issues specific to a browser or plug-in configuration that impact user experience. Over the past year a number of service providers have started to surface in support of this requirement. Other than storing these errors in application data stores, web applications can log this data to web analytics or existing monitoring tools such as New Relic to offload storage requirements.","theta":"110","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Continuous delivery for mobile devices","id":"528","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"2","radius":"120","description":"Since the last radar a few advances have made continuous delivery for native apps on mobile devices less painful. Xctool, the recently open-sourced \u0027better xcodebuild\u0027 improves iOS build automation and unit testing. The arrival of automatic updates in iOS7 reduces the friction of regular releases. Travis-CI now supports OS X agents, removing another hurdle in seamless CD pipelines for mobile platforms. Our advice from the last radar on the value of hybrid approaches and the importance of test automation for mobile still applies.","theta":"150","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Mobile testing on mobile networks","id":"526","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"3","radius":"80","description":"We increasingly see mobile applications that work really well during development and testing, but run into trouble when they are deployed in the real world. Mobile testing on mobile networks reveals how your app performs under a variety of conditions. You might test using 3G or LTE or deliberately use a poor WiFi network with overloaded access points. Measure network performance for your target environment, then simulate the conditions using latency and packet-loss inducing tools. In addition, it is sometimes necessary to examine exactly how your device and software are using the network with a tool such as Wireshark.","theta":"110","editStatus":"Include w/o Write Up","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Segregated DOM plus node for JS Testing","id":"698","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"4","radius":"120","description":"","theta":"100","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Windows infrastructure automation","id":"401","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"5","radius":"60","description":"Previously, support for Windows in tools like Chef and Puppet was lacking, leading to large amounts of Powershell scripting to achieve simple infrastructure automation tasks. Achieving the same level of automation for Windows was more challenging than for Unix. In the last 12 months however, both Chef and Puppet support for Windows has improved drastically.  That support, combined with the inherent power of Powershell makes Windows infrastructure automation extremely viable.","theta":"150","editStatus":"Include w/o Write Up","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Capture domain events explicitily","id":"706","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"6","radius":"210","description":"","theta":"170","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Client and server rendering with same code","id":"707","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"7","radius":"260","description":"Increasingly, HTML is rendered not only on the server but also on the client, in the web browser. In many cases this split rendering will remain a necessity but with the growing maturity of JavaScript templating libraries an interesting approach has become viable: client and server rendering with same code.","theta":"120","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"HTML5 storage instead of cookies","id":"660","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"8","radius":"180","description":"HTML5 storage, also known as local storage or web storage, is a mechanism for storing client side data in modern browsers, including iOS and Android mobile browsers. We recommend using HTML5 storage instead of cookies in almost all cases. HTML5 Storage can accommodate up to 5MB of data while cookies are limited to 4KB. Cookie data is transmitted in every request, which slows down your application and potentially exposes data over insecure HTTP connections. In contrast, HTML5 storage data remains securely in the browser. Cookies should be reserved for storing small simple pieces of data like a session ID.","theta":"100","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Instrument all the things","id":"708","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"9","radius":"250","description":"You cannot act on important business events unless you monitor them. The principle, instrument all the things, encourages us to think proactively about how we achieve this at the start of our software development.This allows us to expose key metrics, monitor them, and report on them to improve operational effectiveness.","theta":"140","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Masterless Chef/Puppet","id":"709","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"10","radius":"210","description":"","theta":"130","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Microservices","id":"395","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"11","radius":"170","description":"We are seeing an uptick in adoption of microservices as a technique for distributed system design, both in Thoughtworks and in the wider community. Frameworks such as Dropwizard and practices like declarative provisioning point to a maturing of the technologies and tools. Avoiding the usual monolithic approach and being sympathetic to the need to replace parts of systems individually has important positive implications for the total cost of ownership of systems. We see this as having greatest impact in the mid-to-long term, specifically with respect to the two-to-five year rewrite cycle.","theta":"150","editStatus":"Include w/o Write Up","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Perimeterless enterprise","id":"574","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"12","radius":"200","description":"","theta":"115","editStatus":"Include w/o Write Up","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Provisioning testing","id":"710","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"13","radius":"225","description":"","theta":"100","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Structured logging","id":"711","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"14","radius":"160","description":"","theta":"130","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Bridging physical and digital worlds with simple hardware","id":"700","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"15","radius":"317","description":"","theta":"150","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Collaborative analytics and data science","id":"628","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"16","radius":"285","description":"For years, teams and organizations have seen the dangers of siloing expertise around technical disciplines. While we value input from experts on advanced applications, developers should have basic knowledge of user interfaces, databases, and data science, the newest industry darling. While advanced applications requires deep expertise, we are pushing for collaborative analytics and data science, where all developers use basic statistical analysis and tools to make better decisions, and work closely with experts when things get complicated.","theta":"160","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Datensparsamkeit","id":"699","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"17","radius":"290","description":"","theta":"140","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Development environments in the cloud","id":"633","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"18","radius":"310","description":"","theta":"110","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Focus on mean time to recovery","id":"623","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"19","radius":"290","description":"In previous radars we recommended arranging automated acceptance tests into longer journeys and, in what we call semantic monitoring, running these tests continuously against a production environment. We still believe that this is an important technique for scenarios the team can anticipate in advance. A variation of this approach, seen especially with startups, is to reduce the number of tests while increasing  monitoring and automatic alarms.  This shifts the focus from avoiding problems that can be anticipated to reducing mean time to recovery for all problems.","theta":"130","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Machine image as a build artifact","id":"625","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"20","radius":"310","description":"Most virtualization technologies provide a way to launch a machine from an image. By creating a machine image as a build artifact early in your build pipeline and promoting it through the pipeline as it passes further suites of tests, you can reliably deploy the exact machine that passed the tests into production. This technique eliminates most causes of the snowflake server anti-pattern.","theta":"170","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Tangible interaction","id":"701","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"21","radius":"320","description":"","theta":"100","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Cloud lift and shift","id":"702","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"22","radius":"375","description":"","theta":"130","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Ignoring OWASP Top 10","id":"703","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"23","radius":"375","description":"","theta":"170","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Siloed metrics","id":"704","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"24","radius":"375","description":"As more businesses move online we have noted a tendency to end up with siloed metrics. Specific tools are implemented to gather and display specific metrics: one tool for page-views and browser behavior, another for operational data and another to consolidate log messages. This leads to data silos and the need to swivel-chair integrate between the tools in order to gather business intelligence that is crucial to running the business. This is a tool-led split in the analytics domain that hurts the team’s ability to make decisions. A much better solution is to have a consolidated view of near-real time analytics using integrated dashboards displaying time-sensitive domain and team relevant information.","theta":"110","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Velocity as productivity","id":"705","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"25","radius":"375","description":"","theta":"150","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Elastic Search","id":"667","quadrant":"Platforms","ring":"Adopt","movement":"c","radarId":"26","radius":"115","description":"Over the past year we have seen a gradual uptake in the adoption of Elastic Search as an open source search platform. It is an extensible, multi-tenanted, and horizontally scalable search solution based on Apache Lucene. It allows complex data structures to be indexed and retrieved through a JSON based REST API. It provides an elegant model of operation with automatic discovery of peers in a cluster, failover, and replication. Elastic Search can be extended with a plugin system that allows adding new functionality and changing existing behavior. The community around this tool is quite vibrant as illustrated by the number of client libraries available in languages like Java, C#, Ruby, and JavaScript.","theta":"225","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"MongoDB","id":"508","quadrant":"Platforms","ring":"Adopt","movement":"c","radarId":"27","radius":"40","description":"For problems that fit the document database model, MongoDB is now the most popular choice. In addition to ease of use and a solid technical implementation, the community and ecosystem contributed to this success. We are aware of problems where teams were tempted by the popularity of MongoDB when a document database was not a good fit or they did not understand the inherent complexity. When used appropriately, however, MongoDB has proven itself on many projects.","theta":"215","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Neo4J","id":"460","quadrant":"Platforms","ring":"Adopt","movement":"c","radarId":"28","radius":"115","description":"Graph databases store information as arbitrarily interconnected nodes linked by named relations, rather than as tables and joins. Schema-less and highly extensible, they are an excellent choice for modelling semi-structured data in complex domains. Neo4j is the front-runner in the space both its REST API and its Cypher query language support simple and fast storage and traversal of graphs.","theta":"255","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Node.js","id":"280","quadrant":"Platforms","ring":"Adopt","movement":"t","radarId":"29","radius":"128","description":"Node.js is a lightweight web container that is a strong option for development of micro services and as a server to mobile and single-page web applications. Due to the asynchronous nature of node.js, developers are turning to promise libraries to simplify their application code. As the use of promises mature within the node.js community, we expect to see more applications developed for node.js. For those teams that are reluctant to try node.js in production, it is still worthwhile to consider node.js for development tasks like running JavaScript tests outside of the browser or generating static web content from tools like CoffeeScript, SASS, and LESS.","theta":"205","editStatus":"Include w/o Write Up","faded":"","lastModified":"2014-01","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Redis","id":"534","quadrant":"Platforms","ring":"Adopt","movement":"c","radarId":"30","radius":"75","description":"Redis has proven a useful tool on multiple Thoughtworks projects, used as both structured cache and data store distributed across multiple countries.","theta":"200","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"SMS and USSD as a UI","id":"562","quadrant":"Platforms","ring":"Adopt","movement":"c","radarId":"31","radius":"70","description":"58%  of all phones sold last year globally were feature phones. In many developing countries, this is an even larger majority. If your market requires you to develop for these areas, you need to develop with this constraint in mind. These phones use SMS and USSD as a user interface. SMS is a long standing technique for sending messages, and USSD allows you to send SMS like messages in a secure session.  You should look at USSD and SMS as another UI and UX platform and treat them as first-class citizens.","theta":"235","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Hadoop 2.0","id":"674","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"32","radius":"170","description":"","theta":"210","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Hadoop as a service","id":"697","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"33","radius":"240","description":"We observe organizations that have piloted Hadoop successfully starting to consolidate their Hadoop infrastructure services into a centralized, managed platform before rolling it out across the enterprise.These Hadoop as a service platforms are characterized by the control tier that interfaces with and coordinates among different core Hadoop infrastructure components. The capabilities of the platform are usually exposed via higher-level abstractions to the enterprise. Such a managed platform gives organizations the ability to deploy processes, infrastructure and datasets in a fairly consistent way across the organization. These services are built in private data centers and public cloud infrastructure.","theta":"225","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"OpenStack","id":"604","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"34","radius":"200","description":"The open source OpenStack project is gathering steam, and in recent months is becoming a more viable platform for deploying your own private clouds. Many issues which made OpenStack hard to get up and running have been addressed, and new features are being added all the time. It is clear that the OpenStack consortium and its members like Rackspace, Redhat, and HP are committed to the project as the basis for their own OpenStack-based cloud services.","theta":"240","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"PostgreSQL for NoSQL","id":"643","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"35","radius":"241","description":"","theta":"256","editStatus":"Include w/o Write Up","faded":"","lastModified":"2014-01","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Vumi","id":"570","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"36","radius":"240","description":"Vumi is a scalable open source messaging engine driving conversations through frugal methods on mobile devices. Vumi facilitates SMS, IM and USSD interactions between companies and their clients, health services and their patients, governments and citzens, and more. Vumi integrates with telcos and allows you to build apps on top of it easily. You only have to pay for carrier charges.","theta":"195","editStatus":"Include w/o Write Up","faded":"","lastModified":"2014-01","quadrantSortOrder":"3","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Akka","id":"688","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"37","radius":"327","description":"Akka is a toolkit and runtime for building highly concurrent, distributed, and fault tolerant event-driven applications on the JVM. It offers very lightweight event-driven processes with approximately 2.7 million actors per GB RAM and a \u0027let-it-crash\u0027model of fault-tolerance designed to work in a distributed environment. Akka can be used as a library for web-apps or as a stand-alone kernel to drop an application into.","theta":"255","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Backend as a service","id":"689","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"38","radius":"320","description":"The recent explosion of mobile-focused products, coupled with widespread adoption of \u0027Lean Start-up\u0027 approaches that put a premium on time-to-market for new ideas, has spawned an ecosystem of Backend as a service (BaaS) offerings that enable developers to focus on the client application while offloading backend concerns. Assess adding these services to your toolkit where fast and low-cost proving of a new product idea is important. Our usual advice on build/buy/borrow decisions still applies: be clear on which functional areas are strategic to your business and which are commodities. For potentially strategic areas be sure to plan a migration path that will allow you to use the BaaS provider to get started quickly, while avoiding friction when your architecture evolves and you need to migrate to owning this functionality and customizing it as a differentiator.","theta":"210","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Low-cost robotics","id":"690","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"39","radius":"320","description":"","theta":"193","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"PhoneGap/Apache Cordova","id":"532","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"40","radius":"300","description":"PhoneGap, now renamed as Apache Cordova, is a platform that lets you develop cross-platform mobile applications using HTML, CSS and JavaScript. It abstracts away platform specific native code through a set JavaScript APIs that remain consistent across different mobile platforms. Cordova is available for a wide array of platforms including iOS, Android, Blackberry, Windows Phone, and WebOS.","theta":"200","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Private Clouds","id":"691","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"41","radius":"294","description":"The need for physically storing data within nations or organizations has increased significantly in recent years. There is concern around sensitivity of information hosted in cloud environments. Organizations are looking into private cloud as an alternative when data that needs to be housed in close proximity with control over access and distribution. Private cloud offers cloud infrastructure provisioned for exclusive use by a single organization with the following characteristics; on-demand self-service, broad network access, resource pooling, rapid elasticity and measured service.","theta":"218","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"SPDY","id":"692","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"42","radius":"329","description":"","theta":"233","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Storm","id":"693","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"43","radius":"319","description":"","theta":"246","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Web Components standard","id":"694","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"44","radius":"329","description":"","theta":"225","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"3","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Big enterprise solutions","id":"600","quadrant":"Platforms","ring":"Hold","movement":"c","radarId":"45","radius":"375","description":"","theta":"200","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"CMS as a platform","id":"696","quadrant":"Platforms","ring":"Hold","movement":"t","radarId":"46","radius":"375","description":"","theta":"251","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Enterprise Data Warehouse","id":"695","quadrant":"Platforms","ring":"Hold","movement":"t","radarId":"47","radius":"375","description":"","theta":"228","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"3","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"D3","id":"500","quadrant":"Tools","ring":"Adopt","movement":"c","radarId":"48","radius":"100","description":"\u003ca href\u003d\u0027http://d3js.org/\u0027\u003eD3\u003c/a\u003e continues to gain traction as a library for creating rich visualisations in the browser. Previously, it was somewhat low-level, requiring more work for the creation of commonly used visualisations than less sophisticated, more targeted libraries. Since the last radar, libraries like Rickshaw for charting and Crossfilter for in-browser dataset exploration have helped make D3 even more accessible than before.","theta":"60","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Dependency management for JavaScript","id":"712","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"49","radius":"32","description":"","theta":"35","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"2","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Ansible","id":"720","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"50","radius":"182","description":"In the category of DevOps orchestration engines, Ansible has nearly universal acclaim within Thoughtworks projects. It has useful tools and abstractions at a useful level of granularity.","theta":"52","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Calabash","id":"721","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"51","radius":"232","description":"On mobile projects, we have been impressed with the functionality and gradually evolving capabilities and maturity of Calabash. It is an automated acceptance test tool for both Android and iOS applications that supports common ecosystem tools like Cucumber. It is an attractive choice on heterogeneous projects.","theta":"45","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Chaos Monkey","id":"722","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"52","radius":"205","description":"","theta":"71","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Gatling","id":"655","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"53","radius":"220","description":"Gatling is another newer player in the automated performance testing space. It is similar to Locust and is much lighter weight than the older options such as JMeter and Grinder. Built on Scala, the DSL provides extensive functionality out of the box including easily configured data feeds and response assertions. In cases where customization is needed, it is easy to drop into Scala to provide extensions. The default generation of numerous dynamic views of the data via Highcharts adds to its appeal.","theta":"35","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Grunt.js","id":"723","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"54","radius":"184","description":"Several of our Thoughtworks teams developing Node.js apps are using Grunt to automate most of the development activities like minification, compilation, and linting. Many of the common tasks are available as Grunt plugins. You can even programmatically generate the configuration if necessary.","theta":"17","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Hystrix","id":"554","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"55","radius":"245","description":"Managing the web of dependencies in a distributed system is complicated, and is a problem more people are facing with the move to finer-grained microservices. Hystrix is a library for the JVM from Netflix that implements patterns for dealing with downstream failure, offers real-time monitoring of connections, and caching and batching mechanisms to make inter-service dependencies more efficient. In combination with hystrix-dashboard and Turbine, this tool can be used to build more resilient systems and provide near-real time data on throughput, latency and fault tolerance.","theta":"17","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Icon fonts","id":"622","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"56","radius":"220","description":"With the rise of devices with multiple form factors and pixel densities, the issue of presenting high quality icons at all scales has become important. Icon fonts solve this problem by using browser support for WebFonts and SVG instead of scaled images or maintaining different icon sets. As always, when making extensive use of SVG, pay attention to power consumption on mobile devices and performance on older devices.","theta":"25","editStatus":"Include w/o Write Up","faded":"","lastModified":"2014-01","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Librarian-puppet and Librarian-Chef","id":"557","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"57","radius":"212","description":"Both Puppet and Chef have had to deal with sharing community-contributed modules and manifests for commonly used services and tasks. Both the Puppet Forge and Chef’s Cookbook repository have helped, but people ended up copying and pasting these recipes into their own codebases, preventing them from taking advantage of later bugfixes and improvements. Librarian-puppet and Librarian-Chef attempt to solve this by making it easy to declare your module dependencies, including pulling in known versions of code from these community sites.","theta":"7","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Logstash \u0026 Graylog2","id":"638","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"58","radius":"170","description":"As the systems we build involve more fine-grained services spread across more machines than ever before, the challenge of how to get information aggregated to allow for easy problem identification and resolution is more pressing than ever. Logstash has emerged as an easy way to parse and filter logs at source, and then forward them to a single aggregation point. Although Logstash provides some searching and filtering, Graylog2 is often used in conjunction to provide for more fully-featured querying and reporting.","theta":"62","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Moco","id":"724","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"59","radius":"192","description":"","theta":"44","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"PhantomJS","id":"583","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"60","radius":"235","description":"We see interest on Thoughtworks projects around PhantomJS, a headless web testing tool that allows functional testing against a realistic target.","theta":"60","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Prototype On Paper","id":"725","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"61","radius":"235","description":"","theta":"84","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"SnapCI","id":"726","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"62","radius":"184","description":"","theta":"29","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Snowplow Analytics \u0026 Piwik","id":"646","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"63","radius":"245","description":"","theta":"75","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"2","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Cloud-init","id":"713","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"64","radius":"309","description":"Cloud-init is a simple but powerful technique for carrying out actions on a cloud instance at boot time. It is particularly useful when used with instance metadata to allow a newly booted instance to pull the configuration, dependencies and software needed to perform a particular role. When used together with the Immutable or Phoenix server pattern, this can create a very responsive and light-weight mechanism for managing deployments in the cloud.","theta":"11","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Docker","id":"714","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"65","radius":"300","description":"The Docker open-source project has generated a great deal of interest within Thoughtworks, and is growing in momentum and maturity. Docker allows applications to be packaged and published as portable lightweight containers that run identically on a laptop or a production cluster. It provides tooling for the creation and management of application containers, and a run-time environment based on LXC (LinuX Containers).","theta":"40","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Octopus","id":"560","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"66","radius":"312","description":"Windows infrastructure automation should be adopted, however it still remains more difficult than automation on a Unix platform. Tools like Chef and Puppet are increasing their support, but there are also Windows specific solutions being developed like Octopus. Octopus allows automated deployment of your ASP.NET applications and Windows services and decreases dependency on PowerShell. It can be used with both NuGet using Octopak and TeamCity to create a full build, package, and deployment pipeline.","theta":"75","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Sensu","id":"715","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"67","radius":"312","description":"Many monitoring tools are built around the idea of the machine. We monitor what the machine is doing and which software is running on it. When it comes to cloud based infrastructure, especially patterns like Phoenix and Immutable servers this is a problematic approach. Machines come and go, but what is important is that the services remain working. Sensu allows a machine to register itself as playing a particular role and Sensu then monitors it on that basis. When we are finished with the machine we can simply de-register it.","theta":"58","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Travis for OSX/iOS","id":"716","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"68","radius":"309","description":"","theta":"67","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Visual regression testing tools","id":"717","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"69","radius":"333","description":"","theta":"24","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Xamarin","id":"718","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"70","radius":"337","description":"","theta":"49","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"2","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Ant","id":"719","quadrant":"Tools","ring":"Hold","movement":"t","radarId":"71","radius":"375","description":"","theta":"68","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Heavyweight test tools","id":"579","quadrant":"Tools","ring":"Hold","movement":"c","radarId":"72","radius":"375","description":"Many organizations that have moved to more agile ways of working continue to use heavyweight testing tools. These tools have problems that make them unsuitable for fast moving software delivery. Large complex tools have high learning curves and require specialist skills and training, making it hard for the team themselves to test. Often this results in an unnecessary overhead for every release as other teams get involved. Expensive and limiting software licenses makes this problem even worse. Some heavyweight tools use a \u0027model driven\u0027 approach where an attempt is made to accurately model the usage patterns of the application, which leads to costly test script maintenance and development time being lost to \u0027false positives\u0027. We have seen few situations where simple open source solutions cannot give the required level of confidence for much less time, effort and money.","theta":"59","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"TFS","id":"307","quadrant":"Tools","ring":"Hold","movement":"c","radarId":"73","radius":"375","description":"","theta":"54","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"2","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Clojure","id":"258","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radarId":"74","radius":"70","description":"Clojure is a dynamic, functional language that runs on the JVM. Although its roots are in Lisp, one of the oldest computer languages, it also embodies many modern programming concepts, including lazy evaluation and advanced concurrency abstractions. Clojure has spawned a vibrant community of programmers who are contributing a rich set of frameworks and tools. One example of these is Midje, an innovative spin on unit testing and mocking frameworks.","theta":"280","editStatus":"Include w/o Write Up","faded":"","lastModified":"2012-10","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Dropwizard","id":"519","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"75","radius":"130","description":"","theta":"290","editStatus":"Include w/o Write Up","faded":"","lastModified":"2014-01","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Scala, the good parts","id":"257","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radarId":"76","radius":"100","description":"","theta":"300","editStatus":"In Editing","faded":"","lastModified":"2011-01","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Sinatra","id":"516","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radarId":"77","radius":"125","description":"Micro-frameworks are emerging as a way to handle increasing complexity in applications both on client- and server-side. Sinatra was one of the first examples of that trend in the server-side space, exposing a lightweight DSL to build fast services that can be easily composed. Similar offerings are available for other languages, including Spark for Java, Flask for Python, Sclatra for Scala, Compojure for Clojure and Nancy for .NET.","theta":"315","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"4","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"CoffeeScript","id":"648","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"78","radius":"225","description":"The expansion of single-page and mobile browser-based applications into mainstream use, along with continued growth of node.js for server-side applications, have led to increased adoption of CoffeeScript to simplify JavaScript codebases. As a language that compiles into JavaScript code for runtime execution, many concerns have been raised about the difficulty of debugging applications written in CoffeeScript. The introduction of Source Maps in CoffeeScript 1.6.1 is helping producers of development tools address this concern.  We expect this will lead to further adoption of the language following the lead of highly visible technology firms such as Dropbox.","theta":"337","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Go language","id":"684","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"79","radius":"252","description":"The Go language was originally developed by Google as a system programming language to replace C \u0026 C++. Four years out, Go is gaining traction in other areas. The combination of very small, statically linked binaries combined with an excellent HTTP library means Go has been popular with organizations making use of finer-grained, microservice architectures.","theta":"296","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Hive","id":"685","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"80","radius":"175","description":"","theta":"281","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Play Framework 2","id":"669","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"81","radius":"225","description":"","theta":"310","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Reactive Extensions across languages","id":"686","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"82","radius":"199","description":"Reactive Programming deals with streams or values that change over time. Using elements of data flow, implicit concurrency and transparent event propagation, these techniques enable efficient handling of events on a large scale with a high degree of efficiency and low latency. In the previous radar, we mentioned Reactive Extensions in .NET due to the extensive work done by Microsoft in making Rx a core part of the .NET framework. Since then, with the introduction of the Reactive Cocoa library for Objective C, the Java port of Reactive Extensions, the React JavaScript library, the Elm language based on Haskell \u0026 the Flapjax JavaScript library, we are extending this blip to include Reactive Extensions across languages.","theta":"328","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Web API","id":"687","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"83","radius":"205","description":"Until recently, Microsoft\u0027s Web API was the least-worst option for building a RESTful service using ASP.NET. Web API 2 fixes a number of rough edges with better support for flexible routing, sub-resources, media types and improved testability. It continues to be our preferred library for building .NET REST APIs.","theta":"348","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"4","ringSortOrder":"2","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Elixir","id":"676","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"84","radius":"335","description":"Elixir is a dynamic, functional, homoiconic programming language built on top of the Erlang virtual machine with a powerful macro system that makes it ideal for building Domain Specific Languages. Elixir has distinctive features such as the Pipe operator that allows developers to build a pipeline of functions like you would in the UNIX command shell. The shared byte code allows Elixir to interoperate with Erlang and leverage existing libraries while supporting tools such as the Mix build tool, the Iex interactive shell and the ExUnit unit testing framework. It is a practical alternative to Erlang for building DSLs.","theta":"280","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Julia","id":"677","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"85","radius":"324","description":"","theta":"345","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Nancy","id":"630","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"86","radius":"285","description":"Nancy is a lightweight, open-source web framework for .NET.  In the spirit of Sinatra for Ruby, Nancy provides just the essentials necessary to implement web applications with minimal extraneous code.  Because the framework is independent of any particular hosting environment, the developer is freed from the IIS and ASP.NET environment.  This makes Nancy an excellent complement to OWIN and compatible with other OWIN modules.  We are really happy to see the emergence of lightweight web frameworks in a number of other languages as well; Spark for Java, Flask for Python, etc..","theta":"331","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"OWIN","id":"637","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"87","radius":"285","description":"One thing that has slowed the evolution of a rich, open source web development ecosystem on the .NET platform has been over-dependence on IIS and the ASP.NET framework.  OWIN specifies an open HTTP handling interface that decouples web server from application much like Rack has done for the Ruby community.  We are excited about OWIN because it opens up the possibility of new .NET web development tools composed of simple, independently-developed modules.  Nancy is the perfect example of this.  We also hope it will increase the practice of deploying web applications as standalone, self-hosted services on the .NET platform.","theta":"354","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Pester","id":"678","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"88","radius":"305","description":"","theta":"315","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Pointer Events","id":"680","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"89","radius":"321","description":"","theta":"327","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Python 3","id":"679","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"90","radius":"285","description":"","theta":"284","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"TypeScript","id":"681","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"91","radius":"333","description":"","theta":"322","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Yeoman","id":"682","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"92","radius":"295","description":"Yeoman attempts to make web application developers more productive by simplifying activities like scaffold, build and package management. It is a collection of the tools Yo, Grunt and Bower that work well as a set.","theta":"303","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"4","ringSortOrder":"3","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"Handwritten CSS","id":"594","quadrant":"languages-and-frameworks","ring":"Hold","movement":"c","radarId":"93","radius":"375","description":"","theta":"330","editStatus":"Include w/o Write Up","faded":"","lastModified":"2013-04","quadrantSortOrder":"4","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2014-01"},{"name":"JSF","id":"683","quadrant":"languages-and-frameworks","ring":"Hold","movement":"t","radarId":"94","radius":"375","description":"","theta":"322","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"4","ringSortOrder":"4","type":"Blip","urlLabel":"","volume":"2014-01"}],"date":"2014-01"},{"blips":[{"name":"Forward Secrecy","id":"764","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"1","radius":"90","description":"\u003cb\u003eForward Secrecy\u003c/b\u003e (sometimes known as \u0026quot;Perfect Forward Secrecy\u0026quot; or PFS) is a cryptographic technique that protects previous communications sessions even if a server’s master keys are later compromised. Despite being simple to enable for HTTPS connections, many servers are not configured this way, and we recommend enabling forward secrecy to improve security. Note that we don\u0027t generally like the word \u0026quot;perfect\u0026quot; when used to describe cryptographic protocols - even the best protocol can be broken by a flaw in implementation, random number generator, or by advances in cryptanalytic techniques. Even so, it\u0027s important to enable the best security available, whilst keeping informed of new attacks and protocol improvements.","theta":"        150","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Segregated DOM plus node for JS Testing","id":"698","quadrant":"Techniques","ring":"Adopt","movement":"c","radarId":"2","radius":"120","description":"As client-side JavaScript applications grow in sophistication, we see an increased need for engineering sophistication to match. A common architectural flaw is unfettered access to the DOM from across the codebase - mixing DOM manipulation with application logic and AJAX calls. This makes the code difficult to understand and extend. Thinking about separation of concerns is a useful antidote, aggressively restricting all DOM access (usually jQuery usage) to a thin \u0027segregation layer\u0027. One pleasant side-effect of this approach is that everything outside of the \u003cb\u003esegregated DOM\u003c/b\u003e layer can be tested rapidly in isolation from the browser using a lean JavaScript engine such as \u003cb\u003enode.js.\u003c/b\u003e","theta":"        120","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Capture domain events explicitly","id":"706","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"3","radius":"210","description":"When using techniques such as \u0026quot;instrument all the things\u0026quot; and semantic logging, it can be very useful to \u003cb\u003ecapture domain events explicitly\u003c/b\u003e. You can avoid having to infer user intent behind state transitions by modeling these transitions as first-class concerns. One method of achieving this outcome is to use an event sourced architecture with application events being mapped to business meaningful events.","theta":"        175","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Development environments in the cloud","id":"633","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"4","radius":"250","description":"\u003cb\u003eDevelopment environments in the cloud\u003c/b\u003e allow you to entirely outsource development infrastructure, leaving your team with nothing more than laptops and an internet connection. By using a combination of best-of-breed services such as private GitHub repositories and Snap CI\u0027s continuous integration in the cloud, your teams may never need to bother in-house IT for infrastructure again.","theta":"        169","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Event Sourcing","id":"738","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"5","radius":"200","description":"\u003cb\u003eEvent Sourcing\u003c/b\u003e ensures that all changes to application state are stored as a sequence of events. Not only can we query these events, we can also use the event log to reconstruct past states, and as a foundation to automatically adjust the state to cope with retroactive changes. Complementary to the capture of business meaningful events, the technique has positive implications for analytics in driving greater customer insight.","theta":"        164","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Focus on mean time to recovery","id":"623","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"6","radius":"220","description":"In DevOps-savvy organizations delivery teams often configure production monitoring and respond to incidents themselves. This visibility and access into production environments allows those teams to make changes to their systems to improve their ability to recover quickly when something goes wrong. This \u003cb\u003efocus on mean time to recovery\u003c/b\u003e improves quality of service overall, and allows teams to safely deploy more frequently. This can also reduce the emphasis on expensive test execution in non-production environments. Techniques we\u0027ve used include end-to-end \u0027semantic monitoring\u0027 or reconciliation of real business transactions, and the injection of \u0027synthetic transactions\u0027 which exercise systems in non-destructive ways in production.","theta":"        158","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Humane registry","id":"747","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"7","radius":"255","description":"A Microservice architecture by its very nature increases significantly the number of applications, services, and interactions in your deployed environments. Our projects are showing renewed focus on building \u003ca href\u003d\u0027http://martinfowler.com/bliki/HumaneRegistry.html\u0027\u003e\u003cb\u003eHumane Registries\u003c/b\u003e\u003c/a\u003e which aggregate information about running services from the live environment and present it in a form for humans to comprehend. These registries favor up-to-date information from running services instead of human-curated documentation.","theta":"        152","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Inverse Conway Maneuver","id":"749","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"8","radius":"200","description":"Conway\u0027s Law asserts that organizations are constrained to produce application designs which are copies of their communication structures. This often leads to unintended friction points. The \u0027\u003cb\u003eInverse Conway Maneuver\u003c/b\u003e\u0027 recommends evolving your team and organizational structure to promote your desired architecture. Ideally your technology architecture will display isomorphism with your business architecture.","theta":"        147","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Living CSS Style Guides","id":"752","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"9","radius":"180","description":"A \u003cb\u003eliving CSS style guide\u003c/b\u003e is a page on your site that uses your current CSS styles and acts as a reference for all the currently available visual elements and design patterns. This helps to tightly integrate design into your delivery process by promoting co-ownership of the UI and avoids duplication of styling across your application. Styling changes are visible in the guide immediately and changes propagate across your site from a central location. A sensible way to do this is with a well organized SASS/LESS file structure with semantically named elements that separates structure, aesthetics, and interaction.","theta":"        141","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Machine image as a build artifact","id":"625","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"10","radius":"240","description":"Many of our teams are getting great benefit from publishing virtual \u003cb\u003emachine images as a build artifact\u003c/b\u003e during their automated build processes. These machine images are published with the application and all dependencies, often in an immutable state. With minimal additional configuration the image can be used to create identical virtual machines in all environments eliminating many common sources of error and waste. Tools are emerging to make this approach simpler, for example Packer in the tools section of the Radar. This approach is working well in companies that take a mature approach to cloud and virtualization, and where delivery teams have responsibility and access right through to production.","theta":"        135","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Masterless Chef/Puppet","id":"709","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"11","radius":"210","description":"Chef and Puppet servers are a central place to store recipes/manifests that propagate configuration changes to managed machines. They are also a central database of node information and provide access control for manifests/recipes. The disadvantage of having these servers is that they become a bottleneck when multiple clients simultaneously connect to them. They are a single point of failure and take effort to be robust and reliable. In light of this, we recommend \u003cb\u003echef-solo or standalone puppet\u003c/b\u003e in conjunction with a version control system when the server is primarily used to store recipes/manifests. Teams can always introduce the servers as the need arises or if they find themselves reinventing solutions to the problems the servers have already solved.","theta":"        130","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Perimeterless enterprise","id":"574","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"12","radius":"200","description":"Technology trends have broken down the garden walls that used to surround corporate IT networks and lead to a \u003cb\u003eperimeterless enterprise\u003c/b\u003e. Employees frequently use their own consumer devices to access corporate data through cloud services and web APIs, often without the organization\u0027s knowledge. As devices continue to proliferate and more applications move to the cloud, businesses are being forced to rethink fundamental assumptions about data access and network security.","theta":"        124","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Provisioning testing","id":"710","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"13","radius":"225","description":"Virtualization and Cloud Computing have made it easy to procure and provision hardware and virtual servers. But with this flexibility comes scale and complexity, and managing our virtual estates has become increasingly difficult. Using techniques more familiar in the software development world such as TDD, BDD and CI offers an approach to managing this complexity and gives us the confidence to make changes to our infrastructure in a safe, repeatable and automatable manner. \u003cb\u003eProvisioning testing\u003c/b\u003e tools, like rspec-puppet, Test Kitchen and serverspec, are available for most platforms.","theta":"        119","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Front end instrumentation","id":"763","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"14","radius":"225","description":"With the proliferation of single-page JavaScript applications, we have found that slow Ajax calls, excessive DOM manipulation, and unexpected JavaScript errors in the browser can have a big impact on perceived website responsiveness. It is very useful to collect and aggregate this profiling information from real end-users\u0027 browsers. \u003ca href\u003d\u0027http://newrelic.com/real-user-monitoring\u0027\u003e\u003cb\u003eReal user monitoring\u003c/b\u003e\u003c/a\u003e provides early warning and diagnosis of production issues, and helps pinpoint them to a specific locality.","theta":"        113","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"REST without PUT","id":"769","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"15","radius":"170","description":"In the last radar we talked about Capturing Explicit Domain Events, putting emphasis on recording the business-meaningful events that have triggered state transitions instead of just CRUD\u0027ing entities. REST interfaces commonly use PUT to update resource state, however it\u0027s often better to POST to record a new event resource which captures intent. \u003cb\u003eREST without PUT \u003c/b\u003ehas a side-benefit of separating command and query interfaces and forces consumers to allow for eventual consistency.","theta":"        107","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Structured logging","id":"711","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"16","radius":"160","description":"Treating logs as data gives us greater insight into the operational activity of the systems we build. \u003cb\u003eStructured logging\u003c/b\u003e, which is using a consistent, predetermined message format containing semantic information, builds on this technique and enables tools such as Graylog2 and Splunk to yield deeper insights.","theta":"        102","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Tailored Service Template","id":"777","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"17","radius":"237","description":"We see multiple organizations creating a \u003cb\u003eTailored Service Template\u003c/b\u003e which can be used to quickly seed new services, pre-configured to operate within that organization\u0027s production environment. The template contains a default set of decisions such as web frameworks, logging, monitoring, build, packaging, and deployment approaches. This is a very useful technique for encouraging collaborative evolution while retaining lightweight governance.","theta":"        96","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Bridging physical and digital worlds with simple hardware","id":"700","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"18","radius":"317","description":"The reduction in cost, size, power consumption and simplicity of physical devices has led to an explosion in devices that open physical domains to software. These devices often contain little more than a sensor and a communication component like Bluetooth Low Energy or WiFi. As software engineers, we need to expand our thinking to include \u003cb\u003ebridging physical and digital worlds with simple hardware\u003c/b\u003e. We are already seeing this in the car, the home, the human body, agriculture and other physical environments. The cost and time required to prototype such devices is shrinking to match the fast iterations possible in software.","theta":"        168","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Datensparsamkeit","id":"699","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"19","radius":"290","description":"In our desire to support ever-changing business models, learn from past behavior and provide the best experience for every individual visitor, we are tempted to record as much data as possible. At the same time hackers are more ferocious than ever, with one spectacular security breach after another, and we now know of unprecedented mass-surveillance by government agencies. The term \u003cb\u003eDatensparsamkeit\u003c/b\u003e is taken from German privacy legislation and describes the idea to only store as much personal information as is absolutely required for the business or applicable laws. Some examples are instead of storing a customer\u0027s full IP address in access logs, just using the first two or three octets and instead of logging transit journeys with a username using an anonymous token. If you never store the information, you do not need to worry about someone stealing it.","theta":"        155","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Machine image pipelines","id":"753","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"20","radius":"300","description":"Many deployments require machine images for different server roles like applications and services, databases, and reverse proxies. Because building a machine image from scratch, using an operating system ISO and provisioning scripts, can take a considerable amount of time it can be useful to create a \u003cb\u003ebuild pipeline for machine images\u003c/b\u003e. The first stage in the pipeline sets up a base image according to general standards in the organization. Subsequent stages can then enhance the base image for different purposes. If several applications or services have similar requirements, an application server for example, the pipeline can be extended by an intermediate stage, which takes the base image and provides an image with an application server but no application/service. These pipelines are not linear, they are trees that are branching out from the base image.","theta":"        142","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Pace-layered Application Strategy","id":"759","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"21","radius":"317","description":"Gartner\u0027s \u003cb\u003ePace-layered Application Strategy\u003c/b\u003e approach to architecture attempts to articulate the fact that decisions about architecture shouldn\u0027t be a one-size-fits-all approach. Instead, it is important to take a balanced view to your technology portfolio in terms of where to be conservative, and where to take risks. While we have qualms about some of the more prescriptive recommendations that seem to come with Pace, in general we like the concept and many organizations could benefit from adapting similar models.","theta":"        129","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Property-based unit testing","id":"765","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"22","radius":"325","description":"We value unit testing on projects and we like techniques such as \u003cb\u003eproperty-based unit testing\u003c/b\u003e which augment it. This is a practice of using data generators to create randomized inputs within defined ranges. It allows a quick check for boundary conditions and other unanticipated failure modes and has burgeoning support on multiple platforms.","theta":"        116","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Tangible interaction","id":"701","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"23","radius":"320","description":"As the lines between hardware and software continue to blur, we see traditional computing increasingly embedded in everyday objects. Although connected devices are now ubiquitous in retail spaces, automobiles, homes, and workplaces, we still do not understand how to blend them into a useful computing experience that goes beyond a simple glass screen. \u003cb\u003eTangible interaction\u003c/b\u003e is a discipline that blends software and hardware technology, architecture, user experience, and industrial design. The goal is to provide natural environments made up of physical objects where humans can manipulate and understand digital data.","theta":"        103","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Cloud lift and shift","id":"702","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"24","radius":"375","description":"As cloud adoption grows we are unfortunately seeing a trend to treat the cloud as just another hosting provider. \u003cb\u003eCloud lift and shift\u003c/b\u003e is unfortunately being encouraged by large vendors re-branding existing hosting offerings as \u0026quot;cloud.\u0026quot; Few of these offer any real flexibility or pay-as-you-use pricing. If you think you can move to the cloud without re-architecting, you are probably not doing it right.","theta":"        165","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"DevOps as a team","id":"734","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"25","radius":"375","description":"Some companies with good intentions create a separate \u003cb\u003eDevOps team\u003c/b\u003e, which misconstrues the definition of DevOps. Rather than a role, DevOps is a cultural movement encouraging collaboration between operations specialists and developers. Rather than create yet another silo and suffer the consequences of Conway\u0027s Law, we advise you to embed these skills into teams, improving feedback loops and communication pathways by removing friction.","theta":"        150","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Ignoring OWASP Top 10","id":"703","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"26","radius":"375","description":"Barely a week goes by without the IT industry being embarrassed by yet another high profile loss of data, leak of passwords, or breach of a supposedly secure system. There are good resources to help with making sure security gets treated as a first-class concern during software development and we need to stop ignoring them; the \u003cb\u003eOWASP Top 10\u003c/b\u003e is a good place to start.","theta":"        135","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Testing as a separate organization","id":"778","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"27","radius":"375","description":"We continue to see organizations create separate Development and QA teams. Fast feedback is a core tenet of Agile and critical to the success of a project. Using a separate QA team slows down this feedback, creates an \u0026quot;us and them\u0026quot; mentality and makes it more difficult to build quality into the software. Testing should be a tightly integrated activity and isn\u0027t something the team can outsource. We recommend integrated teams where testers work closely with developers instead of having \u003cb\u003etesting as a separate organization.\u003c/b\u003e","theta":"        120","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Velocity as productivity","id":"705","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"28","radius":"375","description":"Of all the approaches that we might disagree with, equating velocity with productivity has become so prevalent that we felt it important to call it out in our hold ring. When properly used, velocity allows the incorporation of \u0026quot;yesterday\u0027s weather\u0026quot; into the iteration planning process. Velocity is simply a capacity estimate for a given team at a given time. It can improve as a team gels or by fixing problems like technical debt or a flaky build server. However, like all metrics, it can be misused. For example, over-zealous project managers attempt to insist on continual improvement of velocity. Treating \u003cb\u003evelocity as productivity\u003c/b\u003e leads to unproductive team behaviors that optimize the metric at the expense of actual working software.","theta":"        105","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Hadoop 2.0","id":"674","quadrant":"Platforms","ring":"Adopt","movement":"c","radarId":"29","radius":"130","description":"Hadoop\u0027s initial architecture was based on the paradigm of scaling data horizontally and metadata vertically. While data storage and processing were handled by the slave nodes reasonably well, the masters that managed metadata were a single point of failure and limiting for web scale usage. \u003cb\u003eHadoop 2.0\u003c/b\u003e has significantly re-architected both HDFS and the Map Reduce framework to address these issues. The HDFS namespace can be federated now using multiple name nodes on the same cluster and deployed in a HA mode. MapReduce has been replaced with YARN, which decouples cluster resource management from job state management and eliminates the scale/performance issues with the JobTracker. Most importantly, this change encourages deploying new distributed programming paradigms in addition to MapReduce on Hadoop clusters.","theta":"        210","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Vumi","id":"570","quadrant":"Platforms","ring":"Adopt","movement":"c","radarId":"30","radius":"120","description":"In the last technology radar, we spoke about \u003cb\u003eVumi\u003c/b\u003e as a platform for using USSD as a UI for feature phones. Vumi has become very stable and its open source nature gives it appeal. In our projects, we have been able to integrate with telecommunication networks seamlessly and rapidly due to the simplicity of configuration. The platform is also readily available and scalable.","theta":"        240","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"iBeacon","id":"748","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"31","radius":"192","description":"\u003cb\u003eiBeacons\u003c/b\u003e are the Apple implementation of the broader category of beacons, which are small devices that use low energy Bluetooth (BLE) to provide fine-grained proximity information for mobile phones and other devices. Despite the hype surrounding iBeacons and the limitations to the accuracy and reliability of the information they provide, we do feel that they open interesting opportunities as trigger points for interacting with your users in a contextually relevant manner.","theta":"        202","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"PostgreSQL for NoSQL","id":"643","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"32","radius":"241","description":"\u003cb\u003ePostgreSQL\u003c/b\u003e is expanding to become the NoSQL choice of SQL databases. Version 9.2 includes the ability to store JSON data with full querying capabilities on the content of the JSON document. Other extensions let the user store and query data in the form of key/value pairs. This lets you take advantage of the underlying storage and transactional capabilities of a time-tested database without being tied to a relational data model. This is ideal for those who want both SQL and NoSQL applications but prefer a single reliable infrastructure that they already know how to support.","theta":"        225","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Private Clouds","id":"691","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"33","radius":"210","description":"The number and maturity of on-premise \u003cb\u003eprivate cloud\u003c/b\u003e options continue to increase. From OpenStack-based options like Rackspace\u0027s private cloud to PAAS options like CloudFoundry, for those organizations seeking to make use of existing infrastructure or for whom an increased level of control is needed over off-premise cloud, then these solutions are well worth a look.","theta":"        247","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"ARM Server SoC","id":"729","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"34","radius":"330","description":"AMD recently released an \u003ca href\u003d\u0027http://www.anandtech.com/show/7989/amd-announces-project-skybridge-pincompatible-arm-and-x86-socs-in-2015\u0027\u003e8-core \u003cb\u003eARM SoC\u003c/b\u003e (System on a Chip)\u003c/a\u003e designed for servers and has committed to releasing an ARM SoC with integrated graphics in 2015. ARM-based servers are an interesting alternative to x86 because they are significantly more energy efficient. For some workloads, building an ARM-powered Cloud is preferable.","theta":"        186","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"CoAP","id":"731","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"35","radius":"288","description":"\u003cb\u003eCoAP\u003c/b\u003e is an open standards communication protocol for the Internet of Things (IoT). While there is currently a proliferation of competing standards in the IoT space, we particularly like CoAP. It is specifically designed for resource-constrained devices and local radio networks. It uses UDP for transport, but is semantically compatible with HTTP. CoAP uses a web-based model of devices with their own URLs and a request-response paradigm that supports RESTful and decentralized approaches.","theta":"        193","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"DigitalOcean","id":"735","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"36","radius":"305","description":"Although the IaaS space is crowded, there is room for new competitors to enter the market. \u003ca href\u003d\u0027http://digitalocean.com\u0027\u003e\u003cb\u003eDigitalOcean\u003c/b\u003e\u003c/a\u003e has impressed us recently with its cost, speed and simplicity. If all you need is basic compute infrastructure, it is well worth a look.","theta":"        200","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Espruino","id":"737","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"37","radius":"305","description":"\u003cb\u003eEspruino\u003c/b\u003e is a microcontroller that natively executes JavaScript and thus lets the large number of JavaScript programmers get started very quickly. Using an event-based model similar to Node.js, Espurino devices can be very power efficient while still being responsive. Less powerful than a Raspberry Pi and slightly slower than an Arduino, Espruino makes an interesting alternative in low-power environments that need responsive behavior but can sacrifice some of the raw high level features and execution speed of those platforms.","theta":"        207","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"EventStore","id":"739","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"38","radius":"293","description":"Given the popularity of event sourcing, it is no surprise that tools in this space are maturing. \u003ca href\u003d\u0027http://geteventstore.com\u0027\u003e\u003cb\u003eEventStore\u003c/b\u003e\u003c/a\u003e is an open source functional database for storing immutable events and performing complex event processing on the event streams. Unlike other tools in this space, EventStore exposes event streams as Atom collections which therefore require no special infrastructure such as message buses or highly specialized clients to use.\u0026nbsp;","theta":"        214","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Low-cost robotics","id":"690","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"39","radius":"320","description":"With the cost of industrial robots dropping and their safety and ease of use increasing, the world of useful, commercial robotics is opening up. Robots like Rethink Robotics\u0027 Baxter or Universal Robotics\u0027 U5, make it feasible for small to medium-sized businesses to automate repetitive tasks previously performed by humans. Increasingly, enterprise software will have to integrate with \u003cb\u003elow-cost robotics\u003c/b\u003e as another participant in the value stream. The challenge lies in making the experience easy and productive for the human co-workers as well.","theta":"        221","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Mapbox","id":"754","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"40","radius":"330","description":"\u003ca href\u003d\u0027http://mapbox.com\u0027\u003e\u003cb\u003eMapbox\u003c/b\u003e\u003c/a\u003e is an open mapping platform we have used on several projects. It allows a developer to quickly add a map to an application and to style the map. Mapbox can serve as an alternative to conventional mapping platforms, and it also allows for mobile friendly maps.","theta":"        228","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"OpenID Connect","id":"757","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"41","radius":"339","description":"\u003cb\u003eOpenID Connect\u003c/b\u003e is a standard protocol for federated identity built on OAuth 2.0. It addresses a long-standing need for a simple, web-based protocol to exchange trusted authentication and authorization information. Previous standards like SAML or generic OAuth 2.0 have proven too broad and complex to ensure universal compatibility. Our hope is that OpenID Connect can provide a useful basis for secure access to RESTful microservices with authenticated end-user identity.","theta":"        235","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"SPDY","id":"692","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"42","radius":"329","description":"\u003cb\u003eSPDY\u003c/b\u003e is an open networking protocol for low-latency transport of web content proposed for HTTP 2.0 that has seen a rise in modern browser support. SPDY reduces page load time by prioritizing the transfer of subresources so that only one connection is required per client. Transport layer security is used in SPDY implementations with the transmission headers gzip or deflate compressed instead of human-readable text as in HTTP. It is great for high-latency environments.","theta":"        242","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Storm","id":"693","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"43","radius":"319","description":"Heterogeneous and overwhelmingly large amounts of data is not the only theme of big data. In certain circumstances, speed of processing can be as important as the volume. \u003cb\u003eStorm\u003c/b\u003e is a distributed realtime computation system. It has similar scalability to Hadoop, with throughput as fast as a million tuples per second. It enables for real time processing what Hadoop does for batch.","theta":"        249","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"TOTP Two-Factor Authentication","id":"779","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"44","radius":"290","description":"\u003cb\u003eTwo-factor authentication\u003c/b\u003e significantly improves security over simple password-based systems. \u003ca href\u003d\u0027http://tools.ietf.org/html/rfc6238\u0027\u003eRFC 6238\u003c/a\u003e -- \u003ca href\u003d\u0027http://en.wikipedia.org/wiki/Time-based_One-time_Password_Algorithm\u0027\u003eTime-based One-Time Password\u003c/a\u003e Algorithm -- is a standard for two-factor authentication. \u0026quot;Standard\u0026quot; authenticator apps from \u003ca href\u003d\u0027https://play.google.com/store/apps/details?id\u003dcom.google.android.apps.authenticator2\u0027\u003eGoogle\u003c/a\u003e and \u003ca href\u003d\u0027http://www.windowsphone.com/en-us/store/app/authenticator/e7994dbc-2336-4950-91ba-ca22d653759b\u0027\u003eMicrosoft\u003c/a\u003e provide tokens to smartphone users, and there are a number of other client and server implementations readily available. With providers such as Google, Facebook, Dropbox and Evernote using \u003cb\u003eTOTP\u003c/b\u003e, there really is no excuse to continue using simple password-based authentication where stronger security would be appropriate.","theta":"        256","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Web Components standard","id":"694","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"45","radius":"329","description":"In the previous radar we cautioned against the use of traditional web component frameworks that provide a component model on the server side. The \u003cb\u003eWeb Components standard\u003c/b\u003e that originated at Google is something quite different. It provides an easier way to create recyclable widgets by helping with encapsulation of HTML, CSS and JavaScript, so they do not interfere with the rest of the page and the page does not interfere with them. Developers can use as much or as little of the framework as needed. Early support is provided by the Polymer Project.","theta":"        263","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Big enterprise solutions","id":"600","quadrant":"Platforms","ring":"Hold","movement":"c","radarId":"46","radius":"375","description":"The gap between what \u0026quot;enterprise-class\u0026quot; commercial packages provide and what is actually needed is widening. This is especially true for internet facing applications. Innovative solutions that really scale and easily support modern techniques such as continuous delivery are written by practitioners for practitioners. They originate with many internet scale companies and are refined as open source software. \u003cb\u003eBig enterprise solutions\u003c/b\u003e often obstruct effective delivery due to their accumulated bloat, cumbersome licensing restrictions, and feature sets that are driven by check-lists and imaginary requirements far removed from the realities of most development teams.","theta":"        198","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"CMS as a platform","id":"696","quadrant":"Platforms","ring":"Hold","movement":"c","radarId":"47","radius":"375","description":"Content Management Systems (CMS) have their place. In many cases it is unreasonable to write editing and workflow functionality from scratch. However, we have experienced serious problems when \u003cb\u003eCMS as a platform\u003c/b\u003e becomes an IT solution that grows beyond managing simple content.","theta":"        216","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Enterprise Data Warehouse","id":"695","quadrant":"Platforms","ring":"Hold","movement":"c","radarId":"48","radius":"375","description":"While centralized integration of data for analysis and reporting remains a good strategy, traditional \u003cb\u003eEnterprise Data Warehouse\u003c/b\u003e (EDW) initiatives have a higher than 50% failure rate. Big up-front data modeling results in overbuilt warehouses that take years to deliver and are expensive to maintain. We are placing these old-style EDWs and techniques on hold in this edition of the radar. Instead, we advocate evolving towards an EDW. Test and learn by building small, valuable increments that are frequently released to production. Nontraditional tools and techniques can help, for example using a Data Vault schema design or even a NoSQL document store such as HDFS.","theta":"        234","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"OSGi","id":"758","quadrant":"Platforms","ring":"Hold","movement":"t","radarId":"49","radius":"375","description":"","theta":"        252","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Ansible","id":"720","quadrant":"Tools","ring":"Adopt","movement":"c","radarId":"50","radius":"80","description":"Since first featuring \u003cb\u003eAnsible\u003c/b\u003e in the last radar, we continue to be impressed with its capabilities and ease of use compared to other offerings in this space. Based on our experiences over the last year we have no hesitation in recommending Ansible as a great option for automated control of your infrastructure.","theta":"        60","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Dependency management for JavaScript","id":"712","quadrant":"Tools","ring":"Adopt","movement":"c","radarId":"51","radius":"32","description":"Using \u003cb\u003eDependency management \u003c/b\u003etools\u003cb\u003e for JavaScript\u003c/b\u003e has helped our delivery teams handle large amounts of JavaScript by structuring their code and loading the dependencies at runtime. Though this simplified the effort in most cases, lazy loading complicates supporting offline mode. Different dependency management tools have different strengths, so choose based on your context.","theta":"        30","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"CartoDB","id":"730","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"52","radius":"190","description":"\u003cb\u003eCartoDB\u003c/b\u003e is an open-source GIS tool built on PostGIS and PostgreSQL. It allows for storage and searching of geospatial data using SQL. It also provides a handy JavaScript library, CartoDB.js, for map styling and data visualization.","theta":"        85","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Chaos Monkey","id":"722","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"53","radius":"205","description":"Following our recommendation in the last radar to consider a focus on reducing mean time to recovery, we want to highlight \u003cb\u003eChaos Monkey\u003c/b\u003e from Netflix\u0027s Simian Army suite. It is a tool that randomly disables instances in the production environment during normal operation. When run with comprehensive monitoring and a team on stand by, it helps to uncover unexpected weaknesses in the system, which in turn allows the development team to build automatic recovery mechanisms ahead of time, rather than struggling to respond to an outage that caught everyone by surprise.","theta":"        80","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Docker","id":"714","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"54","radius":"210","description":"\u003cb\u003eDocker\u003c/b\u003e continues to gain momentum, and is seeing use on projects although mostly in non-production environments. Docker provides a set of tools to efficiently package and distribute executable machine images, which can then be launched as lightweight containers. A considerable community is growing around the tool. Notable is \u003ca href\u003d\u0027https://coreos.com/\u0027\u003eCoreOS\u003c/a\u003e which is an operating system based on ChromeOS built for deploying Docker containers across a cluster with tools for deployment, service discovery and configuration.","theta":"        75","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Flyway","id":"741","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"55","radius":"248","description":"Automated database migrations are common on agile projects, and we are happy to see advances in the tools for this space. \u003cb\u003eFlyway\u003c/b\u003e makes it as painless as possible to automate changes to databases. While not as feature-rich as some competing tools, we have used it on multiple projects and appreciate its low friction.","theta":"        70","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Foreman","id":"742","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"56","radius":"190","description":"The big Cloud providers have clearly raised the bar for provisioning, monitoring, and configuration, simplifying these tasks dramatically through powerful tools. Organizations that want to keep their compute and storage resources in-house are looking for similar solutions that work within their organizational context. \u003ca href\u003d\u0027http://theforeman.org/\u0027\u003e\u003cb\u003eForeman\u003c/b\u003e\u003c/a\u003e has worked really well for us, and it is open-source software, too.","theta":"        65","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"GenyMotion","id":"743","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"57","radius":"219","description":"Device fragmentation in the Android world is often cited as a problem because it can be difficult to understand how your applications will behave on a large number of disparate platforms. \u003ca href\u003d\u0027http://genymotion.com\u0027\u003e\u003cb\u003eGenyMotion\u003c/b\u003e\u003c/a\u003e is an emulator which can mimic the characteristics of a number of different Android devices. Our teams have found this very effective in giving fast feedback for our Android applications.","theta":"        60","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"GoCD","id":"744","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"58","radius":"248","description":"Owing to the increasing interest in Continuous Delivery and deployment pipelines, we see many teams trying to extend their Continuous Integration tooling with plugins that provide deployment pipelines at a visual level. \u003ca href\u003d\u0027http://go.cd\u0027\u003e\u003cb\u003eGoCD\u003c/b\u003e\u003c/a\u003e is a tool that was built with the concept of deployment pipelines at its core. GoCD has the ability to sequence workflows both sequentially and in parallel at many levels, to execute specific tasks only on certain machines as well as to deterministically promote and propagate artifacts, which is a key enabler for Continuous Delivery. These are capabilities that most Continuous Integration tools lack, and we recommend that teams who might have otherwise tried to build a deployment pipeline from their Continuous Integration server try GoCD instead. GoCD was built by Thoughtworks, is open-source, and is available for free for all teams. The \u003ca href\u003d\u0027https://github.com/gocd/gocd/\u0027\u003esource code\u003c/a\u003e is available under the Apache 2.0 license.","theta":"        55","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Grunt.js","id":"723","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"59","radius":"248","description":"We have seen a growth in the \u003cb\u003eGrunt\u003c/b\u003e ecosystem and it is currently being used in several of our projects. With the proliferation of plugins and the ease to author and publish self-written plugins to npm, automation using Grunt can be done with little effort. We suggest choosing a task runner that best meets the needs of the project and Grunt is one of the task runners you should consider.","theta":"        50","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Gulp","id":"745","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"60","radius":"248","description":"\u003cb\u003eGulp\u003c/b\u003e is an alternative to Grunt. It is a command-line task automation tool that helps developers with SaaS compilation, autoprefixing, minification, concatenation and so on. Gulp\u0027s central idea is the use of streams, and its plugins are designed to do only one task.","theta":"        45","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Moco","id":"724","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"61","radius":"192","description":"Testing HTTP-based micro-services can be painful and tricky. Particularly in two scenarios, the consumption of a group of micro-services from front-end, and the communication between micro-services. To deal with these, \u003cb\u003eMoco\u003c/b\u003e can be handy. It is a lightweight stub framework for testing HTTP-based endpoints. You can have an embedded stubbed service up and running with 2 lines of Java or Groovy code, or a standalone one with few lines of JSON to describe the required behavior.","theta":"        40","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Packer","id":"760","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"62","radius":"190","description":"We featured \u0027Machine image as a build artifact\u0027 in the last Radar, as an excellent way to implement fast spin-up, immutable servers. The thing holding this technique back was the difficulty in building images, especially when targeting more than one platform. \u003ca href\u003d\u0027http://packer.io\u0027\u003e\u003cb\u003ePacker\u003c/b\u003e\u003c/a\u003e\u0026nbsp;solves this, using your configuration management tool of choice to create images for a number of platforms including AWS, Rackspace, DigitalOcean and even Docker and Vagrant, although we have found the VMWare support to be problematic.","theta":"        35","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Pact \u0026 Pacto","id":"761","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"63","radius":"248","description":"Consumer-Driven Contracts are a testing approach to help service interfaces evolve with confidence without unknowingly breaking consumers. The similarly named \u003ca href\u003d\u0027https://github.com/realestate-com-au/pact\u0027\u003e\u003cb\u003ePact\u003c/b\u003e\u003c/a\u003e and \u003ca href\u003d\u0027http://thoughtworks.github.io/pacto\u0027\u003e\u003cb\u003ePacto\u003c/b\u003e\u003c/a\u003e are two new open-source tools which allow testing interactions between service providers and consumers in isolation against a contract. Both have grown out of projects which are building RESTful microservices and show great promise.","theta":"        30","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Prototype On Paper","id":"725","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"64","radius":"235","description":"We have long favored the use of hand-drawn, low fidelity prototypes to illustrate user interactions without getting caught up in the nitty-gritty of the graphic design. \u003cb\u003ePrototype On Paper\u003c/b\u003e is a tool that allows individual mockups drawn on paper to be captured via camera on iOS or Android and linked together to allow for testing of user interaction. This bridges the gap nicely between the static, lo-fi paper prototypes and more hi-fi prototyping techniques.","theta":"        25","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Protractor for AngularJS","id":"766","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"65","radius":"180","description":"\u003cb\u003eProtractor\u003c/b\u003e is a testing framework based on Jasmine that wraps WebDriverJS with functionality specifically designed to execute end-to-end tests\u003cb\u003e for Angular.JS\u003c/b\u003e applications. We\u0027ve found it to be a standout in the rapidly evolving space of JavaScript testing frameworks. Despite being designed to run end-to-end tests with a real backend, Protractor tests can also be made to work with a stubbed HTTP gateway to run purely client side tests.","theta":"        20","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"SnapCI","id":"726","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"66","radius":"184","description":"We mentioned Thoughtworks\u0027 \u003cb\u003eSnapCI\u003c/b\u003e - a hosted service that provides deployment pipelines - on the last edition of the Radar. Since then, we have seen many teams successfully use SnapCI on their projects. If you need a simple continuous delivery solution in the cloud, SnapCI can provide it with one click. No hardware, no hassle.","theta":"        15","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Snowplow Analytics \u0026 Piwik","id":"646","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"67","radius":"245","description":"With increasing scrutiny over the privacy of data, more companies are concerned about sharing web analytics with third parties. \u003cb\u003eSnowplow Analytics and Piwik\u003c/b\u003e are examples of open-source analytics platforms that can be self-hosted and provide a promising feature set and roadmap.","theta":"        10","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Visual regression testing tools","id":"717","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"68","radius":"250","description":"Growing complexity in web applications has increased the awareness that appearance should be tested in addition to functionality. This has given rise to a variety of \u003cb\u003evisual regression testing tools\u003c/b\u003e, including CSS Critic, dpxdt, Huxley, PhantomCSS, and Wraith. Techniques range from straightforward assertions of CSS values to actual screenshot comparison. While this is a field still in active development we believe that testing for visual regressions should be added to Continuous Delivery pipelines.","theta":"        5","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Appium","id":"728","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"69","radius":"295","description":"Mobile test automation is becoming increasingly important. \u003ca href\u003d\u0027http://appium.io\u0027\u003e\u003cb\u003eAppium\u003c/b\u003e\u003c/a\u003e is a test automation framework which can be used to test mobile web, mobile native and mobile hybrid applications on iOS and Android. At the core, Appium is a webserver that exposes a REST API, receiving connections from a client, listening for commands, executing those commands on a mobile device and responding with an HTTP response representing the result of the command execution. It allows tests to be written against multiple platforms (iOS, Android) using the same API. Appium is open source with easy set up using npm.","theta":"        83","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Consul","id":"732","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"70","radius":"327","description":"","theta":"        75","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Flume","id":"740","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"71","radius":"294","description":"When using techniques such as \u0027instrument all the things\u0027 and semantic logging, you may end up with huge amount of log data. Collecting, aggregating and moving this data can be problematic. \u003cb\u003eFlume\u003c/b\u003e is a distributed system for exactly this purpose. It has a flexible architecture based on streaming data flows. With built-in support for HDFS, Flume can easily move multi-terabyte log data from many different sources to a centralized data store for further processing.","theta":"        68","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Hosted solutions for testing iOS","id":"716","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"72","radius":"300","description":"All development for iOS must be carried out on OS X. Due to technical and licensing restrictions running server farms with OS X is neither easy nor common. In spite of these difficulties, \u003cb\u003eTravis CI\u003c/b\u003e, with support from Sauce Labs, now provides cloud-based continuous integration services for iOS and OS X projects.","theta":"        60","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"leaflet.js","id":"751","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"73","radius":"330","description":"\u003ca href\u003d\u0027http://leafletjs.com\u0027\u003e\u003cb\u003eLeaflet.js\u003c/b\u003e\u003c/a\u003e is a JavaScript library for mobile-friendly interactive maps. The library places a huge emphasis on performance, usability and simplicity, and as such works efficiently across mobile platforms and desktop browsers. It is a viable library to consider when building interactive maps for mobiles.","theta":"        53","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Mountebank","id":"755","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"74","radius":"302","description":"When testing services, we commonly need to stub out downstream collaborating services. Written by a Thoughtworker, \u003ca href\u003d\u0027http://www.mbtest.org\u0027\u003e\u003cb\u003eMountebank\u003c/b\u003e\u003c/a\u003e is a lightweight service which you can configure via HTTP that is capable of stubbing and mocking HTTP, HTTPS, SMTP and TCP.","theta":"        45","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Papertrail","id":"762","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"75","radius":"324","description":"\u003cb\u003ePapertrail\u003c/b\u003e is a log aggregation service that aggregates data from a variety of sources including web-servers, routers, databases and PaaS services. In addition to aggregation it provides search, filtering, and alerts and notifications out of the box. While undeniably convenient and expedient in many cases, we remain concerned about widespread adoption of services that centralize large quantities of data aggregated from multiple parties.","theta":"        38","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Roslyn","id":"770","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"76","radius":"331","description":"\u003cb\u003eRoslyn\u003c/b\u003e, a .NET compiler platform under the Apache License 2.0, is a next-generation set of compilers for C# and VB.NET written entirely as managed code. It provides access to the compiler as a service and includes code analysis APIs allowing developers to access information from the compiler that was previously treated as a black box, for example syntactic and semantic models. The most immediate impact should be seen in enhancements to .NET IDEs through refactoring and code generation tools. We also expect to see improved code diagnostics and static analysis, although it will be interesting to see what the community comes up with. Meanwhile Xamarin has a Mono-compatible copy of Roslyn source code hosted on GitHub and plans to bundle Roslyn’s compilers with Mono as it stabilizes, in addition to integrating the best parts into their code base.","theta":"        30","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Spark","id":"773","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"77","radius":"300","description":"For iterative processing such as machine learning and interactive analysis, Hadoop map-reduce does not work very well because of its batch-oriented nature. \u003cb\u003eSpark\u003c/b\u003e is a fast and general engine for large-scale data processing. It aims to extend map-reduce for iterative algorithms and interactive low latency data mining. It also ships with a machine learning library.","theta":"        23","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Swagger","id":"776","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"78","radius":"330","description":"\u003ca href\u003d\u0027https://helloreverb.com/developers/swagger\u0027\u003e\u003cb\u003eSwagger\u003c/b\u003e\u003c/a\u003e is a standard way to describe a RESTful API so that documentation and client examples can be generated automatically. We think there\u0027s a need for some standards in this area and hope that this approach embraces Postel\u0027s law and avoids the \u003ca href\u003d\u0027http://en.wikipedia.org/wiki/Robustness_principle\u0027\u003etight-coupling and inflexibility\u003c/a\u003e of standards like WSDL. A number of tools are now available to \u003ca href\u003d\u0027https://github.com/wordnik/swagger-ui\u0027\u003erender documentation and client pages\u003c/a\u003e from swagger-compliant descriptions.","theta":"        15","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Xamarin","id":"718","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"79","radius":"337","description":"Among the various choices available for building cross-platform mobile apps, \u003cb\u003eXamarin\u003c/b\u003e offers a fairly unique toolset. It supports C# and F# as the primary language with bindings to platform-specific SDKs and the Mono runtime environment that works across iOS, Android and Windows Phone. Applications are compiled to native code instead of the typical cross-platform approach that renders HTML-based UI in an embedded browser. This gives apps a more native look and feel. When using this toolset, it is imperative that the platform-specific UI tier be separated from the rest of the tiers to ensure code reuse across different platforms. The application binary tends to be a bit bigger due to the runtime environment that is included.","theta":"        8","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Ant","id":"719","quadrant":"Tools","ring":"Hold","movement":"c","radarId":"80","radius":"375","description":"We continue to see teams expend significant effort on un-maintainable \u003cb\u003eAnt\u003c/b\u003e and Nant build scripts. These are hard to understand and extend due to the inherent lack of expressiveness and clean modularity provided by the tools. Alternatives like Gradle, Buildr, and PSake have clearly demonstrated superior maintainability and productivity.","theta":"        60","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"TFS","id":"307","quadrant":"Tools","ring":"Hold","movement":"c","radarId":"81","radius":"375","description":"We continue to see teams run into productivity problems attempting to use \u003cb\u003eTFS\u003c/b\u003e as a version control system. Teams that want to practice frequent code check-ins, a core part of continuous integration, have found its heavyweight approach significantly drains productivity. This often leads to teams checking in less frequently, causing more problematic merges. We recommend tools such as Git, Perforce, and Subversion instead.","theta":"        30","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Dropwizard","id":"519","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radarId":"82","radius":"130","description":"\u003cb\u003eDropwizard\u003c/b\u003e is an opinionated combination of several lightweight Java tools and frameworks, many of which would merit mention in their own right. The package embodies many of our favorite techniques, including an embedded HTTP server, support for RESTful endpoints, built-in operational metrics and health-checks, and straightforward deployments. Dropwizard makes it easy to do the right thing, allowing you to concentrate on the essential complexity of a problem rather than the plumbing.","theta":"        285","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Go language","id":"684","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radarId":"83","radius":"90","description":"The \u003cb\u003eGo language\u003c/b\u003e gradually changed status from \u0026quot;Just Another Language\u0026quot; to a valuable tool in many projects. While steadfastly single paradigm in a world of increasingly complex languages, it seems to keep a nice balance between expressiveness, power, and simplicity.","theta":"        300","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Java 8","id":"750","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"84","radius":"110","description":"The team behind \u003cb\u003eJava 8\u003c/b\u003e had to fight two battles: the community forces encouraging forever backwards compatibility (a long hallmark of Java) and the technical challenge of making a deep language change mesh with existing libraries and features. They succeeded on both fronts, breathing new life into the Java Language and placing it on par with other mainstream languages in terms of functional programming features. In particular, Java 8 has excellent syntactic magic that allows seamless interoperability between Lambda blocks, the new higher-order function feature, and SAM (Single Abstract Method) interfaces, the traditional way of passing behavior.","theta":"        315","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Reactive Extensions across languages","id":"686","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radarId":"85","radius":"120","description":"The \u003cb\u003ereactive architecture\u003c/b\u003e keeps spreading across platforms and paradigms simply because it solves a common problem in an elegant way, hiding inevitable application plumbing in a nice encapsulation.","theta":"        330","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Scala, the good parts","id":"257","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radarId":"86","radius":"100","description":"Scala is a large language that is popular because of its approachability for new developers. This banquet of features is a problem because many aspects of Scala, like implicit conversions and dynamics, can get you into trouble. To successfully use Scala, you need to research the language and have a very strong opinion on which parts are right for you, creating your own definition of \u003cb\u003eScala, the good parts\u003c/b\u003e. You can disable the parts you do not want using a system called feature flags.","theta":"        345","editStatus":"In Editing","faded":"","lastModified":"2011-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"AngularJS","id":"727","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"87","radius":"218","description":"We continue to see JavaScript frameworks as a useful way to structure code and bring better coding techniques to JavaScript. \u003cb\u003eAngularJS\u003c/b\u003e is used widely by Thoughtworks projects. However we do advise teams to assess other good alternatives such as Ember.js and Knockout.js.","theta":"        279","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Core Async","id":"733","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"88","radius":"253","description":"The Clojure \u003cb\u003ecore.async\u003c/b\u003e library allows asynchronous communication using channels, with similar syntax and capabilities to Google\u0027s Go language. The core.async library solves many common problems in an elegant way, cleaning up event callback setup and adding simple concurrency primitives. It also highlights one of the advantages of the Lisp nature of Clojure: channels add operators that are consistent with existing Clojure operators, seamlessly weaving new functionality into the language core. In addition, core.async is supported in both Clojure and ClojureScript (despite JavaScript\u0027s lack of threads), utilizing underlying platform abstractions to provide a consistent interface to both languages.","theta":"        288","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"HAL","id":"746","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"89","radius":"225","description":"We see lots of teams creating RESTful interfaces without paying any attention to hypermedia. \u003ca href\u003d\u0027http://stateless.co/hal_specification.html\u0027\u003e\u003cb\u003eHAL\u003c/b\u003e\u003c/a\u003e is a simple format for incorporating hyperlinks into JSON representations which is easy to implement and consume. HAL is well supported by libraries for parsing and representing JSON, and there are HAL-aware REST client libraries such as \u003ca href\u003d\u0027https://github.com/codegram/hyperclient\u0027\u003eHyperclient\u003c/a\u003e which make it easy to navigate resources by following links.","theta":"        297","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Hive","id":"685","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"90","radius":"175","description":"\u003cb\u003eHive\u003c/b\u003e is a data warehouse built on top of Hadoop which provides a SQL-like query and data definition language. Hive converts queries into MapReduce jobs that can be run across the entire Hadoop cluster. Like all useful abstractions, Hive does not try to deny the existence of the underlying mechanics of Hadoop and supports custom map-reduce operations as a powerful extension mechanism. Despite the superficial similarities to SQL, Hive does not try to be a replacement for low-latency, real-time query engines found on relational database systems. We strongly advise against using Hive for online ad-hoc querying purposes.","theta":"        306","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Nancy","id":"630","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"91","radius":"240","description":"\u003cb\u003eNancy\u003c/b\u003e continues to gain traction in the Alt.NET community and we have found it particularly useful for deploying low-ceremony, lightweight fakes for testing in a microservices environment.","theta":"        315","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Pester","id":"678","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"92","radius":"240","description":"PowerShell remains a widely used option for doing low-level automation on Windows machines. \u003cb\u003ePester\u003c/b\u003e is a testing library that makes it possible to execute and validate PowerShell commands. Pester simplifies testing of scripts during development with a powerful mocking system that makes it possible to setup stubs and doubles in tests. Pester tests can also be integrated into a continuous integration system to prevent regression defects.","theta":"        324","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Play Framework 2","id":"669","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"93","radius":"225","description":"The \u003cb\u003ePlay Framework 2\u003c/b\u003e blip has generated many internal discussions. We had competing suggestions to move it to adopt and hold. These differences relate primarily to the specific applications for which it is used, how it is used, and what expectations people have for it. While none of these issues are unique for Play, Play has generated far more controversy than is typical in the standard library versus framework debate. We reiterate the cautions stated in the previous radar, and we will monitor how Play continues to mature to support its sweet spot.","theta":"        333","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Q \u0026 Bluebird","id":"767","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"94","radius":"182","description":"\u003ca href\u003d\u0027https://github.com/kriskowal/q\u0027\u003e\u003cb\u003eQ\u003c/b\u003e\u003c/a\u003e is a fully Promises/A+ compliant implementation in JavaScript that lets users compose promises arbitrarily deeply without the need for the deeply nested callbacks that obscure control flow. Q takes care of threading fulfilled values and rejected promises through the appropriate code paths. The space of Promises/A+ compliant libraries is currently very active with alternatives like \u003ca href\u003d\u0027https://github.com/petkaantonov/bluebird\u0027\u003e\u003cb\u003eBluebird\u003c/b\u003e\u003c/a\u003e also rapidly gaining mindshare.","theta":"        342","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"R as Compute Platform","id":"768","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"95","radius":"244","description":"R is traditionally used as stand alone analysis tool by research teams. With improvements in packages like Rook and RJSONIO, it has become trivial to wrap the computational logic and expose it as an API. Thoughtworks teams are using \u003cb\u003eR as Compute platform\u003c/b\u003e to crunch large datasets in real time, using in-memory storage integrated with enterprise systems.","theta":"        351","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Elm","id":"736","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"96","radius":"335","description":"\u003cb\u003eElm\u003c/b\u003e is a functional programming language that is used to build web based user interfaces in a functional reactive style. Elm is strongly statically typed and built on the Haskell platform. Elm has a Haskell-like syntax but compiles down to HTML, CSS and JavaScript. While still in its very early days, individuals and teams interested in exploring highly interactive web-based GUIs should look into this interesting little language.","theta":"        278","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Julia","id":"677","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"97","radius":"324","description":"\u003cb\u003eJulia\u003c/b\u003e is a dynamic, procedural and homoiconic programming language designed to address the needs of high performance scientific computing. The implementation of the language is organized around the concept of generic functions and dynamic method dispatch. Julia programs are largely functions that can contain multiple definitions for different combinations of argument types. The combination of these language features and the LLVM based just-in-time compiler help Julia achieve a high level of performance. Julia also supports a multiprocessing environment based on message passing to allow programs to run on multiple processes. This enables programmers to create distributed programs based on any of the models for parallel programming.","theta":"        286","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Om","id":"756","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"98","radius":"318","description":"Adopting the entire Clojure stack (the Clojure and ClojureScript languages, and optionally the Datomic database) offers some advantages like immutable data structures from user interface to backend. Several frameworks have appeared in the Clojure space to leverage its unique features, but the most promising so far is \u003cb\u003eOm\u003c/b\u003e. Om is a ClojureScript wrapper around Facebook\u0027s React JavaScript reactive programming framework. Yet Om leverages the inherent immutability of ClojureScript, allowing automatic features like snapshots of UI state and undo. And due to the efficiency of ClojureScript\u0027s data structures, some Om applications run faster than identical ones based on the raw underlying React framework. We expect significant evolution and innovation to continue around Om.","theta":"        294","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Pointer Events","id":"680","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"99","radius":"321","description":"After some delays, mainly caused by patent claims from Apple, the W3C has now finalized the Touch Events recommendation. However, in the meantime, \u003cb\u003ePointer Events\u003c/b\u003e, a newer, broader, and richer standard, is picking up momentum. We recommend considering Pointer Events for HTML interfaces that must work across different input methods.","theta":"        302","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Python 3","id":"679","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"100","radius":"285","description":"\u003cb\u003ePython 3\u003c/b\u003e was a major change from the previous Python 2.x that introduced backwards incompatible changes. It was notable for actually removing languages features, making Python 3 easier to use and more consistent without reducing its power. This has led to problems in adoption as some widely used supporting libraries have not been ported, and Python developers often have to find new ways of doing things. Nonetheless the drive towards making a language simpler is to be applauded, and if you are actively developing in Python, then give Python 3 another look.","theta":"        310","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Rust","id":"771","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"101","radius":"323","description":"","theta":"        319","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Spray/akka-http","id":"774","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"102","radius":"337","description":"\u003cb\u003eSpray/akka-http\u003c/b\u003e is a suite of lightweight Scala libraries providing client/server RESTful support on top of Akka. It fully embraces the Actor-, Future-, and Stream-based programming models used by the underlying platform. This lets you work on RESTful applications with idiomatic Scala code without worrying about wrapping around other Java libraries.","theta":"        327","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Spring Boot","id":"775","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"103","radius":"314","description":"\u003ca href\u003d\u0027http://projects.spring.io/spring-boot\u0027\u003e\u003cb\u003eSpring Boot\u003c/b\u003e\u003c/a\u003e allows easy set up of standalone Spring-based applications. It\u0027s ideal for pulling up new microservices and easy to deploy. It also makes data access less of a pain due to the hibernate mappings with much less boilerplate code.","theta":"        335","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"TypeScript","id":"681","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"104","radius":"333","description":"\u003cb\u003eTypeScript\u003c/b\u003e is an interesting approach to bringing a new programming language to the browser. With TypeScript, the new language features compile down to normal JavaScript, and yet as a superset of JavaScript it does not feel like a completely new language. It does not represent an either-or proposition and it does not relegate JavaScript to an intermediate execution platform. Many of the language features are based on planned future extensions of JavaScript.","theta":"        343","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Wolfram Language","id":"780","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"105","radius":"334","description":"We are intrigued by the possibilities offered by the \u003cb\u003eWolfram language\u003c/b\u003e. Building on the symbolic approaches of the Mathematica language it also has access to a vast array of algorithms and data from the Wolfram Alpha project, which means that very succinct programs can analyze and visualize powerful combinations of real-world data.","theta":"        351","editStatus":"In Editing","faded":"","lastModified":"2014-06","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"Handwritten CSS","id":"594","quadrant":"languages-and-frameworks","ring":"Hold","movement":"c","radarId":"106","radius":"375","description":"Along with JavaScript and HTML, CSS is a core technology for creating websites. Unfortunately, the language itself lacks key features, which leads to a high level of duplication and a lack of meaningful abstractions. While CSS3 aims to rectify some of these issues, it will be years before the modules that make up CSS3 will be properly supported in most browsers. Fortunately, there is a solution today using \u003cb\u003eCSS preprocessors\u003c/b\u003e like SASS and LESS. Due to their quality and support, we believe that the days of \u003cb\u003ehandwritten CSS\u003c/b\u003e, for anything apart from trivial work, are over.","theta":"        300","editStatus":"In Editing","faded":"","lastModified":"2013-04","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"},{"name":"JSF","id":"683","quadrant":"languages-and-frameworks","ring":"Hold","movement":"c","radarId":"107","radius":"375","description":"We continue to see teams run into trouble using \u003cb\u003eJSF\u003c/b\u003e\u0026nbsp;- JavaServer Faces - and are recommending you avoid this technology. Teams seem to choose JSF because it is a Java EE standard without really evaluating whether the programming model suits them. We think JSF is flawed because its programming model encourages use of its own abstractions rather than fully embracing the underlying web model. JSF, like ASP.NET webforms, attempts to create stateful component trees on top HTML markup and the stateless HTTP protocol. The improvements in JSF 2.0 and 2.2, such as the introduction of stateless views and the promotion of GET, are steps in the right direction, maybe even an acknowledgement that the original model was flawed, but we feel this is a too little too late. Rather than dealing with the complexity of JSF we recommend teams use simple frameworks and work closely with web technologies including HTTP, HTML and CSS.","theta":"        330","editStatus":"In Editing","faded":"","lastModified":"2014-01","quadrantSortOrder":"1","ringSortOrder":"1","type":"Blip","urlLabel":"","volume":"2014-07"}],"date":"2014-07"},{"blips":[{"name":"Focus on mean time to recovery","id":"623","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"1","radius":"55","description":"","theta":"        158","lastModified":"42005","volume":"2015-01"},{"name":"Forward Secrecy","id":"764","quadrant":"Techniques","ring":"Adopt","movement":"c","radarId":"2","radius":"90","description":"\u003cp\u003e\u003cb\u003eForward Secrecy\u003c/b\u003e (sometimes known as \u0027Perfect Forward Secrecy\u0027 or PFS) is a cryptographic technique that protects previous communications sessions even if a server’s master keys are later compromised. Despite being simple to enable for HTTPS connections, many servers are not configured this way, and we recommend enabling forward secrecy to improve security. Note that we don\u0027t generally like the word \u0027perfect\u0027 when used to describe cryptographic protocols -- even the best protocol can be broken by a flaw in implementation, random number generator, or by advances in cryptanalytic techniques. Even so, it is important to enable the best security available, while\u0026nbsp;keeping informed of new attacks and protocol improvements.\u003c/p\u003e","theta":"        135","lastModified":"41791","volume":"2015-01"},{"name":"Structured logging","id":"711","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"3","radius":"100","description":"","theta":"        113","lastModified":"42005","volume":"2015-01"},{"name":"Canary builds","id":"781","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"4","radius":"178","description":"","theta":"        174","lastModified":"42005","volume":"2015-01"},{"name":"Datensparsamkeit","id":"699","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"5","radius":"225","description":"","theta":"        168","lastModified":"42005","volume":"2015-01"},{"name":"Front end instrumentation","id":"763","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"6","radius":"160","description":"\u003cp\u003eWith the proliferation of complex JavaScript websites and applications, we are finding that browser-side issues such as\u0026nbsp;slow network\u0026nbsp;calls, poor render times, and JavaScript errors can have a big impact on user experience. Server-side monitoring clearly does not help in these scenarios and often these types of issues are being missed. \u003cstrong\u003eFront end instrumentation\u003c/strong\u003e extends the types of monitoring we are used to with\u0026nbsp;server-side code to the browser, allowing for early warning of potential issues and far easier diagnosis should\u0026nbsp;production issues occur.\u003c/p\u003e","theta":"        161","lastModified":"42005","volume":"2015-01"},{"name":"Hipster batch","id":"782","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"7","radius":"250","description":"\u003cp\u003eThere has been a lot of recent attention to the use of ATOM-style event feeds over HTTP as a method of integration. \u0026nbsp;Instead of maintaining\u0026nbsp;a live service to expose those feeds, it is often acceptable to use old-style scheduled batch processing to create and publish feed files. \u0026nbsp;When combined with cloud technology like Amazon\u0027s S3 file storage and hypermedia linking, this can create a highly available, yet simple and testable solution. \u0026nbsp;Our teams have started to call this old-meets-new approach \u0027\u003cstrong\u003eHipster batch\u003c/strong\u003e\u0027.\u003c/p\u003e","theta":"        155","lastModified":"42005","volume":"2015-01"},{"name":"Humane registry","id":"747","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"8","radius":"255","description":"\u003cp\u003eA Microservice architecture by its very nature increases significantly the number of applications, services, and interactions in your deployed environments. Our projects are showing renewed focus on building \u003ca href\u003d\u0027http://martinfowler.com/bliki/HumaneRegistry.html\u0027\u003e\u003cb\u003eHumane Registries\u003c/b\u003e\u003c/a\u003e which aggregate information about running services from the live environment and present it in a form for humans to comprehend. These registries favor up-to-date information from running services instead of human-curated documentation.\u003c/p\u003e","theta":"        148","lastModified":"41791","volume":"2015-01"},{"name":"Inverse Conway Maneuver","id":"749","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"9","radius":"200","description":"\u003cp\u003eConway\u0027s Law asserts that organizations are constrained to produce application designs which are copies of their communication structures. This often leads to unintended friction points. The \u0027\u003cb\u003eInverse Conway Maneuver\u003c/b\u003e\u0027 recommends evolving your team and organizational structure to promote your desired architecture. Ideally your technology architecture will display isomorphism with your business architecture.\u003c/p\u003e","theta":"        142","lastModified":"41791","volume":"2015-01"},{"name":"Living CSS Style Guides","id":"752","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"10","radius":"180","description":"\u003cp\u003eA \u003cb\u003eliving CSS style guide\u003c/b\u003e is a page on your site that uses your current CSS styles and acts as a reference for all the currently available visual elements and design patterns. This helps to tightly integrate design into your delivery process by promoting co-ownership of the UI and avoids duplication of styling across your application. Styling changes are visible in the guide immediately and changes propagate across your site from a central location. A sensible way to do this is with a well organized SASS/LESS file structure with semantically named elements that separates structure, aesthetics, and interaction.\u003c/p\u003e","theta":"        135","lastModified":"41791","volume":"2015-01"},{"name":"Local storage sync","id":"783","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"11","radius":"220","description":"","theta":"        129","lastModified":"42005","volume":"2015-01"},{"name":"NoPSD","id":"784","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"12","radius":"170","description":"","theta":"        123","lastModified":"42005","volume":"2015-01"},{"name":"Partition infrastructure along team bounds","id":"785","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"13","radius":"240","description":"\u003cp\u003eMany of our customers have made DevOps a reality in their organization with delivery teams that build, deploy, and support their own applications and services. \u0026nbsp;Unfortunately, a regular roadblock on that journey is allowing teams to have superuser privileges in production environments. \u0026nbsp;In most organizations, the production environment is shared, and therefore risky to provide access widely. \u0026nbsp;It is effective when we can \u003cstrong\u003epartition infrastructure along team bounds,\u003c/strong\u003e so that those teams can have safe isolated access to do their work, without risking impact to other systems. \u0026nbsp;Where cloud environments are used, this is much easier to implement, aligning account structures to team boundaries.\u0026nbsp;\u003c/p\u003e","theta":"        116","lastModified":"42005","volume":"2015-01"},{"name":"REST without PUT","id":"769","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"14","radius":"170","description":"\u003cp\u003eIn the last radar we talked about Capturing Explicit Domain Events, putting emphasis on recording the business-meaningful events that have triggered state transitions instead of just CRUD\u0027ing entities. REST interfaces commonly use PUT to update resource state, however it\u0027s often better to POST to record a new event resource which captures intent. \u003cb\u003eREST without PUT \u003c/b\u003ehas a side-benefit of separating command and query interfaces and forces consumers to allow for eventual consistency.\u003c/p\u003e","theta":"        110","lastModified":"41791","volume":"2015-01"},{"name":"Static site generators","id":"786","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"15","radius":"201","description":"\u003cp\u003e\u003cstrong\u003eStatic site generators\u003c/strong\u003e like Middleman or Jekyll have become popular for creating simple websites or blogs, but we are increasingly seeing their use as part of more complex application stacks. The default assumption that all content delivered over HTTP has to be dynamically created on request is shifting, with more teams looking to use static pre-generated content.\u003c/p\u003e","theta":"        103","lastModified":"42005","volume":"2015-01"},{"name":"Tailored Service Template","id":"777","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"16","radius":"237","description":"\u003cp\u003eWe see multiple organizations creating a \u003cb\u003eTailored Service Template\u003c/b\u003e which can be used to quickly seed new services, pre-configured to operate within that organization\u0027s production environment. The template contains a default set of decisions such as web frameworks, logging, monitoring, build, packaging, and deployment approaches. This is a very useful technique for encouraging collaborative evolution while retaining lightweight governance.\u003c/p\u003e","theta":"        97","lastModified":"41791","volume":"2015-01"},{"name":"Append-only data store","id":"787","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"17","radius":"320","description":"","theta":"        165","lastModified":"42005","volume":"2015-01"},{"name":"Blockchain beyond bitcoin","id":"788","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"18","radius":"320","description":"","theta":"        150","lastModified":"42005","volume":"2015-01"},{"name":"Enterprise Data Lake","id":"789","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"19","radius":"290","description":"","theta":"        135","lastModified":"42005","volume":"2015-01"},{"name":"Machine image pipelines","id":"753","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"20","radius":"300","description":"\u003cp\u003eMany deployments requires machine images for different server roles like applications and services, databases, and reverse proxies. Because building a machine image from scratch, using an operating system ISO and provisioning scripts, can take a considerable amount of time it can be useful to create a \u003cb\u003ebuild pipeline for machine images\u003c/b\u003e. The first stage in the pipeline sets up a base image according to general standards in the organization. Subsequent stages can then enhance the base image for different purposes. If several applications or services have similar requirements, an application server for example, the pipeline can be extended by an intermediate stage, which takes the base image and provides an image with an application server but no application/service. These pipelines are not linear, they are trees that are branching out from the base image.\u003c/p\u003e","theta":"        120","lastModified":"41791","volume":"2015-01"},{"name":"Pace-layered Application Strategy","id":"759","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"21","radius":"317","description":"\u003cp\u003eGartner\u0027s \u003cstrong\u003ePace-layered Application Strategy\u003c/strong\u003e approach to architecture attempts to articulate the fact that decisions about architecture should not be a one-size fits all approach. Instead, it is important to take a balanced view of\u0026nbsp;your technology portfolio. We have qualms about some of the prescriptive recommendations that come with Pace. In particular, we have\u0026nbsp;found some situations where the layering concept is too simplistic. That said, we believe the core idea that different components and systems within an architecture need\u0026nbsp;to change at different paces is sound.\u003c/p\u003e","theta":"        105","lastModified":"42005","volume":"2015-01"},{"name":"Cloud lift and shift","id":"702","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"22","radius":"375","description":"\u003cp\u003eAs cloud adoption grows we are unfortunately seeing a trend to treat the cloud as just another hosting provider. \u003cb\u003eCloud lift and shift\u003c/b\u003e is unfortunately being encouraged by large vendors re-branding existing hosting offerings as \u0026quot;cloud.\u0026quot; Few of these offer any real flexibility or pay-as-you-use pricing. If you think you can move to the cloud without re-architecting, you are probably not doing it right.\u003c/p\u003e","theta":"        171","lastModified":"41640","volume":"2015-01"},{"name":"Long lived branches with Gitflow","id":"790","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"23","radius":"375","description":"","theta":"        162","lastModified":"42005","volume":"2015-01"},{"name":"Microservice envy","id":"791","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"24","radius":"375","description":"","theta":"        153","lastModified":"42005","volume":"2015-01"},{"name":"Programming in your CI/CD tool","id":"792","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"25","radius":"375","description":"","theta":"        144","lastModified":"42005","volume":"2015-01"},{"name":"SAFe™","id":"793","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"26","radius":"375","description":"","theta":"        135","lastModified":"42005","volume":"2015-01"},{"name":"Security sandwich","id":"794","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"27","radius":"375","description":"\u003cp\u003eTraditional approaches to security have relied on up-front specification followed by validation at the end. This \u003cstrong\u003e“Security Sandwich”\u003c/strong\u003e approach is hard to integrate into Agile teams, since much of the design happens throughout the process, and it does not leverage the automation opportunities provided by continuous delivery. Organizations should look at how they can inject security practices throughout the agile development cycle. This includes: evaluating the right level of Threat Modeling to do up-front; when to classify security concerns as their own stories, acceptance criteria, or cross-cutting non-functional requirements; including automatic static and dynamic security testing into your build pipeline; and how to include deeper testing, such as penetration testing, into releases in\u0026nbsp;a continuous delivery\u0026nbsp;model. In much the same way that DevOps has recast how historically adversarial\u0026nbsp;groups can work together, the same is happening for security and development professionals.\u0026nbsp;\u003c/p\u003e","theta":"        126","lastModified":"42005","volume":"2015-01"},{"name":"Separate DevOps team","id":"734","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"28","radius":"375","description":"","theta":"        117","lastModified":"42005","volume":"2015-01"},{"name":"Testing as a separate organization","id":"778","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"29","radius":"375","description":"\u003cp\u003eWe continue to see organizations create separate Development and QA teams. Fast feedback is a core tenet of Agile and critical to the success of a project. Using a separate QA team slows down this feedback, creates an \u0026quot;us and them\u0026quot; mentality and makes it more difficult to build quality into the software. Testing should be a tightly integrated activity and isn\u0027t something the team can outsource. We recommend integrated teams where testers work closely with developers instead of having \u003cb\u003etesting as a separate organization.\u003c/b\u003e\u003c/p\u003e","theta":"        108","lastModified":"41791","volume":"2015-01"},{"name":"Velocity as productivity","id":"705","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"30","radius":"375","description":"\u003cp\u003eWe continue to see teams and organizations equating velocity with productivity. When properly used, velocity allows the incorporation of \\”yesterday\u0027s weather\\”\u0026nbsp;into a team’s internal iteration planning process. The key here is that velocity is an internal measure for a team, it is just a capacity estimate for that given team at that given time. Organizations and managers who equate internal velocity with external productivity start to set targets for velocity, forgetting that what actually matters is working software in production. Treating \u003cb\u003evelocity as productivity\u003c/b\u003e leads to unproductive team behaviors that optimize this metric at the expense of actual working software.\u003c/p\u003e","theta":"        99","lastModified":"42005","volume":"2015-01"},{"name":"DigitalOcean","id":"735","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"31","radius":"172","description":"","theta":"        210","lastModified":"42005","volume":"2015-01"},{"name":"iBeacon","id":"748","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"32","radius":"192","description":"\u003cp\u003e\u003cb\u003eiBeacons\u003c/b\u003e are the Apple implementation of the broader category of beacons, which are small devices that use low energy Bluetooth (BLE) to provide fine-grained proximity information for mobile phones and other devices. Despite the hype surrounding iBeacons and the limitations to the accuracy and reliability of the information they provide, we do feel that they open interesting opportunities as trigger points for interacting with your users in a contextually relevant manner.\u003c/p\u003e","theta":"        240","lastModified":"41791","volume":"2015-01"},{"name":"Apache Mesos","id":"796","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"33","radius":"321","description":"","theta":"        185","lastModified":"42005","volume":"2015-01"},{"name":"ARM Server SoC","id":"729","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"34","radius":"330","description":"\u003cp\u003eAMD recently released an \u003ca href\u003d\u0027http://www.anandtech.com/show/7989/amd-announces-project-skybridge-pincompatible-arm-and-x86-socs-in-2015\u0027\u003e8-core \u003cb\u003eARM SoC\u003c/b\u003e (System on a Chip)\u003c/a\u003e designed for servers and has committed to releasing an ARM SoC with integrated graphics in 2015. ARM-based servers are an interesting alternative to x86 because they are significantly more energy efficient. For some workloads, building an ARM-powered Cloud is preferable.\u003c/p\u003e","theta":"        190","lastModified":"41791","volume":"2015-01"},{"name":"CoAP","id":"731","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"35","radius":"288","description":"\u003cp\u003e\u003ca href\u003d\u0027http://coap.technology/\u0027\u003e\u003cb\u003eCoAP\u003c/b\u003e\u003c/a\u003e is an open standards communication protocol for the Internet of Things (IoT). While there is currently a proliferation of competing standards in the IoT space, we particularly like CoAP. It is specifically designed for resource-constrained devices and local radio networks. It uses UDP for transport, but is semantically compatible with HTTP. CoAP uses a web-based model of devices with their own URLs and a request-response paradigm that supports RESTful and decentralized approaches.\u003c/p\u003e","theta":"        195","lastModified":"41791","volume":"2015-01"},{"name":"CoreOS","id":"797","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"36","radius":"311","description":"","theta":"        201","lastModified":"42005","volume":"2015-01"},{"name":"EventStore","id":"739","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"37","radius":"293","description":"\u003cp\u003eGiven the popularity of event sourcing, it is no surprise that tools in this space are maturing. \u003ca href\u003d\u0027http://geteventstore.com\u0027\u003e\u003cb\u003eEventStore\u003c/b\u003e\u003c/a\u003e is an open source functional database for storing immutable events and performing complex event processing on the event streams. Unlike other tools in this space, EventStore exposes event streams as Atom collections which therefore require no special infrastructure such as message buses or highly specialized clients to use.\u0026nbsp;\u003c/p\u003e","theta":"        206","lastModified":"41791","volume":"2015-01"},{"name":"Jackrabbit Oak","id":"800","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"38","radius":"287","description":"","theta":"        211","lastModified":"42005","volume":"2015-01"},{"name":"Linux security modules","id":"795","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"39","radius":"312","description":"","theta":"        217","lastModified":"42005","volume":"2015-01"},{"name":"Mapbox","id":"754","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"40","radius":"330","description":"\u003cp\u003e\u003ca href\u003d\u0027http://mapbox.com\u0027\u003e\u003cb\u003eMapbox\u003c/b\u003e\u003c/a\u003e is an open mapping platform we have used on several projects. It allows a developer to quickly add a map to an application and to style the map. Mapbox can serve as an alternative to conventional mapping platforms, and it also allows for mobile friendly maps.\u003c/p\u003e","theta":"        222","lastModified":"41791","volume":"2015-01"},{"name":"MariaDB","id":"798","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"41","radius":"311","description":"","theta":"        227","lastModified":"42005","volume":"2015-01"},{"name":"Netflix OSS Full stack","id":"799","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"42","radius":"337","description":"","theta":"        232","lastModified":"42005","volume":"2015-01"},{"name":"OpenAM","id":"801","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"43","radius":"300","description":"\u003cp\u003eWhen Oracle ceased\u0026nbsp;development on\u0026nbsp;Sun’s OpenSSO—an open source access management platform—It was picked up by ForgeRock and integrated into their Open Identity Suite. \u0026nbsp;Now named \u003cstrong\u003e\u003ca href\u003d\u0027http://forgerock.com/products/open-identity-stack/openam/\u0027\u003eOpenAM\u003c/a\u003e\u003c/strong\u003e, it fills the niche for a scalable, open-source platform that supports a variety of federated identity\u0026nbsp;standards, including OpenID Connect and SAML 2.0. \u0026nbsp;These standards are a necessary enabler for secure microservice implementations.\u003c/p\u003e","theta":"        238","lastModified":"42005","volume":"2015-01"},{"name":"OpenID Connect","id":"757","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"44","radius":"339","description":"\u003cp\u003e\u003cb\u003eOpenID Connect\u003c/b\u003e is a standard protocol for federated identity built on OAuth 2.0. It addresses a long-standing need for a simple, web-based protocol to exchange trusted authentication and authorization information. Previous standards like SAML or generic OAuth 2.0 have proven too broad and complex to ensure universal compatibility. Our hope is that OpenID Connect can provide a useful basis for secure access to RESTful microservices with authenticated end-user identity.\u003c/p\u003e","theta":"        243","lastModified":"41791","volume":"2015-01"},{"name":"SDN","id":"802","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"45","radius":"305","description":"","theta":"        248","lastModified":"42005","volume":"2015-01"},{"name":"Text it as a service / Rapidpro.io","id":"803","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"46","radius":"330","description":"","theta":"        254","lastModified":"42005","volume":"2015-01"},{"name":"TOTP Two-Factor Authentication","id":"779","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"47","radius":"290","description":"\u003cp\u003e\u003cb\u003eTwo-factor authentication\u003c/b\u003e significantly improves security over simple password-based systems. \u003ca href\u003d\u0027http://tools.ietf.org/html/rfc6238\u0027\u003eRFC 6238\u003c/a\u003e -- \u003ca href\u003d\u0027http://en.wikipedia.org/wiki/Time-based_One-time_Password_Algorithm\u0027\u003eTime-based One-Time Password\u003c/a\u003e Algorithm -- is a standard for two-factor authentication. \u0027Standard\u0027 authenticator apps from \u003ca href\u003d\u0027https://play.google.com/store/apps/details?id\u003dcom.google.android.apps.authenticator2\u0027\u003eGoogle\u003c/a\u003e and \u003ca href\u003d\u0027http://www.windowsphone.com/en-us/store/app/authenticator/e7994dbc-2336-4950-91ba-ca22d653759b\u0027\u003eMicrosoft\u003c/a\u003e provide tokens to smartphone users, and there are a number of other client and server implementations readily available. With providers such as Google, Facebook, Dropbox and Evernote using \u003cb\u003eTOTP\u003c/b\u003e, there really is no excuse to continue using simple password-based authentication where stronger security would be appropriate.\u003c/p\u003e","theta":"        259","lastModified":"41791","volume":"2015-01"},{"name":"U2F","id":"804","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"48","radius":"291","description":"","theta":"        264","lastModified":"42005","volume":"2015-01"},{"name":"CMS as a platform","id":"696","quadrant":"Platforms","ring":"Hold","movement":"t","radarId":"49","radius":"375","description":"\u003cp\u003eIn previous editions of the radar, we have written about the pitfalls of trying to use a \u003cstrong\u003eCMS as a platform\u003c/strong\u003e\u0026nbsp;and we continue to see this problematic approach “in the wild.” CMS as an editing, collaboration and\u0026nbsp;workflow\u0026nbsp;platform can work well, and we certainly do not discount these features.\u0026nbsp;We have had success using \u003ca href\u003d\u0027http://martinfowler.com/articles/two-stack-cms/\u0027\u003eTwo Stack CMS\u003c/a\u003e,\u0026nbsp;an approach that \u003ca href\u003d\u0027http://martinfowler.com/bliki/EditingPublishingSeparation.html\u0027\u003eseparates the concerns of \u003cem\u003eediting\u003c/em\u003e and \u003cem\u003epublishing\u003c/em\u003e\u003c/a\u003e content.\u003c/p\u003e","theta":"        210","lastModified":"42005","volume":"2015-01"},{"name":"OSGi","id":"758","quadrant":"Platforms","ring":"Hold","movement":"c","radarId":"50","radius":"375","description":"","theta":"        240","lastModified":"41791","volume":"2015-01"},{"name":"Flyway","id":"741","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"51","radius":"90","description":"\u003cp\u003eWith techniques such as continuous delivery becoming more mainstream, automated database migrations are a baseline capability\u0026nbsp;for many software teams. While\u0026nbsp;there are many tools in this space, we continue to recommend \u003cstrong\u003eFlyway\u003c/strong\u003e for its low-friction approach. Flyway has a vibrant open-source community behind it, and support for both traditional and cloud-based databases such as Amazon Redshift and Google Cloud SQL.\u003c/p\u003e","theta":"        60","lastModified":"42005","volume":"2015-01"},{"name":"GoCD","id":"744","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"52","radius":"51","description":"","theta":"        30","lastModified":"42005","volume":"2015-01"},{"name":"Appium","id":"728","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"53","radius":"190","description":"\u003cp\u003eMobile test automation is becoming increasingly important. \u003ca href\u003d\u0027http://appium.io\u0027\u003e\u003cb\u003eAppium\u003c/b\u003e\u003c/a\u003e is a test automation framework that can test mobile web, mobile native and mobile hybrid applications on iOS and Android. We have used this in multiple projects and have seen significant gains.\u0026nbsp;At the core, Appium is a webserver that exposes a REST API, receiving connections from a client, listening for commands, executing those commands on a mobile device and responding with an HTTP response representing the result of the command execution. It allows tests to be written against iOS and Android\u0026nbsp;using the same API. Appium is open source with easy setup using npm.\u003c/p\u003e","theta":"        86","lastModified":"42005","volume":"2015-01"},{"name":"Boot2docker","id":"805","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"54","radius":"227","description":"","theta":"        81","lastModified":"42005","volume":"2015-01"},{"name":"Composer","id":"806","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"55","radius":"264","description":"\u003cp\u003eAlthough the idea of dependency management is not new and considered to be a fundamental development practice, it is not widely adopted by the PHP community. \u003ca href\u003d\u0027https://getcomposer.org\u0027\u003eComposer\u003c/a\u003e is a tool for dependency management in PHP. It is strongly influenced by tools from other technology\u0026nbsp;stacks like Node\u0027s npm and Ruby\u0027s Bundler.\u0026nbsp;\u003c/p\u003e","theta":"        76","lastModified":"42005","volume":"2015-01"},{"name":"Cursive","id":"807","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"56","radius":"240","description":"","theta":"        72","lastModified":"42005","volume":"2015-01"},{"name":"Docker","id":"714","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"57","radius":"180","description":"\u003cp\u003eSince our last radar, \u003ca href\u003d\u0027https://www.docker.com/\u0027\u003e\u003cstrong\u003eDocker\u003c/strong\u003e\u003c/a\u003e has hit 1.0 and has been declared production ready by the authors. During this same period we have seen an explosion of tools based on Docker. We now have PAAS solutions in the form of \u003ca href\u003d\u0027http://deis.io/\u0027\u003eDeis\u003c/a\u003e, cluster management in \u003ca href\u003d\u0027https://coreos.com/using-coreos/clustering/\u0027\u003eCoreOS\u003c/a\u003e and\u0026nbsp;\u003ca href\u003d\u0027https://github.com/googlecloudplatform/kubernetes\u0027\u003eKubernetes\u003c/a\u003e, and \u003ca href\u003d\u0027http://msopentech.com/blog/2014/08/28/docker-containers-on-microsoft-azure-with-kubernetes-visualizer/\u0027\u003eMicrosoft\u003c/a\u003e, \u003ca href\u003d\u0027https://cloud.google.com/compute/docs/containers\u0027\u003eGoogle\u003c/a\u003e,\u0026nbsp;\u003ca href\u003d\u0027http://aws.amazon.com/blogs/aws/cloud-container-management/\u0027\u003eAWS\u003c/a\u003e\u0026nbsp;and\u0026nbsp;a host of smaller players\u0026nbsp;are offering or will shortly offer\u0026nbsp;Docker hosting. Microsoft is even \u003ca href\u003d\u0027http://www.zdnet.com/docker-container-support-coming-to-microsofts-next-windows-server-release-7000034708/\u0027\u003elooking to support Docker\u003c/a\u003e in their next version of Windows Server.\u0026nbsp;Aside from all this change, Docker is being used in anger now by many people, for dev \u0026amp; test and for production loads.\u0026nbsp;We fully expect to see a large pace of change in the Docker ecosystem over\u0026nbsp;the next year, and strongly suggest you take a look at what Docker could offer your own organisation.\u003c/p\u003e","theta":"        67","lastModified":"42005","volume":"2015-01"},{"name":"Foreman","id":"742","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"58","radius":"190","description":"\u003cp\u003eThe big Cloud providers have clearly raised the bar for provisioning, monitoring, and configuration, simplifying these tasks dramatically through powerful tools. Organizations that want to keep their compute and storage resources in-house are looking for similar solutions that work within their organizational context. \u003ca href\u003d\u0027http://theforeman.org/\u0027\u003e\u003cb\u003eForeman\u003c/b\u003e\u003c/a\u003e has worked really well for us, and it is open-source software, too.\u003c/p\u003e","theta":"        62","lastModified":"41791","volume":"2015-01"},{"name":"GenyMotion","id":"743","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"59","radius":"219","description":"\u003cp\u003eDevice fragmentation in the Android world is often cited as a problem because it can be difficult to understand how your applications will behave on a large number of disparate platforms. \u003ca href\u003d\u0027http://genymotion.com\u0027\u003e\u003cb\u003eGenyMotion\u003c/b\u003e\u003c/a\u003e is an emulator which can mimic the characteristics of a number of different Android devices. Our teams have found this very effective in giving fast feedback for our Android applications.\u003c/p\u003e","theta":"        57","lastModified":"41791","volume":"2015-01"},{"name":"Gitlab","id":"808","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"60","radius":"193","description":"","theta":"        53","lastModified":"42005","volume":"2015-01"},{"name":"Grunt.js","id":"723","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"61","radius":"248","description":"\u003cp\u003e\u003cstrong\u003eGrunt\u003c/strong\u003e is rapidly becoming the de facto JavaScript build tool with high adoption and a growing ecosystem. While slower than newer alternatives, such as Gulp, in terms of file processing, Grunt covers a broader set of build-related activities, has a proliferation of plugins and makes it easy to author and publish self-written plugins to npm.\u003c/p\u003e","theta":"        48","lastModified":"42005","volume":"2015-01"},{"name":"IndexedDB","id":"809","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"62","radius":"205","description":"","theta":"        43","lastModified":"42005","volume":"2015-01"},{"name":"Packer","id":"760","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"63","radius":"190","description":"\u003cp\u003eWe featured \u0027Machine image as a build artifact\u0027 in the last Radar, as an excellent way to implement fast spin-up, immutable servers. The thing holding this technique back was the difficulty in building images, especially when targeting more than one platform. \u003ca href\u003d\u0027http://packer.io\u0027\u003e\u003cb\u003ePacker\u003c/b\u003e\u003c/a\u003e\u0026nbsp;solves this, using your configuration management tool of choice to create images for a number of platforms including AWS, Rackspace, DigitalOcean and even Docker and Vagrant, although we have found the VMWare support to be problematic.\u003c/p\u003e","theta":"        38","lastModified":"41791","volume":"2015-01"},{"name":"Pact \u0026 Pacto","id":"761","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"64","radius":"248","description":"\u003cp\u003eConsumer-Driven Contracts are a testing approach to help service interfaces evolve with confidence without unknowingly breaking consumers. The similarly named \u003ca href\u003d\u0027https://github.com/realestate-com-au/pact\u0027\u003e\u003cb\u003ePact\u003c/b\u003e\u003c/a\u003e and \u003ca href\u003d\u0027http://thoughtworks.github.io/pacto\u0027\u003e\u003cb\u003ePacto\u003c/b\u003e\u003c/a\u003e are two new open-source tools which allow testing interactions between service providers and consumers in isolation against a contract. Both have grown out of projects which are building RESTful microservices and show great promise.\u003c/p\u003e","theta":"        34","lastModified":"41791","volume":"2015-01"},{"name":"Papertrail","id":"762","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"65","radius":"201","description":"\u003cp\u003eIn the previous radar, we mentioned the log aggregation service \u003cb\u003ePapertrail\u003c/b\u003e as a way to collect and analyze logs from a variety of sources including web\u0026nbsp;servers, routers, databases and PaaS services. Our subsequent experiences using it and the\u0026nbsp;integrations from PaaS providers such as Heroku nudge it into something we would happily recommend as a\u0026nbsp;convenient and expedient option, notwithstanding our concerns\u0026nbsp;about widespread adoption of services that centralize large quantities of data aggregated from multiple parties.\u003c/p\u003e","theta":"        29","lastModified":"42005","volume":"2015-01"},{"name":"Postman","id":"810","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"66","radius":"241","description":"\u003cp\u003e\u003ca href\u003d\u0027http://www.getpostman.com/features\u0027\u003ePostman\u003c/a\u003e is a Chrome extension that acts as a REST client in your browser, allowing you to create requests and inspect responses. \u0026nbsp;It is a useful tool when developing an API\u0026nbsp;or implementing a client to call an existing API. It offers a suite of extensions that allow you to use it as a full-blown test runner too, although we discourage\u0026nbsp;the record and replay style of testing it promotes.\u003c/p\u003e","theta":"        24","lastModified":"42005","volume":"2015-01"},{"name":"SnapCI","id":"726","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"67","radius":"184","description":"\u003cp\u003eWe mentioned Thoughtworks\u0027 \u003cb\u003eSnapCI\u003c/b\u003e -- a hosted service that provides deployment pipelines -- on the last edition of the Radar. Since then, we have seen many teams successfully use SnapCI on their projects. If you need a simple continuous delivery solution in the cloud, SnapCI can provide it with one click. No hardware, no hassle.\u003c/p\u003e","theta":"        19","lastModified":"41640","volume":"2015-01"},{"name":"Snowplow Analytics \u0026 Piwik","id":"646","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"68","radius":"245","description":"\u003cp\u003eWith increasing scrutiny over the privacy of data, more companies are concerned about sharing web analytics with third parties. \u003cb\u003eSnowplow Analytics and Piwik\u003c/b\u003e are examples of open-source analytics platforms that can be self-hosted and provide a promising feature set and roadmap.\u003c/p\u003e","theta":"        15","lastModified":"41640","volume":"2015-01"},{"name":"Swagger","id":"776","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"69","radius":"241","description":"","theta":"        10","lastModified":"42005","volume":"2015-01"},{"name":"Xamarin","id":"718","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"70","radius":"187","description":"","theta":"        5","lastModified":"42005","volume":"2015-01"},{"name":"Blackbox","id":"811","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"71","radius":"298","description":"\u003cp\u003e\u003ca href\u003d\u0027https://github.com/StackExchange/blackbox\u0027\u003e\u003cstrong\u003eBlackbox\u003c/strong\u003e\u003c/a\u003e is a simple tool for encrypting specific files while at rest in your source repository. This is particularly useful if you need to store passwords or private keys. Blackbox works with Git, Mercurial and Subversion and uses GPG for the encryption. \u0026nbsp;Each user has their own key, which\u0026nbsp;makes\u0026nbsp;it easy to revoke access on a granular level.\u003c/p\u003e","theta":"        83","lastModified":"42005","volume":"2015-01"},{"name":"Consul","id":"732","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"72","radius":"327","description":"\u003cp\u003e\u003ca href\u003d\u0027http://consul.io\u0027\u003e\u003cb\u003eConsul\u003c/b\u003e\u003c/a\u003e makes it simple for services to register themselves and discover other services via DNS or HTTP. It scales automatically, with service look up locally or across data centers. Consul also provides a flexible key/value store for dynamic configuration, with notification of configuration changes. The internal gossip protocol used by Consul is powered by the \u003ca href\u003d\u0027http://serfdom.io\u0027\u003eSerf\u003c/a\u003e library, leveraging and building upon the membership and failure detection features.\u003c/p\u003e","theta":"        75","lastModified":"41791","volume":"2015-01"},{"name":"Dc.js","id":"812","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"73","radius":"321","description":"\u003cp\u003eWe have recommended D3.js before and in this radar we want to extend our recommendation to \u003ca href\u003d\u0027http://dc-js.github.io/dc.js/\u0027\u003e\u003cstrong\u003eDc.js\u003c/strong\u003e\u003c/a\u003e, a charting library based on D3 for exploring large multi-dimensional datasets. With D3, it shares the ease with which beautiful interactive graphs can be created. It is different in that it trades the flexibility to create almost any kind of data visualization for a simpler programming model to create common chart types.\u003c/p\u003e","theta":"        68","lastModified":"42005","volume":"2015-01"},{"name":"Gorilla REPL","id":"813","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"74","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\u0027http://gorilla-repl.org/\u0027\u003eGorillaREPL\u003c/a\u003e\u003c/strong\u003e is a tool for creating nicely-rendered documents consisting of text,\u0026nbsp;live Clojure code, and plots. \u0026nbsp;In some ways similar to iPython notebooks, GorillaREPL should be particularly useful for data analysts or code\u0026nbsp;tutorials. \u0026nbsp;But beyond that, GorillaREPL is fun!. \u0026nbsp;It is a creative way to\u0026nbsp;demonstrate\u0026nbsp;the power\u0026nbsp;of Clojure’s simple abstractions over immutable values.\u0026nbsp;\u003c/p\u003e","theta":"        60","lastModified":"42005","volume":"2015-01"},{"name":"Gulp","id":"745","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"75","radius":"339","description":"\u003cp\u003eIn the last radar we called out \u003cstrong\u003eGulp\u003c/strong\u003e as a strong competitor to Grunt, with a clean API and fast builds thanks to its streaming approach. While we still like it as a tool, we are moving it out from trial back to assess since Grunt has both a broader usage model and better industry adoption and tooling. We do see some teams successfully using Gulp inside Grunt, when the speed of intermediate result caching is required, but we are not recommending it as the default\u0026nbsp;JavaScript build tool.\u0026nbsp;\u003c/p\u003e","theta":"        53","lastModified":"42005","volume":"2015-01"},{"name":"leaflet.js","id":"751","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"76","radius":"330","description":"\u003cp\u003e\u003ca href\u003d\u0027http://leafletjs.com\u0027\u003e\u003cb\u003eLeaflet.js\u003c/b\u003e\u003c/a\u003e is a JavaScript library for mobile-friendly interactive maps. The library places a huge emphasis on performance, usability and simplicity, and as such works efficiently across mobile platforms and desktop browsers. It is a viable library to consider when building interactive maps for mobiles.\u003c/p\u003e","theta":"        45","lastModified":"41791","volume":"2015-01"},{"name":"Mountebank","id":"755","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"77","radius":"302","description":"\u003cp\u003eWhen testing services, we commonly need to stub out downstream collaborating services. Written by a Thoughtworker, \u003ca href\u003d\u0027http://www.mbtest.org\u0027\u003e\u003cb\u003eMountebank\u003c/b\u003e\u003c/a\u003e is a lightweight service which you can configure via HTTP that is capable of stubbing and mocking HTTP, HTTPS, SMTP and TCP.\u003c/p\u003e","theta":"        38","lastModified":"41791","volume":"2015-01"},{"name":"Packet beat","id":"814","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"78","radius":"312","description":"","theta":"        30","lastModified":"42005","volume":"2015-01"},{"name":"Roslyn","id":"770","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"79","radius":"331","description":"\u003cp\u003e\u003cb\u003eRoslyn\u003c/b\u003e, a .NET compiler platform under the Apache License 2.0, is a next-generation set of compilers for C# and VB.NET written entirely as managed code. It provides access to the compiler as a service and includes code analysis APIs allowing developers to access information from the compiler that was previously treated as a black box, for example syntactic and semantic models. The most immediate impact should be seen in enhancements to .NET IDEs through refactoring and code generation tools. We also expect to see improved code diagnostics and static analysis, although it will be interesting to see what the community comes up with. Meanwhile Xamarin has a Mono-compatible copy of Roslyn source code hosted on GitHub and plans to bundle Roslyn’s compilers with Mono as it stabilizes, in addition to integrating the best parts into their code base.\u003c/p\u003e","theta":"        23","lastModified":"41791","volume":"2015-01"},{"name":"Spark","id":"773","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"80","radius":"300","description":"\u003cp\u003eFor iterative processing such as machine learning and interactive analysis, Hadoop map-reduce does not work very well because of its batch-oriented nature. \u003cb\u003eSpark\u003c/b\u003e is a fast and general engine for large-scale data processing. It aims to extend map-reduce for iterative algorithms and interactive low latency data mining. It also ships with a machine learning library.\u003c/p\u003e","theta":"        15","lastModified":"41791","volume":"2015-01"},{"name":"Terraform","id":"815","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"81","radius":"300","description":"\u003cp\u003eWith \u003cstrong\u003eTerraform,\u003c/strong\u003e cloud infrastructure can be managed by writing declarative definitions. The configuration of the servers instantiated by Terraform is usually left to tools like Puppet, Chef, or Ansible. We like Terraform because the syntax of its files is quite readable and because it supports multiple cloud providers while making no attempt to provide an artificial abstraction across these providers. At this stage, Terraform is new and not everything is implemented yet. We have also found its state management to be fragile, often needing awkward manual work to untangle.\u003c/p\u003e","theta":"        8","lastModified":"42005","volume":"2015-01"},{"name":"Citrix for development","id":"816","quadrant":"Tools","ring":"Hold","movement":"t","radarId":"82","radius":"375","description":"","theta":"        45","lastModified":"42005","volume":"2015-01"},{"name":"Go language","id":"684","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radarId":"83","radius":"90","description":"\u003cp\u003eThe \u003ca href\u003d\u0027https://golang.org/\u0027\u003e\u003cb\u003eGo language\u003c/b\u003e\u003c/a\u003e gradually changed status from \u0026quot;Just Another Language\u0026quot; to a valuable tool in many projects. While steadfastly single paradigm in a world of increasingly complex languages, it seems to keep a nice balance between expressiveness, power, and simplicity.\u003c/p\u003e","theta":"        300","lastModified":"41640","volume":"2015-01"},{"name":"Java 8","id":"750","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radarId":"84","radius":"110","description":"\u003cp\u003eThe team behind \u003cb\u003eJava 8\u003c/b\u003e had to fight two battles: the community forces encouraging forever backwards compatibility (a long hallmark of Java) and the technical challenge of making a deep language change mesh with existing libraries and features. They succeeded on both fronts, breathing new life into the Java Language and placing it on par with other mainstream languages in terms of functional programming features. In particular, Java 8 has excellent syntactic magic that allows seamless interoperability between Lambda blocks, the new higher-order function feature, and SAM (Single Abstract Method) interfaces, the traditional way of passing behavior.\u003c/p\u003e","theta":"        330","lastModified":"41791","volume":"2015-01"},{"name":"AngularJS","id":"727","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"85","radius":"218","description":"\u003cp\u003eWe continue to see JavaScript frameworks as a useful way to structure code and bring better coding techniques to JavaScript. \u003cb\u003eAngularJS\u003c/b\u003e is used widely by Thoughtworks projects. However, we are a bit concerned about the future of the framework. \u0026nbsp;The 2.0 version\u0026nbsp;currently under development represents a ground-up\u0026nbsp;redesign that some might not be happy with. \u0026nbsp;Without an evolutionary migration path, maintainers of existing AngularJS\u0026nbsp;applications will be forced to either live with an unsupported version or undertake a large rewrite. \u0026nbsp;We advise teams to first assess their requirements to understand if a single-page JavaScript application is really necessary. \u0026nbsp;In many cases, a traditional page-model app\u0026nbsp;is simpler to write and easier to maintain. \u0026nbsp;Remember that there are\u0026nbsp;other good alternatives to AngularJS,\u0026nbsp;such as Ember.js,\u0026nbsp;Knockout.js, and\u0026nbsp;React.js.\u003c/p\u003e","theta":"        277","lastModified":"42005","volume":"2015-01"},{"name":"Core Async","id":"733","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"86","radius":"253","description":"\u003cp\u003eThe Clojure \u003cb\u003ecore.async\u003c/b\u003e library allows asynchronous communication using channels, with similar syntax and capabilities to Google\u0027s Go language. The core.async library solves many common problems in an elegant way, cleaning up event callback setup and adding simple concurrency primitives. It also highlights one of the advantages of the Lisp nature of Clojure: channels add operators that are consistent with existing Clojure operators, seamlessly weaving new functionality into the language core. In addition, core.async is supported in both Clojure and ClojureScript (despite JavaScript\u0027s lack of threads), utilizing underlying platform abstractions to provide a consistent interface to both languages.\u003c/p\u003e","theta":"        285","lastModified":"41791","volume":"2015-01"},{"name":"Dashing","id":"817","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"87","radius":"257","description":"","theta":"        292","lastModified":"42005","volume":"2015-01"},{"name":"Django Rest","id":"818","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"88","radius":"162","description":"","theta":"        300","lastModified":"42005","volume":"2015-01"},{"name":"HAL","id":"746","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"89","radius":"225","description":"\u003cp\u003eWe see lots of teams creating RESTful interfaces without paying any attention to hypermedia. \u003ca href\u003d\u0027http://stateless.co/hal_specification.html\u0027\u003e\u003cb\u003eHAL\u003c/b\u003e\u003c/a\u003e is a simple format for incorporating hyperlinks into JSON representations which is easy to implement and consume. HAL is well supported by libraries for parsing and representing JSON, and there are HAL-aware REST client libraries such as \u003ca href\u003d\u0027https://github.com/codegram/hyperclient\u0027\u003eHyperclient\u003c/a\u003e which make it easy to navigate resources by following links.\u003c/p\u003e","theta":"        307","lastModified":"41791","volume":"2015-01"},{"name":"Ionic Framework","id":"819","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"90","radius":"262","description":"","theta":"        315","lastModified":"42005","volume":"2015-01"},{"name":"Nashorn","id":"820","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"91","radius":"176","description":"","theta":"        322","lastModified":"42005","volume":"2015-01"},{"name":"Om","id":"756","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"92","radius":"163","description":"","theta":"        330","lastModified":"42005","volume":"2015-01"},{"name":"Q \u0026 Bluebird","id":"767","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"93","radius":"182","description":"\u003cp\u003e\u003ca href\u003d\u0027https://github.com/kriskowal/q\u0027\u003e\u003cb\u003eQ\u003c/b\u003e\u003c/a\u003e is a fully Promises/A+ compliant implementation in JavaScript that lets users compose promises arbitrarily deeply without the need for the deeply nested callbacks that obscure control flow. Q takes care of threading fulfilled values and rejected promises through the appropriate code paths. The space of Promises/A+ compliant libraries is currently very active with alternatives like \u003ca href\u003d\u0027https://github.com/petkaantonov/bluebird\u0027\u003e\u003cb\u003eBluebird\u003c/b\u003e\u003c/a\u003e also rapidly gaining mindshare.\u003c/p\u003e","theta":"        337","lastModified":"41791","volume":"2015-01"},{"name":"R as Compute Platform","id":"768","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"94","radius":"244","description":"\u003cp\u003eR is traditionally used as stand alone analysis tool by research teams. With improvements in packages like Rook and RJSONIO, it has become trivial to wrap the computational logic and expose it as an API. Thoughtworks teams are using \u003cb\u003eR as Compute platform\u003c/b\u003e to crunch large datasets in real time, using in-memory storage integrated with enterprise systems.\u003c/p\u003e","theta":"        345","lastModified":"41791","volume":"2015-01"},{"name":"Retrofit","id":"821","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"95","radius":"232","description":"","theta":"        352","lastModified":"42005","volume":"2015-01"},{"name":"Flight.js","id":"823","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"96","radius":"307","description":"\u003cp\u003eIn the crowded space of JavaScript frameworks, we want to highlight \u003ca href\u003d\u0027https://flightjs.github.io/\u0027\u003e\u003cstrong\u003eFlight.js\u003c/strong\u003e\u003c/a\u003e as an alternative to consider. Flight is extremely lightweight and gets by without much magic when adding behavior to DOM nodes. Its event-driven and component-based nature promotes writing decoupled code. This makes testing individual components comparatively easy. Care must be taken, however, when components need to interact with each other. \u0026nbsp;There is little support for testing and a real danger to get into \u003cem\u003eevent hell\u003c/em\u003e. We do like that it uses functional mixins for behaviour, like composition instead of inheritance.\u003c/p\u003e","theta":"        280","lastModified":"42005","volume":"2015-01"},{"name":"Haskell Hadoop library","id":"824","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"97","radius":"330","description":"","theta":"        290","lastModified":"42005","volume":"2015-01"},{"name":"Lotus","id":"825","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"98","radius":"336","description":"","theta":"        300","lastModified":"42005","volume":"2015-01"},{"name":"React.js","id":"827","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"99","radius":"321","description":"\u003cp\u003eOne benefit to the ongoing\u0026nbsp;avalanche of front-end JavaScript frameworks is that occasionally, a new\u0026nbsp;idea crops up that makes us think. \u0026nbsp;\u003cstrong\u003eReact.js\u003c/strong\u003e is a UI/View framework in which\u0026nbsp;JavaScript functions\u0026nbsp;generate HTML in a reactive data flow. \u0026nbsp;Although we are wary of mixing code and markup, it results in UI components that are nicely encapsulated and composable. \u0026nbsp;React.js is getting a lot of developer attention and will benefit\u0026nbsp;from more tools and examples\u003cstrong\u003e\u003cstrong\u003e\u003cstrong\u003e\u003cstrong\u003e\u0026nbsp;\u003c/strong\u003e\u003c/strong\u003e\u003c/strong\u003e\u003c/strong\u003ebecoming available.\u003c/p\u003e","theta":"        310","lastModified":"42005","volume":"2015-01"},{"name":"Reagent","id":"828","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"100","radius":"298","description":"","theta":"        320","lastModified":"42005","volume":"2015-01"},{"name":"Rust","id":"771","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"101","radius":"323","description":"\u003cp\u003e\u003ca href\u003d\u0027http://www.rust-lang.org/\u0027\u003e\u003cb\u003eRust\u003c/b\u003e\u003c/a\u003e is a system programming language with modern affordances. It features a rich typing system, safe memory model and task-based concurrency. Compared to the Go language, Rust is more friendly to people who would like to write code in a functional style.\u003c/p\u003e","theta":"        330","lastModified":"41791","volume":"2015-01"},{"name":"Spring Boot","id":"775","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"102","radius":"314","description":"\u003cp\u003e\u003ca href\u003d\u0027http://projects.spring.io/spring-boot\u0027\u003e\u003cb\u003eSpring boot\u003c/b\u003e\u003c/a\u003e allows easy set up of standalone Spring-based applications. It\u0027s ideal for pulling up new microservices and easy to deploy. It also makes data access less of a pain due to the hibernate mappings with much less boilerplate code.\u003c/p\u003e","theta":"        340","lastModified":"41791","volume":"2015-01"},{"name":"Swift","id":"830","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"103","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\u0027http://www.apple.com/swift/\u0027\u003eSwift,\u003c/a\u003e Apple’s new development language, contains many improvements over the perennial Objective-C, including emphasis on functional programming and modern syntax. In most ways, this is an upgrade if you are coding on the Apple platform.\u003c/p\u003e","theta":"        350","lastModified":"42005","volume":"2015-01"},{"name":"JSF","id":"683","quadrant":"languages-and-frameworks","ring":"Hold","movement":"c","radarId":"104","radius":"375","description":"","theta":"        315","lastModified":"41640","volume":"2015-01"}],"date":"2015-01"},{"blips":[{"name":"Consumer-driven contract testing","id":"833","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"1","display_name":"Consumer-driven contract testing","radius":"75","description":"","theta":"162","volume":"2015-05"},{"name":"Focus on mean time to recovery","id":"623","quadrant":"Techniques","ring":"Adopt","movement":"c","radarId":"2","display_name":"Focus on mean time to recovery","radius":"55","description":"\u003cp\u003eTraditionally operations groups look to improve the mean time between failures. While avoiding failures is obviously still important, lessons from cloud computing have taught us to expect failure and instead to \u003cstrong\u003efocus on mean time to recovery\u003c/strong\u003e. Continuous Delivery automation makes rolling out rapid fixes easier and we are also seeing a growth in monitoring techniques to spot failures quickly through a ‘production immune system’. Teams are also successfully using semantic monitoring and synthetic transactions to exercise production systems in non-destructive ways. This combined focus allows teams to move rapidly with higher confidence, it can also reduce the emphasis on expensive test-execution in pre-production environments and is particularly important in responding to the ever-growing list of security vulnerabilities that are being discovered.\u003c/p\u003e","theta":"144","volume":"2015-05"},{"name":"Generated infrastructure diagrams","id":"832","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"3","display_name":"Generated infrastructure diagrams","radius":"120","description":"","theta":"126","volume":"2015-05"},{"name":"Structured logging","id":"711","quadrant":"Techniques","ring":"Adopt","movement":"c","radarId":"4","display_name":"Structured logging","radius":"100","description":"\u003cp\u003eTreating logs as data gives us greater insight into the operational activity of the systems we build. \u003cstrong\u003eStructured logging\u003c/strong\u003e , which is using a consistent, predetermined message format containing semantic information, builds on this technique and enables tools such as Graylog2 and Splunk to yield deeper insights. We recommend adopting structured logging because the benefits outweigh the minimal effort involved and the practice is becoming the default standard.\u003c/p\u003e","theta":"108","volume":"2015-05"},{"name":"Canary builds","id":"781","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"5","display_name":"Canary builds","radius":"178","description":"\u003cp\u003eMany projects have external code dependencies, a large amount of which is provided by open source projects. In order to ensure our builds are reproducible, we integrate against known versions of them, but that can mean that it takes a while for us to integrate against newer versions of these libraries leading to a larger merge effort down the line. One approach we have seen to avoid this is to have a nightly \u003cstrong\u003eCanary Build\u003c/strong\u003e which tries to pull in the latest version of all dependencies. If the build is green, we know we can change which versions we depend on.\u003c/p\u003e","theta":"169","volume":"2015-05"},{"name":"Datensparsamkeit","id":"699","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"6","display_name":"Datensparsamkeit","radius":"225","description":"\u003cp\u003eThe term \u003ca href\u003d\"http://martinfowler.com/bliki/Datensparsamkeit.html\"\u003e\u003cstrong\u003eDatensparsamkeit\u003c/strong\u003e\u003c/a\u003e is taken from German privacy legislation and describes the idea to only store as much personal information as is absolutely required for the business or applicable laws. Customer privacy continues to be a hot topic. Companies such as \u003ca href\u003d\"http://www.washingtonpost.com/blogs/the-switch/wp/2014/12/01/is-ubers-rider-database-a-sitting-duck-for-hackers/\"\u003eUber are apparently collecting highly personal customer data, as well as being quite lax with security.\u003c/a\u003e This is a disaster waiting to happen. Following datensparsamkeit or using \u003ca href\u003d\"https://en.wikipedia.org/wiki/De-identification\"\u003ede-identification\u003c/a\u003e techniques even in jurisdictions where it is not legally mandated, can allow you to reduce the information you store. If you never store the information, you do not need to worry about someone stealing it.\u003c/p\u003e","theta":"158","volume":"2015-05"},{"name":"Local storage sync","id":"783","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"7","display_name":"Local storage sync","radius":"220","description":"\u003cp\u003eWhen implementing single-page applications, sooner or later the question of offline use will come up. Given how hard it is to get this right when retrofitting an offline mode into an existing application, there is a trend towards implementing single-page applications with an “offline-first” mindset. An important implementation technique that we have used successfully is \u003cstrong\u003elocal storage sync\u003c/strong\u003e. With this technique, the user facing code never makes requests to the backend. It retrieves data solely from local storage. A background worker synchronises the data in local storage with the backend systems, usually employing calls to some form of REST API.\u003c/p\u003e","theta":"147","volume":"2015-05"},{"name":"NoPSD","id":"784","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"8","display_name":"NoPSD","radius":"170","description":"\u003cp\u003e\u003ca href\u003d\"https://www.thoughtworks.com/p2magazine/issue02/continuous-design/\"\u003e\u003cstrong\u003eNoPSD\u003c/strong\u003e\u003c/a\u003e is a movement to integrate design activities into the iterative feedback cycles required to build great software. The name aims to dislodge the PSD as the final canonical design artifact rather than taking a dig at the Adobe software. Instead of signing off on a pixel-perfect design specification at the start of a project, teams are urged to embrace Continuous Design: embedding designers into delivery teams, using lo-fi techniques for prototyping, and collaborating to refine the design in the target UI technology (normally HTML and CSS). This approach speeds responding to real user feedback, allows testing designs across multiple devices and form-factors, and embraces the dynamic nature of both digital products and the product creation process.\u003c/p\u003e","theta":"135","volume":"2015-05"},{"name":"Offline first web applications","id":"877","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"9","display_name":"Offline first web applications","radius":"250","description":"","theta":"124","volume":"2015-05"},{"name":"Products over projects","id":"838","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"10","display_name":"Products over projects","radius":"175","description":"\u003cp\u003eMost software development efforts are done using the mental model of a project, something that is planned, executed, and delivered within defined time-slots. Agile development challenged much of this model, replacing an up-front determination of requirements with an on-going discovery process that runs concurrently with development. Lean startup techniques, such as A/B testing of \u003ca href\u003d\"http://martinfowler.com/bliki/ObservedRequirement.html\"\u003eobserved requirements\u003c/a\u003e, further erode this mindset. We consider that most software efforts should follow the lead of \u003ca href\u003d\"https://info.thoughtworks.com/lean-enterprise-book.html\"\u003eLean Enterprise\u003c/a\u003e and consider themselves to be building products that support underlying business processes. Such products do not have a final delivery, rather an on-going process of exploring how best to support and optimize that business process which continues as long as the business is worthwhile. For these reasons we encourage organizations to think in terms of \u003cstrong\u003eproducts rather than projects\u003c/strong\u003e.\u003c/p\u003e","theta":"113","volume":"2015-05"},{"name":"Threat Modeling","id":"871","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"11","display_name":"Threat Modeling","radius":"220","description":"\u003cp\u003eAt this point the vast majority of development teams are aware of the importance of writing secure software and dealing with their users’ data in a responsible way. They do face a steep learning curve and a vast number of potential threats, ranging from organized crime and government spying to teenagers who attack systems \u0027for the lulz\u0027. \u003ca href\u003d\"https://www.owasp.org/index.php/Category:Threat_Modeling\"\u003e\u003cstrong\u003eThreat Modeling\u003c/strong\u003e\u003c/a\u003eis a set of techniques, mostly from a defensive perspective, that help understand and classify potential threats. When turned into \u0027evil user stories\u0027 this can give a team a manageable and effective approach to making their systems more secure.\u003c/p\u003e","theta":"102","volume":"2015-05"},{"name":"Append-only data store","id":"787","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"12","display_name":"Append-only data store","radius":"320","description":"\u003cp\u003eImmutable data structures are becoming more popular with functional languages such as Clojure providing immutability by default. Immutability allows code to be more easily written, read, and reasoned about. Using an \u003cstrong\u003eappend-only data store\u003c/strong\u003e can confer some of these benefits in the database layer, as well as making audit and historical querying simple. Implementation options vary, from specific append-only data stores such as \u003ca href\u003d\"http://www.datomic.com/\"\u003eDatomic\u003c/a\u003e to simply using an “append-don’t-update” approach with a traditional database.\u003c/p\u003e","theta":"169","volume":"2015-05"},{"name":"Blockchain beyond bitcoin","id":"788","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"13","display_name":"Blockchain beyond bitcoin","radius":"320","description":"\u003cp\u003eWhile the currency aspect of Bitcoin and other cryptocurrencies gets most of the news, we are equally excited about possibilities for using the \u003cstrong\u003eBlockchain beyond bitcoin\u003c/strong\u003e and financial transactions. The Blockchain is a mechanism for verifying the contents of a shared ledger without relying on a centralized service. We already see the Blockchain (either the underlying technology or the public Bitcoin Blockchain) being used at the heart of systems as varied as identity, ownership, record-keeping, voting, cloud storage and even managing networks of smart devices. If you are building systems that require trust over decentralized networks, then the Blockchain is a technology worth assessing.\u003c/p\u003e","theta":"158","volume":"2015-05"},{"name":"Enterprise Data Lake","id":"789","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"14","display_name":"Enterprise Data Lake","radius":"290","description":"\u003cp\u003eAn \u003cstrong\u003eEnterprise Data Lake\u003c/strong\u003e is an immutable data store of largely un-processed “raw” data, acting as a source for other processing streams but also made directly available to a significant number of internal, technical consumers using some efficient processing engine. Examples include HDFS or HBase within a Hadoop, Spark or Storm processing framework. We can contrast this with a typical system that collects raw data into some highly restricted space that is only made available to these consumers as the end result of a highly controlled ETL process.\u003c/p\u003e\n\n\u003cp\u003eEmbracing the concept of the data lake is about eliminating bottlenecks due to lack of ETL developer staffing or excessive up front data model design. It is about empowering developers to create their own data processing pipelines in an agile fashion when they need it and how they need it—within reasonable limits—and so has much in common with another model that we think highly of, the DevOps model.\u003c/p\u003e","theta":"147","volume":"2015-05"},{"name":"Flux","id":"837","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"15","display_name":"Flux","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"https://facebook.github.io/flux/\"\u003e\u003cstrong\u003eFlux\u003c/strong\u003e\u003c/a\u003e is an application architecture that Facebook has adopted for its web application development. Usually mentioned in conjunction with \u003cstrong\u003ereact.js\u003c/strong\u003e , Flux is based on a one-way flow of data up through the rendering pipeline triggered by users or other external events modifying data stores. It’s been a while since we’ve seen any alternatives to the venerable model-view-* architectures and Flux embraces the modern web landscape of client-side JavaScript applications talking to multiple back-end services.\u003c/p\u003e","theta":"135","volume":"2015-05"},{"name":"Git based CMS/Git for non-code","id":"835","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"16","display_name":"Git based CMS/Git for non-code","radius":"330","description":"\u003cp\u003eThese days, most software developers are used to working with Git for source code control and collaboration. But Git can be used as a base mechanism for other circumstances where a group of people need to collaborate on textual documents (that can easily be merged). We’ve seen increasing amounts of projects use \u003ca href\u003d\"http://git-scm.com/\"\u003e\u003cstrong\u003eGit\u003c/strong\u003e\u003c/a\u003e as the basis for a lightweight \u003cstrong\u003eCMS\u003c/strong\u003e , with text-based editing formats. Git has powerful features for tracking changes and exploring alternatives, with a distributed storage model that is fast in use and tolerant of networking issues. The biggest problem with wider adoption is that Git isn’t very easy to learn for non-programmers, but we expect to see more tools that build on top of the core Git plumbing. Such tools simplify the workflow for specific audiences, such as content authors. We would also welcome more tools to support diffing and merging for non-textual documents.\u003c/p\u003e","theta":"124","volume":"2015-05"},{"name":"Phoenix Environments","id":"834","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"17","display_name":"Phoenix Environments","radius":"290","description":"\u003cp\u003eThe idea of \u003ca href\u003d\"http://martinfowler.com/bliki/PhoenixServer.html\"\u003ephoenix servers\u003c/a\u003e is now well established and has brought many benefits when applied to the right kinds of problems, but what about the environment we deploy these servers into? The concept of \u003cstrong\u003ePhoenix Environments\u003c/strong\u003e can help. We can use automation to allow us to create whole environments, including network configuration, load balancing and firewall ports, for example by using \u003cstrong\u003eCloudFormation\u003c/strong\u003e in AWS. We can then prove that the process works, by tearing the environments down and recreating them from scratch on a regular basis. Phoenix Environments can support provisioning new environments for testing, development, UAT and so on. They can also simplify the provision of a disaster recovery environment. As with Phoenix Servers this pattern is not always applicable and we need to think about carefully about things like state and dependencies. Treating the whole environment as a \u003ca href\u003d\"http://martinfowler.com/bliki/BlueGreenDeployment.html\"\u003egreen/blue deployment\u003c/a\u003e can be one approach when environment reconfiguration needs to be done.\u003c/p\u003e","theta":"113","volume":"2015-05"},{"name":"Reactive Architectures","id":"836","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"18","display_name":"Reactive Architectures","radius":"310","description":"","theta":"102","volume":"2015-05"},{"name":"Long lived branches with Gitflow","id":"790","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"19","display_name":"Long lived branches with Gitflow","radius":"375","description":"\u003cp\u003e\u003cstrong\u003eGitflow\u003c/strong\u003e is a strict branching pattern for releases using Git. Although not an inherently bad pattern, we often see it misused. If the feature and develop branches are short lived and merged often, you are really using the power of Git, which makes these activities easy. However, a problem we often see is that these become \u003cstrong\u003elong lived branches\u003c/strong\u003e , which results in the dreaded merge conflicts many people began using Git to escape. A merge is a merge. Regardless of the source control tool or pattern you use. If you wait more than a day or two to merge, you could hit a big merge conflict. This becomes a real issue if you have a larger team. If you have more than a few people waiting to merge, you can have a serious a bottleneck. Introducing patterns like Gitflow require the discipline to merge often to be successful. So by all means use the pattern, but only if you have the discipline to prevent long lived branches\u003c/p\u003e","theta":"168","volume":"2015-05"},{"name":"Microservice envy","id":"791","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"20","display_name":"Microservice envy","radius":"375","description":"","theta":"155","volume":"2015-05"},{"name":"Programming in your CI/CD tool","id":"792","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"21","display_name":"Programming in your CI/CD tool","radius":"375","description":"","theta":"142","volume":"2015-05"},{"name":"SAFe™","id":"793","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"22","display_name":"SAFe™","radius":"375","description":"\u003cp\u003eScaling agile across enterprises is a continuing challenge. Several approaches have been proposed, with \u003cstrong\u003eSAFe™\u003c/strong\u003e being one gaining significant mindshare. While SAFe™ provides a useful checklist for areas of concern, they are easy to misuse, by introducing the same kind of large release tendencies like the release train and gated control processes that agile removes. Enterprises in particular look for a degree of commonality across endeavors that SAFe™ seems to provide, promoting aggressive standardization when some degree of customization provides significant value. Other lean approaches that include experimentation and incorporate continuous improvement practices like the Improvement Katas offer organizations a better model for scaling agile.\u003c/p\u003e\n\n\u003cp\u003eScaled Agile Framework® and SAFe™ are trademarks of Scaled Agile, Inc.\u003c/p\u003e","theta":"129","volume":"2015-05"},{"name":"Security sandwich","id":"794","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"23","display_name":"Security sandwich","radius":"375","description":"\u003cp\u003eTraditional approaches to security have relied on up-front specification followed by validation at the end. This \u003cstrong\u003e“Security Sandwich”\u003c/strong\u003e approach is hard to integrate into Agile teams, since much of the design happens throughout the process, and it does not leverage the automation opportunities provided by continuous delivery. Organizations should look at how they can inject security practices throughout the agile development cycle. This includes: evaluating the right level of Threat Modeling to do up-front; when to classify security concerns as their own stories, acceptance criteria, or cross-cutting non-functional requirements; including automatic static and dynamic security testing into your build pipeline; and how to include deeper testing, such as penetration testing, into releases in a continuous delivery model. In much the same way that DevOps has recast how historically adversarial groups can work together, the same is happening for security and development professionals. (But despite our dislike of the Security Sandwich model, it is much better than not considering security at all, which is sadly still a common circumstance.)\u003c/p\u003e","theta":"116","volume":"2015-05"},{"name":"Separate DevOps team","id":"734","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"24","display_name":"Separate DevOps team","radius":"375","description":"","theta":"103","volume":"2015-05"},{"name":"Apache Spark","id":"773","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"25","display_name":"Apache Spark","radius":"170","description":"","theta":"198","volume":"2015-05"},{"name":"Cloudera Impala","id":"873","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"26","display_name":"Cloudera Impala","radius":"180","description":"","theta":"216","volume":"2015-05"},{"name":"DigitalOcean","id":"735","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"27","display_name":"DigitalOcean","radius":"172","description":"\u003cp\u003eWe have been using \u003ca href\u003d\"http://digitalocean.com\"\u003e\u003cstrong\u003eDigitalOcean\u003c/strong\u003e\u003c/a\u003e for basic compute infrastructure, and the service continues to impress us. If you need developer-friendly cloud infrastructure, it is worth a look.\u003c/p\u003e","theta":"234","volume":"2015-05"},{"name":"TOTP Two-Factor Authentication","id":"779","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"28","display_name":"TOTP Two-Factor Authentication","radius":"170","description":"\u003cp\u003ePasswords continue to be a poor mechanism for authenticating users and we’ve recently seen companies such as Yahoo! move to a “no passwords” solution—a one-time code is texted to your phone whenever you need to log in from a new browser. If you are still using passwords we recommend employing \u003cstrong\u003etwo-factor authentication\u003c/strong\u003e which can significantly improve security. \u003ca href\u003d\"http://en.wikipedia.org/wiki/Time-based_One-time_Password_Algorithm\"\u003eTime-based One-Time Password\u003c/a\u003e ( \u003cstrong\u003eTOTP\u003c/strong\u003e ) is the standard algorithm in this space, with free smartphone authenticator apps from \u003ca href\u003d\"https://play.google.com/store/apps/details?id\u003dcom.google.android.apps.authenticator2\"\u003eGoogle\u003c/a\u003e and \u003ca href\u003d\"http://www.windowsphone.com/en-us/store/app/authenticator/e7994dbc-2336-4950-91ba-ca22d653759b\"\u003eMicrosoft\u003c/a\u003e.\u003c/p\u003e","theta":"252","volume":"2015-05"},{"name":"Apache Kylin","id":"862","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"29","display_name":"Apache Kylin","radius":"310","description":"","theta":"185","volume":"2015-05"},{"name":"Apache Mesos","id":"796","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"30","display_name":"Apache Mesos","radius":"321","description":"\u003cp\u003e\u003ca href\u003d\"http://mesos.apache.org/\"\u003eMesos\u003c/a\u003e is a platform that abstracts out underlying computing resources to make it easier to build massively scalable distributed systems. It can be used to provide a scheduling layer for Docker, or to act as an abstraction layer to things like AWS. Twitter has used it to great effect to help them scale their infrastructure. Tools build on top of Mesos are starting to appear such as \u003ca href\u003d\"http://nerds.airbnb.com/introducing-chronos/\"\u003eChronos\u003c/a\u003e, which is a distributed, fault tolerant cron replacement.\u003c/p\u003e","theta":"190","volume":"2015-05"},{"name":"CoreCLR and CoreFX","id":"866","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"31","display_name":"CoreCLR and CoreFX","radius":"320","description":"","theta":"195","volume":"2015-05"},{"name":"CoreOS","id":"797","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"32","display_name":"CoreOS","radius":"311","description":"\u003cp\u003e\u003cstrong\u003eCoreOS\u003c/strong\u003e is a Linux distribution designed to run large, scalable systems. All applications deployed on a CoreOS instance are run in separate Docker containers, and CoreOS provides a suite of tools to help manage them, including etcd their own distributed configuration store. Newer services, such as fleet, help cluster management by ensuring that a specific number of service instances are always kept running. FastPatch allows atomic CoreOS upgrades using an active-passive root partition scheme and helps with quick rollback in case of problems. These new developments make CoreOS well worth looking into if you are already comfortable with Docker.\u003c/p\u003e","theta":"201","volume":"2015-05"},{"name":"Deis","id":"865","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"33","display_name":"Deis","radius":"310","description":"","theta":"206","volume":"2015-05"},{"name":"H2O","id":"869","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"34","display_name":"H2O","radius":"287","description":"\u003cp\u003ePredictive analytics are used in more and more products, often directly in end-user facing functionality. \u003ca href\u003d\"http://docs.0xdata.com/\"\u003e\u003cstrong\u003eH2O\u003c/strong\u003e\u003c/a\u003e is an interesting new open source package (with a startup behind it) that makes predictive analytics accessible to project teams due to its easy-to-use user interface. At the same time it integrates with the data scientists’ favourite tools, R and Python, as well as Hadoop and Spark. It offers great performance and, in our experience, easy integration at runtime, especially on JVM-based platforms.\u003c/p\u003e","theta":"211","volume":"2015-05"},{"name":"Jackrabbit Oak","id":"800","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"35","display_name":"Jackrabbit Oak","radius":"287","description":"\u003cp\u003e\u003ca href\u003d\"http://jackrabbit.apache.org/oak/\"\u003eJackrabbit Oak\u003c/a\u003e, formerly named Jackrabbit 3, is a scalable and performant implementation of hierarchical content repository for use as the foundation of content management system. In addition to file based storage solution, MongoDB and RDMS storage are also supported, and preferred in large volume use scenarios. Although implemented in Java, it can be easily accessed from various platforms via standards like JCR.\u003c/p\u003e","theta":"217","volume":"2015-05"},{"name":"Linux security modules","id":"795","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"36","display_name":"Linux security modules","radius":"312","description":"","theta":"222","volume":"2015-05"},{"name":"MariaDB","id":"798","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"37","display_name":"MariaDB","radius":"311","description":"\u003cp\u003eAfter Oracle\u0027s acquisition of MySQL, more and more close sourced modules are bundled into its enterprise edition. There are concerns over the future of MySQL. \u003ca href\u003d\"https://mariadb.org/\"\u003eMariaDB\u003c/a\u003e is a community-developed GPL-only fork of MySQL intended to remain truly open source, yet fully compatible and competitive with MySQL. High-profile adopters include large-scale internet organizations Google and Wikipedia, as well as key Linux distributors RedHat and SUSE.\u003c/p\u003e","theta":"227","volume":"2015-05"},{"name":"Netflix OSS Full stack","id":"799","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"38","display_name":"Netflix OSS Full stack","radius":"337","description":"\u003cp\u003eWhile we are reluctant to recommend wholesale adoption of the \u003cstrong\u003eNetflix OSS Full Stack\u003c/strong\u003e unless you happen to be entering the globally distributed video streaming business, the stack is chock full of interesting ideas, complete with open source implementations. Some of the tools, Asgard for example, are highly coupled into a virtually turnkey architecture, making them challenging to use individually. Other tools like Ice and Hystrix, which we featured on the radar previously, can be used stand-alone. We think teams should understand the ideas and approaches encapsulated within the tools even when they choose not to leverage the full stack.\u003c/p\u003e","theta":"232","volume":"2015-05"},{"name":"OpenAM","id":"801","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"39","display_name":"OpenAM","radius":"310","description":"\u003cp\u003eWhen Oracle ceased development on Sun’s OpenSSO—an open source access management platform—It was picked up by ForgeRock and integrated into their Open Identity Suite. Now named \u003cstrong\u003e\u003ca href\u003d\"http://forgerock.com/products/open-identity-stack/openam/\"\u003eOpenAM\u003c/a\u003e\u003c/strong\u003e, it fills the niche for a scalable, open-source platform that supports OpenID Connect and SAML 2.0. However, OpenAM’s long history has resulted in a sprawling codebase whose documentation can be inscrutable. Hopefully, a slimmed-down alternative with better support for automated deployment and provisioning will emerge soon.\u003c/p\u003e","theta":"238","volume":"2015-05"},{"name":"SDN","id":"802","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"40","display_name":"SDN","radius":"305","description":"\u003cp\u003eSoftware Defined Networking ( \u003cstrong\u003eSDN\u003c/strong\u003e ) is a broad topic, but is becoming ever more important. The ability to configure our networking devices using software is blurring the lines of where our application deployments end. It encompasses everything from virtual networking appliances like AWS’ Load Balancers or \u003ca href\u003d\"https://github.com/coreos/flannel\"\u003eCoreOS’ Flannel\u003c/a\u003e, to networking equipment that supports standards like \u003ca href\u003d\"https://www.opennetworking.org/sdn-resources/openflow\"\u003eOpenFlow\u003c/a\u003e. Where cloud providers have previously focused on compute and storage, we expect the growing array of SDN tools to deliver further efficiencies to how we handle our systems both off and on premise.\u003c/p\u003e","theta":"243","volume":"2015-05"},{"name":"Spark Photon/Spark Electron","id":"864","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"41","display_name":"Spark Photon/Spark Electron","radius":"340","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.spark.io/\"\u003eSpark\u003c/a\u003e\u003c/strong\u003e is a full stack solution for cloud connected devices. \u003cstrong\u003eSpark Photon\u003c/strong\u003e is a microcontroller with wifi module. \u003cstrong\u003eSpark Electron\u003c/strong\u003e is a variant that connects to a cellular network. Spark OS adds REST API to the devices. This simplifies the entry to IoT and building your own connected devices.\u003c/p\u003e","theta":"248","volume":"2015-05"},{"name":"Text it as a service / Rapidpro.io","id":"803","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"42","display_name":"Text it as a service / Rapidpro.io","radius":"330","description":"\u003cp\u003e\u003cstrong\u003eText-it-as-a-service\u003c/strong\u003e / \u003cstrong\u003e\u003ca href\u003d\"http://rapidpro.io/\"\u003eRapidpro\u003c/a\u003e\u003c/strong\u003e offers ability to easily set up or modify complex short message service application for business without extensive need of a developer. With the lower costs of text messages compared to USSD sessions, this provides a more affordable way to build scalable applications targeting feature phones and we have seen success in our projects. Flows are very simple to build and actions can be triggered at any point such as sending an sms, email or even calling an external api.\u003c/p\u003e","theta":"254","volume":"2015-05"},{"name":"Time series databases","id":"863","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"43","display_name":"Time series databases","radius":"330","description":"","theta":"259","volume":"2015-05"},{"name":"U2F","id":"804","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"44","display_name":"U2F","radius":"291","description":"\u003cp\u003eSecuring online accounts is at the same time extremely important and notoriously difficult. Two-factor authentication does greatly increase security and we have recommended TOTP as a good solution. A new entrant in this field is Universal 2nd Factor ( \u003cstrong\u003eU2F\u003c/strong\u003e ), a solution based on public key cryptography and inexpensive USB hardware tokens. While developed at Google, it has now become a standard managed by the FIDO Alliance. We do like the promise of better protection against phishing and man-in-the-middle attacks, but are concerned because the standard currently references a specific elliptic curve digital signature algorithm that is considered to be flawed.\u003c/p\u003e","theta":"264","volume":"2015-05"},{"name":"Application Servers","id":"872","quadrant":"Platforms","ring":"Hold","movement":"t","radarId":"45","display_name":"Application Servers","radius":"375","description":"","theta":"202","volume":"2015-05"},{"name":"OSGi","id":"758","quadrant":"Platforms","ring":"Hold","movement":"c","radarId":"46","display_name":"OSGi","radius":"375","description":"\u003cp\u003e\u003cstrong\u003eOSGi\u003c/strong\u003e (Open Service Gateway initiative) is a specification that aims to remedy the lack of a module system for Java, allowing for dynamic reloading of components. While some projects (notably Eclipse) use OSGi successfully, other uses have exposed the hazards of adding abstractions to platforms never designed for them. Projects that rely on OSGi to define a component system quickly realize that it solves only a small part of the overall problem, and often adds its own accidental complexity to projects such as more complex builds. Most projects now either use old-fashioned JAR files or microservice architectures to manage components, and await the native solution in Java in the Jigsaw module specification.\u003c/p\u003e","theta":"225","volume":"2015-05"},{"name":"SPDY","id":"692","quadrant":"Platforms","ring":"Hold","movement":"t","radarId":"47","display_name":"SPDY","radius":"375","description":"","theta":"247","volume":"2015-05"},{"name":"Composer","id":"806","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"48","display_name":"Composer","radius":"95","description":"","theta":"72","volume":"2015-05"},{"name":"GoCD","id":"744","quadrant":"Tools","ring":"Adopt","movement":"c","radarId":"49","display_name":"GoCD","radius":"51","description":"\u003cp\u003eContinuously delivering high quality software to production in a rapid and reliable manner requires coordinating many automated steps. \u003ca href\u003d\"http://go.cd\"\u003e\u003cstrong\u003eGoCD\u003c/strong\u003e\u003c/a\u003e is an open-source tool built by ThoughtWorks to handle exactly this scenario, with the concept of deployment pipelines at its core, it handles complex workflows over many nodes and enables transparent, traceable promotion of trusted artifacts across environments. While it is possible to craft deployment pipelines on top of continuous integration tools, our teams see the benefit derived from a tool purpose built for this job.\u003c/p\u003e","theta":"54","volume":"2015-05"},{"name":"Mountebank","id":"755","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"50","display_name":"Mountebank","radius":"90","description":"","theta":"36","volume":"2015-05"},{"name":"Postman","id":"810","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"51","display_name":"Postman","radius":"70","description":"","theta":"18","volume":"2015-05"},{"name":"Boot2docker","id":"805","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"52","display_name":"Boot2docker","radius":"227","description":"\u003cp\u003e\u003cstrong\u003eBoot2docker\u003c/strong\u003e is a lightweight linux distribution running Docker, packaged as a VM for OSX and Windows. This is a great way to get started experimenting with Docker. For teams using microservices, it can also be an effective way to run multiple services on a local machine for dev and test purposes, where the overhead of multiple vagrant VMs may be too much.\u003c/p\u003e","theta":"84","volume":"2015-05"},{"name":"Brighter","id":"855","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"53","display_name":"Brighter","radius":"200","description":"\u003cp\u003e\u003ca href\u003d\"https://www.goparamore.io/\"\u003e\u003cstrong\u003eBrighter\u003c/strong\u003e\u003c/a\u003e is an open source library for .Net that provides scaffolding to implement Command Invocation. We have had good feedback from teams using it, especially in conjunction with the ports and adaptors pattern and \u003cstrong\u003eCQRS\u003c/strong\u003e. They especially like that it integrates well with \u003cstrong\u003ePolly\u003c/strong\u003e to provide circuit breaking functionality.\u003c/p\u003e","theta":"77","volume":"2015-05"},{"name":"Consul","id":"732","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"54","display_name":"Consul","radius":"180","description":"","theta":"70","volume":"2015-05"},{"name":"Cursive","id":"807","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"55","display_name":"Cursive","radius":"240","description":"\u003cp\u003e\u003ca href\u003d\"https://cursiveclojure.com/\"\u003eCursive\u003c/a\u003e is a Clojure IDE that works as a plugin for IntelliJ. While still in early access, we have found it very useful when working with larger Clojure codebases. Cursive provides strong renaming and navigation support, has shown itself to be stable and reliable, and is great for environments with mixed JVM languages. For organizations adopting Clojure, Cursive has helped lower the barrier to entry for existing developers.\u003c/p\u003e","theta":"63","volume":"2015-05"},{"name":"GitLab","id":"808","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"56","display_name":"GitLab","radius":"193","description":"\u003cp\u003e\u003cstrong\u003eGitLab\u003c/strong\u003e is an on-premise Git repository hosting platform that gives proprietary software development teams the familiar and ubiquitous workflow that hosted version control services like GitHub and BitBucket provide OSS developers. While it is available as free community edition software, the commercial enterprise option provides support and deep integration with LDAP servers.\u003c/p\u003e","theta":"56","volume":"2015-05"},{"name":"Hamms","id":"853","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"57","display_name":"Hamms","radius":"240","description":"","theta":"49","volume":"2015-05"},{"name":"IndexedDB","id":"809","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"58","display_name":"IndexedDB","radius":"205","description":"","theta":"42","volume":"2015-05"},{"name":"Polly","id":"856","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"59","display_name":"Polly","radius":"200","description":"\u003cp\u003eSeveral of our teams working on .Net projects have recommended \u003ca href\u003d\"https://github.com/michael-wolfenden/Polly\"\u003e\u003cstrong\u003ePolly\u003c/strong\u003e\u003c/a\u003e as being useful when building microservice based systems. It encourages the fluent expression of transient exception handling policies and the circuit breaker pattern including policies such as Retry, Retry Forever and Wait and Retry. Libraries already exist in other languages, Hystrix for Java for example, and Polly is a welcome addition from the .Net community.\u003c/p\u003e","theta":"35","volume":"2015-05"},{"name":"REST-assured","id":"860","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"60","display_name":"REST-assured","radius":"220","description":"","theta":"28","volume":"2015-05"},{"name":"Swagger","id":"776","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"61","display_name":"Swagger","radius":"241","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://helloreverb.com/developers/swagger\"\u003eSwagger\u003c/a\u003e\u003c/strong\u003e\u003ca href\u003d\"https://helloreverb.com/developers/swagger\"\u003e\u003cstrong\u003e2.0\u003c/strong\u003e\u003c/a\u003e is a standard way to describe a RESTful API so that human-readable documentation and client examples can be generated automatically. The update to version 2.0 provides some significant flexibility enhancements and the list of tools for generating documentation continues to expand. There are also several alternatives to Swagger emerging from the vendor community, most significantly \u003ca href\u003d\"http://raml.org/\"\u003eRAML\u003c/a\u003e and \u003ca href\u003d\"http://apiblueprint.org/\"\u003eAPI Blueprint\u003c/a\u003e.\u003c/p\u003e","theta":"21","volume":"2015-05"},{"name":"Xamarin","id":"718","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"62","display_name":"Xamarin","radius":"187","description":"\u003cp\u003eWe are excited by the progress made by \u003cstrong\u003eXamarin\u003c/strong\u003e in offering a solid choice for building cross-platform mobile apps. It supports C# and F# as the primary languages with bindings to platform specific SDKs and the Mono runtime environment that works across iOS, Android and Windows Phone. Applications are compiled to native code giving apps a more native look and feel. When using this toolset, it is imperative that the platform specific UI tier be separated from the rest of the tiers to ensure code reuse across different platforms. The recent open-sourcing of the .NET platform should be beneficial for \u003cstrong\u003eXamarin\u003c/strong\u003e both in allowing access to a broader set of .NET tooling and also making development easier on other operating systems.\u003c/p\u003e","theta":"14","volume":"2015-05"},{"name":"ZAP","id":"857","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"63","display_name":"ZAP","radius":"175","description":"","theta":"7","volume":"2015-05"},{"name":"Apache Kafka","id":"850","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"64","display_name":"Apache Kafka","radius":"285","description":"","theta":"84","volume":"2015-05"},{"name":"Blackbox","id":"811","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"65","display_name":"Blackbox","radius":"298","description":"\u003cp\u003e\u003ca href\u003d\"https://github.com/StackExchange/blackbox\"\u003e\u003cstrong\u003eBlackbox\u003c/strong\u003e\u003c/a\u003e is a simple tool for encrypting specific files while at rest in your source repository. This is particularly useful if you need to store passwords or private keys. Blackbox works with Git, Mercurial and Subversion and uses GPG for the encryption. Each user has their own key, which makes it easy to revoke access on a granular level. There is a lot happening in this space and a few other players to consider including \u003cstrong\u003egit-crypt\u003c/strong\u003e and \u003cstrong\u003eTrousseau\u003c/strong\u003e.\u003c/p\u003e","theta":"77","volume":"2015-05"},{"name":"Bokeh/Vega","id":"843","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"66","display_name":"Bokeh/Vega","radius":"330","description":"\u003cp\u003eIn the world of data science and analytics, much of the work is done using Python and R, languages which sadly offer few options for web-accessible plotting of visualizations. One approach is to convert the result of analysis into something that can be easily visualized and interacted with in the browser. We’re aware of two tools that are an attempt to do this. \u003ca href\u003d\"http://bokeh.pydata.org/\"\u003e\u003cstrong\u003eBokeh\u003c/strong\u003e\u003c/a\u003e is a Python and JavaScript library that allows you to create interactive visualizations “in the style of D3.js” but with high performance over large or streaming data sets. \u003ca href\u003d\"http://trifacta.github.io/vega/\"\u003e\u003cstrong\u003eVega\u003c/strong\u003e\u003c/a\u003e is a declarative visualization grammar for D3 that consumes server-generated JSON datasets and translates visualization descriptions into D3.js code.\u003c/p\u003e","theta":"70","volume":"2015-05"},{"name":"Gor","id":"841","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"67","display_name":"Gor","radius":"290","description":"","theta":"63","volume":"2015-05"},{"name":"NaCl","id":"840","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"68","display_name":"NaCl","radius":"285","description":"\u003cp\u003eThe \u003ca href\u003d\"http://nacl.cr.yp.to/\"\u003e\u003cstrong\u003eNaCl\u003c/strong\u003e\u003c/a\u003e library (pronounced \u0027Salt\u0027) provides a set of features for encryption, decryption, and signatures designed to make it easier to implement secure network communication or other cryptography requirements. Although these functions exist in other libraries, NaCl promises higher speed and easier to use APIs. Current support is for C and C++ with Python wrappers in progress.\u003c/p\u003e","theta":"56","volume":"2015-05"},{"name":"Origami","id":"852","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"69","display_name":"Origami","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://facebook.github.io/origami/\"\u003eOrigami\u003c/a\u003e\u003c/strong\u003e is a free tool for designing user prototypes with a variety of keyboard shortcuts for common functions. It provides the possibility of exporting the prototypes as code snippets to Objective-C for iOS, Java for Android and JavaScript for Web. This tool can be used to rapidly build interactive user facing prototypes and testing user flows. We recommend investigating this tool if the use case fits from the experience we have gathered from several of our teams.\u003c/p\u003e","theta":"49","volume":"2015-05"},{"name":"Packetbeat","id":"814","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"70","display_name":"Packetbeat","radius":"312","description":"\u003cp\u003eAs distributed systems become more complex, it can be useful to have tools that help you understand how your system is behaving in production. \u003ca href\u003d\"https://www.elastic.co/beats/packetbeat\"\u003ePacketbeat\u003c/a\u003e is an open source tool which uses agents to sniff traffic between nodes, allowing you to see traffic patterns, error rates and other useful information. It requires \u003ca href\u003d\"http://www.elasticsearch.org/overview/elasticsearch/\"\u003eElasticsearch\u003c/a\u003e and \u003ca href\u003d\"http://www.elasticsearch.org/overview/kibana/\"\u003eKibana\u003c/a\u003e to work, but if you are already using these tools as part of log aggregation, it could be an easy drop-in to give you more insight into your production system.\u003c/p\u003e","theta":"42","volume":"2015-05"},{"name":"pdfmake","id":"847","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"71","display_name":"pdfmake","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/bpampuch/pdfmake\"\u003epdfmake\u003c/a\u003e\u003c/strong\u003e is a JavaScript library which allows for creation and printing of PDF documents directly in the browser. To use pdfmake you construct a document object that supports structural elements such as tables, columns, and rich styling, then helper methods can create and print or download a PDF without leaving client-side JavaScript.\u003c/p\u003e","theta":"35","volume":"2015-05"},{"name":"PlantUML","id":"844","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"72","display_name":"PlantUML","radius":"290","description":"\u003cp\u003eDeveloping a software system by first creating a large number of detailed diagrams is an approach that, in our experience, does not compare favourably to the alternatives. However, describing a particularly complex and intricate part of the system with a diagram is usually a good idea, and the UML itself offers a number of useful and commonly understood diagrams. We like \u003ca href\u003d\"http://plantuml.sourceforge.net/\"\u003e\u003cstrong\u003ePlantUML\u003c/strong\u003e\u003c/a\u003efor creating these diagrams because it allows expressing the intent behind the diagrams in a clear textual form, without having to fiddle with overloaded graphical tools. Having a textual form also allows versioning and storage alongside the source code.\u003c/p\u003e","theta":"28","volume":"2015-05"},{"name":"Prometheus","id":"849","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"73","display_name":"Prometheus","radius":"290","description":"\u003cp\u003eSoundCloud have recently open sourced a Graphite replacement, \u003ca href\u003d\"http://prometheus.io/\"\u003e\u003cstrong\u003ePrometheus\u003c/strong\u003e\u003c/a\u003e. Developed as a reaction to difficulties with \u003cstrong\u003eGraphite\u003c/strong\u003e in their production systems, Prometheus works differently to Graphite, by primarily supporting a pull-based HTTP model (although a more Graphite-like push model is also supported). It also goes beyond Graphite by being built to support alerting based on captured metrics, so it becomes a much more active part of your operational toolset. Some caution should be used in adopting new technology in the production monitoring space, but early reports are that SoundCloud are happy using it in production, and Docker are also contributing to ongoing development.\u003c/p\u003e","theta":"21","volume":"2015-05"},{"name":"Quick","id":"848","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"74","display_name":"Quick","radius":"305","description":"","theta":"14","volume":"2015-05"},{"name":"Security Monkey","id":"846","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"75","display_name":"Security Monkey","radius":"280","description":"","theta":"7","volume":"2015-05"},{"name":"Citrix for development","id":"816","quadrant":"Tools","ring":"Hold","movement":"c","radarId":"76","display_name":"Citrix for development","radius":"375","description":"\u003cp\u003eFor security and compliance reasons, offshore teams are sometimes asked to use \u003cstrong\u003eCitrix\u003c/strong\u003e to connect to an onshore virtual desktop, where they do \u003cstrong\u003edevelopment\u003c/strong\u003e. While a good tool for some use cases, Citrix provides an extremely poor remote development experience and often cripples an offshore team. There are many better technical solutions, such as the NoMachine remote desktop or Cloud9 IDE, which can provide a more workable experience. An even better solution is to tackle the underlying security and compliance concerns. Since you are trusting the remote team to work on your source code and check in to your code repository, you should try to get to a point where you also trust them to have source code on their machines. They will be much more productive!\u003c/p\u003e","theta":"45","volume":"2015-05"},{"name":"Nancy","id":"630","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"77","display_name":"Nancy","radius":"125","description":"","theta":"315","volume":"2015-05"},{"name":"Dashing","id":"817","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"78","display_name":"Dashing","radius":"257","description":"\u003cp\u003eThe importance of big, visible displays in team areas has been written about many times before, and we certainly value the approach of helping everyone see and understand key pieces of information about how our software or our teams are doing. \u003ca href\u003d\"http://dashing.io/\"\u003eDashing\u003c/a\u003e is a Ruby-based dashboard system we have been using for many years to create clear, visible displays optimized for large monitors. It is very hackable, allowing you to pull in information from a variety of sources from build systems, ticket or story tracking tools, or production monitoring systems.\u003c/p\u003e","theta":"280","volume":"2015-05"},{"name":"Django REST","id":"818","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"79","display_name":"Django REST","radius":"162","description":"\u003cp\u003eWe have used the \u003ca href\u003d\"http://www.django-rest-framework.org/\"\u003eDjango REST framework\u003c/a\u003e, which is a flexible and customizable framework that makes it easy to build web APIs, in several of our projects. It allows you to build RESTful APIs in Python with Django, exposing API endpoints which are accessible from a consumer front-end. Django REST gives a browsable web API that allows developers to visualize data being transferred through the API and returns response examples, which the consumer application will receive. It provides a number of authentication schemes out of the box, and allows implementation of custom schemes.\u003c/p\u003e","theta":"290","volume":"2015-05"},{"name":"Ionic Framework","id":"819","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"80","display_name":"Ionic Framework","radius":"262","description":"\u003cp\u003e\u003ca href\u003d\"http://ionicframework.com/\"\u003eIonic framework\u003c/a\u003e is an open-source front-end framework that offers a library of mobile-optimized HTML, CSS and JavaScript components and tools for building highly interactive applications. It is built with SASS and optimized for AngularJS. We have seen success in several of our projects employing this framework, with its ease to install and test. We recommend investigating this framework when you are performance obsessed and looking for a seamlessly integrated front-end framework.\u003c/p\u003e","theta":"300","volume":"2015-05"},{"name":"Nashorn","id":"820","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"81","display_name":"Nashorn","radius":"176","description":"\u003cp\u003e\u003cstrong\u003eNashorn\u003c/strong\u003e is a new JavaScript engine for Java that has been released with Java 8. When the exact same code should be run in the web browser and on the server, which is often the case for validation and data migration logic, it is the tool of choice in the Java world, and that is the case despite some rough edges. We are not convinced that using Nashorn to host entire applications, via Node support or the Avatar project, is a good idea.\u003c/p\u003e","theta":"310","volume":"2015-05"},{"name":"Om","id":"756","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"82","display_name":"Om","radius":"163","description":"\u003cp\u003eWe have seen continued interest in \u003cstrong\u003eOm\u003c/strong\u003e , a ClojureScript wrapper around Facebook\u0027s ReactJS front-end programming framework. Om leverages the inherent immutability of ClojureScript, allowing automatic features like snapshots of UI state and undo. And due to the efficiency of ClojureScript\u0027s data structures, some Om applications run faster than identical ones based on the raw underlying React framework. The ecosystem of components and applications around Om is growing and our teams are starting to pick it up.\u003c/p\u003e","theta":"320","volume":"2015-05"},{"name":"React.js","id":"827","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"83","display_name":"React.js","radius":"210","description":"\u003cp\u003eOne benefit to the ongoing avalanche of front-end JavaScript frameworks is that occasionally, a new idea crops up that makes us think. \u003ca href\u003d\"http://facebook.github.io/react/\"\u003e\u003cstrong\u003eReact.js\u003c/strong\u003e\u003c/a\u003e is a UI/View framework in which JavaScript functions generate HTML in a reactive data flow. We have seen several smaller projects achieve success with React.js and developers are drawn to its clean, composeable approach to componentization.\u003c/p\u003e","theta":"330","volume":"2015-05"},{"name":"Retrofit","id":"821","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"84","display_name":"Retrofit","radius":"232","description":"\u003cp\u003e\u003ca href\u003d\"http://square.github.io/retrofit/\"\u003eRetrofit\u003c/a\u003e offers a reliable way to build HTTP clients on Android projects by converting a REST API into a Java interface. Retrofit integrates with OkHttp and allows developers to provide custom error handling for requests. It does JSON parsing automatically using Gson and has a very well supported community.\u003c/p\u003e","theta":"340","volume":"2015-05"},{"name":"Spring Boot","id":"775","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"85","display_name":"Spring Boot","radius":"210","description":"\u003cp\u003e\u003ca href\u003d\"http://projects.spring.io/spring-boot\"\u003e\u003cstrong\u003eSpring Boot\u003c/strong\u003e\u003c/a\u003e allows easy set up of standalone Spring-based applications. It\u0027s ideal for pulling up new microservices and easy to deploy. It also makes data access less of a pain due to the hibernate mappings with much less boilerplate code. We like that Spring Boot simplifies Java services built with Spring, but have learned to be cautious of the many dependencies. Spring still lurks just beneath the surface.\u003c/p\u003e","theta":"350","volume":"2015-05"},{"name":"Ember.js","id":"879","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"86","display_name":"Ember.js","radius":"310","description":"","theta":"282","volume":"2015-05"},{"name":"Flight.js","id":"823","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"87","display_name":"Flight.js","radius":"310","description":"\u003cp\u003eIn the crowded space of JavaScript frameworks, we want to highlight \u003ca href\u003d\"https://flightjs.github.io/\"\u003e\u003cstrong\u003eFlight.js\u003c/strong\u003e\u003c/a\u003e as a lightweight framework to build components. Flight gets by without much magic when adding behavior to DOM nodes. Its event-driven and component-based nature promotes writing decoupled code. This makes testing individual components comparatively easy. Care must be taken, however, when components need to interact with each other. There is little support for testing and a real danger to get into \u003cem\u003eevent hell\u003c/em\u003e. We do like that it uses functional mixins for behavior, like composition instead of inheritance.\u003c/p\u003e","theta":"295","volume":"2015-05"},{"name":"Haskell Hadoop library","id":"824","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"88","display_name":"Haskell Hadoop library","radius":"330","description":"\u003cp\u003eWhile there are lots of fans of \u003cstrong\u003eHaskell\u003c/strong\u003e among ThoughtWorks\u0027 language devotees, we rarely see it on the kinds of projects we work on—until recently. Several open source projects now marry \u003cstrong\u003eHadoop\u003c/strong\u003e ’s map/reduce jobs to Haskell’s syntax, which some developers and/or data scientists find appealing.\u003c/p\u003e","theta":"308","volume":"2015-05"},{"name":"Lotus","id":"825","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"89","display_name":"Lotus","radius":"336","description":"\u003cp\u003eWe don’t know who named \u003cstrong\u003e\u003ca href\u003d\"http://lotusrb.org/\"\u003eLotus\u003c/a\u003e\u003c/strong\u003e, but we can only assume they are too young to have worked with a certain office collaboration product. Lotus is a new Rack-based MVC framework written in Ruby that can be deployed modularly so that you are free to use only the portions of the framework you need. It is a modern alternative to the monolithic Ruby-on-Rails framework (that turned 10 this year). Lotus has the potential to make full-stack Ruby MVC development as easy as 1-2-3.\u003c/p\u003e","theta":"321","volume":"2015-05"},{"name":"Reagent","id":"828","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"90","display_name":"Reagent","radius":"298","description":"\u003cp\u003e\u003ca href\u003d\"http://holmsand.github.io/reagent/\"\u003eReagent\u003c/a\u003e has emerged as a lightweight minimalist alternative to Om for wrapping React.js in ClojureScript. Whereas Om provides a comprehensive Clojure-idiomatic front-end programming framework, Reagent takes advantage of Clojure’s expressiveness to focus on simple components and a readable DSL for writing HTML. By representing HTML in Clojure data, Reagent retains the performance and understandability of React.js without embedding foreign markup in the code.\u003c/p\u003e","theta":"334","volume":"2015-05"},{"name":"Swift","id":"830","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"91","display_name":"Swift","radius":"310","description":"\u003cp\u003eWith some real-world experience under our belt, \u003ca href\u003d\"https://developer.apple.com/swift/\"\u003e\u003cstrong\u003eSwift\u003c/strong\u003e\u003c/a\u003e still shows a lot of promise. Some of the problems, like long compile times, are being addressed. However, continued language changes cause extra development effort and make building older versions of your own software burdensome. Testing and refactoring also remain painful. On balance, though, you should still consider Swift when starting new development projects for the Apple ecosystem.\u003c/p\u003e","theta":"347","volume":"2015-05"},{"name":"JSF","id":"683","quadrant":"languages-and-frameworks","ring":"Hold","movement":"c","radarId":"92","display_name":"JSF","radius":"375","description":"\u003cp\u003eWe continue to see teams run into trouble using \u003cstrong\u003eJSF\u003c/strong\u003e - JavaServer Faces - and are recommending you avoid this technology. Teams seem to choose JSF because it is a Java EE standard without really evaluating whether the programming model suits them. We think JSF is flawed because its programming model encourages use of its own abstractions rather than fully embracing the underlying web model. JSF, like ASP.NET webforms, attempts to create stateful component trees on top HTML markup and the stateless HTTP protocol. The improvements in JSF 2.0 and 2.2, such as the introduction of stateless views and the promotion of GET, are steps in the right direction, maybe even an acknowledgement that the original model was flawed, but we feel this is a too little too late. Rather than dealing with the complexity of JSF we recommend teams use simple frameworks and work closely with web technologies including HTTP, HTML and CSS.\u003c/p\u003e","theta":"315","volume":"2015-05"}],"date":"2015-05"},{"blips":[{"name":"Consumer-driven contract testing","id":"833","quadrant":"Techniques","ring":"Adopt","movement":"c","radarId":"1","display_name":"Consumer-driven contract testing","radius":"75","description":"\u003cp\u003eWhen two independently developed services are collaborating, changes to the supplier’s API can cause failures for all its consumers. Consuming services usually cannot test against live suppliers since such tests are slow and \u003ca href\u003d\"http://martinfowler.com/articles/nonDeterminism.html#RemoteServices\"\u003ebrittle\u003c/a\u003e, so it’s best to use \u003ca href\u003d\"http://martinfowler.com/bliki/TestDouble.html\"\u003eTest Doubles\u003c/a\u003e, leading to the danger that the test doubles get out of sync with the real supplier service. Consumer teams can protect themselves from these failures by using \u003ca href\u003d\"http://martinfowler.com/bliki/IntegrationContractTest.html\"\u003eintegration contract tests\u003c/a\u003e – tests that compare actual service responses with test values. While such contract tests are valuable, they are even more useful when consuming services provide these tests to the supplier, who can then run all their consumers’ contract tests to determine if their changes are likely to cause problems – adopting \u003ca href\u003d\"http://www.martinfowler.com/articles/consumerDrivenContracts.html\"\u003econsumer-driven contracts\u003c/a\u003e. Such \u003cstrong\u003econsumer-driven contract tests\u003c/strong\u003e are an essential part of a mature \u003ca href\u003d\"http://martinfowler.com/articles/microservice-testing/\"\u003emicroservice testing\u003c/a\u003e portfolio.\u003c/p\u003e","theta":"168","volume":"2015-11"},{"name":"Decoupling deployment from release","id":"893","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"2","display_name":"Decoupling deployment from release","radius":"75","description":"","theta":"155","volume":"2015-11"},{"name":"Generated infrastructure diagrams","id":"832","quadrant":"Techniques","ring":"Adopt","movement":"c","radarId":"3","display_name":"Generated infrastructure diagrams","radius":"120","description":"\u003cp\u003eWhen we need a diagram that describes the current infrastructure or physical architecture we usually take to our favorite technical diagramming tool. If you are using the cloud or virtualization technologies this no longer makes sense, we can use the provided APIs to interrogate the actual infrastructure and generate a live, \u003cstrong\u003eautomated infrastructure diagram\u003c/strong\u003e using simple tools like \u003ca href\u003d\"http://www.graphviz.org/\"\u003eGraphViz\u003c/a\u003e or by outputting SVG.\u003c/p\u003e","theta":"142","volume":"2015-11"},{"name":"NoPSD","id":"784","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"4","display_name":"NoPSD","radius":"60","description":"\u003cp\u003e\u0027Just In Time Design\u0027 is an important and useful concept for visual design that the \u003ca href\u003d\"https://www.thoughtworks.com/p2magazine/issue02/continuous-design/\"\u003e\u003cstrong\u003eNoPSD\u003c/strong\u003e\u003c/a\u003e movement attempts to capture. You don\u0027t need to design the whole application or every UI element up front. Design things as you need them with as lightweight tools as you can use. We have seen a corresponding growth in simpler tools with faster learning curves, such as \u003ca href\u003d\"http://www.sketchapp.com/\"\u003e\u003cstrong\u003eSketch\u003c/strong\u003e\u003c/a\u003e, as well as an increasing return to pen-and-paper (especially when paired with an existing robust \u003ca href\u003d\"https://www.thoughtworks.com/radar/techniques/living-css-style-guides\"\u003e\u003cstrong\u003edigital style guide\u003c/strong\u003e\u003c/a\u003e). Because of the limitations of flat mock-ups when you’re designing for screens, creating prototypes of varying fidelity with tools such as \u003ca href\u003d\"http://www.invisionapp.com/\"\u003e\u003cstrong\u003eInvision\u003c/strong\u003e\u003c/a\u003e, \u003ca href\u003d\"http://framerjs.com/\"\u003e\u003cstrong\u003eFramerJS\u003c/strong\u003e\u003c/a\u003e and \u003cstrong\u003eOrigami\u003c/strong\u003e - or simply HTML/CSS and a bit of JavaScript - has also become increasingly common and valuable for communicating design intent.\u003c/p\u003e","theta":"129","volume":"2015-11"},{"name":"Products over projects","id":"838","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"5","display_name":"Products over projects","radius":"95","description":"","theta":"116","volume":"2015-11"},{"name":"Threat Modeling","id":"871","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"6","display_name":"Threat Modeling","radius":"115","description":"\u003cp\u003eWith the number of high-profile security breaches in the past months, software development teams no longer need convincing that they must place an emphasis on writing secure software and dealing with their users’ data in a responsible way. The teams face a steep learning curve, though, and the vast number of potential threats - ranging from organized crime and government spying to teenagers who attack systems \u0027for the lulz\u0027 can be overwhelming. \u003ca href\u003d\"https://www.owasp.org/index.php/Category:Threat_Modeling\"\u003e\u003cstrong\u003eThreat Modeling\u003c/strong\u003e\u003c/a\u003e provides a set of techniques, mostly from a defensive perspective, that help you understand and classify potential threats. Turned into \u0027evil-user stories\u0027, threat models can give a team a manageable and effective approach to making their systems more secure.\u003c/p\u003e","theta":"103","volume":"2015-11"},{"name":"BEM","id":"861","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"7","display_name":"BEM","radius":"200","description":"\u003cp\u003eDebugging CSS problems can be painful. How many times have you had to trawl through thousands of overridden styles to work out the source of your problem? This has led many of our teams to introduce various guidelines such as avoiding cascading and overrides, making styles opt-in and emphasizing thoughtful naming. \u003ca href\u003d\"http://getbem.com/\"\u003e\u003cstrong\u003eBEM\u003c/strong\u003e\u003c/a\u003e is a simple CSS naming convention (standing for Block, Element, Modifier) that helps give semantic clarity and structure to your CSS. By using BEM, it becomes much easier to understand which CSS rules are influencing the appearance of an element and, more importantly, the intent of those rules. This approach can be seen as moving the OO lesson of favoring composition over inheritance to the world of CSS.\u003c/p\u003e","theta":"173","volume":"2015-11"},{"name":"BFF - Backend for frontends","id":"886","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"8","display_name":"BFF - Backend for frontends","radius":"170","description":"","theta":"165","volume":"2015-11"},{"name":"Docker for builds","id":"884","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"9","display_name":"Docker for builds","radius":"200","description":"\u003cp\u003eOne of the many innovative uses of \u003ca href\u003d\"https://www.docker.com/\"\u003eDocker\u003c/a\u003e that we’ve seen on our projects is a technique to manage build-time dependencies. In the past, it was common to run build agents on an OS, augmented with dependencies needed for the target build. But with Docker it is possible to run the compilation step in an isolated environment complete with dependencies without contaminating the build agent. This technique of using \u003cstrong\u003eDocker for builds\u003c/strong\u003e  has proven particularly useful for compiling Golang binaries, and the \u003ca href\u003d\"https://github.com/CenturyLinkLabs/golang-builder\"\u003egolang-builder\u003c/a\u003e container is available for this very purpose.\u003c/p\u003e","theta":"158","volume":"2015-11"},{"name":"Event Storming","id":"883","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"10","display_name":"Event Storming","radius":"200","description":"\u003cp\u003e\u003ca href\u003d\"http://ziobrando.blogspot.be/2013/11/introducing-event-storming.html\"\u003e\u003cstrong\u003eEvent Storming\u003c/strong\u003e\u003c/a\u003e is a useful way to do rapid “outside-in” domain modeling: starting with the events that occur in the domain rather than a static data model. Run as a facilitated workshop, it focuses on discovering key domain events, placing them along a timeline, identifying their triggers and then exploring their relationships. This approach is particularly useful for people taking a CQRS or \u003ca href\u003d\"https://www.thoughtworks.com/radar/techniques/event-sourcing\"\u003eEvent Sourcing\u003c/a\u003e approach. Getting the right people in the room is important - a blend of business and technical people who bring both the questions and the answers. Ensuring that you have enough wall space for modeling is the second key to success. Look to discover the big picture, with the goal of collectively understanding the domain in all of its complexity, before diving into solutions.\u003c/p\u003e","theta":"150","volume":"2015-11"},{"name":"Flux","id":"837","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"11","display_name":"Flux","radius":"200","description":"","theta":"143","volume":"2015-11"},{"name":"Idempotency filter","id":"882","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"12","display_name":"Idempotency filter","radius":"180","description":"","theta":"135","volume":"2015-11"},{"name":"iFrames for sandboxing","id":"887","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"13","display_name":"iFrames for sandboxing","radius":"220","description":"","theta":"128","volume":"2015-11"},{"name":"NPM for all the things","id":"900","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"14","display_name":"NPM for all the things","radius":"170","description":"","theta":"120","volume":"2015-11"},{"name":"Offline first web applications","id":"877","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"15","display_name":"Offline first web applications","radius":"250","description":"\u003cp\u003e\u003cstrong\u003eOffline first web applications\u003c/strong\u003e provide the ability to design web applications for offline access by employing caching and updating mechanisms. The implementation requires a flag in the DOM to check whether the accessing device is offline or online, accessing local storage when offline, and synchronising data when online. All the major browsers now support an offline mode, which bootstraps the process of downloading and caching the resources such as HTML, CSS, JavaScript, images and other kinds of resources. There are some tools which help simplify offline first implementation such as \u003ca href\u003d\"http://hood.ie/\"\u003e\u003cstrong\u003eHoodie\u003c/strong\u003e\u003c/a\u003e, and \u003ca href\u003d\"http://couchdb.apache.org/\"\u003e\u003cstrong\u003eCouchDB\u003c/strong\u003e\u003c/a\u003e also offers ability to work with a locally deployed application on a local data storage.\u003c/p\u003e","theta":"113","volume":"2015-11"},{"name":"Phoenix Environments","id":"834","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"16","display_name":"Phoenix Environments","radius":"170","description":"","theta":"105","volume":"2015-11"},{"name":"QA in production","id":"881","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"17","display_name":"QA in production","radius":"220","description":"","theta":"98","volume":"2015-11"},{"name":"Accumulate-only data","id":"787","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"18","display_name":"Accumulate-only data","radius":"310","description":"\u003cp\u003eImmutable data structures are becoming more popular, with functional languages such as Clojure and Scala providing immutability by default. Immutability allows code to be more easily written, read and reasoned about. Using an \u003cstrong\u003eaccumulate-only data store\u003c/strong\u003e can confer some of these benefits in the database layer, as well as make audit and historical querying simple. Implementation options vary, from specific accumulative data stores such as \u003ca href\u003d\"http://www.datomic.com/\"\u003eDatomic\u003c/a\u003e to simply using an “append-don’t-update” approach with a traditional database. \u003cstrong\u003eAccumulate-only\u003c/strong\u003e is a design strategy whereby data is removed via retraction rather than update; \u003cstrong\u003eappend-only\u003c/strong\u003e is an implementation technique.\u003c/p\u003e","theta":"168","volume":"2015-11"},{"name":"Bug bounties","id":"947","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"19","display_name":"Bug bounties","radius":"330","description":"\u003cp\u003eMore and more organizations are starting to use \u003cstrong\u003ebug bounties\u003c/strong\u003e to encourage reporting of what are often security-related bugs, and in general help improve the quality of their software. To support these programs, companies like \u003ca href\u003d\"https://hackerone.com/\"\u003eHackerOne\u003c/a\u003e and \u003ca href\u003d\"https://bugcrowd.com/\"\u003eBugCrowd\u003c/a\u003e can help organizations manage this process more easily. We have limited experience with these offerings ourselves, but we like the idea of encouraging people to help come forward and highlight what can often be damaging vulnerabilities in an open and transparent way. It\u0027s worth noting that there might be some legal issues with encouraging users to find vulnerabilities in your software, so please do check that out first.\u003c/p\u003e","theta":"155","volume":"2015-11"},{"name":"Data Lake","id":"789","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"20","display_name":"Data Lake","radius":"310","description":"\u003cp\u003eA \u003ca href\u003d\"http://martinfowler.com/bliki/DataLake.html\"\u003e\u003cstrong\u003eData Lake\u003c/strong\u003e\u003c/a\u003e is an immutable data store of largely unprocessed \u0027raw\u0027 data, acting as a source for data analytics. Whereas the more familiar Data Warehouse filters and processes the data before storing it, the lake just captures the raw data, leaving it to the users of that data to carry out the particular analysis that they need. Examples include HDFS or HBase within a \u003ca href\u003d\"https://hadoop.apache.org/\"\u003eHadoop\u003c/a\u003e, \u003ca href\u003d\"http://spark.apache.org/\"\u003eSpark\u003c/a\u003e or \u003ca href\u003d\"https://storm.apache.org/\"\u003eStorm\u003c/a\u003e processing framework. Usually only a small group of data scientists work on the raw data, developing streams of processed data into lakeshore data marts for most users to query. A Data Lake should only be used for analytics and reporting. For collaboration between operational systems we prefer using services designed for that purpose.\u003c/p\u003e","theta":"142","volume":"2015-11"},{"name":"Hosted IDE\u0027s","id":"914","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"21","display_name":"Hosted IDE\u0027s","radius":"290","description":"","theta":"129","volume":"2015-11"},{"name":"Monitoring of invariants","id":"888","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"22","display_name":"Monitoring of invariants","radius":"310","description":"","theta":"116","volume":"2015-11"},{"name":"Reactive Architectures","id":"836","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"23","display_name":"Reactive Architectures","radius":"310","description":"\u003cp\u003eThe techniques of functional reactive programming have steadily gained in popularity over recent years, and we’re seeing increased interest in extending this concept to distributed systems architectures. Partly inspired by “\u003ca href\u003d\"http://www.reactivemanifesto.org/\"\u003eThe Reactive Manifesto\u003c/a\u003e”, these \u003cstrong\u003ereactive architectures\u003c/strong\u003e are based on a one-way, asynchronous flow of immutable events through a network of independent processes (perhaps implemented as microservices). In the right setting, these systems are scalable and resilient and decrease the coupling between individual processing units. However, architectures based entirely on asynchronous message passing introduce complexity and often rely on proprietary frameworks. We recommend assessing the performance and scalability needs of your system before committing to this as a default architectural style.\u003c/p\u003e","theta":"103","volume":"2015-11"},{"name":"Gitflow","id":"948","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"24","display_name":"Gitflow","radius":"385","description":"","theta":"169","volume":"2015-11"},{"name":"High performance envy/web scale envy","id":"918","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"25","display_name":"High performance envy/web scale envy","radius":"365","description":"","theta":"158","volume":"2015-11"},{"name":"Microservice envy","id":"791","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"26","display_name":"Microservice envy","radius":"365","description":"\u003cp\u003eWe remain convinced that microservices can offer significant advantages to organizations, in terms of improving team autonomy and faster frequency of change. The additional complexity that comes from distributed systems requires an additional level of maturity and investment. We are concerned that some teams are rushing in to adopting microservices without understanding the changes to development, test, and operations that are required to do them well. Our general advice remains simple. Avoid \u003cstrong\u003emicroservice envy\u003c/strong\u003e  and start with one or two services before rushing headlong into developing more, to allow your teams time to adjust and understand the right level of granularity.\u003c/p\u003e","theta":"147","volume":"2015-11"},{"name":"Pace-layered Application Strategy","id":"759","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"27","display_name":"Pace-layered Application Strategy","radius":"375","description":"\u003cp\u003eGartner\u0027s \u003cstrong\u003ePace-layered Application Strategy\u003c/strong\u003e approach appears to be creating an unhelpful focus on the idea of layers within an architecture. We find thinking about the pace of change within different \u003cstrong\u003ebusiness capabilities\u003c/strong\u003e (which can be made up of several architectural layers) to be a more useful concept. The danger in focusing on layers is that many types of change cut across multiple layers. For example, being able to add new class of stock to a website is not just about having an easy-to-change CMS; you also need to update the database, integration points, warehouse systems, etc. The recognition that some parts of an architecture need to be more maneuverable than others is useful. However, a focus on layers is proving unhelpful.\u003c/p\u003e","theta":"135","volume":"2015-11"},{"name":"Programming in your CI/CD tool","id":"792","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"28","display_name":"Programming in your CI/CD tool","radius":"375","description":"\u003cp\u003eWe still see teams configure their CI and CD tools by directly embedding complex multi-line commands directly into the configuration of the tool. Often these embedded commands also contains steps that would only ever take effect in the build environment including things such as CI specific environment variables, steps that would create/modify files and templates only in the CI environment etc. This makes the build environment a special beast - whose results cannot be duplicated locally on a developer\u0027s machine.\u003c/p\u003e\n\n\u003cp\u003eThis is extremely problematic because the CI/CD tool, which is supposed to expose problems in your code, itself becomes a complex beast whose behavior is hard to debug and whose results are hard to replicate.\u003c/p\u003e\n\n\u003cp\u003eThe way to avoid \u003cstrong\u003eprogramming in your CI/CD tool\u003c/strong\u003e is to extract the complexities of the build process from the guts of the tool and into a simple script which can be invoked by a single command. This script can then be executed on any developer workstation and therefore eliminates the privileged/singular status of the build environment.\u003c/p\u003e","theta":"124","volume":"2015-11"},{"name":"SAFe™","id":"793","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"29","display_name":"SAFe™","radius":"390","description":"","theta":"113","volume":"2015-11"},{"name":"Separate DevOps team","id":"734","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"30","display_name":"Separate DevOps team","radius":"380","description":"\u003cp\u003eIn the last radar issue we advised against creating a \u003cstrong\u003eseparate DevOps team\u003c/strong\u003e , as DevOps is about creating a culture of shared responsibility in delivery teams. We recommend embedding operations skills into delivery teams to reduce friction and deliver better outcomes. However where there is a need for significant investment in tooling and automation, we do see a role for a Delivery Engineering team.  Rather than being a helpdesk, these teams build tooling and enable teams to deploy, monitor, and maintain their own production environments.\u003c/p\u003e","theta":"102","volume":"2015-11"},{"name":"TOTP Two-Factor Authentication","id":"779","quadrant":"Platforms","ring":"Adopt","movement":"t","radarId":"31","display_name":"TOTP Two-Factor Authentication","radius":"75","description":"","theta":"225","volume":"2015-11"},{"name":"Apache Mesos","id":"796","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"32","display_name":"Apache Mesos","radius":"210","description":"","theta":"191","volume":"2015-11"},{"name":"Apache Spark","id":"773","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"33","display_name":"Apache Spark","radius":"170","description":"\u003cp\u003e\u003ca href\u003d\"https://spark.apache.org/\"\u003e\u003cstrong\u003eApache Spark\u003c/strong\u003e\u003c/a\u003e has been steadily gaining ground as a fast and general engine for large-scale data processing. The engine is written in Scala and is well suited for applications that reuse a working set of data across multiple parallel operations. It’s designed to work as a standalone cluster or as part of Hadoop YARN cluster. It can access data from sources such as HDFS, Cassandra, S3 etc. Spark also offers many higher level operators in order to ease the development of data parallel applications. As a generic data processing platform it has enabled development of many higher level tools such as interactive SQL (Spark SQL), real time streaming (Spark Streaming), machine learning library (MLib), R-on-Spark etc.\u003c/p\u003e","theta":"202","volume":"2015-11"},{"name":"AWS Lambda","id":"919","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"34","display_name":"AWS Lambda","radius":"210","description":"\u003cp\u003eAWS releases a huge number of new features on what seems like a monthly basis, so it can sometimes be hard for any new service offering to rise above the noise, but \u003cstrong\u003e\u003ca href\u003d\"https://aws.amazon.com/lambda/\"\u003eLambda\u003c/a\u003e\u003c/strong\u003e certainly manages to attract notice. Initially just supporting JavaScript, but now adding support for JVM-based applications (with more no doubt to follow), Lambda allows you to fire up very short-lived processes either in reaction to an event, or via a call from the related \u003ca href\u003d\"https://aws.amazon.com/api-gateway/\"\u003eAPI Gateway\u003c/a\u003e. For stateless services, this means you don’t need to worry about running any long-lived machines, potentially reducing costs and improving security. Despite other forays into the PaaS space by AWS, Lambda looks the closest to getting this right.\u003c/p\u003e","theta":"213","volume":"2015-11"},{"name":"Cloudera Impala","id":"873","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"35","display_name":"Cloudera Impala","radius":"180","description":"\u003cp\u003eFor a while now the Hadoop community has been trying to bring low-latency, interactive SQL capability to the Hadoop platform (better known as SQL-on-Hadoop). This has led to a few open source systems such as Cloudera Impala, Apache Drill, Facebook’s Presto etc being developed actively through 2014. We think the SQL-on-Hadoop trend signals an important shift as it changes Hadoop\u0027s proposition from being a batch oriented technology that was complementary to databases into something that could compete with them.  \u003ca href\u003d\"http://www.cloudera.com/content/cloudera/en/products-and-services/cdh/impala.html\"\u003e\u003cstrong\u003eCloudera Impala\u003c/strong\u003e\u003c/a\u003e was one of the first SQL-on-Hadoop platforms. It is a distributed, massively-parallel, C++ based query engine. The core component of this platform is the Impala daemon that coordinates the execution of the SQL query across one or more nodes of the Impala cluster. Impala is designed to read data from files stored on HDFS in all popular file formats. It leverages Hive\u0027s metadata catalog, in order to share databases and tables between the two database platforms. Impala comes with a shell as well as JDBC and ODBC drivers for applications to use.\u003c/p\u003e","theta":"225","volume":"2015-11"},{"name":"Fastly","id":"891","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"36","display_name":"Fastly","radius":"210","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.fastly.com/\"\u003eFastly\u003c/a\u003e\u003c/strong\u003e, one of a number of CDNs on the market, has a large and growing following on ThoughtWorks projects and is used by many web-scale household names, such as GitHub and Twitter. Its feature set, speed and price point combine to make it a very attractive option when you’re looking for an edge caching solution. We have also seen significant cost savings on projects that move to this platform from another CDN. If you are in the market for a CDN, you could do worse than investigate this one.\u003c/p\u003e","theta":"236","volume":"2015-11"},{"name":"H2O","id":"869","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"37","display_name":"H2O","radius":"240","description":"\u003cp\u003ePredictive analytics are used in more and more products, often directly in end user-facing functionality. \u003ca href\u003d\"http://h2o.ai/\"\u003e\u003cstrong\u003eH2O\u003c/strong\u003e\u003c/a\u003e is an interesting open source package (with a startup behind it) that makes predictive analytics accessible to development teams, offering straightforward use of a wide variety of analytics, great performance and easy integration on JVM-based platforms. At the same time it integrates with the data scientists’ favorite tools, R and Python, as well as Hadoop and Spark.\u003c/p\u003e","theta":"247","volume":"2015-11"},{"name":"HSTS","id":"885","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"38","display_name":"HSTS","radius":"190","description":"","theta":"258","volume":"2015-11"},{"name":"Apache Kylin","id":"862","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"39","display_name":"Apache Kylin","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"http://www.kylin.io/\"\u003e\u003cstrong\u003eApache Kylin\u003c/strong\u003e\u003c/a\u003e is an open source analytics solution from eBay Inc. that enables SQL based multidimensional analysis (OLAP) on very large datasets. Kylin is intended to be a Hadoop based hybrid OLAP (HOLAP) solution that will eventually support both MOLAP and ROLAP style multidimensional analysis. With Kylin you can define cubes using a Cube Designer and initiate an offline process that builds these cubes. The offline process performs a pre-join step to join facts and dimension tables into a flattened out structure. This is followed by a pre-aggregation phase where individual cuboids are built using Map Reduce jobs. The results are stored in HDFS sequence files and are later loaded into HBase. The data requests can originate from SQL submitted using a SQL-based tool. The query engine (based on \u003cstrong\u003eApache Calcite\u003c/strong\u003e ), determines if the target dataset exists in HBase. If so, the engine directly accesses the target data from HBase and returns the result with sub-second latency. If not, the engine routes the queries to \u003cstrong\u003eHive\u003c/strong\u003e (or any other SQL on Hadoop solution enabled on the cluster).\u003c/p\u003e","theta":"186","volume":"2015-11"},{"name":"AWS ECS","id":"924","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"40","display_name":"AWS ECS","radius":"310","description":"","theta":"192","volume":"2015-11"},{"name":"Ceph","id":"923","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"41","display_name":"Ceph","radius":"320","description":"","theta":"199","volume":"2015-11"},{"name":"CoreCLR and CoreFX","id":"866","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"42","display_name":"CoreCLR and CoreFX","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/dotnet/coreclr\"\u003eCoreCLR\u003c/a\u003e\u003c/strong\u003e and** \u003ca href\u003d\"https://github.com/dotnet/corefx\"\u003eCoreFX\u003c/a\u003e** is the core platform and framework for .NET. Although not new, they have recently been open sourced by Microsoft. A key change is that these dependencies are bin-deployable, they do not need to be installed on a machine in advance.  This eases side-by-side deployments, allowing applications to use different framework versions without conflicts. Something written in .NET is then an implementation detail, you can install a .NET dependency into any environment. A .NET tool is no different than something written in C from an external dependency perspective, making it a much more attractive option for general purpose applications and utilities. CoreFX is also being factored into individual NuGet dependencies, so that applications can pull what they need, keeping the footprint for .NET applications and libraries small and making it easier to replace part of the framework.\u003c/p\u003e","theta":"205","volume":"2015-11"},{"name":"Deis","id":"865","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"43","display_name":"Deis","radius":"310","description":"\u003cp\u003eHeroku, with its 12-factor application model, has changed the way we think about building, deploying, and hosting web applications.  \u003ca href\u003d\"http://deis.io/\"\u003e\u003cstrong\u003eDeis\u003c/strong\u003e\u003c/a\u003e encapsulates the Heroku PaaS model in an open-source framework that deploys onto Docker containers hosted anywhere.  Deis is still evolving, but for applications that fit the 12-factor model it has the potential to greatly simplify deployment and hosting in the environment of your choice.  Deis is yet another example of the rich ecosystem of platforms and tools emerging around Docker.\u003c/p\u003e","theta":"212","volume":"2015-11"},{"name":"Kubernetes","id":"925","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"44","display_name":"Kubernetes","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://kubernetes.io/\"\u003eKubernetes\u003c/a\u003e\u003c/strong\u003e is Google\u0027s answer to the problem of deploying containers into a cluster of machines, which is becoming an increasingly common scenario. It is not the solution used by Google internally but an open source project that originated at Google and has seen a fair number of external contributions. \u003ca href\u003d\"https://www.docker.com/\"\u003eDocker\u003c/a\u003e and \u003ca href\u003d\"https://coreos.com/rkt/\"\u003eRocket\u003c/a\u003e are supported as container formats, and services offered include health management, replication and discovery. A similar solution in this space is \u003ca href\u003d\"/radar/platforms/rancher\"\u003eRancher\u003c/a\u003e.\u003c/p\u003e","theta":"218","volume":"2015-11"},{"name":"Linux security modules","id":"795","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"45","display_name":"Linux security modules","radius":"312","description":"\u003cp\u003eWhile server hardening is an old technique that is considered fairly commonplace by sysadmins who have had to manage production systems, it has not become commonplace among the developer community. However, the rise in the DevOps culture has resulted in renewed focus on tools like SELinux, AppArmor and Grsecurity that aim to make this simpler, at least on the Linux ecosystem. Each of these tools comes with their own strengths and weaknesses and it is currently hard to pick one as being the only one you will need. That said, we highly recommend that all teams at least assess which \u003cstrong\u003eLinux security modules\u003c/strong\u003e would be the right one for them and make security and server hardening a part of their development workflow.\u003c/p\u003e","theta":"225","volume":"2015-11"},{"name":"Mesosphere DCOS","id":"889","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"46","display_name":"Mesosphere DCOS","radius":"320","description":"","theta":"231","volume":"2015-11"},{"name":"Microsoft Nano Server","id":"921","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"47","display_name":"Microsoft Nano Server","radius":"320","description":"\u003cp\u003eIn contrast to modern cloud and container solutions based on Linux, even Windows Server Core is large and unwieldy. Microsoft is reacting and has provided the \u003ca href\u003d\"http://www.theregister.co.uk/2015/05/15/wrestling_with_microsoft_nano_server_preview/?page\u003d1\"\u003efirst previews\u003c/a\u003e of \u003ca href\u003d\"https://msdn.microsoft.com/en-us/library/mt126167.aspx\"\u003e\u003cstrong\u003eNano Server\u003c/strong\u003e\u003c/a\u003e, a further-stripped-down version of Windows Server that drops the GUI stack, 32-bit Win32 support, local logins and remote desktop support, resulting in an on-disk size of about 400MB. The early previews are difficult to work with, and the final solution will be restricted to using the CoreCLR, but for companies that are interested in running .NET-based solutions, Nano Server is definitely worth a look at this stage.\u003c/p\u003e","theta":"237","volume":"2015-11"},{"name":"Particle Photon/Particle Electron","id":"864","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"48","display_name":"Particle Photon/Particle Electron","radius":"340","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.particle.io/\"\u003eParticle\u003c/a\u003e\u003c/strong\u003e (formally Spark.io) is a full stack solution for cloud connected devices. \u003cstrong\u003eParticle Photon\u003c/strong\u003e is a microcontroller with wifi module. \u003cstrong\u003eParticle Electron\u003c/strong\u003e is a variant that connects to a cellular network. Particle OS adds REST API to the devices. This simplifies the entry to IoT and building your own connected devices.\u003c/p\u003e","theta":"244","volume":"2015-11"},{"name":"Presto","id":"929","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"49","display_name":"Presto","radius":"320","description":"","theta":"250","volume":"2015-11"},{"name":"Rancher","id":"927","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"50","display_name":"Rancher","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://rancher.com/\"\u003eRancher\u003c/a\u003e\u003c/strong\u003e is an open source solution that allows deployment of containers into a cluster of machines, which is becoming an increasingly common scenario. It provides services such lifecycle management, monitoring, health checks and discovery. Also included is a completely containerized operating system based on \u003ca href\u003d\"https://www.docker.com/\"\u003eDocker\u003c/a\u003e. The broad focus on containerization and very small footprint are key advantages for Rancher. A similar solution in this space is \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e.\u003c/p\u003e","theta":"257","volume":"2015-11"},{"name":"Time series databases","id":"863","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"51","display_name":"Time series databases","radius":"330","description":"\u003cp\u003eA \u003cstrong\u003etime series database\u003c/strong\u003e (TSDB) is a system that is optimized for handling time series data. It allows users to perform CRUD operations on various time series organized as database objects. It also provides the ability to perform statistical calculations on the series as a whole. Although TSDBs are not entirely a new technology we are seeing a renewed interest in the these databases primarily in the realm of IoT applications. This is being facilitated by many open source and commercial platforms (such as  \u003cstrong\u003eOpenTSDB\u003c/strong\u003e , \u003cstrong\u003eInfluxDB\u003c/strong\u003e , \u003cstrong\u003eDruid\u003c/strong\u003e , \u003cstrong\u003eBlueFloodDB\u003c/strong\u003e etc.) that have mushroomed recently. Its also worth mentioning that some of these systems use other distributed databases such \u003cstrong\u003eCassandra\u003c/strong\u003e and \u003cstrong\u003eHBase\u003c/strong\u003e as their underlying storage engine.\u003c/p\u003e","theta":"263","volume":"2015-11"},{"name":"Application Servers","id":"872","quadrant":"Platforms","ring":"Hold","movement":"c","radarId":"52","display_name":"Application Servers","radius":"375","description":"","theta":"198","volume":"2015-11"},{"name":"Over-ambitious API Gateways","id":"931","quadrant":"Platforms","ring":"Hold","movement":"t","radarId":"53","display_name":"Over-ambitious API Gateways","radius":"375","description":"","theta":"216","volume":"2015-11"},{"name":"SPDY","id":"692","quadrant":"Platforms","ring":"Hold","movement":"c","radarId":"54","display_name":"SPDY","radius":"375","description":"\u003cp\u003eThe \u003cstrong\u003e\u003ca href\u003d\"https://www.chromium.org/spdy/spdy-whitepaper\"\u003eSPDY\u003c/a\u003e\u003c/strong\u003e protocol was developed by Google from 2009 as an experiment to provide an alternative protocol to address performance shortcomings of HTTP/1.1. The new HTTP/2 standard protocol includes many of the key performance features of SPDY, and Google has announced it will drop browser SPDY support in early 2016. If your application requires the features of SPDY, we recommend you look instead at HTTP/2.\u003c/p\u003e","theta":"234","volume":"2015-11"},{"name":"Superficial private cloud","id":"932","quadrant":"Platforms","ring":"Hold","movement":"t","radarId":"55","display_name":"Superficial private cloud","radius":"375","description":"","theta":"252","volume":"2015-11"},{"name":"Composer","id":"806","quadrant":"Tools","ring":"Adopt","movement":"c","radarId":"56","display_name":"Composer","radius":"95","description":"\u003cp\u003eAlthough the idea of dependency management is not new and considered to be a fundamental development practice, it is not widely adopted by the PHP community. \u003cstrong\u003e\u003ca href\u003d\"https://getcomposer.org\"\u003eComposer\u003c/a\u003e\u003c/strong\u003e is a tool for dependency management in PHP. It is strongly influenced by tools from other technology stacks like Node\u0027s npm and Ruby\u0027s Bundler. We are now seeing wide adoption across PHP projects and it is fairly mature. You can still have to do some shims for internal libraries, you can use it for most external libraries.\u003c/p\u003e","theta":"68","volume":"2015-11"},{"name":"Mountebank","id":"755","quadrant":"Tools","ring":"Adopt","movement":"c","radarId":"57","display_name":"Mountebank","radius":"90","description":"\u003cp\u003eGood testing of components in an enterprise system is critical and with increased emphasis on service-based separation and deployment automation—critical factors for success with microservices—better tooling in this space is needed. The industry term “service virtualization” refers to tools that can emulate specific components in such an environment. We have seen great success with \u003ca href\u003d\"http://www.mbtest.org/\"\u003e\u003cstrong\u003eMountebank\u003c/strong\u003e\u003c/a\u003e, a lightweight tool for stubbing and mocking HTTP, HTTPS, SMTP and TCP.\u003c/p\u003e","theta":"45","volume":"2015-11"},{"name":"Postman","id":"810","quadrant":"Tools","ring":"Adopt","movement":"c","radarId":"58","display_name":"Postman","radius":"70","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://www.getpostman.com/features\"\u003ePostman\u003c/a\u003e\u003c/strong\u003e is a Chrome extension that acts as a REST client in your browser, allowing you to create requests and inspect responses.  It is a useful tool when developing an API or implementing a client to call an existing API. Postman supports OAuth1 and OAuth2 tokens allowing addition of them to requests where necessary. The response is available as a prettified JSON or XML. With Postman you are able to retrieve a history of requests performed to quickly edit and test the API response to different data. It offers a suite of extensions that allow you to use it as a full-blown test runner too, although we discourage the record and replay style of testing it promotes.\u003c/p\u003e","theta":"23","volume":"2015-11"},{"name":"Browsersync","id":"904","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"59","display_name":"Browsersync","radius":"240","description":"","theta":"84","volume":"2015-11"},{"name":"Carthage","id":"902","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"60","display_name":"Carthage","radius":"230","description":"","theta":"78","volume":"2015-11"},{"name":"Consul","id":"732","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"61","display_name":"Consul","radius":"195","description":"\u003cp\u003eWe continue to be impressed with \u003cstrong\u003e\u003ca href\u003d\"http://consul.io\"\u003eConsul\u003c/a\u003e\u003c/strong\u003e, a service discovery tool supporting both DNS and HTTP-based discovery mechanisms. It goes beyond other discovery tools by providing customizable health-checks for registered services, ensuring that unhealthy instances are marked accordingly. More tools have emerged to work with Consul to make it even more powerful. \u003ca href\u003d\"https://github.com/hashicorp/consul-template\"\u003eConsul Template\u003c/a\u003e enables configuration files to be populated with information from Consul, making things like client-side load balancing using mod_proxy much easier. In the world of Docker, \u003ca href\u003d\"https://github.com/gliderlabs/registrator\"\u003eregistrator\u003c/a\u003e can automatically register docker containers as they appear with Consul with extremely little effort, making it much easier to manage container-based setups.\u003c/p\u003e","theta":"71","volume":"2015-11"},{"name":"Docker Toolbox","id":"899","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"62","display_name":"Docker Toolbox","radius":"205","description":"\u003cp\u003ePreviously, we recommended \u003ca href\u003d\"https://www.thoughtworks.com/radar/tools/boot2docker\"\u003eboot2docker\u003c/a\u003e as a way of easily running Docker on your local Windows or OS X machine. \u003cstrong\u003e\u003ca href\u003d\"https://www.docker.com/toolbox\"\u003eDocker Toolbox\u003c/a\u003e\u003c/strong\u003e now replaces boot2docker, adding some tooling as well. Now included is \u003ca href\u003d\"https://kitematic.com/\"\u003eKitematic\u003c/a\u003e for managing your containers, as well as \u003ca href\u003d\"https://docs.docker.com/compose/\"\u003eDocker Compose\u003c/a\u003e for managing multi-Docker setup (Mac only). It can be used safely as a drop-in replacement for boot2docker, and it will even handle the upgrade for you.\u003c/p\u003e","theta":"65","volume":"2015-11"},{"name":"Gitrob","id":"897","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"63","display_name":"Gitrob","radius":"210","description":"\u003cp\u003eSafely storing secrets such as passwords and access tokens in code repositories is now supported by a growing number of tools - for example, \u003ca href\u003d\"https://github.com/AGWA/git-crypt\"\u003egit-crypt\u003c/a\u003e and \u003ca href\u003d\"https://www.thoughtworks.com/radar/tools/blackbox\"\u003eBlackbox\u003c/a\u003e, which we mentioned in the previous Technology Radar. Despite the availability of these tools, it is still, unfortunately, all too common that secrets are stored unprotected. In fact, it is so common that automated exploit software is used to find AWS credentials and spin up EC2 instances to mine Bitcoins, leaving the attacker with the Bitcoins and the account owner with the bill. \u003ca href\u003d\"https://github.com/michenriksen/gitrob\"\u003e\u003cstrong\u003eGitrob\u003c/strong\u003e\u003c/a\u003e takes a similar approach and scans an organization’s GitHub repositories, flagging all files that might contain sensitive information that shouldn’t have been pushed to the repository. This is obviously a reactive approach. Gitrob can only alert teams when it is (almost) too late. For this reason, Gitrob can only ever be a complementary tool, to minimize damage.\u003c/p\u003e","theta":"58","volume":"2015-11"},{"name":"GitUp","id":"895","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"64","display_name":"GitUp","radius":"260","description":"","theta":"52","volume":"2015-11"},{"name":"Hamms","id":"853","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"65","display_name":"Hamms","radius":"240","description":"\u003cp\u003eMany many wonderful stories of failure in our industry are caused by the assumption that networks are always reliable and servers respond quickly and correctly all the time. \u003ca href\u003d\"https://github.com/kevinburke/hamms\"\u003e\u003cstrong\u003eHamms\u003c/strong\u003e\u003c/a\u003e is an interesting open-source tool which acts as a badly behaved HTTP server, triggering a number of failures including connection failures or slow and/or malformed responses. It may be useful for testing that your software handles failures gracefully.\u003c/p\u003e","theta":"45","volume":"2015-11"},{"name":"IndexedDB","id":"809","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"66","display_name":"IndexedDB","radius":"205","description":"\u003cp\u003eAs single page applications and offline-first become more viable and widespread there is a growing need to persist data in the web browser. Local Storage is very easy to use and well supported by the web browsers. For more complex use cases, there is IndexedDB. While it can be a good solution we recommend to only use it when absolutely necessary, due to the increase in complexity and a somewhat clumsy API. We have also had positive experience with the \u003ca href\u003d\"https://github.com/mozilla/localForage\"\u003elocalForage\u003c/a\u003e framework that provides an abstraction layer over the various persistence solutions.\u003c/p\u003e","theta":"39","volume":"2015-11"},{"name":"Polly","id":"856","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"67","display_name":"Polly","radius":"230","description":"\u003cp\u003eSeveral of our teams working on .NET projects have recommended \u003cstrong\u003e\u003ca href\u003d\"https://github.com/michael-wolfenden/Polly\"\u003ePolly\u003c/a\u003e\u003c/strong\u003e as being useful in building microservice-based systems. It encourages the fluent expression of transient exception-handling policies and the Circuit Breaker pattern, including policies such as Retry, Retry Forever and Wait and Retry. Similar libraries already exist in other languages (Hystrix for Java for example), and Polly is a welcome addition from the .NET community. Integrating well with Polly is \u003cstrong\u003e\u003ca href\u003d\"https://www.thoughtworks.com/radar/tools/brighter\"\u003eBrighter\u003c/a\u003e\u003c/strong\u003e. Brighter is another small open source .Net library that provides scaffolding to implement command invocation. Combining the two libraries provides useful circuit-breaking functionality especially in the context of the Ports and Adapters pattern and CQRS. Although they can be used separately, in the wild our teams find they work well together.\u003c/p\u003e","theta":"33","volume":"2015-11"},{"name":"REST-assured","id":"860","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"68","display_name":"REST-assured","radius":"220","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://code.google.com/p/rest-assured/\"\u003eREST-assured\u003c/a\u003e\u003c/strong\u003e is a Java domain specific language for testing and validating RESTful services. It simplifies the testing of REST based services built on top of HTTP Builder. REST-assured supports the different REST requests and can be used to validate and verify the responses from the APIs. It also provides a JSON schema validation and can thus be used to verify that the endpoints are returning the right types of expected data.\u003c/p\u003e","theta":"26","volume":"2015-11"},{"name":"Sensu","id":"715","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"69","display_name":"Sensu","radius":"215","description":"\u003cp\u003eMany monitoring tools are built around the concept of the machine or instance. The increasing use of patterns like \u003ca href\u003d\"http://martinfowler.com/bliki/PhoenixServer.html\"\u003ePhoenix Server\u003c/a\u003e and tools like \u003ca href\u003d\"https://www.docker.com/\"\u003eDocker\u003c/a\u003e mean this is an increasingly unhelpful way to model infrastructure: Instances are becoming transient while services are the things that persist. \u003ca href\u003d\"https://sensu.io/\"\u003e\u003cstrong\u003eSensu\u003c/strong\u003e\u003c/a\u003e allows an instance to register itself as playing a particular role, and Sensu then monitors it on that basis. Over time, different instances playing that role may come and go. Given these factors and the increasing maturity of the tool, we felt it was time to bring Sensu back on to the radar.\u003c/p\u003e","theta":"20","volume":"2015-11"},{"name":"SysDig","id":"896","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"70","display_name":"SysDig","radius":"180","description":"","theta":"13","volume":"2015-11"},{"name":"ZAP","id":"857","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"71","display_name":"ZAP","radius":"175","description":"\u003cp\u003eThe \u003cstrong\u003e\u003ca href\u003d\"https://www.owasp.org/index.php/OWASP_Zed_Attack_Proxy_Project\"\u003eZED Attack Proxy (ZAP)\u003c/a\u003e\u003c/strong\u003e is a project from OWASP which allows you to probe an existing site for security vulnerabilities in an automated fashion. It can be used as part of periodic security testing, or else integrated into a CD pipeline to provide ongoing checks for common vulnerabilities. The use of a tool like ZAP doesn’t replace the need to think carefully about security and do other sorts of more thorough testing, but as another tool to help ensure our systems are more secure it’s a good addition to the toolbox.\u003c/p\u003e","theta":"7","volume":"2015-11"},{"name":"Apache Kafka","id":"850","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"72","display_name":"Apache Kafka","radius":"285","description":"\u003cp\u003eMany recent developments in enterprise software revolve around asynchronous sequences of immutable event sequences as opposed to synchronous, point-to-point requests that modify state. \u003ca href\u003d\"http://kafka.apache.org/\"\u003e\u003cstrong\u003eApache\u003c/strong\u003e   \u003cstrong\u003eKafka\u003c/strong\u003e\u003c/a\u003e is an open-source messaging framework that supports this architectural style by publishing ordered message feeds to many independent, lightweight consumers. Kafka’s unique design allows the number of consumers to scale while maintaining strong ordering on the messages.\u003c/p\u003e","theta":"84","volume":"2015-11"},{"name":"Concourse CI","id":"928","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"73","display_name":"Concourse CI","radius":"325","description":"","theta":"78","volume":"2015-11"},{"name":"Espresso","id":"911","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"74","display_name":"Espresso","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://developer.android.com/training/testing/espresso\"\u003eEspresso\u003c/a\u003e\u003c/strong\u003e is an Android functional-testing tool. Its small-core API hides the messy implementation details and helps in writing concise tests, with faster and reliable test execution.\u003c/p\u003e","theta":"72","volume":"2015-11"},{"name":"Gauge","id":"912","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"75","display_name":"Gauge","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://gauge.org/\"\u003eGauge\u003c/a\u003e\u003c/strong\u003e is a lightweight cross-platform test-automation tool. Specifications are written in free-form Markdown, so test cases can be written in the business language and can be incorporated into any existing documentation format. Supported languages are implemented as plugins to a single core implementation, which ensures consistency across language implementations. This tool, open sourced by ThoughtWorks, also supports parallel execution out of the box for all supported platforms.\u003c/p\u003e","theta":"66","volume":"2015-11"},{"name":"Gor","id":"841","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"76","display_name":"Gor","radius":"290","description":"\u003cp\u003e\u003ca href\u003d\"https://github.com/buger/gor\"\u003e\u003cstrong\u003eGor\u003c/strong\u003e\u003c/a\u003e is an open-source tool for capturing and replaying live HTTP traffic into a test environment in order to continuously test your system with real data. It can be used to increase confidence in code deployments, configuration changes and infrastructure changes.\u003c/p\u003e","theta":"60","volume":"2015-11"},{"name":"ievms","id":"908","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"77","display_name":"ievms","radius":"285","description":"","theta":"54","volume":"2015-11"},{"name":"Let\u0027s Encrypt","id":"946","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"78","display_name":"Let\u0027s Encrypt","radius":"340","description":"\u003cp\u003eAlthough more sites every day are implementing HTTPS to help protect their own users and improve the integrity of the web as a whole, there are many more sites to go. In addition, we see more and more people using HTTPS within their enterprises, to provide additional security guarantees. One of the main blockers to wider adoption has been the process of getting a certificate in the first place. Aside from the cost, the process itself is far from slick. \u003ca href\u003d\"https://letsencrypt.org/\"\u003e\u003cstrong\u003eLet’s Encrypt\u003c/strong\u003e\u003c/a\u003e, a new Certificate Authority, aims to solve all this. First, it provides certificates for free. Second, and arguably more important, it also provides an extremely easy-to-use command-line API, making it easy to fully automate the process of issuing, upgrading and installing certificates. We think that Let’s Encrypt, in beta at the moment, has the chance to be revolutionary in terms of helping more of the web get on to HTTPS, and at the same time showing what good, automatable tools for the security-conscious should look like.\u003c/p\u003e","theta":"48","volume":"2015-11"},{"name":"Pageify","id":"907","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"79","display_name":"Pageify","radius":"325","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/paramadeep/pageify\"\u003ePageify\u003c/a\u003e\u003c/strong\u003e is a Ruby library for building page objects for UI automation tests, focusing on faster test execution and code readability. It offers simple APIs to dynamically define, operate and assert on the page objects, allowing readable code even when handling elements with complex hierarchies in the DOM. It bundles integration for \u003cstrong\u003eWebDriver\u003c/strong\u003e and \u003cstrong\u003eCapybara\u003c/strong\u003e.\u003c/p\u003e","theta":"42","volume":"2015-11"},{"name":"Prometheus","id":"849","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"80","display_name":"Prometheus","radius":"290","description":"","theta":"36","volume":"2015-11"},{"name":"Quick","id":"848","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"81","display_name":"Quick","radius":"305","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/Quick/Quick\"\u003eQuick\u003c/a\u003e\u003c/strong\u003e is a testing framework for Swift and Objective-C, which comes bundled with \u003cstrong\u003eNimble\u003c/strong\u003e , a matcher framework for tests. Quick helps verify the behavior of Swift and Objective-C programs. Quick has the same syntactic flavour as \u003cstrong\u003eRSpec\u003c/strong\u003e and \u003cstrong\u003eJasmine\u003c/strong\u003e and is easy to set up. It is very organized, allows for assertion of types and makes it easy to test asynchronous code.\u003c/p\u003e","theta":"30","volume":"2015-11"},{"name":"RAML","id":"913","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"82","display_name":"RAML","radius":"325","description":"","theta":"24","volume":"2015-11"},{"name":"Security Monkey","id":"846","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"83","display_name":"Security Monkey","radius":"280","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/Netflix/security_monkey\"\u003eSecurity Monkey\u003c/a\u003e\u003c/strong\u003e is another tool in Netflix’s Simian Army, which is a suite of tools designed to ensure that systems are being built in a resilient fashion. As well as providing a (configurable) assessment of any potential security vulnerabilities in your AWS setup, it can also be used to monitor changes on an ongoing basis, alerting different groups as required. It does overlap in some ways with AWS’ own \u003ca href\u003d\"https://aws.amazon.com/premiumsupport/trustedadvisor/\"\u003eTrusted Advisor Report\u003c/a\u003e and \u003ca href\u003d\"http://aws.amazon.com/cloudtrail/\"\u003eCloudTrail\u003c/a\u003e service, as it was developed prior to both these services being made generally available, but its capabilities do go beyond these offerings. If either of those services don’t quite meet your requirements, Security Monkey is worth a look.\u003c/p\u003e","theta":"18","volume":"2015-11"},{"name":"Sleepy Puppy","id":"940","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"84","display_name":"Sleepy Puppy","radius":"330","description":"","theta":"12","volume":"2015-11"},{"name":"Visual Studio Code","id":"909","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"85","display_name":"Visual Studio Code","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://code.visualstudio.com/\"\u003eVisual Studio Code\u003c/a\u003e\u003c/strong\u003e is Microsoft’s free IDE editor, available across platforms. We find the version-control integration with Git very beneficial to promoting continuous integration practices. Visual Studio Code also provides a means of integrating with external tools via tasks, with autodetection of grunt/gulp tasks eliminating the need for running grunt/gulp tasks via terminals and simply using the editor. With the growth of the Docker ecosystem, this IDE offers support for the dockerfile with snippets and definitions of valid commands.\u003c/p\u003e","theta":"6","volume":"2015-11"},{"name":"Citrix for development","id":"816","quadrant":"Tools","ring":"Hold","movement":"t","radarId":"86","display_name":"Citrix for development","radius":"375","description":"\u003cp\u003eMany organizations are still forcing distributed or offshore development teams to use \u003cstrong\u003eCitrix remote desktop for development\u003c/strong\u003e. Although this provides a simple security model – assets supposedly never leave the organization’s servers - using remote desktops for development absolutely cripples developer productivity. There’s not much point paying a cheaper hourly rate for developers if you’re going to impose both the distribution and remote-desktop burdens on them, and we wish more offshore vendors would admit these drawbacks to their clients. It’s much better to use either a \u0027clean room\u0027 secured offshore environment where local development can be done, or a \u003ca href\u003d\"/radar/techniques/hosted-ide-s\"\u003eHosted IDE\u003c/a\u003e (e.g. \u003ca href\u003d\"/radar/tools/ievms\"\u003eievms\u003c/a\u003e)\u003c/p\u003e","theta":"45","volume":"2015-11"},{"name":"ECMAScript 6","id":"892","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"87","display_name":"ECMAScript 6","radius":"125","description":"","theta":"292","volume":"2015-11"},{"name":"Nancy","id":"630","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radarId":"88","display_name":"Nancy","radius":"125","description":"\u003cp\u003eSince we last talked about \u003cstrong\u003e\u003ca href\u003d\"http://nancyfx.org/\"\u003eNancy\u003c/a\u003e\u003c/strong\u003e on the technology radar it has become the default choice on our .NET projects. Architectures centred around small, vertical slices and microservices simply require light-weight deployment options and low ceremony tooling.\u003c/p\u003e","theta":"315","volume":"2015-11"},{"name":"Swift","id":"830","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"89","display_name":"Swift","radius":"75","description":"\u003cp\u003eA year after its public debut, \u003ca href\u003d\"https://developer.apple.com/swift/\"\u003e\u003cstrong\u003eSwift\u003c/strong\u003e\u003c/a\u003e is now our default choice for development in the Apple ecosystem. With the recent release of Swift 2, the language approaches a level of maturity that provides the stability and performance required for most projects. Swift still has issues, especially around tool support, refactoring and testing. However, we feel that these are not substantial enough to warrant avoiding Swift. At the same time, porting large, existing Objective-C codebases is unlikely to pay off. The announcement that Swift will become open source software is a further positive sign. We are hopeful that this will not just be another dumping of internally developed code into a public repository, because Apple has clearly stated that community contributions are encouraged and will be accepted.\u003c/p\u003e","theta":"337","volume":"2015-11"},{"name":"Enlive","id":"903","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"90","display_name":"Enlive","radius":"250","description":"","theta":"288","volume":"2015-11"},{"name":"React.js","id":"827","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"91","display_name":"React.js","radius":"210","description":"\u003cp\u003eOne benefit of the ongoing avalanche of front-end JavaScript frameworks is that occasionally a new idea crops up that makes us think. \u003ca href\u003d\"http://facebook.github.io/react/\"\u003e\u003cstrong\u003eReact.js\u003c/strong\u003e\u003c/a\u003e is a UI/view framework in which JavaScript functions generate HTML in a reactive data flow. It differs significantly from frameworks like \u003ca href\u003d\"https://www.thoughtworks.com/radar/languages-and-frameworks/angularjs\"\u003eAngularJS\u003c/a\u003e in that it only allows one-way data bindings, greatly simplifying the rendering logic. We have seen several smaller projects achieve success with React.js, and developers are drawn to its clean, composable approach to componentization.\u003c/p\u003e","theta":"306","volume":"2015-11"},{"name":"SignalR","id":"936","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"92","display_name":"SignalR","radius":"200","description":"","theta":"324","volume":"2015-11"},{"name":"Spring Boot","id":"775","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"93","display_name":"Spring Boot","radius":"250","description":"\u003cp\u003e\u003ca href\u003d\"http://projects.spring.io/spring-boot\"\u003e\u003cstrong\u003eSpring Boot\u003c/strong\u003e\u003c/a\u003e allows easy setup of standalone Spring-based applications. It\u0027s ideal for pulling up new microservices and easy to deploy. It also makes data access less of a pain, thanks to the JPA mappings through Spring Data. We like that Spring Boot simplifies Java services built with Spring but have learned to be cautious of the many dependencies. Spring still lurks just beneath the surface. If you’re writing microservices with Java, you might also consider using \u003cstrong\u003eDropwizard\u003c/strong\u003e or a microframework like \u003ca href\u003d\"http://sparkjava.com/\"\u003eSpark\u003c/a\u003e to get the benefits of Spring Boot without the enormous weight of Spring.\u003c/p\u003e","theta":"342","volume":"2015-11"},{"name":"Axon","id":"935","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"94","display_name":"Axon","radius":"290","description":"\u003cp\u003eWhile we still have some reservations about \u003ca href\u003d\"http://martinfowler.com/bliki/CQRS.html\"\u003eCQRS\u003c/a\u003e as a general pattern, the approach can work very well in specific places. In those specific situations, however, a lot of work is left to the developer to properly execute CQRS. \u003cstrong\u003e\u003ca href\u003d\"http://www.axonframework.org/\"\u003eAxon\u003c/a\u003e\u003c/strong\u003e is a framework that can help with this on the JVM, and we’ve used it with some success. Although it certainly can’t be considered a perfect solution right now, it continues to evolve and may make much more sense than trying to write everything from scratch.\u003c/p\u003e","theta":"279","volume":"2015-11"},{"name":"Ember.js","id":"879","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"95","display_name":"Ember.js","radius":"310","description":"\u003cp\u003eWidespread usage of AngularJS continues on ThoughtWorks projects, although not every experience is positive. We continue to advise teams to assess whether the additional complexity of a single-page JavaScript application is necessary to meet their requirements.  We also recommend assessing alternative frameworks, and in this radar edition we highlight \u003ca href\u003d\"http://emberjs.com/\"\u003e\u003cstrong\u003eEmber.js\u003c/strong\u003e\u003c/a\u003e which is growing in popularity within ThoughtWorks.  Ember is praised for its approach of opinionated convention over configuration, responsive core team of committers, performance, and build tooling support via Ember CLI.\u003c/p\u003e","theta":"288","volume":"2015-11"},{"name":"Frege","id":"944","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"96","display_name":"Frege","radius":"330","description":"\u003cp\u003eFollowing many other programming languages, one of the language geeks’ absolute favourites, \u003ca href\u003d\"https://www.haskell.org/\"\u003eHaskell\u003c/a\u003e, is now also available on the JVM in the form of \u003ca href\u003d\"https://github.com/Frege/frege\"\u003e\u003cstrong\u003eFrege\u003c/strong\u003e\u003c/a\u003e. This brings a purely functional programming language onto the platform, allowing for easy interoperability with other JVM languages and libraries.\u003c/p\u003e","theta":"297","volume":"2015-11"},{"name":"HyperResource","id":"934","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"97","display_name":"HyperResource","radius":"340","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://hyperresource.com/doc/\"\u003eHyperResource\u003c/a\u003e\u003c/strong\u003e is a Ruby framework for building a RESTful API client. The framework accepts JSON in \u003cstrong\u003eHAL\u003c/strong\u003e format and dynamically generates a model object complete with hypermedia links. Although the framework is still in its infancy, we like that it embraces \u003ca href\u003d\"http://martinfowler.com/articles/richardsonMaturityModel.html\"\u003eRichardson level 3 REST\u003c/a\u003e for better service discoverability and self-documenting protocols.\u003c/p\u003e","theta":"306","volume":"2015-11"},{"name":"Material UI","id":"938","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"98","display_name":"Material UI","radius":"325","description":"\u003cp\u003e\u003ca href\u003d\"http://material-ui.com/\"\u003e\u003cstrong\u003eMaterial UI\u003c/strong\u003e\u003c/a\u003e provides reusable components for use in \u003ca href\u003d\"https://www.thoughtworks.com/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e applications that implement Google\u0027s Material Design language. Filling a similar space to \u003ca href\u003d\"https://www.thoughtworks.com/radar/languages-and-frameworks/twitter-bootstrap\"\u003eTwitter Bootstrap\u003c/a\u003e, it gets you up and running quickly but doesn\u0027t have the same drawbacks as your application grows. \u003ca href\u003d\"http://elemental-ui.com/\"\u003eElemental UI\u003c/a\u003e is worth investigating as an alternative.\u003c/p\u003e","theta":"315","volume":"2015-11"},{"name":"OkHttp","id":"941","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"99","display_name":"OkHttp","radius":"300","description":"","theta":"324","volume":"2015-11"},{"name":"React Native","id":"937","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"100","display_name":"React Native","radius":"310","description":"\u003cp\u003eYet another entrant into the cross-platform mobile development world, Facebook’s \u003ca href\u003d\"https://facebook.github.io/react-native/\"\u003e\u003cstrong\u003eReact Native\u003c/strong\u003e\u003c/a\u003e brings the React.js programming model to iOS and Android developers. React Native programs are written in JavaScript, but unlike a hybrid framework such as Ionic, React Native gives developers access to native UI components on the target platform. This is an approach we’ve seen before (e.g., \u003ca href\u003d\"http://calatrava.github.io/\"\u003eCalatrava\u003c/a\u003e), but React Native has already inspired a substantial developer community and builds on the momentum generated by React.js. This framework could play a significant role in the future of mobile app development.\u003c/p\u003e","theta":"333","volume":"2015-11"},{"name":"TLA+","id":"943","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"101","display_name":"TLA+","radius":"340","description":"\u003cp\u003eBuilding systems using microservices requires us to think more deeply about failure isolation and testing. *\u003cem\u003e\u003ca href\u003d\"https://lamport.azurewebsites.net/tla/tla.html\"\u003eTLA+\u003c/a\u003e *\u003c/em\u003eis a formal specification language that can be useful in both these scenarios. For failure isolation, TLA+ can be used to identify invariants in your system that can be monitored directly. An invariant can be the ratio of number of requests to one service to the number of requests to a second service, for example. Any change in this ratio would lead to an alert. TLA+ is also being used to identify subtle design flaws in distributed systems. Amazon, for example, used model-checking based on a formal specification written in TLA+ to identify subtle bugs in Dynamo DB before it was released to the public. For most systems, the investment required to create the formal specification and then perform model checking is probably too great; however, for critical systems - complex ones, or those with many users - we think it’s very valuable to have another tool in our toolbox.\u003c/p\u003e","theta":"342","volume":"2015-11"},{"name":"Traveling Ruby","id":"939","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"102","display_name":"Traveling Ruby","radius":"325","description":"\u003cp\u003e\u003ca href\u003d\"https://github.com/FooBarWidget/traveling-ruby\"\u003e\u003cstrong\u003eTraveling Ruby\u003c/strong\u003e\u003c/a\u003e makes it possible to distribute portable, ready-to-run, platform-agnostic Ruby binaries without the need to install an interpreter, packages or additional gems. It decouples running Ruby applications from the development environment they run in.\u003c/p\u003e","theta":"351","volume":"2015-11"}],"date":"2015-11"},{"blips":[{"name":"Decoupling deployment from release","id":"893","quadrant":"Techniques","ring":"Adopt","movement":"c","radarId":"1","display_name":"Decoupling deployment from release","radius":"75","description":"\u003cp\u003eImplementing \u003ca href\u003d\"http://martinfowler.com/bliki/ContinuousDelivery.html\"\u003eContinuous Delivery\u003c/a\u003e continues to be a challenge for many organizations, and it remains important to highlight useful techniques such as \u003cstrong\u003edecoupling deployment from release\u003c/strong\u003e. We recommend strictly using the term \u003cem\u003eDeployment\u003c/em\u003e when referring to the act of deploying a change to application components or infrastructure. The term \u003cem\u003eRelease\u003c/em\u003e should be used when a feature change is released to end users, with a business impact. Using techniques such as feature toggles and dark launches, we can deploy changes to production systems more frequently without releasing features. More-frequent deployments reduce the risk associated with change, while business stakeholders retain control over when features are released to end users.\u003c/p\u003e","theta":"158","volume":"2016-04"},{"name":"Products over projects","id":"838","quadrant":"Techniques","ring":"Adopt","movement":"c","radarId":"2","display_name":"Products over projects","radius":"95","description":"\u003cp\u003eWe’ve long been championing the idea that thinking of software development as a project - something budgeted and delivered during a limited time slot - doesn’t fit the needs of the modern business. Important software efforts need to be an ongoing product that supports and rethinks the business process it is supporting. Such efforts are not complete until the business process, and its software, cease to be useful. Our observation of this \u003cstrong\u003eproducts over projects\u003c/strong\u003e approach, both with our own projects and outside, makes us determine that it is the approach to use for all but exceptional cases.\u003c/p\u003e","theta":"135","volume":"2016-04"},{"name":"Threat Modeling","id":"871","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"3","display_name":"Threat Modeling","radius":"70","description":"","theta":"113","volume":"2016-04"},{"name":"BFF - Backend for frontends","id":"886","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"4","display_name":"BFF - Backend for frontends","radius":"170","description":"\u003cp\u003eValuable services support many variations in clients, such as mobile versus web and different forms of web interface. It’s tempting to design a single back-end API to support all clients with a reusable API. But client needs vary, as do constraints such as bandwidth for mobile devices versus the desire for lots of data on fast web connections. Consequently it’s often best to \u003cstrong\u003edefine different back-end services for each kind of front-end\u003c/strong\u003e client. These back ends should be developed by teams aligned with each front end to ensure that each back end properly meets the needs of its client.\u003c/p\u003e","theta":"173","volume":"2016-04"},{"name":"Bug bounties","id":"947","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"5","display_name":"Bug bounties","radius":"210","description":"","theta":"165","volume":"2016-04"},{"name":"Data Lake","id":"789","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"6","display_name":"Data Lake","radius":"200","description":"","theta":"158","volume":"2016-04"},{"name":"Event Storming","id":"883","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"7","display_name":"Event Storming","radius":"200","description":"\u003cp\u003e\u003ca href\u003d\"http://ziobrando.blogspot.be/2013/11/introducing-event-storming.html\"\u003e\u003cstrong\u003eEvent Storming\u003c/strong\u003e\u003c/a\u003e is a useful way to do rapid \"outside-in\" domain modeling: starting with the events that occur in the domain rather than a static data model. Run as a facilitated workshop, it focuses on discovering key domain events, placing them along a timeline, identifying their triggers and then exploring their relationships. This approach is particularly useful for people taking an \u003ca href\u003d\"https://www.thoughtworks.com/radar/techniques/event-sourcing\"\u003eEvent Sourced\u003c/a\u003e approach. Getting the right people in the room is important - a blend of business and technical people who bring both the questions and the answers. Ensuring that you have enough wall space for modeling is the second key to success. Look to discover the big picture, with the goal of collectively understanding the domain in all of its complexity, before diving into solutions.\u003c/p\u003e","theta":"150","volume":"2016-04"},{"name":"Flux","id":"837","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"8","display_name":"Flux","radius":"200","description":"\u003cp\u003e\u003ca href\u003d\"https://facebook.github.io/flux/\"\u003e\u003cstrong\u003eFlux\u003c/strong\u003e\u003c/a\u003e is an application architecture introduced by Facebook. Usually mentioned in conjunction with \u003cstrong\u003eReact.js\u003c/strong\u003e , Flux is based on a one-way flow of data up through the rendering pipeline. Flux embraces the modern web landscape of client-side JavaScript applications in a way that avoids the venerable MV* clichés. ThoughtWorks teams are now starting to gain some experience with this architectural style and find that it meshes well with service orientation and solves some of the problems inherent in two-way data binding.\u003c/p\u003e","theta":"143","volume":"2016-04"},{"name":"Idempotency filter","id":"882","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"9","display_name":"Idempotency filter","radius":"180","description":"\u003cp\u003eMany services, especially legacy services, are written with the assumption that any request will occur only once. Networks being what they are, this can be difficult to arrange. An \u003cstrong\u003eidempotency filter\u003c/strong\u003e is a simple component that merely checks for duplicate requests and ensures that they are sent to the supplier service only once. Such a filter should do only this one task and be used as a decorator over existing service calls.\u003c/p\u003e","theta":"135","volume":"2016-04"},{"name":"iFrames for sandboxing","id":"887","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"10","display_name":"iFrames for sandboxing","radius":"220","description":"\u003cp\u003eModern web pages tend to contain a plethora of JavaScript widgets and snippets coming from a variety of third-party sources. This can have a negative impact on both security and performance. While we are still waiting for fuller JavaScript isolation with web components, our teams have benefited from using HTML5 \u003ca href\u003d\"http://www.html5rocks.com/en/tutorials/security/sandboxed-iframes/\"\u003e\u003cstrong\u003eiFrames for sandboxing\u003c/strong\u003e\u003c/a\u003e untrusted JavaScript.\u003c/p\u003e","theta":"128","volume":"2016-04"},{"name":"NPM for all the things","id":"900","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"11","display_name":"NPM for all the things","radius":"170","description":"\u003cp\u003eThe JavaScript world has a plethora of dependency and package-management tools, all of which rely on the Node Package Manager (NPM). Teams are starting to see these extra tools as redundant and are recommending that if you can use solely NPM for package and dependency management, you should. The simplification of using \u003cstrong\u003eNPM for all the things\u003c/strong\u003e helps reduce some of the churn in the JavaScript tools space.\u003c/p\u003e","theta":"120","volume":"2016-04"},{"name":"Phoenix Environments","id":"834","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"12","display_name":"Phoenix Environments","radius":"170","description":"\u003cp\u003eThe time taken to provision and update environments continues to be a significant bottleneck on many software projects. Phoenix Environments can help with this delay by extending the idea of \u003ca href\u003d\"http://martinfowler.com/bliki/PhoenixServer.html\"\u003ePhoenix Servers\u003c/a\u003e to cover entire environments. We feel this is such a valuable and time-saving technique that you should consider trialing this approach. Using automation, we can create whole environments - including network configuration, load balancing and firewall ports - for example by using \u003ca href\u003d\"https://aws.amazon.com/cloudformation/\"\u003e\u003cstrong\u003eCloudFormation\u003c/strong\u003e\u003c/a\u003e in AWS. We can then prove that the process works by tearing the environments down and recreating them from scratch on a regular basis. \u003cstrong\u003ePhoenix Environments\u003c/strong\u003e can support provisioning new environments for testing, development, UAT and disaster recovery. As with Phoenix Servers, this pattern is not always applicable, and we need to think carefully about things like state and dependencies. Treating the whole environment as a \u003ca href\u003d\"http://martinfowler.com/bliki/BlueGreenDeployment.html\"\u003eblue/green deployment\u003c/a\u003e can be one approach when environment reconfiguration needs to be done.\u003c/p\u003e","theta":"113","volume":"2016-04"},{"name":"QA in production","id":"881","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"13","display_name":"QA in production","radius":"220","description":"\u003cp\u003eTraditionally, QA roles have focused on assessing the quality of a software product in a pre-production environment. With the rise of Continuous Delivery, the QA role is shifting to include analyzing software product quality in production. This involves monitoring of the production systems, coming up with alert conditions to detect urgent errors, determining ongoing quality issues and figuring out what measurements you can use in the production environment to make this work. While there is a danger that some organizations will go too far and neglect pre-production QA, our experience shows that \u003cstrong\u003eQA in production\u003c/strong\u003e is a valuable tool for organizations that have already progressed to a reasonable degree of Continuous Delivery.\u003c/p\u003e","theta":"105","volume":"2016-04"},{"name":"Reactive architectures","id":"836","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"14","display_name":"Reactive architectures","radius":"170","description":"","theta":"98","volume":"2016-04"},{"name":"Content Security Policies","id":"997","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"15","display_name":"Content Security Policies","radius":"340","description":"","theta":"170","volume":"2016-04"},{"name":"Hosted IDE\u0027s","id":"914","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"16","display_name":"Hosted IDE\u0027s","radius":"290","description":"\u003cp\u003eMany organizations want to leverage distributed or offshore development but have security concerns with their code and other intellectual property sitting outside their control. The result is often to use high-latency remote-desktop solutions for development, adhering to an organization’s security controls but crippling developer productivity. An alternative is to use a \u003cstrong\u003eHosted IDE\u003c/strong\u003e delivered to a browser via VPN. The IDE, code and build environment are hosted within the organization\u0027s private cloud, easing security concerns, and the developer experience is significantly improved. Tools in this space include \u003ca href\u003d\"https://orionhub.org/\"\u003eOrion\u003c/a\u003e and \u003ca href\u003d\"http://www.eclipse.org/che/\"\u003eChe\u003c/a\u003e from the Eclipse Foundation, \u003ca href\u003d\"https://c9.io/\"\u003eCloud9\u003c/a\u003e and \u003ca href\u003d\"https://codenvy.com/\"\u003eCode Envy\u003c/a\u003e.\u003c/p\u003e","theta":"160","volume":"2016-04"},{"name":"Hosting PII data in the EU","id":"1001","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"17","display_name":"Hosting PII data in the EU","radius":"290","description":"\u003cp\u003eIn a number of countries around the world, we see government agencies seeking broad access to private, personally identifiable information (PII). In the EU, the highest court has invalidated the Safe Harbor framework, and Privacy Shield, its successor, is expected to be challenged too. At the same time, the use of cloud computing is increasing, and all the major cloud providers—Amazon, Google and Microsoft—offer multiple data centers and regions within the European Union. Therefore, we recommend that companies, especially those with a global user base, assess the feasibility of a safe haven for their users\u0027 data, protected by the most progressive privacy laws, by \u003cstrong\u003eHosting PII in the EU\u003c/strong\u003e.\u003c/p\u003e","theta":"150","volume":"2016-04"},{"name":"Monitoring of invariants","id":"888","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"18","display_name":"Monitoring of invariants","radius":"310","description":"\u003cp\u003eIn monitoring, the common approach is to conceive of erroneous conditions and set alerts when these appear. But it’s often difficult to enumerate the myriad failure modes in a software system. \u003cstrong\u003eMonitoring of invariants\u003c/strong\u003e is a complementary approach to setting expected normal ranges, often by examining historical behavior, and alerting whenever a system goes outside those bounds.\u003c/p\u003e","theta":"140","volume":"2016-04"},{"name":"OWASP ASVS","id":"996","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"19","display_name":"OWASP ASVS","radius":"290","description":"","theta":"130","volume":"2016-04"},{"name":"Serverless architecture","id":"999","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"20","display_name":"Serverless architecture","radius":"310","description":"\u003cp\u003e\u003cstrong\u003eServerless architecture\u003c/strong\u003e replaces long-running virtual machines with ephemeral compute power that comes into existence on request and disappears immediately after use. Examples include \u003ca href\u003d\"https://www.firebase.com/\"\u003eFirebase\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/aws-lambda\"\u003eAWS Lambda\u003c/a\u003e. Use of this architecture can mitigate some security concerns such as security patching and SSH access control, and can make much more efficient use of compute resources. These systems cost very little to operate and can have inbuilt scaling features (this is especially true for AWS Lambda). An example architecture could be a JavaScript app with static assets served by a CDN or S3 coupled with AJAX calls served by the API Gateway and Lambda. While serverless architectures have significant benefits, there are drawbacks too: Deploying, managing and sharing code across services is more complex, and local or offline testing is more difficult if not impossible.\u003c/p\u003e","theta":"120","volume":"2016-04"},{"name":"Unikernels","id":"995","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"21","display_name":"Unikernels","radius":"330","description":"","theta":"110","volume":"2016-04"},{"name":"VR beyond gaming","id":"1000","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"22","display_name":"VR beyond gaming","radius":"330","description":"","theta":"100","volume":"2016-04"},{"name":"A single CI instance for all teams","id":"1004","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"23","display_name":"A single CI instance for all teams","radius":"380","description":"","theta":"165","volume":"2016-04"},{"name":"Big Data envy","id":"1003","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"24","display_name":"Big Data envy","radius":"360","description":"\u003cp\u003eWhile we\u0027ve long understood the value of Big Data to better understand how people interact with us, we\u0027ve noticed an alarming trend of \u003cstrong\u003eBig Data envy\u003c/strong\u003e : organizations using complex tools to handle \"not-really-that-big” Data. Distributed map-reduce algorithms are a handy technique for large data sets, but many data sets we see could easily fit in a single-node relational or graph database. Even if you do have more data than that, usually the best thing to do is to first pick out the data you need, which can often then be processed on such a single node. So we urge that before you spin up your clusters, take a realistic assessment of what you need to process, and if it fits—maybe in RAM—use the simple option.\u003c/p\u003e","theta":"150","volume":"2016-04"},{"name":"Gitflow","id":"948","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"25","display_name":"Gitflow","radius":"385","description":"\u003cp\u003eWe firmly believe that long-lived version-control branches harm valuable engineering practices such as continuous integration, and this belief underlies our dislike for \u003cstrong\u003eGitflow\u003c/strong\u003e. We love the flexibility of \u003ca href\u003d\"https://git-scm.com\"\u003eGit\u003c/a\u003e underneath but abhor tools that encourage bad engineering practices. Very short-lived branches hurt less, but most teams we see using Gitflow feel empowered to abuse its branch-heavy workflow, which encourages late integration (therefore discouraging true continuous integration).\u003c/p\u003e","theta":"135","volume":"2016-04"},{"name":"High performance envy/web scale envy","id":"918","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"26","display_name":"High performance envy/web scale envy","radius":"365","description":"\u003cp\u003eWe see many teams run into trouble because they have chosen complex tools, frameworks or architectures because they \"might need to scale\". Companies such as Twitter and Netflix need to be able to support extreme loads and so need these architectures, but they also have extremely skilled development teams able to handle the complexity. Most situations do not require these kinds of engineering feats; teams should keep their  \u003cstrong\u003eweb scale envy\u003c/strong\u003e in check in favor of simpler solutions that still get the job done.\u003c/p\u003e","theta":"120","volume":"2016-04"},{"name":"SAFe™","id":"793","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"27","display_name":"SAFe™","radius":"387","description":"\u003cp\u003eThe \u003ca href\u003d\"http://www.scaledagileframework.com/\"\u003eScaled Agile Framework®\u003c/a\u003e (aka  \u003cstrong\u003eSAFe™\u003c/strong\u003e ) continues to gain mindshare in many organizations at scale. In addition, tools and certification are becoming a significant aspect of the adoption of SAFe™. We continue to be concerned that actual adoptions are prone to over-standardization and are tending towards large release practices, resulting in practices that hinder agile adoption. In its place, we continue to recommend lean approaches that include experimentation and incorporate continuous improvement practices like the Improvement Katas offer organizations a better model for scaling agile.\u003c/p\u003e\n\n\u003cp\u003eScaled Agile Framework® and SAFe™ are trademarks of Scaled Agile, Inc.\u003c/p\u003e","theta":"105","volume":"2016-04"},{"name":"Docker","id":"714","quadrant":"Platforms","ring":"Adopt","movement":"t","radarId":"28","display_name":"Docker","radius":"125","description":"","theta":"210","volume":"2016-04"},{"name":"TOTP Two-Factor Authentication","id":"779","quadrant":"Platforms","ring":"Adopt","movement":"c","radarId":"29","display_name":"TOTP Two-Factor Authentication","radius":"75","description":"\u003cp\u003ePassword security is still a hotly debated topic with the \u003ca href\u003d\"https://www.gov.uk/government/publications/password-policy-simplifying-your-approach/password-policy-executive-summary\"\u003eUK government advocating technical controls\u003c/a\u003e that let users remember simpler passwords and \u003ca href\u003d\"https://www.youtube.com/watch?v\u003dyzGzB-yYKcc\"\u003eEdward Snowden’s password advice\u003c/a\u003e being described as only \"\u003ca href\u003d\"http://www.wired.com/2015/04/snowden-sexy-margaret-thatcher-password-isnt-so-sexy/\"\u003eborderline secure\u003c/a\u003e\". Passwords are generally one of the weakest links in the security chain, so we recommend employing \u003cstrong\u003etwo-factor authentication\u003c/strong\u003e , which can significantly improve security. \u003ca href\u003d\"http://en.wikipedia.org/wiki/Time-based_One-time_Password_Algorithm\"\u003eTime-based One-Time Password\u003c/a\u003e ( \u003cstrong\u003eTOTP\u003c/strong\u003e ) is the standard algorithm in this space, with straightforward server-side implementations and free smartphone authenticator apps from \u003ca href\u003d\"https://play.google.com/store/apps/details?id\u003dcom.google.android.apps.authenticator2\"\u003eGoogle\u003c/a\u003e and \u003ca href\u003d\"http://www.windowsphone.com/en-us/store/app/authenticator/e7994dbc-2336-4950-91ba-ca22d653759b\"\u003eMicrosoft\u003c/a\u003e.\u003c/p\u003e","theta":"240","volume":"2016-04"},{"name":"Apache Mesos","id":"796","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"30","display_name":"Apache Mesos","radius":"210","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://mesos.apache.org/\"\u003eMesos\u003c/a\u003e\u003c/strong\u003e is a platform that abstracts out underlying computing resources to make it easier to build massively scalable distributed systems. It can be used to provide a scheduling layer for \u003ca href\u003d\"https://www.docker.com/\"\u003eDocker\u003c/a\u003e, or to act as an abstraction layer to things like AWS. Twitter has used it to great effect to help it scale its infrastructure. Tools built on top of Mesos are starting to appear, such as \u003ca href\u003d\"http://nerds.airbnb.com/introducing-chronos/\"\u003eChronos\u003c/a\u003e, which is a distributed, fault-tolerant cron replacement. Prominent success stories are appearing, such as \u003ca href\u003d\"https://mesosphere.com/blog/2015/04/23/apple-details-j-a-r-v-i-s-the-mesos-framework-that-runs-siri/\"\u003eApple\u0027s Siri\u003c/a\u003e rearchitecting to use Mesos.\u003c/p\u003e","theta":"190","volume":"2016-04"},{"name":"AWS Lambda","id":"919","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"31","display_name":"AWS Lambda","radius":"215","description":"\u003cp\u003eOur teams continue to enjoy using \u003cstrong\u003e\u003ca href\u003d\"https://aws.amazon.com/lambda/\"\u003eAWS Lambda\u003c/a\u003e\u003c/strong\u003e and are beginning to use it to experiment with \u003ca href\u003d\"/radar/techniques/serverless-architecture\"\u003eServerless architectures\u003c/a\u003e, combining Lambda with the \u003ca href\u003d\"https://aws.amazon.com/api-gateway/\"\u003eAPI Gateway\u003c/a\u003e to produce highly scalable systems with invisible infrastructure. We have run into significant problems using Java for Lambda functions, with erratic latencies up to several seconds as the Lambda container is started. We recommend sticking with JavaScript or Python for the time being.\u003c/p\u003e","theta":"200","volume":"2016-04"},{"name":"H2O","id":"869","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"32","display_name":"H2O","radius":"240","description":"\u003cp\u003ePredictive analytics are used in more and more products, often directly in end user-facing functionality. \u003ca href\u003d\"http://h2o.ai/\"\u003e\u003cstrong\u003eH2O\u003c/strong\u003e\u003c/a\u003e is an interesting open source package (with a startup behind it) that makes predictive analytics accessible to development teams, offering straightforward use of a wide variety of analytics, great performance and easy integration on JVM-based platforms. At the same time it integrates with the data scientists’ favorite tools, R and Python, as well as Hadoop and Spark.\u003c/p\u003e","theta":"210","volume":"2016-04"},{"name":"HSTS","id":"885","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"33","display_name":"HSTS","radius":"190","description":"\u003cp\u003e\u003ca href\u003d\"https://www.owasp.org/index.php/HTTP_Strict_Transport_Security\"\u003eHTTP Strict Transport Security\u003c/a\u003e ( \u003cstrong\u003eHSTS\u003c/strong\u003e ) is a now widely supported policy that allows websites to protect themselves from downgrade attacks. A downgrade attack in the context of HTTPS is one that can cause users of your site to fall back to HTTP rather than HTTPS, allowing for further attacks such as man-in-the-middle attacks. By using the server header, you inform browsers that they should only use HTTPS to access your website, and should ignore downgrade attempts to contact the site via HTTP. Browser support is now widespread enough that this easy-to-implement feature should be considered for any site using HTTPS.\u003c/p\u003e","theta":"220","volume":"2016-04"},{"name":"Kubernetes","id":"925","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"34","display_name":"Kubernetes","radius":"220","description":"","theta":"230","volume":"2016-04"},{"name":"Linux security modules","id":"795","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"35","display_name":"Linux security modules","radius":"167","description":"\u003cp\u003eIn earlier versions of the Radar, we have highlighted the value of \u003cstrong\u003eLinux security modules\u003c/strong\u003e , talking about how they enable people to think about server hardening as a part of their development workflow. More recently, with \u003ca href\u003d\"https://linuxcontainers.org/\"\u003eLXC\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e containers now shipping with default \u003ca href\u003d\"https://wiki.ubuntu.com/AppArmor\"\u003eAppArmor\u003c/a\u003e profiles on certain Linux distributions, it has forced the hand of many teams to understand how these tools work. In the event that teams use container images to run any process that they did not themselves create, these tools help them assess questions about who has access to what resources on the shared host and the capabilities that these contained services have, and be conservative in managing levels of access.\u003c/p\u003e","theta":"240","volume":"2016-04"},{"name":"Pivotal Cloud Foundry","id":"977","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"36","display_name":"Pivotal Cloud Foundry","radius":"220","description":"","theta":"250","volume":"2016-04"},{"name":"Rancher","id":"927","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"37","display_name":"Rancher","radius":"250","description":"","theta":"260","volume":"2016-04"},{"name":"Amazon API Gateway","id":"989","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"38","display_name":"Amazon API Gateway","radius":"315","description":"\u003cp\u003e\u003ca href\u003d\"https://aws.amazon.com/api-gateway/\"\u003e\u003cstrong\u003eAmazon API Gateway\u003c/strong\u003e\u003c/a\u003e is Amazon\u0027s offering enabling developers to expose API services to Internet clients, offering the usual API gateway features like traffic management, monitoring, authentication and authorization. Our teams have been using this service to front other AWS capabilities like AWS Lambda as part of \u003ca href\u003d\"/radar/techniques/serverless-architecture\"\u003eserverless architectures\u003c/a\u003e. We continue to monitor for the challenges presented by \u003ca href\u003d\"/radar/platforms/overambitious-api-gateways\"\u003eoverambitious API gateways\u003c/a\u003e, but at this stage Amazon\u0027s offering appears to be lightweight enough to avoid those problems.\u003c/p\u003e","theta":"186","volume":"2016-04"},{"name":"AWS ECS","id":"924","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"39","display_name":"AWS ECS","radius":"310","description":"\u003cp\u003eThe \u003cstrong\u003e\u003ca href\u003d\"http://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html\"\u003eElastic Container Service (ECS)\u003c/a\u003e\u003c/strong\u003e is AWS’ entry into the multihost Docker space. Although there is a lot of competition in this area, there aren’t many off-premises managed solutions out there yet. Although ECS seems like a good first step, we are worried that it is overly complicated at the moment and lacks a good abstraction layer. If you want to run \u003ca href\u003d\"https://www.docker.com/\"\u003eDocker\u003c/a\u003e on AWS, though, this tool should certainly be high on your list. Just don’t expect it to be easy to get started with.\u003c/p\u003e","theta":"192","volume":"2016-04"},{"name":"Bluetooth Mesh","id":"998","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"40","display_name":"Bluetooth Mesh","radius":"300","description":"\u003cp\u003eWhile many deployments of smart devices rely on Wi-Fi connectivity, we have been seeing success with \u003cstrong\u003eBluetooth Mesh\u003c/strong\u003e networks that don\u0027t necessitate a hub or gateway. With better energy usage than Wi-Fi and better smartphone adoption than ZigBee, Bluetooth LE deployed as a self-healing mesh provides interesting new approaches for connecting local device-area networks. We are still waiting for the formal approach to emerge from the Bluetooth SIG but have already had successful deployments. We particularly like the lack of infrastructure required to stand up a decentralized network but still retain the option to \"progressively enhance\" the system with the addition of a gateway and cloud services.\u003c/p\u003e","theta":"199","volume":"2016-04"},{"name":"Ceph","id":"923","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"41","display_name":"Ceph","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://ceph.com/\"\u003eCeph\u003c/a\u003e\u003c/strong\u003e is a storage platform that can be used as object storage, as block storage, and as a file system, typically running on a cluster of commodity servers. With its first major release having been in July 2012, Ceph is certainly not a new product. We do want to highlight it on this Technology Radar as an important building block for private clouds. It is particularly attractive because its RADOS Gateway component can expose the object store through a RESTful interface that is compatible with \u003ca href\u003d\"https://aws.amazon.com/s3/\"\u003eAmazon S3\u003c/a\u003e and the \u003ca href\u003d\"https://wiki.openstack.org/wiki/Swift\"\u003eOpenStack Swift APIs\u003c/a\u003e.\u003c/p\u003e","theta":"205","volume":"2016-04"},{"name":"Deflect","id":"992","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"42","display_name":"Deflect","radius":"300","description":"\u003cp\u003e\u003ca href\u003d\"https://deflect.ca/\"\u003e\u003cstrong\u003eDeflect\u003c/strong\u003e\u003c/a\u003e is an open source service protecting NGOs, activist and independent media companies from DDoS attacks. Similar to a commercial CDN, it uses distributed reverse-proxy caching and also hides your server IP addresses and blocks public access to admin URLs. Particular effort is put in to combat the botnets typically used for extrajudicial censoring of independent voices.\u003c/p\u003e","theta":"212","volume":"2016-04"},{"name":"ESP8266","id":"987","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"43","display_name":"ESP8266","radius":"310","description":"\u003cp\u003eOur growing ranks of hardware hackers have been excited by the \u003cstrong\u003e\u003ca href\u003d\"http://esp8266.net/\"\u003eESP8266\u003c/a\u003e\u003c/strong\u003e Wi-Fi microcontroller. Rather than a specific technology innovation, it is the combination of low price point and small form factor that has sparked an inflection point in people\u0027s thinking about what is now feasible to achieve with custom hardware devices. Its main characteristics are: Wi-Fi capabilities (it can act as station, access point or a combination of both), low power, open hardware, Arduino SDK programmability, Lua programmability, huge community support and low cost compared with other IoT modules.\u003c/p\u003e","theta":"218","volume":"2016-04"},{"name":"MemSQL","id":"990","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"44","display_name":"MemSQL","radius":"335","description":"\u003cp\u003eAs Moore\u0027s Law predicts, we continue to increase the capacity of computer systems and reduce their cost, and so new processing techniques become possible that only a few years ago would have seemed out of reach. One of these techniques is the in-memory database: Instead of using slow disks or relatively slow SSDs to store data, we can keep it in memory for high performance. One such in-memory database, \u003ca href\u003d\"http://www.memsql.com/\"\u003e\u003cstrong\u003eMemSQL\u003c/strong\u003e\u003c/a\u003e, is making waves because it is horizontally scalable across a cluster and provides a familiar SQL-based query language. MemSQL also connects to Spark for analytics against real-time data, rather than stale data in a warehouse.\u003c/p\u003e","theta":"225","volume":"2016-04"},{"name":"Mesosphere DCOS","id":"889","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"45","display_name":"Mesosphere DCOS","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://mesosphere.com/product/\"\u003eMesosphere DCOS\u003c/a\u003e\u003c/strong\u003e is a platform built on top of \u003ca href\u003d\"http://mesos.apache.org/\"\u003eMesos\u003c/a\u003e. It provides an abstraction over underling machines, giving you a pool of storage and compute that allows services built for DCOS to operate at massive scale (Support is already there for Hadoop, Spark and Cassandra, among others). This is probably overkill for more modest workloads at the moment (where plain old Mesos could still be a good fit), but it will be interesting to see if Mesosphere starts trying to position DCOS as a general-purpose system.\u003c/p\u003e","theta":"231","volume":"2016-04"},{"name":"Nomad","id":"983","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"46","display_name":"Nomad","radius":"300","description":"","theta":"237","volume":"2016-04"},{"name":"Presto","id":"929","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"47","display_name":"Presto","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://prestodb.io/\"\u003ePresto\u003c/a\u003e\u003c/strong\u003e is an open source distributed SQL query engine designed and optimized for running interactive analytics workloads. Presto\u0027s massively parallel processing architecture - combined with advanced code-generation techniques and in-memory processing pipelines - makes it highly scalable. It supports a large subset of ANSI SQL including complex queries, joins, aggregations and window functions. Presto comes with support for a wide range of data sources including \u003cstrong\u003eHive\u003c/strong\u003e , \u003cstrong\u003eCassandra\u003c/strong\u003e , \u003cstrong\u003eMySQL\u003c/strong\u003e and \u003cstrong\u003ePostgreSQL\u003c/strong\u003e , thereby unifying the interactive analytics interface across data stores of an organization. Applications can connect to Presto using its JDBC interface.\u003c/p\u003e","theta":"244","volume":"2016-04"},{"name":"Realm","id":"979","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"48","display_name":"Realm","radius":"305","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://realm.io/\"\u003eRealm\u003c/a\u003e\u003c/strong\u003e is a database designed for use on mobile devices, with its own persistence engine to achieve high performance. Realm is marketed as a replacement for SQLite and Core Data, and our teams have enjoyed using it. Note that migrations are not quite as straightforward as the Realm documentation would have you believe. Still, Realm has us excited, and we suggest you take a look.\u003c/p\u003e","theta":"250","volume":"2016-04"},{"name":"Sandstorm","id":"988","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"49","display_name":"Sandstorm","radius":"300","description":"\u003cp\u003eFor people who want the benefit of cloud-based collaboration tools but don\u0027t want to inadvertently \"become the product\" of a major cloud provider, \u003ca href\u003d\"https://sandstorm.io/\"\u003e\u003cstrong\u003eSandstorm\u003c/strong\u003e\u003c/a\u003e provides an interesting open source alternative with the potential for self-hosting. Of particular interest is the isolation approach, whereby containerization is applied per document rather than per application, and syscall whitelisting is added to further \u003ca href\u003d\"http://docs.sandstorm.io/en/latest/using/security-practices/#server-sandboxing\"\u003esecure the sandbox\u003c/a\u003e.\u003c/p\u003e","theta":"257","volume":"2016-04"},{"name":"TensorFlow","id":"982","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"50","display_name":"TensorFlow","radius":"325","description":"","theta":"263","volume":"2016-04"},{"name":"Application Servers","id":"872","quadrant":"Platforms","ring":"Hold","movement":"c","radarId":"51","display_name":"Application Servers","radius":"375","description":"\u003cp\u003eThe rise of containers, phoenix servers and continuous delivery has seen a move away from the usual approach to deploying web applications. Traditionally we have built an artifact and then installed that artifact into an application server. The result was long feedback loops for changes, increased build times and the not insignificant overhead of managing these application servers in production. Many of them are a pain to automate too. Most teams we work with favor bundling an embedded http server within your web application. There are plenty of options available: Jetty, SimpleWeb, Webbit and Owin Self-Host amongst others. Easier automation, easier deployment and a reduction in the amount of infrastructure you have to manage lead us to recommend embedded servers over \u003cstrong\u003eapplication servers\u003c/strong\u003e for future projects.\u003c/p\u003e","theta":"202","volume":"2016-04"},{"name":"Over-ambitious API Gateways","id":"931","quadrant":"Platforms","ring":"Hold","movement":"c","radarId":"52","display_name":"Over-ambitious API Gateways","radius":"375","description":"\u003cp\u003eOne of our common complaints is the pushing of business smarts into middleware, resulting in application servers and enterprise service buses with ambitions to run critical application logic. These require complex programming in environments not well suited to the purpose. We\u0027re seeing a worrying re-emergence of this disease with \u003cstrong\u003eoverambitious API Gateway\u003c/strong\u003e products. API Gateways can provide utility in dealing with some generic concerns - for example, authentication and rate-limiting - but any domain smarts such as data transformation or rule processing should live in applications or services where they can be controlled by product teams working closely with the domains they support.\u003c/p\u003e","theta":"225","volume":"2016-04"},{"name":"Superficial private cloud","id":"932","quadrant":"Platforms","ring":"Hold","movement":"c","radarId":"53","display_name":"Superficial private cloud","radius":"375","description":"","theta":"247","volume":"2016-04"},{"name":"Consul","id":"732","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"54","display_name":"Consul","radius":"55","description":"","theta":"45","volume":"2016-04"},{"name":"Apache Kafka","id":"850","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"55","display_name":"Apache Kafka","radius":"230","description":"","theta":"84","volume":"2016-04"},{"name":"Browsersync","id":"904","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"56","display_name":"Browsersync","radius":"240","description":"\u003cp\u003eWe\u0027ve had rave reviews from a number of ThoughtWorks teams using \u003ca href\u003d\"http://www.browsersync.io/\"\u003e\u003cstrong\u003eBrowsersync\u003c/strong\u003e\u003c/a\u003e. As the number of devices we deliver web applications to grows, so does the amount of effort that must be devoted to testing across these different devices. Browsersync is a free, open source tool that can dramatically reduce this effort by synchronizing manual browser testing across multiple mobile or desktop browsers. Providing both a CLI and a UI option, the tool is build-pipeline friendly and automates repetitive tasks such as form filling.\u003c/p\u003e","theta":"77","volume":"2016-04"},{"name":"Carthage","id":"902","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"57","display_name":"Carthage","radius":"230","description":"\u003cp\u003eDependency management in iOS and OS X projects used to be either completely manual or completely automatic as part of using \u003ca href\u003d\"https://cocoapods.org/\"\u003eCocoaPods\u003c/a\u003e. With \u003cstrong\u003e\u003ca href\u003d\"https://github.com/Carthage/Carthage\"\u003eCarthage\u003c/a\u003e\u003c/strong\u003e , a new middle ground has become available. Carthage manages dependencies - it downloads, builds and updates frameworks - but it leaves the integration of the frameworks into the build of the project to the project. This is in contrast to CocoaPods, which basically takes over the project structure and build setup. It should be noted that Carthage can only deal with dynamic frameworks, which are not available on iOS 7 and below.\u003c/p\u003e","theta":"70","volume":"2016-04"},{"name":"Gauge","id":"912","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"58","display_name":"Gauge","radius":"210","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://gauge.org/\"\u003eGauge\u003c/a\u003e\u003c/strong\u003e is a lightweight cross-platform test-automation tool. Specifications are written in free-form Markdown so test cases can be written in the business language, as opposed to using the more common but restrictive \"given-when-then\" format. Language and IDE support are implemented as plugins to a single core implementation, allowing testers to use the same IDEs as the rest of the team, with powerful capabilities such as autocompletion and refactoring. This tool, open sourced by ThoughtWorks, also supports parallel execution out of the box for all supported platforms.\u003c/p\u003e","theta":"63","volume":"2016-04"},{"name":"GitUp","id":"895","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"59","display_name":"GitUp","radius":"260","description":"\u003cp\u003eGit can be confusing. Really confusing. And even when it’s used in a simple trunk-based development process, there are still enough nuances to how it works that people can tie themselves in knots from time to time. When this happens, having an understanding of how Git works under the hood is very useful, and \u003cstrong\u003e\u003ca href\u003d\"http://gitup.co/\"\u003eGitUp\u003c/a\u003e\u003c/strong\u003e is a Mac-based tool that gives you exactly that. GitUp provides a graphical representation of what is happening as you type normal Git commands into the terminal. You can learn the various Git commands while also understanding what each one does as you use it. GitUp is a useful tool for both people new to Git and those with more Git experience.\u003c/p\u003e","theta":"56","volume":"2016-04"},{"name":"Let\u0027s Encrypt","id":"946","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"60","display_name":"Let\u0027s Encrypt","radius":"175","description":"","theta":"49","volume":"2016-04"},{"name":"Load Impact","id":"905","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"61","display_name":"Load Impact","radius":"230","description":"","theta":"42","volume":"2016-04"},{"name":"OWASP Dependency-Check","id":"963","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"62","display_name":"OWASP Dependency-Check","radius":"180","description":"","theta":"35","volume":"2016-04"},{"name":"Serverspec","id":"962","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"63","display_name":"Serverspec","radius":"200","description":"","theta":"28","volume":"2016-04"},{"name":"SysDig","id":"896","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"64","display_name":"SysDig","radius":"180","description":"\u003cp\u003eAlthough \u003cstrong\u003e\u003ca href\u003d\"http://www.sysdig.org/\"\u003eSysDig\u003c/a\u003e\u003c/strong\u003e isn’t the newest tool on the Technology Radar, we’re still surprised by how many people haven’t heard of it. A pluggable open source CLI for Linux system troubleshooting, SysDig has some pretty powerful features. One of the key things we like is the ability to generate a system trace on a machine that is experiencing difficulties, which you can then interrogate afterward to find out what was happening. SysDig also contains support for working with containers, something that makes a previously useful tool even more powerful.\u003c/p\u003e","theta":"21","volume":"2016-04"},{"name":"Webpack","id":"964","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"65","display_name":"Webpack","radius":"220","description":"","theta":"14","volume":"2016-04"},{"name":"Zipkin","id":"466","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"66","display_name":"Zipkin","radius":"180","description":"","theta":"7","volume":"2016-04"},{"name":"Apache Flink","id":"972","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"67","display_name":"Apache Flink","radius":"330","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://flink.apache.org/\"\u003eApache Flink\u003c/a\u003e\u003c/strong\u003e is a new-generation platform for scalable distributed batch and stream processing. At its core is a streaming data-flow engine. It also supports tabular (SQL-like), graph-processing and machine-learning operations. Apache Flink stands out with feature-rich capabilities for stream processing: event time, rich streaming window operations, fault tolerance and exactly-once semantics. While it hasn\u0027t reached version 1.0, it has raised significant community interest due to innovations in stream processing, memory handling, state management and simplicity of configuration.\u003c/p\u003e","theta":"84","volume":"2016-04"},{"name":"Concourse CI","id":"928","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"68","display_name":"Concourse CI","radius":"325","description":"\u003cp\u003eMany development teams are making the move from simple continuous integration servers to Continuous Delivery pipelines, often spanning multiple environments, reaching into production. To implement such a pipeline successfully and operate it in a sustainable way requires a CI/CD tool that treats build pipelines and artifacts as first-class citizens; and unfortunately there aren’t many. \u003ca href\u003d\"http://concourse.ci/\"\u003e\u003cstrong\u003eConcourse CI\u003c/strong\u003e\u003c/a\u003e is a promising new entrant in this field, and our teams that have tried it are excited about its setup, which enables builds that run in containers, has a clean, usable UI and discourages snowflake build servers.\u003c/p\u003e","theta":"78","volume":"2016-04"},{"name":"Gitrob","id":"897","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"69","display_name":"Gitrob","radius":"330","description":"\u003cp\u003eAttackers continue to use automated software to crawl public GitHub repositories to find AWS credentials and spin up EC2 instances to mine Bitcoins or for other nefarious purposes. Although adoption of tools like \u003ca href\u003d\"https://github.com/AGWA/git-crypt\"\u003egit-crypt\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/blackbox\"\u003eBlackbox\u003c/a\u003e to safely store secrets such as passwords and access tokens in code repositories is increasing, it is still all too common that secrets are stored unprotected. It is also not uncommon to see project secrets accidentally checked in to developers\u0027 personal repositories. \u003ca href\u003d\"https://github.com/michenriksen/gitrob\"\u003e\u003cstrong\u003eGitrob\u003c/strong\u003e\u003c/a\u003e can help minimize the damage of exposing secrets. It scans an organization\u0027s GitHub repositories, flagging all files that might contain sensitive information that shouldn\u0027t have been pushed to the repository. The current release of the tool has some limitations: It can only be used to scan public GitHub organizations and their members, it doesn\u0027t inspect the contents of files, it doesn\u0027t review the entire commit history, and it fully scans all repositories each time it is run. Despite these limitations, it can be a helpful reactive tool to help alert teams before it is too late. It should be considered a complementary approach to a proactive tool such as \u003ca href\u003d\"https://github.com/thoughtworks/talisman\"\u003eTalisman\u003c/a\u003e.\u003c/p\u003e","theta":"72","volume":"2016-04"},{"name":"Grasp","id":"971","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"70","display_name":"Grasp","radius":"310","description":"","theta":"66","volume":"2016-04"},{"name":"HashiCorp Vault","id":"969","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"71","display_name":"HashiCorp Vault","radius":"300","description":"\u003cp\u003eHaving a way to securely manage secrets is increasingly becoming a huge project issue. The old idea of just having a file with secrets or environment variables is becoming hard to manage, especially in environments with multiple applications like \u003ca href\u003d\"/radar/techniques/microservices\"\u003emicroservices\u003c/a\u003e or microcontainer environments, where the applications need to access a multitude of secrets. \u003ca href\u003d\"https://github.com/hashicorp/vault\"\u003e\u003cstrong\u003eHashiCorp Vault\u003c/strong\u003e\u003c/a\u003e is a promising tool that tries to solve the problem by providing mechanisms for securely accessing secrets through an unified interface. It has some features that make life easier, such as encryption and automatically generating secrets for known tools, among others.\u003c/p\u003e","theta":"60","volume":"2016-04"},{"name":"ievms","id":"908","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"72","display_name":"ievms","radius":"285","description":"\u003cp\u003eDespite the shrinking usage of Internet Explorer, for many products the IE user base is not an insignificant share of the market, and browser compatibility needs to be tested. This is particularly troublesome if you prefer the joys of a UNIX-based system for development. To aid in this dilemma, \u003ca href\u003d\"https://github.com/xdissent/ievms\"\u003e\u003cstrong\u003eievms\u003c/strong\u003e\u003c/a\u003e provides a utility script that brings together Windows-distributed VM images and VirtualBox to automate the setup and testability of various IE versions, from 6 up to Edge.\u003c/p\u003e","theta":"54","volume":"2016-04"},{"name":"Jepsen","id":"950","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"73","display_name":"Jepsen","radius":"290","description":"\u003cp\u003eWith the growth in usage of NoSQL data stores, and the growth in popularity of polyglot approaches to persistence, teams now have many choices when it comes to storing their data. While this has brought many advantages, product behavior with flaky networks can introduce subtle (and not so subtle) issues that are often not well understood, even in some cases by the product developers themselves. The \u003ca href\u003d\"https://github.com/aphyr/jepsen\"\u003e\u003cstrong\u003eJepsen\u003c/strong\u003e\u003c/a\u003e toolkit and accompanying \u003ca href\u003d\"https://aphyr.com/tags/Jepsen\"\u003eblog\u003c/a\u003e have become the de-facto reference for anyone looking to understand how different database and queuing technologies react under adverse conditions. Crucially, the approach to testing, which includes clients in the transactions, shines a spotlight on possible failure modes for many teams building microservices.\u003c/p\u003e","theta":"48","volume":"2016-04"},{"name":"LambdaCD","id":"968","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"74","display_name":"LambdaCD","radius":"300","description":"","theta":"42","volume":"2016-04"},{"name":"Pinpoint","id":"967","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"75","display_name":"Pinpoint","radius":"320","description":"","theta":"36","volume":"2016-04"},{"name":"Pitest","id":"970","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"76","display_name":"Pitest","radius":"300","description":"","theta":"30","volume":"2016-04"},{"name":"Prometheus","id":"849","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"77","display_name":"Prometheus","radius":"290","description":"\u003cp\u003eSoundCloud has recently open sourced its monitoring and alerting toolkit, \u003ca href\u003d\"http://prometheus.io/\"\u003e\u003cstrong\u003ePrometheus\u003c/strong\u003e\u003c/a\u003e. Developed in reaction to difficulties with \u003ca href\u003d\"http://graphite.readthedocs.org/\"\u003eGraphite\u003c/a\u003e in its production systems, Prometheus primarily supports a pull-based HTTP model (although a more Graphite-like push model is also supported). It also goes further by supporting alerts, making it an active part of your operational toolset. As of this writing, Prometheus is still only in release 0.15.1 but is evolving rapidly. We’re glad to see the recent product focus on core time-series DB and multidimensional indexing capabilities while allowing for export to a wider variety of front-end graphing tools.\u003c/p\u003e","theta":"24","volume":"2016-04"},{"name":"RAML","id":"913","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"78","display_name":"RAML","radius":"325","description":"\u003cp\u003eWith a growing landscape of services providing RESTful APIs, it is becoming increasingly important to document them. We have previously mentioned \u003ca href\u003d\"https://www.thoughtworks.com/radar/tools/swagger\"\u003eSwagger\u003c/a\u003e, and in this Technology Radar we’d like to highlight the RESTful API modeling language (\u003ca href\u003d\"http://raml.org/\"\u003e\u003cstrong\u003eRAML\u003c/strong\u003e\u003c/a\u003e). Our teams feel that in comparison to Swagger it is more lightweight and moves the focus from adding documentation to existing APIs to designing APIs.\u003c/p\u003e","theta":"18","volume":"2016-04"},{"name":"Repsheet","id":"980","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"79","display_name":"Repsheet","radius":"330","description":"","theta":"12","volume":"2016-04"},{"name":"Sleepy Puppy","id":"940","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"80","display_name":"Sleepy Puppy","radius":"330","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/Netflix/sleepy-puppy\"\u003eSleepy Puppy\u003c/a\u003e\u003c/strong\u003e is a delayed cross-site scripting (XSS) payload-management framework recently open sourced by Netflix. It enables you to test vulnerabilities for XSS past the target application when the perpetrator intends to attack a secondary underlying system. With XSS being one of the OWASP Top10, we see this framework assisting with automated security checks for several applications. It simplifies the capturing, managing and tracking of XSS propagation over long periods of time, with customizable payloads. Sleepy puppy also exposes an API that can be integrated with vulnerability tools like \u003ca href\u003d\"https://www.thoughtworks.com/radar/tools/zap\"\u003eZAP\u003c/a\u003e, for automated security checks.\u003c/p\u003e","theta":"6","volume":"2016-04"},{"name":"Jenkins as a deployment pipeline","id":"976","quadrant":"Tools","ring":"Hold","movement":"t","radarId":"81","display_name":"Jenkins as a deployment pipeline","radius":"375","description":"","theta":"45","volume":"2016-04"},{"name":"ES6","id":"892","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radarId":"82","display_name":"ES6","radius":"125","description":"\u003cp\u003eOver many years, JavaScript has grown to become probably the most widely used programming language in the world. Nevertheless, the language itself has a few problems that many have attempted to address by using libraries or even by implementing their own languages that run on top of JavaScript (of which we’ve mentioned both \u003ca href\u003d\"https://www.thoughtworks.com/radar/languages-and-frameworks/coffeescript\"\u003eCoffeeScript\u003c/a\u003e and \u003ca href\u003d\"https://www.thoughtworks.com/radar/languages-and-frameworks/clojurescript\"\u003eClojureScript\u003c/a\u003e before). \u003cstrong\u003e\u003ca href\u003d\"http://es6-features.org/\"\u003eES6\u003c/a\u003e\u003c/strong\u003e (aka ECMAScript 6 or ECMAScript 2015), the new version of JavaScript, addresses many of the concerns of the older versions currently in use. Although browser support is scarce, support from mature transpilers like \u003ca href\u003d\"http://babeljs.io\"\u003eBabel\u003c/a\u003e allows you to write ES6 and have it supported in older browsers. For new projects, we strongly suggest starting with ES6 from day one.\u003c/p\u003e","theta":"288","volume":"2016-04"},{"name":"React.js","id":"827","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"83","display_name":"React.js","radius":"75","description":"","theta":"306","volume":"2016-04"},{"name":"Spring Boot","id":"775","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"84","display_name":"Spring Boot","radius":"95","description":"","theta":"324","volume":"2016-04"},{"name":"Swift","id":"830","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"85","display_name":"Swift","radius":"70","description":"\u003cp\u003e\u003ca href\u003d\"https://developer.apple.com/swift/\"\u003e\u003cstrong\u003eSwift\u003c/strong\u003e\u003c/a\u003e is now our default choice for development in the Apple ecosystem. With the release of Swift 2, the language approached a level of maturity that provides the stability and performance required for most projects. A good number of libraries that support iOS development—\u003ca href\u003d\"https://github.com/SwiftyJSON/SwiftyJSON\"\u003eSwiftyJSON\u003c/a\u003e, \u003ca href\u003d\"https://github.com/Quick/Quick\"\u003eQuick\u003c/a\u003e, etc.—are now migrated over to Swift, which is where the rest of the applications should follow. Swift has now been open sourced, and we are seeing a community of developers dedicated to continuously improving development in iOS.\u003c/p\u003e","theta":"342","volume":"2016-04"},{"name":"Butterknife","id":"961","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"86","display_name":"Butterknife","radius":"250","description":"","theta":"278","volume":"2016-04"},{"name":"Dagger","id":"960","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"87","display_name":"Dagger","radius":"230","description":"","theta":"286","volume":"2016-04"},{"name":"Dapper","id":"952","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"88","display_name":"Dapper","radius":"230","description":"","theta":"294","volume":"2016-04"},{"name":"Ember.js","id":"879","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"89","display_name":"Ember.js","radius":"180","description":"\u003cp\u003e\u003ca href\u003d\"http://emberjs.com/\"\u003e\u003cstrong\u003eEmber.js\u003c/strong\u003e\u003c/a\u003e has developed further support based on project experiences and is clearly a strong contender in the field of JavaScript application frameworks. Ember is praised for its developer experience, with far fewer surprises than other frameworks such as \u003ca href\u003d\"/radar/languages-and-frameworks/angularjs\"\u003eAngularJS\u003c/a\u003e. The Ember CLI build tooling, convention-over-configuration approach and \u003ca href\u003d\"/radar/languages-and-frameworks/es6\"\u003eES6\u003c/a\u003e support also gain positive feedback.\u003c/p\u003e","theta":"302","volume":"2016-04"},{"name":"Enlive","id":"903","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"90","display_name":"Enlive","radius":"250","description":"\u003cp\u003eMost templating frameworks like \u003ca href\u003d\"https://mustache.github.io/\"\u003eMustache\u003c/a\u003e or \u003ca href\u003d\"http://freemarker.org/\"\u003eFreeMarker\u003c/a\u003e mix code with markup in a single file to implement complex, dynamic content. \u003ca href\u003d\"https://github.com/cgrand/enlive/wiki\"\u003e\u003cstrong\u003eEnlive\u003c/strong\u003e\u003c/a\u003e is a Clojure-based templating framework that completely separates programming language from HTML markup and employs CSS selectors to find and replace parts of the document. Enlive demonstrates the power of functional programming to implement complex behavior through a series of simple, composable functions acting on a common abstraction. Our teams working in Clojure have found it to be a very useful and straightforward tool.\u003c/p\u003e","theta":"310","volume":"2016-04"},{"name":"Fetch","id":"953","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"91","display_name":"Fetch","radius":"230","description":"\u003cp\u003eOur teams are moving away from JQuery or raw XHR for remote JavaScript calls and instead are using the new \u003ca href\u003d\"https://fetch.spec.whatwg.org/\"\u003eFetch\u003c/a\u003e API and the \u003cstrong\u003e\u003ca href\u003d\"https://github.com/github/fetch\"\u003eFetch\u003c/a\u003e\u003c/strong\u003e polyfill in particular. The semantics remain similar but have cleaner support for promises and CORS support. We are seeing this as the new de-facto approach.\u003c/p\u003e","theta":"319","volume":"2016-04"},{"name":"React Native","id":"937","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"92","display_name":"React Native","radius":"180","description":"","theta":"327","volume":"2016-04"},{"name":"Redux","id":"951","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"93","display_name":"Redux","radius":"180","description":"\u003cp\u003e\u003ca href\u003d\"http://redux.js.org/\"\u003e\u003cstrong\u003eRedux\u003c/strong\u003e\u003c/a\u003e is a great, mature tool that has helped many of our teams reframe how they think about managing state in client-side apps. Using a \u003ca href\u003d\"/radar/techniques/flux\"\u003eFlux\u003c/a\u003e-style approach, it enables a loosely coupled state-machine architecture that\u0027s easy to reason about. We\u0027ve found it a good companion to some of our favored JavaScript frameworks, such as \u003ca href\u003d\"/radar/languages-and-frameworks/ember-js\"\u003eEmber\u003c/a\u003e and \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e.\u003c/p\u003e","theta":"335","volume":"2016-04"},{"name":"Robolectric","id":"954","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"94","display_name":"Robolectric","radius":"240","description":"","theta":"343","volume":"2016-04"},{"name":"SignalR","id":"936","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"95","display_name":"SignalR","radius":"200","description":"\u003cp\u003eWe have a number of reservations about the use of HTML5 WebSockets. By allowing the server to initiate actions on the browser, WebSockets departs from the connectionless, request/response model that underpins the World Wide Web today. Security is another big risk with WebSockets. For example, the standard does not impose any cross-origin request policy. However, we do recognize that in certain monitoring or alerting applications, WebSockets can be very useful. If you need to build a .NET WebSockets server, \u003ca href\u003d\"http://signalr.net/\"\u003e\u003cstrong\u003eSignalR\u003c/strong\u003e\u003c/a\u003e conveniently implements much of the additional code you need for a robust production application. This includes some recommended security practices such as validating connection tokens and activating SSL when encryption is needed. Although ThoughtWorks teams have been very happy with SignalR, there are still fundamental issues with WebSockets that you should consider before diving in.\u003c/p\u003e","theta":"351","volume":"2016-04"},{"name":"Alamofire","id":"965","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"96","display_name":"Alamofire","radius":"330","description":"\u003cp\u003eNetworking and decoding in iOS applications have been a difficult endeavor for many years. There have been many libraries and attempts to solve this ongoing problem. It looks as though \u003ca href\u003d\"https://github.com/Alamofire/Alamofire\"\u003e\u003cstrong\u003eAlamofire\u003c/strong\u003e\u003c/a\u003e is the most robust and developer-friendly library to handle decoding JSON. It was written by the same creator as its Objective-C counterpart (AFNetworking), which was used at great length during the Objective-C days.\u003c/p\u003e","theta":"278","volume":"2016-04"},{"name":"AngularJS","id":"727","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"97","display_name":"AngularJS","radius":"285","description":"\u003cp\u003eWhile we have delivered many successful projects using \u003ca href\u003d\"https://angularjs.org/\"\u003e\u003cstrong\u003eAngularJS\u003c/strong\u003e\u003c/a\u003e and are seeing an acceleration of adoption in corporate settings, we have decided to move Angular back to Assess on this edition of the Radar. This move is intended as a note of caution: \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e and \u003ca href\u003d\"/radar/languages-and-frameworks/ember-js\"\u003eEmber\u003c/a\u003e offer strong alternatives; the migration path from Angular version 1 to version 2 is causing uncertainty; and we see some organizations adopting the framework without really thinking through whether a single-page application fits their needs. We have passionate internal debates about this topic but have certainly seen codebases become overly complex from a combination of two-way binding and inconsistent state-management patterns. We believe that rather than requiring that a solid framework be jettisoned, these issues can be solved through careful design and use of Redux or Flux from the outset.\u003c/p\u003e","theta":"286","volume":"2016-04"},{"name":"Aurelia","id":"958","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"98","display_name":"Aurelia","radius":"310","description":"","theta":"294","volume":"2016-04"},{"name":"Cylon.js","id":"955","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"99","display_name":"Cylon.js","radius":"320","description":"\u003cp\u003eThe intersection between IoT devices and the JavaScript ecosystem offers interesting possibilities. \u003cstrong\u003e\u003ca href\u003d\"https://cylonjs.com/\"\u003eCylon.js\u003c/a\u003e\u003c/strong\u003e is a JavaScript library for building interfaces for robotics and the Internet of Things, which has excited our technical community. It offers support for 50+ platform devices, as well as general-purpose input/output support with a shared set of drivers provided by the cylon-gpio module. Control of the devices is then possible through a web browser interface.\u003c/p\u003e","theta":"302","volume":"2016-04"},{"name":"Elixir","id":"676","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"100","display_name":"Elixir","radius":"320","description":"\u003cp\u003eWe continue to see a lot of excitement from people using the \u003ca href\u003d\"http://elixir-lang.org/\"\u003e\u003cstrong\u003eElixir\u003c/strong\u003e\u003c/a\u003e programming language. Elixir, which is built on top of the Erlang virtual machine, is showing promise for creating highly concurrent and fault-tolerant systems. Elixir has distinctive features such as the Pipe operator, which allows developers to build a pipeline of functions as you would in the UNIX command shell. The shared byte code allows Elixir to interoperate with Erlang and leverage existing libraries while supporting tools such as the Mix build tool, the Iex interactive shell and the ExUnit unit testing framework.\u003c/p\u003e","theta":"310","volume":"2016-04"},{"name":"Elm","id":"736","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"101","display_name":"Elm","radius":"320","description":"","theta":"319","volume":"2016-04"},{"name":"GraphQL","id":"986","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"102","display_name":"GraphQL","radius":"300","description":"","theta":"327","volume":"2016-04"},{"name":"Immutable.js","id":"956","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"103","display_name":"Immutable.js","radius":"300","description":"\u003cp\u003eImmutability is often emphasized in the functional programming paradigm, and most languages have the ability to create immutable objects, which cannot be changed once created. \u003cstrong\u003e\u003ca href\u003d\"https://facebook.github.io/immutable-js/\"\u003eImmutable.js\u003c/a\u003e\u003c/strong\u003e is a library for JavaScript that provides many persistent immutable data structures, which are highly efficient on modern JavaScript virtual machines. Immutable.js objects are, however, not normal JavaScript objects, so references to JavaScript objects from immutable objects should be avoided. Our teams have had value using this library for tracking mutation and maintaining state, and it is a library we encourage developers to investigate, especially when it\u0027s combined with the rest of the Facebook stack.\u003c/p\u003e","theta":"335","volume":"2016-04"},{"name":"OkHttp","id":"941","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"104","display_name":"OkHttp","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://square.github.io/okhttp/\"\u003eOkHttp\u003c/a\u003e\u003c/strong\u003e is a Java HTTP connection library from Square that provides a fluent interface for creating connections, as well as support for the faster HTTP/2 protocol. Even when using HTTP/1.1, OkHttp can provide performance improvements via connection pooling and transparent gzip compression. Supporting both blocking synchronous and nonblocking asynchronous calls, it can also be used as a drop-in replacement for the widely used Apache HttpClient.\u003c/p\u003e","theta":"343","volume":"2016-04"},{"name":"Recharts","id":"957","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"105","display_name":"Recharts","radius":"300","description":"","theta":"351","volume":"2016-04"},{"name":"JSPatch","id":"959","quadrant":"languages-and-frameworks","ring":"Hold","movement":"t","radarId":"106","display_name":"JSPatch","radius":"385","description":"","theta":"315","volume":"2016-04"}],"date":"2016-04"},{"blips":[{"name":"Consumer-driven contract testing","id":"833","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"1","display_name":"Consumer-driven contract testing","radius":"75","description":"\u003cp\u003eWe’ve decided to bring \u003cstrong\u003econsumer-driven contract testing\u003c/strong\u003e back from the archive for this edition even though we had allowed it to fade in the past. The concept isn’t new, but with the mainstream acceptance of microservices, we need to remind people that \u003ca href\u003d\"http://www.martinfowler.com/articles/consumerDrivenContracts.html\"\u003econsumer-driven contracts\u003c/a\u003e are an essential part of a mature \u003ca href\u003d\"http://martinfowler.com/articles/microservice-testing/\"\u003emicroservice testing\u003c/a\u003e portfolio, enabling independent service deployments. But in addition, we want to point out that consumer-driven contract testing is a technique and an attitude that requires no special tool to implement. We love frameworks like \u003ca href\u003d\"https://github.com/realestate-com-au/pact\"\u003ePact\u003c/a\u003e because they make proper contract tests easier to implement in certain contexts. But we have noticed a tendency for teams to focus on the framework rather than on the general practice. Writing Pact tests is not a guarantee that you are creating consumer-driven contracts; likewise, in many situations you should be creating good consumer-driven contracts even where no pre-built testing tool exists.\u003c/p\u003e","theta":"158","volume":"2016-11"},{"name":"Pipelines as code","id":"1037","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"2","display_name":"Pipelines as code","radius":"75","description":"\u003cp\u003eTeams are pushing for automation across their environments, including their development infrastructure. \u003cstrong\u003ePipelines as code\u003c/strong\u003e is defining the deployment pipeline through code instead of configuring a running CI/CD tool. \u003ca href\u003d\"/radar/tools/lambdacd\"\u003eLambdaCD\u003c/a\u003e, \u003ca href\u003d\"http://readme.drone.io/usage/overview/\"\u003eDrone\u003c/a\u003e, \u003ca href\u003d\"/radar/tools/gocd\"\u003eGoCD\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/concourse-ci\"\u003eConcourse\u003c/a\u003e are examples that allow usage of this technique. Also, configuration automation tools for CI/CD systems like \u003ca href\u003d\"https://github.com/SpringerSBM/gomatic\"\u003eGoMatic\u003c/a\u003e can be used to treat the deployment pipeline as code—versioned and tested.\u003c/p\u003e","theta":"135","volume":"2016-11"},{"name":"Threat Modeling","id":"871","quadrant":"Techniques","ring":"Adopt","movement":"c","radarId":"3","display_name":"Threat Modeling","radius":"70","description":"\u003cp\u003eWith the number of high-profile security breaches in the past months, software development teams no longer need convincing that they must place an emphasis on writing secure software and dealing with their users\u0027 data in a responsible way. The teams face a steep learning curve, though, and the vast number of potential threats—ranging from organized crime and government spying to teenagers who attack systems \"for the lulz\"—can be overwhelming. \u003ca href\u003d\"https://www.owasp.org/index.php/Category:Threat_Modeling\"\u003e\u003cstrong\u003eThreat Modeling\u003c/strong\u003e\u003c/a\u003e provides a set of techniques that help you identify and classify potential threats early in the development process. It is important to understand that it is only part of a strategy to stay ahead of threats. When used in conjunction with techniques such as establishing cross-functional security requirements to address common risks in the technologies a project uses and using automated security scanners, threat modeling can be a powerful asset.\u003c/p\u003e","theta":"113","volume":"2016-11"},{"name":"APIs as a product","id":"1036","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"4","display_name":"APIs as a product","radius":"170","description":"\u003cp\u003eBusinesses have wholeheartedly embraced APIs as a way to expose business capabilities to both external and internal developers. APIs promise the ability to experiment quickly with new business ideas by recombining core capabilities. But what differentiates an API from an ordinary enterprise integration service? One difference lies in treating \u003cstrong\u003eAPIs as a product\u003c/strong\u003e , even when the consumer is an internal system. Teams that build APIs should understand the needs of their customers and make the product compelling to them. Products are also improved, maintained and supported over the long term. They should have an owner who advocates for the customer and strives for continual improvement. Products are actively maintained and supported, easy to find and easy to use. In our experience, a product orientation is the missing ingredient that makes the difference between ordinary enterprise integration and an agile business built on a platform of APIs.\u003c/p\u003e","theta":"169","volume":"2016-11"},{"name":"Bug bounties","id":"947","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"5","display_name":"Bug bounties","radius":"210","description":"\u003cp\u003eThe use of \u003cstrong\u003ebug bounties\u003c/strong\u003e continues to grow in popularity for many organizations, including enterprises and notable government bodies. A bug-bounty program encourages participants to identify potentially damaging vulnerabilities in return for reward or recognition. Companies like \u003ca href\u003d\"https://hackerone.com/\"\u003eHackerOne\u003c/a\u003e and \u003ca href\u003d\"https://bugcrowd.com/\"\u003eBugcrowd\u003c/a\u003e offer services to help organizations manage this process more easily, and we\u0027re seeing these services gather adoption.\u003c/p\u003e","theta":"158","volume":"2016-11"},{"name":"Data Lake","id":"789","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"6","display_name":"Data Lake","radius":"200","description":"\u003cp\u003eA \u003cstrong\u003e\u003ca href\u003d\"http://martinfowler.com/bliki/DataLake.html\"\u003eData Lake\u003c/a\u003e\u003c/strong\u003e is an immutable data store of largely unprocessed \"raw\" data, acting as a source for data analytics. While the technique can clearly be misused, we have used it successfully at clients, hence motivating its move to trial. We continue to recommend other approaches for operational collaborations, limiting the use of the data lake to reporting, analytics and feeding data into data marts.\u003c/p\u003e","theta":"147","volume":"2016-11"},{"name":"Hosting PII data in the EU","id":"1001","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"7","display_name":"Hosting PII data in the EU","radius":"200","description":"\u003cp\u003eIn a number of countries, we see government agencies seeking broad access to private, personally identifiable information (PII). The increased use of public cloud solutions makes it more difficult for organizations to protect the data entrusted to them by their users while also respecting all relevant laws. The European Union has some of the most progressive privacy laws, and all the major cloud providers—Amazon, Google and Microsoft—offer multiple data centers and regions within the European Union. Therefore, we recommend that companies, especially those with a global user base, assess the feasibility of a safe haven for their users\u0027 data by \u003cstrong\u003ehosting PII data in the EU\u003c/strong\u003e. Since we wrote about this technique in the last Radar, we have rolled out a new internal system that handles sensitive information relating to all our employees, and we have chosen to host it in a data center located in the European Union.\u003c/p\u003e","theta":"135","volume":"2016-11"},{"name":"Lightweight Architecture Decision Records","id":"1034","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"8","display_name":"Lightweight Architecture Decision Records","radius":"220","description":"\u003cp\u003eAlthough much documentation can be replaced with highly readable code and tests, in a world of \u003ca href\u003d\"/radar/techniques/evolutionary-architecture\"\u003eevolutionary architecture\u003c/a\u003e it\u0027s important to record certain design decisions for the benefit of future team members and for external oversight. \u003cstrong\u003eLightweight Architecture Decision Records\u003c/strong\u003e is \u003ca href\u003d\"http://thinkrelevance.com/blog/2011/11/15/documenting-architecture-decisions\"\u003ea technique\u003c/a\u003e for capturing important architectural decisions along with their context and consequences. Although these items are often stored in a wiki or collaboration tool, we generally prefer \u003ca href\u003d\"https://github.com/npryce/adr-tools\"\u003estoring them in source control\u003c/a\u003e with simple markup.\u003c/p\u003e","theta":"124","volume":"2016-11"},{"name":"Reactive architectures","id":"836","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"9","display_name":"Reactive architectures","radius":"170","description":"\u003cp\u003eWe see continued adoption and success of \u003cstrong\u003ereactive architectures\u003c/strong\u003e , with reactive language extensions and reactive frameworks being very popular (we added several such blips in this edition of the Radar). User interfaces, in particular, benefit greatly from a reactive style of programming. Our caveats last time still hold true: Architectures based on asynchronous message passing introduce complexity and make the overall system harder to understand—it\u0027s no longer possible to simply read the program code and understand what the system does. We recommend assessing the performance and scalability needs of your system before committing to this architectural style.\u003c/p\u003e","theta":"113","volume":"2016-11"},{"name":"Serverless architecture","id":"999","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"10","display_name":"Serverless architecture","radius":"200","description":"\u003cp\u003e\u003ca href\u003d\"http://www.martinfowler.com/articles/serverless.html\"\u003e\u003cstrong\u003eServerless architecture\u003c/strong\u003e\u003c/a\u003e is an approach that replaces long-running virtual machines with ephemeral compute power that comes into existence on request and disappears immediately after use. Since the last Radar, we have had several teams put applications into production using a \"serverless\" style. Our teams like the approach, it’s working well for them and we consider it a valid architectural choice. Note that serverless doesn’t have to be an all-or-nothing approach: some of our teams have deployed a new chunk of their systems using serverless while sticking to a traditional architectural approach for other pieces.\u003c/p\u003e","theta":"102","volume":"2016-11"},{"name":"Client-directed query","id":"1039","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"11","display_name":"Client-directed query","radius":"300","description":"\u003cp\u003eAlthough many problems that people encounter with RESTful approaches to APIs can be attributed to the \u003ca href\u003d\"/radar/techniques/anemic-rest\"\u003eanemic REST\u003c/a\u003e antipattern, some use cases warrant exploration of other approaches. In particular, organizations that have to support a long tail of client applications (and thus a likely proliferation of API versions even if they employ \u003ca href\u003d\"/radar/techniques/consumer-driven-contract-testing\"\u003econsumer-driven contracts\u003c/a\u003e)—and have a large portion of their APIs supporting the endless-list style of activity feeds—may hit some limits in RESTful architectures. These can sometimes be mitigated by employing the \u003cstrong\u003eclient-directed query\u003c/strong\u003e approach to client-server interaction. We see this approach being successfully used in both \u003ca href\u003d\"/radar/languages-and-frameworks/graphql\"\u003eGraphQL\u003c/a\u003e and \u003ca href\u003d\"https://github.com/Netflix/falcor\"\u003eFalcor\u003c/a\u003e, where clients have more control over both the contents and the granularity of the data returned to them. This does put more responsibility onto the service layer and can still lead to tight coupling to the underlying data model, but the benefits may be worth exploring if well-modeled RESTful APIs aren’t working for you.\u003c/p\u003e","theta":"170","volume":"2016-11"},{"name":"Container security scanning","id":"1041","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"12","display_name":"Container security scanning","radius":"290","description":"\u003cp\u003eThe container revolution instigated by \u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e has massively reduced the friction in moving applications between environments but at the same time has blown a rather large hole in the traditional controls over what can go to production. The technique of \u003cstrong\u003econtainer security scanning\u003c/strong\u003e is a necessary response to this threat vector. Docker now provides its own \u003ca href\u003d\"https://blog.docker.com/2016/05/docker-security-scanning/\"\u003esecurity scanning tools\u003c/a\u003e, as does \u003ca href\u003d\"https://coreos.com/blog/vulnerability-analysis-for-containers/\"\u003eCoreOS\u003c/a\u003e, and we’ve also had success with the \u003ca href\u003d\"https://benchmarks.cisecurity.org/\"\u003eCIS Security Benchmarks\u003c/a\u003e. Whichever approach you take, we believe the topic of automated container security validation is of high value and a necessary part of PaaS thinking.\u003c/p\u003e","theta":"160","volume":"2016-11"},{"name":"Content Security Policies","id":"997","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"13","display_name":"Content Security Policies","radius":"340","description":"\u003cp\u003eWe are finding \u003ca href\u003d\"https://en.wikipedia.org/wiki/Content_Security_Policy\"\u003e\u003cstrong\u003eContent Security Policies\u003c/strong\u003e\u003c/a\u003e to be a helpful addition to our security toolkit when dealing with websites that pull assets from mixed contexts. The policy defines a set of rules about where assets can come from (and whether to allow inline script tags). The browser then refuses to load or execute JavaScript, CSS or images that violate those rules. When used in conjunction with good practices, such as output encoding, it provides good mitigation for XSS attacks. Interestingly, the optional endpoint for posting JSON reports of violations is how Twitter discovered that ISPs were injecting HTML or JavaScript into their pages.\u003c/p\u003e","theta":"150","volume":"2016-11"},{"name":"Differential privacy","id":"1040","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"14","display_name":"Differential privacy","radius":"335","description":"\u003cp\u003eIt has long been known that \"anonymized\" bulk data sets can reveal information about individuals, especially when multiple data sets are cross-referenced together. With \u003ca href\u003d\"https://www.washingtonpost.com/news/the-switch/wp/2016/05/13/new-government-data-shows-a-staggering-number-of-americans-have-stopped-basic-online-activities/\"\u003eincreasing concern over personal privacy\u003c/a\u003e, some companies—including \u003ca href\u003d\"https://www.wired.com/2016/06/apples-differential-privacy-collecting-data/\"\u003eApple\u003c/a\u003e and \u003ca href\u003d\"http://research.google.com/pubs/pub42852.html\"\u003eGoogle\u003c/a\u003e—are turning to \u003cstrong\u003edifferential privacy\u003c/strong\u003e techniques in order to improve individual privacy while retaining the ability to perform useful analytics on large numbers of users. Differential privacy is a cryptographic technique that attempts to maximize the accuracy of statistical queries from a database while minimizing the chances of identifying its records. These results can be achieved by introducing a low amount of \"noise\" to the data, but it’s important to note that this is an ongoing research area. Apple has announced plans to incorporate differential privacy into its products—and we wholeheartedly applaud its commitment to customers\u0027 privacy—but the usual Apple secrecy has left some security experts \u003ca href\u003d\"https://blog.cryptographyengineering.com/2016/06/15/what-is-differential-privacy/\"\u003escratching their heads\u003c/a\u003e. We continue to recommend \u003ca href\u003d\"http://martinfowler.com/bliki/Datensparsamkeit.html\"\u003eDatensparsamkeit\u003c/a\u003e as an alternative approach: simply storing the minimum data you actually need will achieve better privacy results in most cases.\u003c/p\u003e","theta":"140","volume":"2016-11"},{"name":"Micro frontends","id":"1035","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"15","display_name":"Micro frontends","radius":"310","description":"\u003cp\u003eWe\u0027ve seen significant benefit from introducing \u003ca href\u003d\"/radar/techniques/microservices\"\u003emicroservice architectures\u003c/a\u003e, which have allowed teams to scale delivery of independently deployed and maintained services. However, teams have often struggled to avoid the creation of front-end monoliths—large and sprawling browser applications that are as difficult to maintain and evolve as the monolithic server-side applications we\u0027ve abandoned. We\u0027re seeing an approach emerge that our teams call \u003cstrong\u003emicro frontends\u003c/strong\u003e. In this approach, a web application is broken up by its pages and features, with each feature being owned end-to-end by a single team. Multiple techniques exist to bring the application features—some old and some new—together as a cohesive user experience, but the goal remains to allow each feature to be developed, tested and deployed independently from others. The \u003ca href\u003d\"/radar/techniques/bff-backend-for-frontends\"\u003eBFF - backend for frontends\u003c/a\u003e approach works well here, with each team developing a BFF to support its set of application features.\u003c/p\u003e","theta":"130","volume":"2016-11"},{"name":"OWASP ASVS","id":"996","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"16","display_name":"OWASP ASVS","radius":"290","description":"\u003cp\u003eAs more development teams incorporate security earlier in the development life cycle, figuring out requirements to limit security risks can seem like a daunting task. Few people have the extensive technical knowledge needed to identify all the risks that an application might face, and teams might struggle just trying to decide where to begin. Relying on frameworks such as OWASP\u0027s \u003ca href\u003d\"https://www.owasp.org/index.php/Category:OWASP_Application_Security_Verification_Standard_Project\"\u003e\u003cstrong\u003eASVS\u003c/strong\u003e\u003c/a\u003e (Application Security Verification Standard) can help make this easier. Although somewhat lengthy, it contains a thorough list of requirements categorized by functions such as authentication, access control, and error handling and logging, which can be reviewed as needed. It is also helpful as a resource for testers when it comes time to verify software.\u003c/p\u003e","theta":"120","volume":"2016-11"},{"name":"Unikernels","id":"995","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"17","display_name":"Unikernels","radius":"330","description":"\u003cp\u003eWith the continued rise to domination of the container model led by Docker adoption, we think it\u0027s worth calling attention to the continued rapid development in the \u003cstrong\u003eUnikernel\u003c/strong\u003e space. Unikernels are single-purpose library operating systems that can be compiled down from high-level languages to run directly on the hypervisors used by commodity cloud platforms. They promise a number of advantages over containers, not least their superfast startup time and very small attack surface area. Many are still at the research-project phase—\u003ca href\u003d\"http://research.microsoft.com/en-us/projects/drawbridge/\"\u003eDrawbridge\u003c/a\u003e from Microsoft Research, \u003ca href\u003d\"https://mirage.io/\"\u003eMirageOS\u003c/a\u003e and \u003ca href\u003d\"http://galois.com/project/halvm/\"\u003eHaLVM\u003c/a\u003e amongst others—but we think the ideas are very interesting and combine nicely with the technique of \u003ca href\u003d\"/radar/techniques/serverless-architecture\"\u003eserverless architecture\u003c/a\u003e.\u003c/p\u003e","theta":"110","volume":"2016-11"},{"name":"VR beyond gaming","id":"1000","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"18","display_name":"VR beyond gaming","radius":"330","description":"\u003cp\u003eThe idea of virtual reality has been around for more than 50 years, and with successive improvements of computing technology many ideas have been hyped and explored. We believe that we\u0027re reaching a tipping point now. Modern graphics cards provide sufficient compute power to render detailed, realistic scenes in high resolutions, and at the same time at least two consumer-oriented VR headsets (the \u003ca href\u003d\"http://www.htcvive.com/uk/\"\u003eHTC Vive\u003c/a\u003e and Facebook\u0027s \u003ca href\u003d\"https://www.oculus.com/en-us/\"\u003eOculus Rift\u003c/a\u003e) are coming to market. These headsets are affordable, they have high-resolution displays, and they eliminate perceivable motion-tracking lag, which was causing issues such as headaches and nausea before. The headsets are mainly targeted at enthusiast video gaming, but we are convinced that they will open many possibilities for \u003cstrong\u003eVR beyond gaming\u003c/strong\u003e , particularly as the low-fi approaches, such as \u003ca href\u003d\"https://www.google.co.uk/get/cardboard/get-cardboard/\"\u003eGoogle Cardboard\u003c/a\u003e, are driving greater awareness.\u003c/p\u003e","theta":"100","volume":"2016-11"},{"name":"A single CI instance for all teams","id":"1004","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"19","display_name":"A single CI instance for all teams","radius":"380","description":"\u003cp\u003eThere might be the impression that it\u0027s easier to manage a \u003cstrong\u003esingle CI (Continuous Integration) instance for all teams\u003c/strong\u003e because it gives them a single configuration and monitoring point. But a bloated instance that is shared by every team in an organization can cause a lot of damage. We have found that problems like build timeouts, configuration conflicts and gigantic build queues appear more frequently. Having this single point of failure can interrupt the work of many teams. Carefully consider the trade-off between these pitfalls and having a single point of configuration. In organizations with multiple teams, we recommend having CI instances distributed by teams, with enterprise decisions based not on the single CI installation but on defining guidelines about the instances\u0027 selection and configuration.\u003c/p\u003e","theta":"162","volume":"2016-11"},{"name":"Anemic REST","id":"1045","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"20","display_name":"Anemic REST","radius":"375","description":"\u003cp\u003eWith the increasing popularity of the \u003ca href\u003d\"/radar/techniques/bff-backend-for-frontends\"\u003eBFF - Backend for frontends\u003c/a\u003e pattern and use of one-way data-binding frameworks like \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e, we’ve noticed a backlash against REST-style architectures. Critics accuse REST of causing chatty, inefficient interactions among systems and failing to adapt as client needs evolve. They offer frameworks such as \u003ca href\u003d\"/radar/languages-and-frameworks/graphql\"\u003eGraphQL\u003c/a\u003e or \u003ca href\u003d\"https://netflix.github.io/falcor/\"\u003eFalcor\u003c/a\u003e as alternative data-fetch mechanisms that let the client specify the format of the data returned. But in our experience, it isn’t REST that causes these problems. Rather, they stem from a failure to properly model the domain as a set of resources. Naively developing services that simply expose static, hierarchical data models via templated URLs result in an \u003cstrong\u003eanemic REST\u003c/strong\u003e implementation. In a richly modeled domain, REST should enable more than simple repetitive data fetching. In a fully evolved RESTful architecture, business events and abstract concepts are also modeled as resources, and the implementation should make effective use of hypertext, link relations and media types to maximize decoupling between services. This antipattern is closely related to the \u003ca href\u003d\"http://www.martinfowler.com/bliki/AnemicDomainModel.html\"\u003eAnemic Domain Model\u003c/a\u003e pattern and results in services that rank low in \u003ca href\u003d\"http://martinfowler.com/articles/richardsonMaturityModel.html\"\u003eRichardson Maturity Model\u003c/a\u003e. We have more advice for designing effective REST APIs in our \u003ca href\u003d\"https://www.thoughtworks.com/insights/blog/rest-api-design-resource-modeling\"\u003eInsights article\u003c/a\u003e.\u003c/p\u003e","theta":"144","volume":"2016-11"},{"name":"Big Data envy","id":"1003","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"21","display_name":"Big Data envy","radius":"360","description":"\u003cp\u003eWe continue to see organizations chasing \"cool\" technologies, taking on unnecessary complexity and risk when a simpler choice would be better. One particular theme is using distributed, Big Data systems for relatively small data sets. This behavior prompts us to put \u003cstrong\u003eBig Data envy\u003c/strong\u003e on hold once more, with some additional data points from our recent experience. The \u003ca href\u003d\"http://cassandra.apache.org/\"\u003eApache Cassandra\u003c/a\u003e database promises massive scalability on commodity hardware, but we have seen teams overwhelmed by its architectural and operational complexity. Unless you have data volumes that require a 100+ node cluster, we recommend against using Cassandra. The operational team you’ll need to keep the thing running just isn’t worth it. While creating this edition of the Radar, we discussed several new database technologies, many offering \"10x\" performance improvements over existing systems. We’re always skeptical until new technology—especially something as critical as a database—has been properly proven. \u003ca href\u003d\"/radar/tools/jepsen\"\u003eJepsen\u003c/a\u003e provides \u003ca href\u003d\"http://jepsen.io/analyses.html\"\u003eanalysis\u003c/a\u003e of database performance under difficult conditions and has found \u003ca href\u003d\"https://aphyr.com/posts/283-call-me-maybe-redis\"\u003enumerous\u003c/a\u003e \u003ca href\u003d\"https://aphyr.com/posts/284-call-me-maybe-mongodb\"\u003ebugs\u003c/a\u003e in various NoSQL databases. We recommend maintaining a healthy dose of skepticism and keeping an eye on sites such as Jepsen when you evaluate database tech.\u003c/p\u003e","theta":"126","volume":"2016-11"},{"name":"Cloud lift and shift","id":"702","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"22","display_name":"Cloud lift and shift","radius":"375","description":"\u003cp\u003eAs more organizations are choosing to deploy applications in the cloud, we\u0027re regularly finding IT groups that are wastefully trying to replicate their existing data center management and security approaches in the cloud. This often comes in the form of firewalls, load balancers, network proxies, access control, security appliances and services that are extended into the cloud with minimal rethinking. We\u0027ve seen organizations build their own orchestration APIs in front of the cloud providers to constrain the services that can be utilized by teams. In most cases these layers serve only to cripple the capability, taking away most of the intended benefits of moving to the cloud. In this edition of the Radar, we\u0027ve chosen to rehighlight \u003cstrong\u003ecloud lift and shift\u003c/strong\u003e as a technique to avoid. Organizations should instead look more deeply at the intent of their existing security and operational controls, and look for alternative controls that work in the cloud without creating unnecessary constraints. Many of those controls will already exist for mature cloud providers, and teams that adopt the cloud can use native APIs for self-serve provisioning and operations.\u003c/p\u003e","theta":"108","volume":"2016-11"},{"name":"Docker","id":"714","quadrant":"Platforms","ring":"Adopt","movement":"c","radarId":"23","display_name":"Docker","radius":"125","description":"\u003cp\u003eWe remain excited about \u003ca href\u003d\"https://www.docker.com/\"\u003e\u003cstrong\u003eDocker\u003c/strong\u003e\u003c/a\u003e as it evolves from a tool to a complex platform of technologies. Development teams love Docker, as the Docker image format makes it easier to achieve parity between development and production, making for reliable deployments. It is a natural fit in a microservices-style application as a packaging mechanism for self-contained services. On the operational front, Docker support in monitoring tools (\u003ca href\u003d\"/radar/tools/sensu\"\u003eSensu\u003c/a\u003e, \u003ca href\u003d\"/radar/tools/prometheus\"\u003ePrometheus\u003c/a\u003e, \u003ca href\u003d\"https://github.com/google/cadvisor\"\u003ecAdvisor\u003c/a\u003e, etc.), orchestration tools (\u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e, \u003ca href\u003d\"https://mesosphere.github.io/marathon/\"\u003eMarathon\u003c/a\u003e, etc.) and deployment-automation tools reflect the growing maturity of the platform and its readiness for production use. A word of caution, though: There is a prevalent view of Docker and Linux containers in general as being \"lightweight virtualization,\" but we would not recommend using Docker as a secure process-isolation mechanism, though we are paying attention to the introduction of user namespaces and seccomp profiles in version 1.10 in this regard.\u003c/p\u003e","theta":"202","volume":"2016-11"},{"name":"HSTS","id":"885","quadrant":"Platforms","ring":"Adopt","movement":"t","radarId":"24","display_name":"HSTS","radius":"120","description":"\u003cp\u003e\u003ca href\u003d\"https://www.owasp.org/index.php/HTTP_Strict_Transport_Security\"\u003eHTTP Strict Transport Security\u003c/a\u003e ( \u003cstrong\u003eHSTS\u003c/strong\u003e ) is a now widely supported policy that allows websites to protect themselves from downgrade attacks. A downgrade attack in the context of HTTPS is one that can cause users of your site to fall back to HTTP rather than HTTPS, allowing for further attacks such as man-in-the-middle attacks. With HSTS, the server sends a header that informs the browser that it should only use HTTPS to access the website. Browser support is now widespread enough that this easy-to-implement feature should be added to any site using HTTPS. Mozilla’s \u003ca href\u003d\"https://observatory.mozilla.org/\"\u003eObservatory\u003c/a\u003e can help identify this and other useful headers and configuration options that improve security and privacy. When implementing HSTS, it is critical to verify that all resources load properly over HTTPS, because once HSTS is turned on, there is (almost) no turning back until the expiry time. The directive to include subdomains should be added but, again, a thorough verification that all subdomains support secure transport is required.\u003c/p\u003e","theta":"225","volume":"2016-11"},{"name":"Linux security modules","id":"795","quadrant":"Platforms","ring":"Adopt","movement":"t","radarId":"25","display_name":"Linux security modules","radius":"100","description":"\u003cp\u003e\u003ca href\u003d\"http://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-167.pdf\"\u003eApplication whitelisting\u003c/a\u003e has proven to be \u003ca href\u003d\"http://www.asd.gov.au/infosec/top-mitigations/top-4-strategies-explained.htm#mitigation1\"\u003eone of the most effective ways to mitigate cyber intrusion attacks\u003c/a\u003e. A convenient way to implement this widely recommended practice is through \u003cstrong\u003eLinux security modules\u003c/strong\u003e. With SELinux or AppArmor included by default in most Linux distributions, and with more comprehensive tools such as Grsecurity readily available, we have moved this technology into the Adopt ring in this edition. These tools help teams assess questions about who has access to what resources on shared hosts, including contained services. This conservative approach to access management will help teams build security into their SDLC processes.\u003c/p\u003e","theta":"247","volume":"2016-11"},{"name":"Apache Kafka","id":"850","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"26","display_name":"Apache Kafka","radius":"200","description":"\u003cp\u003eMany organizations are now looking closely at new data architectures that capture information as immutable sequences of events at scale. \u003ca href\u003d\"http://kafka.apache.org/\"\u003e\u003cstrong\u003eApache Kafka\u003c/strong\u003e\u003c/a\u003e continues to build momentum as an open source messaging framework that provides a solution for publishing ordered event feeds to large numbers of independent, lightweight consumers. Configuring Kafka is nontrivial, but our teams are reporting positive experiences with the framework.\u003c/p\u003e","theta":"189","volume":"2016-11"},{"name":"Apache Mesos","id":"796","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"27","display_name":"Apache Mesos","radius":"210","description":"\u003cp\u003eWe\u0027ve continued to have positive experiences deploying the \u003cstrong\u003e\u003ca href\u003d\"http://mesos.apache.org/\"\u003eApache Mesos\u003c/a\u003e\u003c/strong\u003e platform to manage cluster resources for highly distributed systems. Mesos abstracts out underlying computing resources such as CPU and storage, aiming to provide efficient utilization while maintaining isolation. Mesos includes \u003ca href\u003d\"https://mesos.github.io/chronos/\"\u003eChronos\u003c/a\u003e for distributed and fault-tolerant execution of scheduled jobs, and \u003ca href\u003d\"https://mesosphere.github.io/marathon/\"\u003eMarathon\u003c/a\u003e for orchestrating long-running processes in containers.\u003c/p\u003e","theta":"198","volume":"2016-11"},{"name":"Auth0","id":"1006","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"28","display_name":"Auth0","radius":"250","description":"\u003cp\u003eWe have a growing belief that for most scenarios it is rarely worth rolling your own authentication code. Outsourced identity management speeds up delivery, reduces mistakes and tends to enable a faster response to newly discovered vulnerabilities. \u003cstrong\u003e\u003ca href\u003d\"https://auth0.com/\"\u003eAuth0\u003c/a\u003e\u003c/strong\u003e has particularly impressed us in this field for its ease of integration, range of protocols and connectors supported, and rich management API.\u003c/p\u003e","theta":"207","volume":"2016-11"},{"name":"AWS Lambda","id":"919","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"29","display_name":"AWS Lambda","radius":"215","description":"\u003cp\u003eOur teams continue to enjoy using \u003cstrong\u003e\u003ca href\u003d\"https://aws.amazon.com/lambda/\"\u003eAWS Lambda\u003c/a\u003e\u003c/strong\u003e and are beginning to use it to experiment with \u003ca href\u003d\"/radar/techniques/serverless-architecture\"\u003eserverless architectures\u003c/a\u003e, combining Lambda with the \u003ca href\u003d\"/radar/platforms/amazon-api-gateway\"\u003eAPI Gateway\u003c/a\u003e. We do recommend that Lambda functions contain only a moderate amount of code. Ensuring the quality of a solution based on a tangle of many large Lambda functions is difficult, and such a solution may not be cost-effective. For more complex needs, deployments based on containers or VMs are still preferable. In addition, we have run into significant problems using Java for Lambda functions, with erratic latencies up to several seconds as the Lambda container is started. Of course, you can sidestep this issue by using JavaScript or Python, and if Lambda functions do not contain a lot of code, the choice of programming language should not matter too much.\u003c/p\u003e","theta":"216","volume":"2016-11"},{"name":"Kubernetes","id":"925","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"30","display_name":"Kubernetes","radius":"220","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://kubernetes.io/\"\u003eKubernetes\u003c/a\u003e\u003c/strong\u003e is Google\u0027s answer to the problem of deploying containers into a cluster of machines, which is becoming an increasingly common scenario. It is not the solution used by Google internally but an open source project that originated at Google and has seen a fair number of external contributions. Since we mentioned Kubernetes on the previous Radar, our initial positive impressions have been confirmed, and we are seeing successful use of Kubernetes in production at our clients.\u003c/p\u003e","theta":"225","volume":"2016-11"},{"name":"Pivotal Cloud Foundry","id":"977","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"31","display_name":"Pivotal Cloud Foundry","radius":"220","description":"\u003cp\u003eThe PaaS space has seen a lot of movement since we last mentioned \u003ca href\u003d\"/radar/platforms/cloud-foundry\"\u003eCloud Foundry\u003c/a\u003e in 2012. While there are various distributions of the open source core, we have been impressed by the offering and ecosystem assembled as \u003ca href\u003d\"http://pivotal.io/platform\"\u003e\u003cstrong\u003ePivotal Cloud Foundry\u003c/strong\u003e\u003c/a\u003e. While we expect continued convergence between the unstructured approach (\u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e, \u003ca href\u003d\"/radar/platforms/apache-mesos\"\u003eMesos\u003c/a\u003e, \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e, etc.) and the more structured and opinionated buildpack style offered by Cloud Foundry and others, we see real benefit for organizations that are willing to accept the constraints and rate of evolution to adopt a PaaS. Of particular interest is the speed of development that comes from the simplification and standardization of the interaction between development teams and platform operations.\u003c/p\u003e","theta":"234","volume":"2016-11"},{"name":"Rancher","id":"927","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"32","display_name":"Rancher","radius":"250","description":"\u003cp\u003eThe emerging Containers as a Service (CaaS) space is seeing a lot of movement and provides a useful option between basic IaaS (Infrastructure as a Service) and more opinionated PaaS (Platform as a Service). While \u003ca href\u003d\"http://rancher.com/\"\u003e\u003cstrong\u003eRancher\u003c/strong\u003e\u003c/a\u003e creates less noise than some other players, we have enjoyed the simplicity that it brings to running \u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e containers in production. It can run stand-alone as a full solution or in conjunction with tools like \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e.\u003c/p\u003e","theta":"243","volume":"2016-11"},{"name":"Realm","id":"979","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"33","display_name":"Realm","radius":"240","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://realm.io/\"\u003eRealm\u003c/a\u003e\u003c/strong\u003e is a database designed for use on mobile devices, with its own persistence engine to achieve high performance. Realm is marketed as a replacement for SQLite and Core Data. Note that migrations are not quite as straightforward as the Realm documentation would have you believe. However, more and more teams are choosing Realm as the persistence mechanism in production environments for mobile applications.\u003c/p\u003e","theta":"252","volume":"2016-11"},{"name":"Unity beyond gaming","id":"1061","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"34","display_name":"Unity beyond gaming","radius":"180","description":"\u003cp\u003eAfter experiencing years of growth as a platform for game development, \u003cstrong\u003e\u003ca href\u003d\"https://unity3d.com/\"\u003eUnity\u003c/a\u003e\u003c/strong\u003e has recently become the platform of choice for VR and AR application development. Whether you’re creating a fully immersive world for the Oculus or HTC Vive headsets, a holographic layer for your newly spatial enterprise application or an AR feature set for your mobile app, Unity likely provides what you need to both prototype it and get it ready for prime time. Many of us at ThoughtWorks believe that VR and AR represent the next significant shift in the computing platform, and for now, Unity is the single most important tool in the toolbox we use to develop for this change. We’ve used Unity to develop all our VR prototypes, as well as AR functionality for headsets and phone/tablet applications.\u003c/p\u003e","theta":"261","volume":"2016-11"},{"name":".NET Core","id":"866","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"35","display_name":".NET Core","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.microsoft.com/net/core\"\u003e.NET Core\u003c/a\u003e\u003c/strong\u003e is an open source modular product for creating applications that can be easily deployed in Windows, macOS and Linux. .NET Core makes it possible to build cross-platform web applications using \u003ca href\u003d\"http://www.asp.net/core\"\u003eASP.NET Core\u003c/a\u003e with a set of tools, libraries and frameworks—another choice for microservices architecture. The community around .NET Core and other related projects has been growing. New tools have appeared and evolved quickly, such as \u003ca href\u003d\"/radar/tools/visual-studio-code\"\u003eVisual Studio Code\u003c/a\u003e. There are \u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e \u003ca href\u003d\"https://www.microsoft.com/net/core#docker\"\u003eimages\u003c/a\u003e based on both Linux and Windows (\u003ca href\u003d\"/radar/platforms/microsoft-nano-server\"\u003eNano Server\u003c/a\u003e) with .NET Core that simplify applying a microservice architecture. CoreCLR and CoreFX appeared in the Radar in the past. However, a few months ago Microsoft \u003ca href\u003d\"https://blogs.msdn.microsoft.com/dotnet/2016/06/27/announcing-net-core-1-0\"\u003eannounced\u003c/a\u003e the release of .NET Core 1.0, the first stable version. We see good new opportunities, changes and a vibrant community as reasons to keep assessing this product.\u003c/p\u003e","theta":"185","volume":"2016-11"},{"name":"Amazon API Gateway","id":"989","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"36","display_name":"Amazon API Gateway","radius":"315","description":"\u003cp\u003e\u003ca href\u003d\"https://aws.amazon.com/api-gateway/\"\u003e\u003cstrong\u003eAmazon API Gateway\u003c/strong\u003e\u003c/a\u003e is Amazon\u0027s offering enabling developers to expose API services to Internet clients. It offers the usual API gateway features like traffic management, monitoring, authentication and authorization. Our teams have been using this service to front other AWS capabilities like AWS Lambda as part of \u003ca href\u003d\"/radar/techniques/serverless-architecture\"\u003eserverless architectures\u003c/a\u003e. We continue to monitor for the challenges presented by \u003ca href\u003d\"/radar/platforms/overambitious-api-gateways\"\u003eoverambitious API gateways\u003c/a\u003e, but at this stage Amazon\u0027s offering appears to be lightweight enough to avoid those problems.\u003c/p\u003e","theta":"191","volume":"2016-11"},{"name":"Apache Flink","id":"972","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"37","display_name":"Apache Flink","radius":"300","description":"\u003cp\u003eInterest continues to build for \u003cstrong\u003e\u003ca href\u003d\"https://flink.apache.org/\"\u003eApache Flink\u003c/a\u003e\u003c/strong\u003e, a new-generation platform for scalable distributed batch and stream processing. At the core of Apache Flink is a streaming data-flow engine, with support for tabular (SQL-like), graph-processing and machine learning operations. Apache Flink stands out with feature rich capabilities for stream processing: event time, rich streaming window operations, fault tolerance and exactly-once semantics. The project shows significant ongoing activity, with the latest release (1.1) introducing new datasource/sink integrations as well as improved streaming features.\u003c/p\u003e","theta":"196","volume":"2016-11"},{"name":"AWS Application Load Balancer","id":"1005","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"38","display_name":"AWS Application Load Balancer","radius":"290","description":"\u003cp\u003eAmazon recently launched the \u003ca href\u003d\"https://aws.amazon.com/blogs/aws/new-aws-application-load-balancer/\"\u003e\u003cstrong\u003eAWS Application Load Balancer\u003c/strong\u003e\u003c/a\u003e (ALB), a direct replacement for Elastic Load Balancers introduced back in 2009. ALB supports Layer 7 traffic inspection and is built to support modern cloud architecture. If you’re building a microservices-based system using \u003ca href\u003d\"/radar/platforms/aws-ecs\"\u003eECS\u003c/a\u003e, the new load balancers will directly understand container hosting and scaling, with multiple containers and ports per EC2 instance. Content-based routing allows segmentation of requests onto groups of target servers, along with independent scaling of those groups. Health checks performed by the load balancers are much improved, with the ability to capture detailed metrics about application performance. We like everything that we see here, and teams have begun to report successful usage of ALB.\u003c/p\u003e","theta":"202","volume":"2016-11"},{"name":"Cassandra carefully","id":"1011","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"39","display_name":"Cassandra carefully","radius":"285","description":"\u003cp\u003eApache’s \u003ca href\u003d\"http://cassandra.apache.org/\"\u003eCassandra\u003c/a\u003e database is a powerful, scalable Big Data solution for storing and processing large amounts of data, often using hundreds of nodes split over multiple worldwide locations. It’s a great tool and we like it, but too often we see teams run into trouble using it. We recommend using \u003cstrong\u003eCassandra carefully\u003c/strong\u003e. Teams often misunderstand the use case for Cassandra, attempting to use it as a general-purpose data store when in fact it is optimized for fast reads on large data sets based on predefined keys or indexes. Its dependence on the storage schema can also make it difficult to evolve over time. Cassandra also has significant operational complexity and some rough edges, so unless you absolutely need the scaling it provides, a simpler solution is usually better. If you don’t need Cassandra’s specific use-case and scaling characteristics, you might just be choosing it out of \u003ca href\u003d\"/radar/techniques/big-data-envy\"\u003eBig Data envy\u003c/a\u003e. Careful use of Cassandra will include extensive automated testing, and we’re happy to recommend \u003ca href\u003d\"https://github.com/jsevellec/cassandra-unit\"\u003eCassandraUnit\u003c/a\u003e as part of your testing strategy.\u003c/p\u003e","theta":"208","volume":"2016-11"},{"name":"Electron","id":"1012","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"40","display_name":"Electron","radius":"330","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://electron.atom.io/\"\u003eElectron\u003c/a\u003e\u003c/strong\u003e is a solid framework for building native desktop clients using web technologies such as HTML, CSS and JavaScript. Teams can leverage their web know-how to deliver polished cross-platform desktop clients without spending time learning another set of technologies.\u003c/p\u003e","theta":"213","volume":"2016-11"},{"name":"Ethereum","id":"1014","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"41","display_name":"Ethereum","radius":"338","description":"\u003cp\u003eThe hype seems to have peaked for blockchain and cryptocurrencies, as evidenced by the previous firehose-scale announcements in this area slowing to a trickle, and we expect some of the more speculative efforts to die out over time. One of the blockchains, \u003ca href\u003d\"https://www.ethereum.org/\"\u003e\u003cstrong\u003eEthereum\u003c/strong\u003e\u003c/a\u003e, is making good progress and is worth watching. Ethereum is a public blockchain with a built-in programming language that allows \"smart contracts\" to be built into it. These are algorithmic movements of \"ether\" (the Ethereum cryptocurrency) in response to activity happening on the blockchain. R3Cev, the consortium building blockchain tech for banks, built its first proofs of concept on Ethereum. Ethereum has been used to build a Distributed Autonomous Organization (DAO)—one of the first \"algorithmic corporations\"—although a recent heist of \u003ca href\u003d\"http://www.coindesk.com/dao-attacked-code-issue-leads-60-million-ether-theft/\"\u003e$150m worth of Ether\u003c/a\u003e demonstrates that the blockchain and cryptocurrencies are still the Wild West of the technology world.\u003c/p\u003e","theta":"219","volume":"2016-11"},{"name":"HoloLens","id":"1016","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"42","display_name":"HoloLens","radius":"330","description":"\u003cp\u003eIn the \u003cstrong\u003e\u003ca href\u003d\"https://www.microsoft.com/microsoft-hololens/en-us\"\u003eHoloLens\u003c/a\u003e\u003c/strong\u003e, Microsoft has delivered the first truly usable AR headset. Not only is it a beautiful piece of industrial design and an eminently comfortable device to wear, but it also clearly demonstrates the promise of AR for the enterprise via its gorgeous optics and deep Windows 10 integration. We expect HoloLens to be the first AR platform on which we deliver substantial application functionality to our clients in the near term, and we look forward to its evolution as it gains broader traction.\u003c/p\u003e","theta":"225","volume":"2016-11"},{"name":"IndiaStack","id":"1010","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"43","display_name":"IndiaStack","radius":"338","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://www.indiastack.org\"\u003eIndiaStack\u003c/a\u003e\u003c/strong\u003e is a set of Open APIs designed with the goal of transforming India from a data-poor to a data-rich country. The stack emphasizes layered innovation by specifying a minimal set of APIs and encourages the rest of the ecosystem to build custom applications on top of these APIs. \u003ca href\u003d\"http://www.indiastack.org/Resource#Aadhaar\"\u003eAadhaar\u003c/a\u003e serves as one of the foundation layers, providing authentication services for more than a billion Indian citizens. In addition, there are services to provide paperless transactions through digital signatures (eSign), unified online payment (UPI) and an electronic consent layer ((e-KYC)[https://uidai.gov.in/ecosystem/authentication-devices-documents/about-aadhaar-paperless-offline-e-kyc.html]) to securely provide Aadhaar details to service providers. We believe in the Open API–driven initiative to bring digital innovation, and the design principles behind IndiaStack could be used as a change agent for other regions/countries.\u003c/p\u003e","theta":"230","volume":"2016-11"},{"name":"Nomad","id":"983","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"44","display_name":"Nomad","radius":"300","description":"\u003cp\u003eHashiCorp continues to turn out interesting software. The latest to catch our attention is \u003ca href\u003d\"https://www.nomadproject.io/\"\u003e\u003cstrong\u003eNomad\u003c/strong\u003e\u003c/a\u003e, which is competing in the ever-more-populated scheduler arena. Major selling points include not just being limited to containerized workloads, and operating in multi–data center / multiregion deployments.\u003c/p\u003e","theta":"236","volume":"2016-11"},{"name":"Nuance Mix","id":"1017","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"45","display_name":"Nuance Mix","radius":"338","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://developer.nuance.com/public/index.php?task\u003dmix\"\u003eNuance Mix\u003c/a\u003e\u003c/strong\u003e is a framework for natural language processing from the company that created the speech-to-text technology behind Dragon Speaking and the first roll-out of Siri. This framework supports the creation of grammars that allow for free-form user interaction via voice. The developer defines a domain-specific grammar that the framework can train itself to understand. The outcomes are responses to user input that identify the user\u0027s intents and interaction concepts. At first, it is limited to phrases close to the ones used to train it, but over time it can start to identify meaning from more divergent phrasing. Though it is still in beta, the accuracy from early exploration has been compelling, and the eventual product is one to watch for application forms that could benefit from hands-free user interaction—including mobile, IoT, AR, VR and interactive spaces.\u003c/p\u003e","theta":"241","volume":"2016-11"},{"name":"OpenVR","id":"1053","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"46","display_name":"OpenVR","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/ValveSoftware/openvr\"\u003eOpenVR\u003c/a\u003e\u003c/strong\u003e is the underlying SDK in making many of the VR head-mounted displays (HMDs) work with Unity and will likely keep growing in importance. Much of the VR work at ThoughtWorks was built on top of OpenVR, because it will run on any HMD, unlike the other SDKs. Though it is not open source, it is free via the license. The Oculus SDK is more restrictive in its licensing and only works on Oculus devices. \u003ca href\u003d\"https://osvr.github.io/\"\u003eOSVR\u003c/a\u003e, while truly open source, doesn\u0027t seem to have as much adoption yet. If you\u0027re going to develop a VR application and target as many devices as possible—and not use Unity or Unreal to develop them—OpenVR is the most concrete and pragmatic solution right now.\u003c/p\u003e","theta":"247","volume":"2016-11"},{"name":"Tarantool","id":"1009","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"47","display_name":"Tarantool","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://tarantool.org\"\u003eTarantool\u003c/a\u003e\u003c/strong\u003e is an open source \u003ca href\u003d\"/radar/tools/nosql\"\u003eNoSQL\u003c/a\u003e solution that combines database and cache into one entity and provides APIs for writing application logic in \u003ca href\u003d\"/radar/languages-and-frameworks/lua\"\u003eLua\u003c/a\u003e. Both in-memory and disk-based engines are supported, and users can create multiple indexes (HASH, TREE, RTREE, BITSET) based on their use cases. The data itself is stored in \u003ca href\u003d\"http://msgpack.org\"\u003eMessagePack\u003c/a\u003e format and uses the same protocol to communicate between clients and server. Tarantool supports write-ahead logs, transactions and asynchronous master-master replication. We are happy with the architectural decision of embracing single-writer policy and cooperative multitasking to handle concurrent connections.\u003c/p\u003e","theta":"253","volume":"2016-11"},{"name":"TensorFlow","id":"982","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"48","display_name":"TensorFlow","radius":"325","description":"\u003cp\u003eGoogle\u0027s \u003cstrong\u003e\u003ca href\u003d\"https://www.tensorflow.org/\"\u003eTensorFlow\u003c/a\u003e\u003c/strong\u003e is an open source machine-learning platform that can be used for everything from research through to production and will run on hardware from a mobile CPU all the way to a large GPU compute cluster. It\u0027s an important platform because it makes implementing deep-learning algorithms much more accessible and convenient. Despite the hype, though, TensorFlow isn\u0027t really anything new algorithmically: All of these techniques have been available in the public domain via academia for some time. It\u0027s also important to realize that most businesses are not yet doing even basic predictive analytics and that jumping to deep learning likely won\u0027t help make sense of most data sets. For those who do have the right problem and data set, however, TensorFlow is a useful toolkit.\u003c/p\u003e","theta":"258","volume":"2016-11"},{"name":"wit.ai","id":"1069","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"49","display_name":"wit.ai","radius":"335","description":"\u003cp\u003eHype surrounding machine intelligence has reached a crescendo, but as with Big Data, useful frameworks and tools are waiting to be discovered among all the hot air. One such tool is \u003ca href\u003d\"https://wit.ai/\"\u003e\u003cstrong\u003ewit.ai\u003c/strong\u003e\u003c/a\u003e, a SaaS platform that allows developers to create conversational interfaces using natural language processing (NLP). Wit works with either text or speech inputs, helps developers manage conversational intent and allows custom business logic to be implemented using JavaScript. The system is free for commercial and noncommercial use and encourages the creation of open applications. Be aware that you must agree to let Wit use your data in order to improve the service and for its own analysis, so read the \u003ca href\u003d\"https://wit.ai/terms\"\u003eterms and conditions\u003c/a\u003e carefully. Another contender in this space is the \u003ca href\u003d\"https://dev.botframework.com/\"\u003eMicrosoft Bot Framework\u003c/a\u003e, but it’s available only in limited preview form as of this writing. As with most things Microsoft, we expect the Bot Framework to evolve quickly, so it’s worth keeping an eye on.\u003c/p\u003e","theta":"264","volume":"2016-11"},{"name":"CMS as a platform","id":"696","quadrant":"Platforms","ring":"Hold","movement":"t","radarId":"50","display_name":"CMS as a platform","radius":"385","description":"\u003cp\u003eWe are seeing too many organizations run into trouble as they attempt to use their \u003cstrong\u003eCMS as a platform\u003c/strong\u003e for delivering large and complex digital applications. This is often driven by the vendor-fueled hope of bypassing unresponsive IT organizations and enabling the business to drag and drop changes directly to production. While we are very supportive of providing content producers with the right tools and workflows, for applications with complex business logic we tend to recommend treating your CMS as a component of your platform (often in a hybrid or headless mode) cooperating cleanly with other services, rather than attempting to implement all of your functionality in the CMS itself.\u003c/p\u003e","theta":"202","volume":"2016-11"},{"name":"Overambitious API gateways","id":"931","quadrant":"Platforms","ring":"Hold","movement":"t","radarId":"51","display_name":"Overambitious API gateways","radius":"375","description":"\u003cp\u003eOne of our regular complaints is about business smarts implemented in middleware, resulting in transport software with ambitions to run critical application logic. Vendors in the highly competitive API gateway market continue to add features that differentiate their products. This results in \u003cstrong\u003eoverambitious API gateway\u003c/strong\u003e products whose functionality—on top of what is essentially a reverse proxy—encourages designs that are difficult to test and deploy. API gateways can provide utility in dealing with some generic concerns—for example, authentication and rate-limiting—but any domain smarts such as data transformation or rule processing should live in applications or services where they can be controlled by product teams working closely with the domains they support.\u003c/p\u003e","theta":"225","volume":"2016-11"},{"name":"Superficial private cloud","id":"932","quadrant":"Platforms","ring":"Hold","movement":"c","radarId":"52","display_name":"Superficial private cloud","radius":"385","description":"\u003cp\u003eWe\u0027ve seen the indisputable productivity gains that come from deployment of applications and services into mature cloud providers. Much of that gain comes from the ability of teams to deploy and operate their own services with a high degree of autonomy and responsibility. We are now regularly coming across \u003cstrong\u003eSuperficial Private Cloud\u003c/strong\u003e offerings within organizations, where basic virtualization platforms are being given the “cloud” label. Often teams can self-provision a restricted set of fixed service types with limited access and little ability to customize the centrally governed “enterprise blueprints,” leading to kludge solutions. Deployment pace regularly remains constrained by manually provisioned infrastructure such as network, firewall and storage. We encourage organizations to more fully consider the costs of mandating the use of an inadequate private cloud offering.\u003c/p\u003e","theta":"247","volume":"2016-11"},{"name":"Babel","id":"1024","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"53","display_name":"Babel","radius":"120","description":"\u003cp\u003e\u003ca href\u003d\"http://babeljs.io/\"\u003e\u003cstrong\u003eBabel.js\u003c/strong\u003e\u003c/a\u003e has become the default compiler for writing next-generation JavaScript. Its ecosystem is really taking off, thanks to its restructured \u003ca href\u003d\"http://babeljs.io/docs/plugins/#presets\"\u003eplugin system\u003c/a\u003e. It allows developers to write \u003ca href\u003d\"/radar/languages-and-frameworks/es6\"\u003eES6\u003c/a\u003e (and even ES7) code that runs in the browser or in the server without sacrificing backward compatibility for older browsers, and with very little configuration. It has first-class support for different build-and-test systems, which makes integration with any current workflow simple. It is a great piece of software that has become the main driver of ES6 (and ES7) adoption and innovation.\u003c/p\u003e","theta":"72","volume":"2016-11"},{"name":"Consul","id":"732","quadrant":"Tools","ring":"Adopt","movement":"c","radarId":"54","display_name":"Consul","radius":"55","description":"\u003cp\u003eWe have moved \u003cstrong\u003e\u003ca href\u003d\"http://consul.io\"\u003eConsul\u003c/a\u003e\u003c/strong\u003e, the service-discovery tool supporting both DNS- and HTTP-based discovery mechanisms, into Adopt. It goes beyond other discovery tools by providing customizable health checks for registered services, ensuring that unhealthy instances are marked accordingly. More tools have emerged to work with Consul to make it even more powerful. \u003ca href\u003d\"https://github.com/hashicorp/consul-template\"\u003eConsul Template\u003c/a\u003e enables configuration files to be populated with information from Consul, making things like client-side load balancing using mod_proxy much easier. In the world of Docker, \u003ca href\u003d\"https://github.com/gliderlabs/registrator\"\u003eregistrator\u003c/a\u003e can automatically register Docker containers as they appear with Consul with extremely little effort, making it much easier to manage container-based setups. You should still think long and hard about whether you need a tool like this or whether something simpler will do, but if you decide you need service discovery, you won\u0027t go far wrong with Consul.\u003c/p\u003e","theta":"54","volume":"2016-11"},{"name":"Grafana","id":"1019","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"55","display_name":"Grafana","radius":"75","description":"\u003cp\u003eWhen combining modern techniques and architecture styles, such as \u003ca href\u003d\"/radar/techniques/microservices\"\u003emicroservices\u003c/a\u003e, \u003ca href\u003d\"/radar/techniques/devops\"\u003eDevOps\u003c/a\u003e and \u003ca href\u003d\"/radar/techniques/qa-in-production\"\u003eQA in production\u003c/a\u003e, development teams need increasingly sophisticated monitoring. Simply looking a graphs of disk usage and CPU utilization is not sufficient anymore, and many teams collect application and business-specific metrics using tools such a Graphite and Kibana. \u003cstrong\u003e\u003ca href\u003d\"http://grafana.org/\"\u003eGrafana\u003c/a\u003e\u003c/strong\u003e makes it easy to create useful and elegant dashboards for data from a number of sources. A particularly useful feature allows timescales of different graphs to be synchronized, which helps with spotting correlations in the underlying data. The templating system that is being added shows a lot promise and will likely make managing sets of similar services even easier. Based on its strengths, Grafana has become our default choice in this category.\u003c/p\u003e","theta":"36","volume":"2016-11"},{"name":"Packer","id":"760","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"56","display_name":"Packer","radius":"35","description":"\u003cp\u003eMachine images have become a staple of modern deployment pipelines, and there are a number of tools and techniques to create the images. Because of its comprehensive feature set and the positive experiences we\u0027ve had with it, we recommend \u003ca href\u003d\"http://packer.io\"\u003e\u003cstrong\u003ePacker\u003c/strong\u003e\u003c/a\u003e over the alternatives. We also recommend against trying to write custom scripts to do what Packer does out of the box.\u003c/p\u003e","theta":"18","volume":"2016-11"},{"name":"Espresso","id":"911","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"57","display_name":"Espresso","radius":"230","description":"\u003cp\u003eAt the top of the testing pyramid for Android application development, our teams are increasingly using \u003cstrong\u003e\u003ca href\u003d\"https://developer.android.com/training/testing/espresso\"\u003eEspresso\u003c/a\u003e\u003c/strong\u003e as the functional-testing tool. Its small-core API hides the messy implementation details and helps in writing concise tests, with faster and reliable test execution. With Espresso, you can run automated UI tests simulating user interactions within a single target app on both emulators and real devices across different Android versions.\u003c/p\u003e","theta":"85","volume":"2016-11"},{"name":"fastlane","id":"1018","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"58","display_name":"fastlane","radius":"170","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://fastlane.tools/\"\u003efastlane\u003c/a\u003e\u003c/strong\u003e is our go-to tool for automating most of the boring activities involved in getting iOS and Android mobile apps built, tested, documented and provisioned. Simple configuration, a range of tooling and multiple pipelines make this a key ingredient in doing \u003ca href\u003d\"/radar/techniques/continuous-delivery-cd\"\u003econtinuous delivery\u003c/a\u003e for mobile.\u003c/p\u003e","theta":"79","volume":"2016-11"},{"name":"Galen","id":"1068","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"59","display_name":"Galen","radius":"250","description":"\u003cp\u003eTesting that layout and styling of responsive websites is working as expected across various form factors can be a slow and often manual process. \u003cstrong\u003e\u003ca href\u003d\"http://galenframework.com/\"\u003eGalen\u003c/a\u003e\u003c/strong\u003e helps ease this problem by providing a simple language, running on top of \u003ca href\u003d\"http://www.seleniumhq.org/\"\u003eSelenium\u003c/a\u003e, that allows you to specify expectations for the appearance of your website in various screen sizes. Although Galen suffers from the typical brittleness and speed issues of any end-to-end testing approach, we have found benefit in the early feedback on design issues.\u003c/p\u003e","theta":"74","volume":"2016-11"},{"name":"HashiCorp Vault","id":"969","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"60","display_name":"HashiCorp Vault","radius":"160","description":"\u003cp\u003eHaving a way to securely manage secrets is increasingly becoming a huge project issue. The old practice of keeping secrets in a file or in environment variables is becoming hard to manage, especially in environments with multiple applications and large numbers of \u003ca href\u003d\"/radar/techniques/microservices\"\u003emicroservices\u003c/a\u003e. \u003ca href\u003d\"https://github.com/hashicorp/vault\"\u003e\u003cstrong\u003eHashiCorp Vault\u003c/strong\u003e\u003c/a\u003e addresses the problem by providing mechanisms for securely accessing secrets through a unified interface. It has served us well on a number of projects, and our teams liked how easy it was to integrate Vault with their services. Storing and updating secrets is a bit cumbersome, because it relies on a command-line tool and a fair amount of discipline from the team.\u003c/p\u003e","theta":"68","volume":"2016-11"},{"name":"JSONassert","id":"1027","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"61","display_name":"JSONassert","radius":"200","description":"\u003cp\u003eMore projects are emitting and consuming information formatted as JSON. Writing tests in Java for JSON can be laborious. \u003cstrong\u003e\u003ca href\u003d\"http://jsonassert.skyscreamer.org/\"\u003eJSONassert\u003c/a\u003e\u003c/strong\u003e is a small library to help write smaller tests dealing with JSON by simplifying assertions and providing better error messages.\u003c/p\u003e","theta":"62","volume":"2016-11"},{"name":"Let\u0027s Encrypt","id":"946","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"62","display_name":"Let\u0027s Encrypt","radius":"175","description":"\u003cp\u003e\u003ca href\u003d\"https://letsencrypt.org/\"\u003e\u003cstrong\u003eLet\u0027s Encrypt\u003c/strong\u003e\u003c/a\u003e first appeared on the Radar last edition, and since December 2015 this project has moved its beta status from private to public, meaning users will no longer be required to have an invitation in order to try it. Let\u0027s Encrypt grants access to a simpler mechanism to obtain and manage certificates for a larger set of users who are seeking a way to secure their websites. It also promotes a big step forward in terms of security and privacy. This trend has already begun within ThoughtWorks, and many of our projects now have certificates verified by Let\u0027s Encrypt.\u003c/p\u003e","theta":"57","volume":"2016-11"},{"name":"Load Impact","id":"905","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"63","display_name":"Load Impact","radius":"230","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://loadimpact.com/\"\u003eLoad Impact\u003c/a\u003e\u003c/strong\u003e is a SaaS load-testing tool that can generate highly realistic loads of up to 1.2 million concurrent users. Record and playback web interactions using a Chrome plugin simulate network connections for mobile or desktop users and generate load from up to 10 different locations around the world. While not the only on-demand load-testing tool we\u0027ve used—we also like \u003ca href\u003d\"https://blazemeter.com/\"\u003eBlazeMeter\u003c/a\u003e—our teams were very enthusiastic about Load Impact.\u003c/p\u003e","theta":"51","volume":"2016-11"},{"name":"OWASP Dependency-Check","id":"963","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"64","display_name":"OWASP Dependency-Check","radius":"180","description":"\u003cp\u003eIn a world full of libraries and tools that simplify the life of many software developers, deficiencies in their security have become visible and have increased the vulnerability surface in the applications that use them. \u003ca href\u003d\"https://www.owasp.org/index.php/OWASP_Dependency_Check\"\u003e\u003cstrong\u003eOWASP Dependency-Check\u003c/strong\u003e\u003c/a\u003e automatically identifies potential security problems in the code, checking if there are any known publicly disclosed vulnerabilities, then using methods to constantly update the database of public vulnerabilities. Dependency-Check has some interfaces and plugins to automate this verification in Java and .NET (which we have used successfully) as well as Ruby, Node.js and Python.\u003c/p\u003e","theta":"45","volume":"2016-11"},{"name":"Pa11y","id":"1025","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"65","display_name":"Pa11y","radius":"190","description":"\u003cp\u003e\u003ca href\u003d\"http://pa11y.org/\"\u003e\u003cstrong\u003ePa11y\u003c/strong\u003e\u003c/a\u003e is an automatic accessibility tester that can run from the command line and be embedded into a build pipeline. Our teams have had success using Pa11y on a highly dynamic site by first creating a static HTML version, then running the accessibility tests against that. For many systems—especially government websites—accessibility testing is a requirement, and Pa11y makes it all a lot easier.\u003c/p\u003e","theta":"40","volume":"2016-11"},{"name":"Serverspec","id":"962","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"66","display_name":"Serverspec","radius":"200","description":"\u003cp\u003eIn the past we have included automated \u003ca href\u003d\"/radar/techniques/provisioning-testing\"\u003eProvisioning Testing\u003c/a\u003e as a recommended technique, and in this issue we highlight \u003ca href\u003d\"http://serverspec.org/\"\u003e\u003cstrong\u003eServerspec\u003c/strong\u003e\u003c/a\u003e as a popular tool for implementing those tests. Although this tool is not new, we are seeing its use become more common as more cross-functional delivery teams take on responsibility for infrastructure provisioning. Serverspec is built on the Ruby library RSpec and comes with a comprehensive set of helpers for asserting that server configuration is correct.\u003c/p\u003e","theta":"34","volume":"2016-11"},{"name":"Talisman","id":"1022","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"67","display_name":"Talisman","radius":"160","description":"\u003cp\u003eWith the maturity of tools such as \u003ca href\u003d\"/radar/tools/hashicorp-vault\"\u003eVault\u003c/a\u003e, there is no longer an excuse for storing secrets in code repositories, particularly since this often ends up being the soft underbelly of important systems. We’ve previously mentioned repository-scanning tools such as \u003ca href\u003d\"/radar/tools/gitrob\"\u003eGitrob\u003c/a\u003e, but we are now pushing proactive tools such as (the ThoughtWorks-created) \u003cstrong\u003e\u003ca href\u003d\"https://github.com/thoughtworks/talisman\"\u003eTalisman\u003c/a\u003e\u003c/strong\u003e, which is a prepush hook for Git that scans commits for secrets matching predefined patterns.\u003c/p\u003e","theta":"29","volume":"2016-11"},{"name":"Terraform","id":"815","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"68","display_name":"Terraform","radius":"160","description":"\u003cp\u003eWith \u003cstrong\u003e\u003ca href\u003d\"https://www.terraform.io/\"\u003eTerraform\u003c/a\u003e\u003c/strong\u003e, you can manage cloud infrastructure by writing declarative definitions. The configuration of the servers instantiated by Terraform is usually left to tools like Puppet, Chef or Ansible. We like Terraform because the syntax of its files is quite readable and because it supports a number of cloud providers while making no attempt to provide an artificial abstraction across those providers. Following our first, more cautious, mention of Terraform almost two years ago, it has seen continued development and has evolved into a stable product that has proven its value in our projects. The issue with state file management can now be sidestepped by using what Terraform calls a \"remote state backend.\" We’ve successfully used \u003ca href\u003d\"/radar/tools/consul\"\u003eConsul\u003c/a\u003e for that purpose.\u003c/p\u003e","theta":"23","volume":"2016-11"},{"name":"tmate","id":"1065","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"69","display_name":"tmate","radius":"220","description":"\u003cp\u003ePair programming is an essential technique for us, and—given that we’re seeing more and more teams whose members are distributed across multiple locations—we have experimented with a number of tools to support remote pairing. We certainly liked \u003ca href\u003d\"https://screenhero.com/\"\u003eScreenHero\u003c/a\u003e but are concerned about its future. For teams that don’t rely on a graphical IDE, using \u003cstrong\u003e\u003ca href\u003d\"https://tmate.io/\"\u003etmate\u003c/a\u003e\u003c/strong\u003e for pairing has turned out to be a great solution. tmate is a fork of the popular tmux tool, and compared to \u003ca href\u003d\"http://hamvocke.com/blog/remote-pair-programming-with-tmux/\"\u003etmux for remote pairing\u003c/a\u003e, the setup is much easier. Compared to graphical screen-sharing solutions, the bandwidth and resource requirements are modest, and it obviously never suffers from blurry screens. Teams can also set up their own server, thus retaining full control of the privacy and integrity of the solution.\u003c/p\u003e","theta":"17","volume":"2016-11"},{"name":"Webpack","id":"964","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"70","display_name":"Webpack","radius":"220","description":"\u003cp\u003e\u003ca href\u003d\"http://webpack.github.io/\"\u003e\u003cstrong\u003eWebpack\u003c/strong\u003e\u003c/a\u003e has solidified itself as our go-to JavaScript module bundler. With its ever-growing \u003ca href\u003d\"https://github.com/webpack/docs/wiki/list-of-loaders\"\u003elist of loaders\u003c/a\u003e, it provides a single dependency tree for all your static assets, allowing flexible manipulation of JavaScript, CSS, etc. and minimizing what needs to be sent to the browser and when. Of particular relevance is the smooth integration among AMD, CommonJS and \u003ca href\u003d\"/radar/languages-and-frameworks/es6\"\u003eES6\u003c/a\u003e modules and how it has enabled teams to work in ES6 and seamlessly transpile (using \u003ca href\u003d\"http://babeljs.io/\"\u003eBabel\u003c/a\u003e) to earlier versions for browser compatibility. Many of our teams also value \u003ca href\u003d\"http://browserify.org/\"\u003eBrowserify\u003c/a\u003e, which covers a similar space but is more focused on making Node.js modules available for client-side use.\u003c/p\u003e","theta":"12","volume":"2016-11"},{"name":"Zipkin","id":"466","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"71","display_name":"Zipkin","radius":"180","description":"\u003cp\u003eDevelopment on \u003ca href\u003d\"https://github.com/openzipkin/zipkin\"\u003e\u003cstrong\u003eZipkin\u003c/strong\u003e\u003c/a\u003e has continued apace, and since the middle of 2015 it has moved to the \u003cem\u003eopenzipkin/zipkin\u003c/em\u003e organization at GitHub. There are now bindings for Python, Go, Java, Ruby, Scala and C#; and there are Docker images available for those wanting to get started quickly. We still like this tool. There is an active and growing community around usage of it, and implementation is getting easier. If you need a way of measuring the end-to-end latency of many logical requests, Zipkin continues to be a strong choice.\u003c/p\u003e","theta":"6","volume":"2016-11"},{"name":"Android-x86","id":"1030","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"72","display_name":"Android-x86","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://www.android-x86.org/\"\u003eAndroid-x86\u003c/a\u003e\u003c/strong\u003e is a port of the \u003ca href\u003d\"http://source.android.com/\"\u003eAndroid open source\u003c/a\u003e project to x86 platforms. The project started by hosting various patches from the community for x86 support but then later created its own codebase to provide support for different x86 platforms. We have seen significant time savings by utilizing Android-x86 in our CI servers instead of emulators for hermetic UI testing. However, for UI-specific tests targeting a particular device resolution—simulating low memory, bandwidth and battery—it is better to stick with emulators.\u003c/p\u003e","theta":"83","volume":"2016-11"},{"name":"axios","id":"1067","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"73","display_name":"axios","radius":"290","description":"\u003cp\u003eOur teams have had success with \u003ca href\u003d\"https://github.com/mzabriskie/axios\"\u003e\u003cstrong\u003eaxios\u003c/strong\u003e\u003c/a\u003e, a promises-based HTTP client in JavaScript that they describe as \"better than \u003ca href\u003d\"/radar/languages-and-frameworks/fetch\"\u003eFetch\u003c/a\u003e.\" The project has lots of endorsements and activity on GitHub, and it gets a thumbs-up from us.\u003c/p\u003e","theta":"75","volume":"2016-11"},{"name":"Bottled Water","id":"1032","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"74","display_name":"Bottled Water","radius":"320","description":"\u003cp\u003eWith the growth of interest in streaming data architectures and the downstream data lakes they feed, we have seen an increased reliance on \"change data capture\" tooling to connect transactional data stores to stream-processing systems. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/confluentinc/bottledwater-pg\"\u003eBottled Water\u003c/a\u003e\u003c/strong\u003e is a welcome addition to this field, converting changes in \u003ca href\u003d\"/radar/platforms/postgresql-for-nosql\"\u003ePostgreSQL\u003c/a\u003e’s write-ahead log into \u003ca href\u003d\"/radar/tools/apache-kafka\"\u003eKafka\u003c/a\u003e events. One downside of this approach, however, is that you are tied to low-level database events rather than the higher-level \u003ca href\u003d\"/radar/techniques/capture-domain-events-explicitly\"\u003ebusiness events\u003c/a\u003e we recommend as the foundation for an event-oriented architecture.\u003c/p\u003e","theta":"68","volume":"2016-11"},{"name":"Clojure.spec","id":"1031","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"75","display_name":"Clojure.spec","radius":"305","description":"\u003cp\u003eOne of those perpetual developer debates involves language typing: How much is just right? \u003ca href\u003d\"/radar/languages-and-frameworks/clojure\"\u003eClojure\u003c/a\u003e, the dynamically typed functional Lisp on the JVM, added a new entry into this discussion that blurs the lines. \u003cstrong\u003e\u003ca href\u003d\"https://clojure.org/about/spec\"\u003eClojure.spec\u003c/a\u003e\u003c/strong\u003e is a new facility built into Clojure that allows developers to wrap type and other verification criteria around data structures, such as allowable value ranges. Once they are established, Clojure uses these specifications to provide a slew of benefits: generated tests, validation, destructuring of data structures and others. Clojure.spec is a promising way to have the benefits of types and ranges where developers need them but not everywhere.\u003c/p\u003e","theta":"60","volume":"2016-11"},{"name":"FBSnapshotTestcase","id":"1029","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"76","display_name":"FBSnapshotTestcase","radius":"330","description":"\u003cp\u003eTesting the visual portion of iOS applications can be painful, slow and flakey, which is why we’re happy to include \u003cstrong\u003e\u003ca href\u003d\"https://github.com/facebook/ios-snapshot-test-case\"\u003eFBSnapshotTestcase\u003c/a\u003e\u003c/strong\u003e in our toolkit. It automates taking, storing and diff-ing snapshots of UI components so you can keep your interfaces pixel-perfect. Since it runs as a unit test (in the simulator), it is faster and more reliable than functional-testing approaches.\u003c/p\u003e","theta":"53","volume":"2016-11"},{"name":"Grasp","id":"971","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"77","display_name":"Grasp","radius":"310","description":"\u003cp\u003eWe had our collective minds blown by a little JavaScript command-line refactoring tool called \u003cstrong\u003e\u003ca href\u003d\"http://www.graspjs.com/\"\u003eGrasp\u003c/a\u003e\u003c/strong\u003e. Providing a rich set of selectors and operating against the abstract syntax tree, it is leagues ahead of fiddling with sed and grep. A useful addition to the toolkit in our ongoing quest to treat \u003ca href\u003d\"/radar/languages-and-frameworks/javascript-as-a-first-class-language\"\u003eJavaScript as a first-class language\u003c/a\u003e.\u003c/p\u003e","theta":"45","volume":"2016-11"},{"name":"LambdaCD","id":"968","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"78","display_name":"LambdaCD","radius":"300","description":"\u003cp\u003e\u003ca href\u003d\"http://www.lambda.cd\"\u003e\u003cstrong\u003eLambdaCD\u003c/strong\u003e\u003c/a\u003e provides teams with a way to define Continuous Delivery pipelines in Clojure. This brings the benefits of \u003ca href\u003d\"/radar/tools/infrastructure-as-code\"\u003eInfrastructure as code\u003c/a\u003e to the configuration of CD servers: source-control management, unit testing, refactoring and code reuse. In the \"pipelines as code\" space, LambdaCD stands out for being lightweight, self-contained and fully programmable, allowing teams to work with their pipelines in the same way that they do with their code.\u003c/p\u003e","theta":"38","volume":"2016-11"},{"name":"Pinpoint","id":"967","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"79","display_name":"Pinpoint","radius":"320","description":"\u003cp\u003eTeams using the Phoenix Server or \u003ca href\u003d\"/radar/techniques/phoenix-environments\"\u003ePhoenix Environment\u003c/a\u003e techniques have found little in the way of support from Application Performance Management (APM) tools. Their licensing models, based on long-running, limited amounts of tin, and their difficulty in dealing with ephemeral hardware, have meant that they are often more trouble than they are worth. However, distributed systems need monitoring, and at some point many teams recognize the need for an APM tool. We think \u003cstrong\u003e\u003ca href\u003d\"https://github.com/naver/pinpoint\"\u003ePinpoint\u003c/a\u003e\u003c/strong\u003e, an open source tool in this space, is worth investigating as an alternative to AppDynamics and Dynatrace. Pinpoint is written in Java, with plugins available for many servers, databases and frameworks. While we think you can go a long way using a combination of other lightweight open source tools—\u003ca href\u003d\"/radar/tools/zipkin\"\u003eZipkin\u003c/a\u003e, for example—if you are in the market for an APM, Pinpoint is worth considering.\u003c/p\u003e","theta":"30","volume":"2016-11"},{"name":"Pitest","id":"970","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"80","display_name":"Pitest","radius":"300","description":"\u003cp\u003e\u003ca href\u003d\"http://pitest.org\"\u003e\u003cstrong\u003ePitest\u003c/strong\u003e\u003c/a\u003e is a test coverage analysis tool for Java that uses a mutation-testing technique. Traditional test coverage analysis tends to measure the number of lines that are executed by your tests. It is therefore only able to identify code that is definitely not tested. Mutation testing, on the other hand, tries to test the quality of those lines that are executed by your test code and yet might contain general errors. Several problems can be spotted this way, helping the team to measure and grow a healthy test suite. Most of such tools tend to be slow and difficult to use, but Pitest has proven to have better performance, is easy to set up, and is actively supported.\u003c/p\u003e","theta":"23","volume":"2016-11"},{"name":"Repsheet","id":"980","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"81","display_name":"Repsheet","radius":"330","description":"\u003cp\u003eAttacks on web properties using bots are becoming more sophisticated. Identifying these bad actors and their behaviors is the goal of the \u003ca href\u003d\"http://getrepsheet.com/\"\u003e\u003cstrong\u003eRepsheet\u003c/strong\u003e\u003c/a\u003e project. It\u0027s a plugin for either Apache or NGINX that records user activity, fingerprints actors using predefined and user-defined rules, and then allows action to be taken, including the ability to block offensive actors. It includes a utility that visualizes current actors; this puts the ability to manage bot-based threats in the hands of team members, increasing security awareness for teams. We like this since it\u0027s a good example of a simple tool solving a very real but often invisible problem—bot-based attacks.\u003c/p\u003e","theta":"15","volume":"2016-11"},{"name":"Scikit-learn","id":"1033","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"82","display_name":"Scikit-learn","radius":"285","description":"\u003cp\u003e\u003ca href\u003d\"http://scikit-learn.org/stable/\"\u003e\u003cstrong\u003eScikit-learn\u003c/strong\u003e\u003c/a\u003e is an increasingly popular machine-learning library written in Python. It provides a robust set of machine-learning models such as clustering, classification, regression and dimensionality reduction, and a rich set of functionality for companion tasks like model selection, model evaluation and data preparation. Since it is designed to be simple, reusable in various contexts and well documented, we see this tool accessible even to nonexperts to explore the machine-learning space.\u003c/p\u003e","theta":"8","volume":"2016-11"},{"name":"Jenkins as a deployment pipeline","id":"976","quadrant":"Tools","ring":"Hold","movement":"c","radarId":"83","display_name":"Jenkins as a deployment pipeline","radius":"375","description":"\u003cp\u003eWe know we\u0027re in perilous territory here, since we build a competing tool, but we feel we have to address a persistent problem. Continuous Integration tools like CruiseControl and Jenkins are valuable for software development, but as your build process gets more complex it requires something beyond just Continuous Integration: It requires a \u003ca href\u003d\"http://martinfowler.com/bliki/DeploymentPipeline.html\"\u003edeployment pipeline\u003c/a\u003e. We frequently see people trying to use \u003cstrong\u003eJenkins as a Deployment Pipeline\u003c/strong\u003e with the aid of plugins, but our experience is that these quickly become a tangle. Jenkins 2.0 introduces \"Pipeline as Code\" but continues to model pipelines using plugins and fails to change the core Jenkins product to model pipelines directly. In our experience, tools that are built around a first-class representation of deployment pipelines are much more suitable, and this is what drove us to replace CruiseControl with \u003ca href\u003d\"https://www.go.cd/\"\u003eGoCD\u003c/a\u003e. Today we see several products that embrace deployment pipelines, including \u003ca href\u003d\"/radar/tools/concourse-ci\"\u003eConcourseCI\u003c/a\u003e, \u003ca href\u003d\"/radar/tools/lambdacd\"\u003eLambdaCD\u003c/a\u003e, \u003ca href\u003d\"http://spinnaker.io/\"\u003eSpinnaker,\u003c/a\u003e \u003ca href\u003d\"https://github.com/drone\"\u003eDrone\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/gocd\"\u003eGoCD\u003c/a\u003e.\u003c/p\u003e","theta":"45","volume":"2016-11"},{"name":"Ember.js","id":"879","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"84","display_name":"Ember.js","radius":"75","description":"\u003cp\u003eIf you are faced with building a single-page application (SPA) and trying to choose a framework to build with, \u003cstrong\u003e\u003ca href\u003d\"http://emberjs.com/\"\u003eEmber.js\u003c/a\u003e\u003c/strong\u003e has emerged as a leading choice. Our teams praise Ember for its highly productive developer experience, with far fewer surprises than other frameworks such as \u003ca href\u003d\"/radar/languages-and-frameworks/angularjs\"\u003eAngularJS\u003c/a\u003e. The Ember CLI build tooling is a haven in the storm of JavaScript build tools, and the Ember core team and community are highly active and responsive.\u003c/p\u003e","theta":"288","volume":"2016-11"},{"name":"React.js","id":"827","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radarId":"85","display_name":"React.js","radius":"75","description":"\u003cp\u003eIn the avalanche of front-end JavaScript frameworks, \u003ca href\u003d\"http://facebook.github.io/react/\"\u003e\u003cstrong\u003eReact.js\u003c/strong\u003e\u003c/a\u003e stands out due to its design around a reactive data flow. Allowing only one-way data binding greatly simplifies the rendering logic and avoids many of the issues that commonly plague applications written with other frameworks. We\u0027re seeing the benefits of React.js on a growing number of projects, large and small, while at the same time we continue to be concerned about the state and the future of other popular frameworks like \u003ca href\u003d\"/radar/languages-and-frameworks/angularjs\"\u003eAngularJS\u003c/a\u003e. This has led to React.js becoming our default choice for JavaScript frameworks.\u003c/p\u003e","theta":"306","volume":"2016-11"},{"name":"Redux","id":"951","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"86","display_name":"Redux","radius":"120","description":"\u003cp\u003eWith the increasing complexity of single-page JavaScript applications, we have seen a more pressing need to make client-side state management predictable. \u003ca href\u003d\"http://redux.js.org/\"\u003e\u003cstrong\u003eRedux\u003c/strong\u003e\u003c/a\u003e, with its \u003ca href\u003d\"http://redux.js.org/docs/introduction/ThreePrinciples.html\"\u003ethree principles\u003c/a\u003e of restrictions for updating state, has proven to be invaluable in a number of projects we have implemented. \u003ca href\u003d\"https://egghead.io/courses/getting-started-with-redux\"\u003eGetting Started with Redux\u003c/a\u003e and \u003ca href\u003d\"https://egghead.io/courses/building-react-applications-with-idiomatic-redux\"\u003eidiomatic Redux\u003c/a\u003e tutorials are a good starting point for new and experienced users. Its minimal library design has spawned a rich set of tools, and we encourage you to check out the \u003ca href\u003d\"https://github.com/markerikson/redux-ecosystem-links\"\u003eredux-ecosystem-links\u003c/a\u003e project for examples, middleware and utility libraries. We also particularly like the testability story: Dispatching actions, state transitions and rendering can be unit-tested separately from one another and with minimal amounts of mocking.\u003c/p\u003e","theta":"324","volume":"2016-11"},{"name":"Spring Boot","id":"775","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radarId":"87","display_name":"Spring Boot","radius":"95","description":"\u003cp\u003eA lot of work has gone into \u003ca href\u003d\"http://projects.spring.io/spring-boot\"\u003e\u003cstrong\u003eSpring Boot\u003c/strong\u003e\u003c/a\u003e to reduce complexity and dependencies, which largely alleviates our previous reservations. If you live in a Spring ecosystem and are moving to microservices, Spring Boot is now the obvious choice. For those not in Springland, \u003ca href\u003d\"/radar/languages-and-frameworks/dropwizard\"\u003eDropwizard\u003c/a\u003e is also worthy of serious consideration.\u003c/p\u003e","theta":"342","volume":"2016-11"},{"name":"Butterknife","id":"961","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"88","display_name":"Butterknife","radius":"250","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/JakeWharton/butterknife\"\u003eButterknife\u003c/a\u003e\u003c/strong\u003e is a field and method binding view-injection library. It allows the injection of arbitrary objects, views and listeners, thereby ensuring cleaner code with reduced glue code for Android development. With Butterknife, multiple views can be grouped into a list or array with common actions applied to the views simultaneously, without heavy reliance on XML configurations. Our project teams have used this library and benefited from its simplicity and ease of use.\u003c/p\u003e","theta":"278","volume":"2016-11"},{"name":"Dagger","id":"960","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"89","display_name":"Dagger","radius":"230","description":"\u003cp\u003eWith the increased need for Android-based applications, \u003cstrong\u003e\u003ca href\u003d\"http://google.github.io/dagger/\"\u003eDagger\u003c/a\u003e\u003c/strong\u003e offers a fully static, compile-time dependency-injection framework. Dagger\u0027s strictly generated implementation and nonreliance on reflection-based solutions addresses many of the performance and development issues, thereby making it suitable for Android development. With Dagger, there is full traceability with easy debugging because the entire call stack for provision and creation is made available.\u003c/p\u003e","theta":"286","volume":"2016-11"},{"name":"Dapper","id":"952","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"90","display_name":"Dapper","radius":"230","description":"\u003cp\u003e\u003ca href\u003d\"https://github.com/StackExchange/dapper-dot-net\"\u003e\u003cstrong\u003eDapper\u003c/strong\u003e\u003c/a\u003e is a minimal, lightweight ORM of sorts for .NET. Rather than trying to write the SQL queries for you, Dapper maps SQL queries to dynamic objects. Though it\u0027s not brand new, Dapper has steadily gained acceptance from ThoughtWorks teams working in .NET. For the C# programmer, it removes some of the drudgery of mapping relational queries to objects while still allowing complete control over the SQL or stored procedures.\u003c/p\u003e","theta":"294","volume":"2016-11"},{"name":"Elixir","id":"676","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"91","display_name":"Elixir","radius":"180","description":"\u003cp\u003eInterest in the \u003ca href\u003d\"http://elixir-lang.org/\"\u003e\u003cstrong\u003eElixir\u003c/strong\u003e\u003c/a\u003e programming language continues to build. Increasingly, we see it used in serious projects and hear feedback from developers who find its Actor model to be robust and very fast. Elixir, which is built on top of the Erlang virtual machine, is showing promise for creating highly concurrent and fault-tolerant systems. Elixir has distinctive features such as the Pipe operator, which allows developers to build a pipeline of functions as you would in the UNIX command shell. The shared byte code allows Elixir to interoperate with Erlang and leverage existing libraries while supporting tools such as the Mix build tool, the IEx interactive shell and the \u003ca href\u003d\"http://elixir-lang.org/docs/stable/ex_unit/ExUnit.html\"\u003eExUnit\u003c/a\u003e unit-testing framework.\u003c/p\u003e","theta":"302","volume":"2016-11"},{"name":"Enzyme","id":"1047","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"92","display_name":"Enzyme","radius":"250","description":"\u003cp\u003eWe’ve been enjoying the rapid component-level UI testing that \u003ca href\u003d\"http://airbnb.io/enzyme/\"\u003e\u003cstrong\u003eEnzyme\u003c/strong\u003e\u003c/a\u003e provides for \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e applications. Unlike many other snapshot-based testing frameworks, Enzyme allows you to test without doing on-device rendering, which results in faster and more granular testing. This is a contributing factor in our ability to massively reduce the amount of functional testing we find we have to do in React applications.\u003c/p\u003e","theta":"310","volume":"2016-11"},{"name":"Immutable.js","id":"956","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"93","display_name":"Immutable.js","radius":"230","description":"\u003cp\u003eImmutability is often emphasized in the functional programming paradigm, and most languages have the ability to create immutable objects—objects that can\u0027t be changed once created. \u003cstrong\u003e\u003ca href\u003d\"https://facebook.github.io/immutable-js/\"\u003eImmutable.js\u003c/a\u003e\u003c/strong\u003e is a library for JavaScript that provides many persistent immutable data structures, which are highly efficient on modern JavaScript virtual machines. Immutable.js objects are, however, not normal JavaScript objects, so references to JavaScript objects from immutable objects should be avoided. More teams are using this library for tracking mutation and maintaining state in production. We recommend that developers investigate this library, especially when it\u0027s combined with the rest of the Facebook stack.\u003c/p\u003e","theta":"319","volume":"2016-11"},{"name":"Phoenix","id":"1050","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"94","display_name":"Phoenix","radius":"210","description":"\u003cp\u003eSome of our ThoughtWorks teams have had very positive experiences with \u003cstrong\u003ePhoenix\u003c/strong\u003e , a server-side web MVC framework written in \u003ca href\u003d\"/radar/languages-and-frameworks/elixir\"\u003eElixir\u003c/a\u003e. In addition to being streamlined and easy to use, Phoenix takes advantage of Elixir to be extremely fast. For some developers, Phoenix evokes the joy they experienced when first discovering Ruby and Rails. Although the ecosystem of libraries for Phoenix is not as extensive as for some more mature frameworks, it should benefit from the continuing success and growth of support for Elixir.\u003c/p\u003e","theta":"327","volume":"2016-11"},{"name":"Quick and Nimble","id":"1059","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"95","display_name":"Quick and Nimble","radius":"200","description":"\u003cp\u003eMost of our iOS teams are now using the \u003cstrong\u003e\u003ca href\u003d\"https://github.com/Quick/Quick\"\u003eQuick\u003c/a\u003e and \u003ca href\u003d\"https://github.com/Quick/Nimble\"\u003eNimble\u003c/a\u003e\u003c/strong\u003e pairing for their unit tests. In the \u003ca href\u003d\"http://rspec.info/\"\u003eRSpec\u003c/a\u003e family of behavior-driven development (BDD) testing tools, it provides very readable tests (with describe blocks) across \u003ca href\u003d\"/radar/languages-and-frameworks/swift\"\u003eSwift\u003c/a\u003e and Objective-C and has good support for asynchronous testing.\u003c/p\u003e","theta":"335","volume":"2016-11"},{"name":"React Native","id":"937","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"96","display_name":"React Native","radius":"180","description":"\u003cp\u003eWe are seeing continued success with \u003ca href\u003d\"https://facebook.github.io/react-native/\"\u003e\u003cstrong\u003eReact Native\u003c/strong\u003e\u003c/a\u003e for rapid cross-platform mobile development. Despite some churn as it undergoes continuing development, the advantages of trivial integration between native and nonnative code and views, the rapid development cycle (instant reload, chrome debugging, Flexbox layout) and general growth of the React style is winning us over. As with many frameworks, care needs to be taken to keep your code well structured, but diligent use of a tool like \u003ca href\u003d\"/radar/languages-and-frameworks/redux\"\u003eRedux\u003c/a\u003e really helps here.\u003c/p\u003e","theta":"343","volume":"2016-11"},{"name":"Robolectric","id":"954","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"97","display_name":"Robolectric","radius":"240","description":"\u003cp\u003eIn the Android application-development world, \u003cstrong\u003e\u003ca href\u003d\"http://robolectric.org/\"\u003eRobolectric\u003c/a\u003e\u003c/strong\u003e is a unit-testing framework that has been used by multiple teams within our technical community. It offers the best option among those available for writing real unit tests that extend or interact directly with Android components and support JUnit tests. We caution, though, that because it is an implementation of the Android SDK, there might be device-specific issues for some tests that pass in Robolectric. To manually mock all the Android dependencies, ensuring only test of the system-in-test will require a lot of complex code, and this framework addresses this effectively.\u003c/p\u003e","theta":"351","volume":"2016-11"},{"name":"Aurelia","id":"958","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"98","display_name":"Aurelia","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"http://aurelia.io/\"\u003e\u003cstrong\u003eAurelia\u003c/strong\u003e\u003c/a\u003e is considered the next-generation JavaScript client framework and was written using a modern version of JavaScript: ECMAScript 2016. Aurelia was created by Rob Eisenberg, the creator of \u003ca href\u003d\"http://durandaljs.com/\"\u003eDurandal\u003c/a\u003e. He left the \u003ca href\u003d\"https://angular.io/\"\u003eAngular 2.0\u003c/a\u003e core team to dedicate his time to this project. The great thing about Aurelia is that it\u0027s highly modular, contains simple small libraries and is designed to be customized easily. Aurelia follows the pattern of convention over configuration, which enables easier production and consumption of modules, but there are no strong conventions that you have to adhere to. Aurelia has a large community, and in the project website you can learn more by using the tutorials.\u003c/p\u003e","theta":"276","volume":"2016-11"},{"name":"ECMAScript 2017","id":"1066","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"99","display_name":"ECMAScript 2017","radius":"290","description":"\u003cp\u003e\u003cstrong\u003eECMAScript 2017\u003c/strong\u003e —not to be confused with ES7 (a.k.a. ECMAScript 2016)—brings several noteworthy improvements to the language. Browsers are expected to implement this standard fully in the summer of 2017, but the \u003ca href\u003d\"/radar/tools/babel\"\u003eBabel\u003c/a\u003e JavaScript compiler already supports a number of the features today. If you make extensive use of JavaScript and your codebase is under active development, we recommend that you add Babel to your build pipeline and begin using the \u003ca href\u003d\"https://www.npmjs.com/package/babel-preset-es2017\"\u003esupported features\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e.\u003c/p\u003e","theta":"283","volume":"2016-11"},{"name":"Elm","id":"736","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"100","display_name":"Elm","radius":"320","description":"\u003cp\u003eWe have been prompted to reconsider \u003ca href\u003d\"http://elm-lang.org/\"\u003e\u003cstrong\u003eElm\u003c/strong\u003e\u003c/a\u003e because of the rapid adoption of \u003ca href\u003d\"/radar/languages-and-frameworks/redux\"\u003eRedux\u003c/a\u003e framework. Elm—the original inspiration for Redux—offers the view componentization and reactiveness of \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e along with the predictable state of Redux in a compiled, strongly typed functional language. Elm is written in Haskell and has a Haskell-like syntax but compiles down to HTML, CSS and JavaScript for the browser. JavaScript programmers rushing to embrace React.js and Redux might want to also consider Elm as a type-safe alternative for some applications.\u003c/p\u003e","theta":"290","volume":"2016-11"},{"name":"GraphQL","id":"986","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"101","display_name":"GraphQL","radius":"300","description":"\u003cp\u003eWhen we look at REST implementations in the wild, we frequently see REST misused to naively retrieve object graphs through chatty interactions between client and server. Facebook\u0027s \u003ca href\u003d\"https://github.com/facebook/graphql\"\u003e\u003cstrong\u003eGraphQL\u003c/strong\u003e\u003c/a\u003e is an interesting alternative to REST that might be a better approach for this very common use case. As a protocol for remotely retrieving object graphs, GraphQL has received enormous attention recently. One of GraphQL\u0027s most interesting features is its consumer-oriented nature: The structure of a response is driven entirely by the client, not the server. This decouples the consumer and forces the server to obey Postel\u0027s law. Client implementations are now available in many programming languages, but we have seen a flurry of interest of Facebook\u0027s \u003ca href\u003d\"https://facebook.github.io/relay/\"\u003eRelay\u003c/a\u003e, a JavaScript framework that was designed to support the \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e stateless component model.\u003c/p\u003e","theta":"297","volume":"2016-11"},{"name":"JuMP","id":"1052","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"102","display_name":"JuMP","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/JuliaOpt/JuMP.jl\"\u003eJuMP\u003c/a\u003e\u003c/strong\u003e is a domain-specific language for \u003ca href\u003d\"https://en.wikipedia.org/wiki/Mathematical_optimization\"\u003emathematical optimizations\u003c/a\u003e in \u003ca href\u003d\"http://julialang.org/\"\u003eJulia\u003c/a\u003e. JuMP defines a common API called \u003ca href\u003d\"https://github.com/JuliaOpt/MathProgBase.jl\"\u003eMathProgBase\u003c/a\u003e and enables users to write solver-agnostic code in Julia. Currently supported solvers include \u003ca href\u003d\"http://artelys.com/en/optimization-tools/knitro\"\u003eArtelys Knitro\u003c/a\u003e, \u003ca href\u003d\"https://projects.coin-or.org/Bonmin\"\u003eBonmin\u003c/a\u003e, \u003ca href\u003d\"https://projects.coin-or.org/Cbc\"\u003eCbc\u003c/a\u003e, \u003ca href\u003d\"https://projects.coin-or.org/Clp\"\u003eClp\u003c/a\u003e, \u003ca href\u003d\"https://projects.coin-or.org/Couenne\"\u003eCouenne\u003c/a\u003e, \u003ca href\u003d\"http://www-01.ibm.com/software/commerce/optimization/cplex-optimizer/\"\u003eCPLEX\u003c/a\u003e, \u003ca href\u003d\"https://github.com/ifa-ethz/ecos\"\u003eECOS\u003c/a\u003e, \u003ca href\u003d\"http://www.fico.com/en/products/fico-xpress-optimization-suite\"\u003eFICO Xpress\u003c/a\u003e, \u003ca href\u003d\"http://www.gnu.org/software/glpk/\"\u003eGLPK\u003c/a\u003e, \u003ca href\u003d\"http://www.gurobi.com\"\u003eGurobi\u003c/a\u003e, \u003ca href\u003d\"https://projects.coin-or.org/Ipopt\"\u003eIpopt\u003c/a\u003e, \u003ca href\u003d\"http://www.mosek.com/\"\u003eMOSEK\u003c/a\u003e, \u003ca href\u003d\"http://ab-initio.mit.edu/wiki/index.php/NLopt\"\u003eNLopt\u003c/a\u003e and \u003ca href\u003d\"https://github.com/cvxgrp/scs\"\u003eSCS\u003c/a\u003e. One other benefit is the implementation of automatic differentiation technique in reverse mode to compute derivatives so users are not limited to the standard operators like sin, cos, log and sqrt but can also implement their own custom objective functions in Julia.\u003c/p\u003e","theta":"304","volume":"2016-11"},{"name":"Physical Web","id":"1054","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"103","display_name":"Physical Web","radius":"295","description":"\u003cp\u003eWe have been intrigued by the \u003cstrong\u003e\u003ca href\u003d\"https://google.github.io/physical-web/\"\u003ePhysical Web\u003c/a\u003e\u003c/strong\u003e standard created by Google. The idea of Physical Web is simple—beacons broadcast a URL—but the possibilities are broad. Basically, this is a way to annotate the physical world, tying objects and locations into the digital realm. The current transport mechanism is \u003ca href\u003d\"https://github.com/google/eddystone/tree/master/eddystone-url\"\u003eEddystone URLs\u003c/a\u003e over Bluetooth LE, and sample clients are available. Although there are obvious security concerns with following randomly discovered links, we are most interested in use cases with customized clients where you can filter or proxy the URLs as required.\u003c/p\u003e","theta":"311","volume":"2016-11"},{"name":"Rapidoid","id":"1051","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"104","display_name":"Rapidoid","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://www.rapidoid.org/\"\u003eRapidoid\u003c/a\u003e\u003c/strong\u003e is a collection of web framework modules, including a fast low-level HTTP server implemented from scratch on top of Java NIO. Clever usage of off-heap input/output buffers, object pools and thread-local data structures provide Rapidoid an edge over other NIO-based servers like \u003ca href\u003d\"http://netty.io/\"\u003eNetty\u003c/a\u003e. Being a fairly new project, Rapidoid has yet to implement a few features like built-in cache and SSL support; we suggest you check the \u003ca href\u003d\"https://github.com/rapidoid/rapidoid\"\u003eroadmap\u003c/a\u003e for updates.\u003c/p\u003e","theta":"318","volume":"2016-11"},{"name":"Recharts","id":"957","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"105","display_name":"Recharts","radius":"300","description":"\u003cp\u003eWe\u0027ve been enjoying how \u003cstrong\u003e\u003ca href\u003d\"http://recharts.org/\"\u003eRecharts\u003c/a\u003e\u003c/strong\u003e integrates \u003ca href\u003d\"/radar/tools/d3\"\u003eD3\u003c/a\u003e charts into \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e in a clean and declarative manner.\u003c/p\u003e","theta":"325","volume":"2016-11"},{"name":"ReSwift","id":"1056","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"106","display_name":"ReSwift","radius":"285","description":"\u003cp\u003eWe are excited that the \u003ca href\u003d\"/radar/languages-and-frameworks/redux\"\u003eRedux\u003c/a\u003e paradigm has made its way to Swift-land in the form of \u003ca href\u003d\"http://reswift.github.io/ReSwift\"\u003e\u003cstrong\u003eReSwift\u003c/strong\u003e\u003c/a\u003e. We’ve found real benefits in the simplicity and readability of codebases once state and state changes are managed in a central place and common idiom. This also helps with building \"offline first\" applications.\u003c/p\u003e","theta":"332","volume":"2016-11"},{"name":"Three.js","id":"1060","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"107","display_name":"Three.js","radius":"310","description":"\u003cp\u003eDespite the fervor surrounding the spate of new headsets, we believe there are many VR and AR scenarios that make sense in the browser, particularly on mobile. Given this trend, we have seen an uptick in usage of \u003ca href\u003d\"https://threejs.org/\"\u003e\u003cstrong\u003eThree.js\u003c/strong\u003e\u003c/a\u003e, a powerful JavaScript visualization and 3D rendering framework. The growth in support for WebGL, which it is based on, has helped adoption, as has the vibrant community supporting this open source project.\u003c/p\u003e","theta":"339","volume":"2016-11"},{"name":"Vue.js","id":"1055","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"108","display_name":"Vue.js","radius":"300","description":"\u003cp\u003eIn the ever-changing world of front-end JavaScript frameworks, \u003ca href\u003d\"https://vuejs.org/\"\u003e\u003cstrong\u003eVue.js\u003c/strong\u003e\u003c/a\u003e has gained a lot of ground as a lightweight alternative to \u003ca href\u003d\"/radar/languages-and-frameworks/angularjs\"\u003eAngularJS\u003c/a\u003e. It is designed to be a very flexible—and a less opinionated—library that offers a set of tools for building interactive web interfaces around concepts like modularity, components and reactive data flow. It has a low learning barrier, which makes it interesting for junior developers and beginners. Vue.js itself is not a full-blown framework; it is focused on the view layer only and therefore is easy to integrate with other libraries or existing projects.\u003c/p\u003e","theta":"346","volume":"2016-11"},{"name":"WebRTC","id":"1063","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"109","display_name":"WebRTC","radius":"320","description":"\u003cp\u003eWidespread adoption of AR/VR as a collaboration and communication medium requires a modern and readily available video streaming platform. \u003cstrong\u003e\u003ca href\u003d\"https://webrtc.org/\"\u003eWebRTC\u003c/a\u003e\u003c/strong\u003e is an emerging standard for real-time communication between browsers that enables video streaming within commonly available web technologies. The range of browsers that support this standard is increasing, but Microsoft and Apple have been slow to adopt WebRTC in their proprietary browsers. If momentum continues to build, WebRTC could form the future foundation for AR/VR collaboration on the web.\u003c/p\u003e","theta":"353","volume":"2016-11"},{"name":"AngularJS","id":"727","quadrant":"languages-and-frameworks","ring":"Hold","movement":"t","radarId":"110","display_name":"AngularJS","radius":"375","description":"\u003cp\u003e\u003ca href\u003d\"https://angularjs.org/\"\u003e\u003cstrong\u003eAngularJS\u003c/strong\u003e\u003c/a\u003e helped revolutionize the world of single-page JavaScript applications, and we have delivered many projects successfully with it over the years. However, we are no longer recommending it (v1) for teams starting fresh projects. We prefer the ramp-up speed and more maintainable codebases we are seeing with \u003ca href\u003d\"/radar/languages-and-frameworks/ember-js\"\u003eEmber\u003c/a\u003e and \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e, particularly in conjunction with \u003ca href\u003d\"/radar/languages-and-frameworks/redux\"\u003eRedux\u003c/a\u003e.\u003c/p\u003e","theta":"300","volume":"2016-11"},{"name":"JSPatch","id":"959","quadrant":"languages-and-frameworks","ring":"Hold","movement":"c","radarId":"111","display_name":"JSPatch","radius":"385","description":"\u003cp\u003eMany iOS developers are using \u003cstrong\u003e\u003ca href\u003d\"https://github.com/bang590/JSPatch\"\u003eJSPatch\u003c/a\u003e\u003c/strong\u003e to dynamically patch their apps. When a JSPatch-enabled app runs, it loads a chunk of JavaScript (potentially via an insecure HTTP connection) and then bridges to the main Objective-C application code to change behavior, fix bugs, and so on. While convenient, we think monkey-patching live apps is a bad idea and should be avoided. When doing any amount of incremental patching, it\u0027s very important that your testing process matches what end users will experience, in order to properly validate functionality. An alternative approach is to use \u003ca href\u003d\"/radar/languages-and-frameworks/react-native\"\u003eReact Native\u003c/a\u003e for the app and \u003ca href\u003d\"https://www.apphub.vip/\"\u003eAppHub\u003c/a\u003e and \u003ca href\u003d\"https://microsoft.github.io/code-push/\"\u003eCodePush\u003c/a\u003e to push small updates and new features.\u003c/p\u003e","theta":"330","volume":"2016-11"}],"date":"2016-11"},{"blips":[{"name":"Pipelines as code","id":"1037","quadrant":"Techniques","ring":"Adopt","movement":"c","radarId":"1","display_name":"Pipelines as code","radius":"75","description":"\u003cp\u003eTeams are pushing for automation across their environments(testing), including their development infrastructure. \u003cstrong\u003ePipelines as code\u003c/strong\u003e is defining the deployment pipeline through code instead of configuring a running CI/CD tool. \u003ca href\u003d\"/radar/tools/lambdacd\"\u003eLambdaCD\u003c/a\u003e, \u003ca href\u003d\"http://readme.drone.io/usage/overview/\"\u003eDrone\u003c/a\u003e, \u003ca href\u003d\"/radar/tools/gocd\"\u003eGoCD\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/concourse-ci\"\u003eConcourse\u003c/a\u003e are examples that allow usage of this technique. Also, configuration automation tools for CI/CD systems like \u003ca href\u003d\"https://github.com/SpringerSBM/gomatic\"\u003eGoMatic\u003c/a\u003e can be used to treat the deployment pipeline as code—versioned and tested.\u003c/p\u003e","theta":"135","volume":"2017-03"},{"name":"APIs as a product","id":"1036","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"2","display_name":"APIs as a product","radius":"170","description":"\u003cp\u003eCompanies have wholeheartedly embraced APIs as a way to expose business capabilities to both external and internal developers. APIs promise the ability to experiment quickly with new business ideas by recombining core capabilities. But what differentiates an API from an ordinary enterprise integration service? One difference lies in treating \u003cstrong\u003eAPIs as a product\u003c/strong\u003e , even when the consumer is an internal system or fellow developer. Teams that build APIs should understand the needs of their customers and make the product compelling to them. Usability testing and UX research can lead to a better design and understanding of the API usage patterns and help bring a product mindset to APIs. APIs, like products, should be actively maintained and supported, and, easy to use. They should have an owner who advocates for the customer and strives for continual improvement. In our experience, product orientation is the missing ingredient that makes the difference between ordinary enterprise integration and an agile business built on a platform of APIs.\u003c/p\u003e","theta":"170","volume":"2017-03"},{"name":"Decoupling secret management from source code","id":"1105","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"3","display_name":"Decoupling secret management from source code","radius":"170","description":"\u003cp\u003eIn previous Radars issues we mentioned tools such as \u003ca href\u003d\"https://www.agwa.name/projects/git-crypt/\"\u003egit-crypt\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/blackbox\"\u003eBlackbox\u003c/a\u003e that allow us to keep secrets safe inside the source code. \u003cstrong\u003eDecoupling secret management from source code\u003c/strong\u003e is our way to remind technologists that there are other options for storing secrets. For example, \u003ca href\u003d\"/radar/tools/hashicorp-vault\"\u003eHashiCorp vault\u003c/a\u003e, CI servers and configuration management tools provide mechanisms for storing secrets that are not linked to the source code of an application. Both approaches are viable and we recommend you use at least one of them in your projects.\u003c/p\u003e","theta":"160","volume":"2017-03"},{"name":"Hosting PII data in the EU","id":"1001","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"4","display_name":"Hosting PII data in the EU","radius":"200","description":"\u003cp\u003eIn a number of countries, we see government agencies seeking broad access to private, personally identifiable information (PII). The increased use of public cloud solutions makes it more difficult for organizations to protect the data entrusted to them by their users while also respecting all relevant laws. The European Union has some of the most progressive privacy laws, and all the major cloud providers—Amazon, Google and Microsoft—offer multiple data centers and regions within the European Union. Therefore, we recommend that companies, especially those with a global user base, assess the feasibility of a safe haven for their users\u0027 data by \u003cstrong\u003ehosting PII data in the EU\u003c/strong\u003e. Since we wrote about this technique in the last Radar, we have rolled out a new internal system that handles sensitive information relating to all our employees, and we have chosen to host it in a data center located in the European Union.\u003c/p\u003e","theta":"150","volume":"2017-03"},{"name":"Legacy in a box","id":"1106","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"5","display_name":"Legacy in a box","radius":"230","description":"\u003cp\u003eWorking with legacy code, especially large monoliths, is one of the most unsatisfying, high-friction \u003ca href\u003d\"https://thoughtworks.wistia.com/medias/ogq5b8d80y\"\u003eexperiences for developers\u003c/a\u003e. Although we caution against extending and actively maintaining legacy monoliths, they continue to be dependencies in our environments, and developers often underestimate the cost and time required to develop against these dependencies. To help reduce the friction, developers have used virtualized \u003ca href\u003d\"/radar/techniques/machine-image-as-a-build-artifact\"\u003emachine images\u003c/a\u003e or container images with \u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e containers to create immutable images of legacy systems and their configurations. The intent is to contain the \u003cstrong\u003elegacy in a box\u003c/strong\u003e for developers to run locally and remove the need for rebuilding, reconfiguring or sharing environments. In an ideal scenario, teams that own legacy systems generate the corresponding boxed legacy images through their build pipelines, and developers can then run and orchestrate these images in their allocated sandbox more reliably. Although this approach has reduced the overall time spent by each developer, it has had limited success when the teams owning the downstream dependencies have been reluctant to create container images for others to use.\u003c/p\u003e","theta":"140","volume":"2017-03"},{"name":"Lightweight Architecture Decision Records","id":"1034","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"6","display_name":"Lightweight Architecture Decision Records","radius":"220","description":"\u003cp\u003eAlthough much documentation can be replaced with highly readable code and tests, in a world of \u003ca href\u003d\"/radar/techniques/evolutionary-architecture\"\u003eevolutionary architecture\u003c/a\u003e it\u0027s important to record certain design decisions for the benefit of future team members and for external oversight. \u003cstrong\u003eLightweight Architecture Decision Records\u003c/strong\u003e is \u003ca href\u003d\"http://thinkrelevance.com/blog/2011/11/15/documenting-architecture-decisions\"\u003ea technique\u003c/a\u003e for capturing important architectural decisions along with their context and consequences. Although these items are often stored in a wiki or collaboration tool, we generally prefer \u003ca href\u003d\"https://github.com/npryce/adr-tools\"\u003estoring them in source control\u003c/a\u003e with simple markup.\u003c/p\u003e","theta":"130","volume":"2017-03"},{"name":"Progressive Web Applications","id":"1107","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"7","display_name":"Progressive Web Applications","radius":"260","description":"\u003cp\u003eThe increase in \u003cstrong\u003eProgressive Web Applications\u003c/strong\u003e (PWAs) is the latest attempt to bring back the mobile web in response to users\u0027 \"app fatigue\". Originally proposed by Google in 2015, PWAs are web applications that take advantage of the latest technologies to combine the best of web and native mobile applications. Using a set of open standard technologies such as, \u003ca href\u003d\"https://w3c.github.io/ServiceWorker/\"\u003eservice workers\u003c/a\u003e, the \u003ca href\u003d\"https://www.w3.org/TR/appmanifest/\"\u003eapp manifest\u003c/a\u003e, and cache and push APIs, we can create applications that are platform independent and deliver app-like user experiences. This brings parity to web and native applications and helps mobile developers reach users beyond the walled garden of the app stores. Think of PWAs as websites that act and feel like native apps.\u003c/p\u003e","theta":"120","volume":"2017-03"},{"name":"Prototyping with InVision and Sketch","id":"1121","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"8","display_name":"Prototyping with InVision and Sketch","radius":"220","description":"\u003cp\u003eThe combined use of InVision and Sketch has changed the way some people approach web application development. Although these are tools, it is really the technique of \u003cstrong\u003eprototyping with InVision and Sketch\u003c/strong\u003e that makes this blip significant. Creating rich, clickable prototypes as the starting point for implementing front-end and back-end behavior helps speed up the development and eliminates churn in the implementation details. This combined use of these tools strikes the right balance between premature elaboration of visual detail and capturing early user feedback on the interactive experience.\u003c/p\u003e","theta":"110","volume":"2017-03"},{"name":"Serverless architecture","id":"999","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"9","display_name":"Serverless architecture","radius":"165","description":"\u003cp\u003eA \u003cstrong\u003e\u003ca href\u003d\"http://www.martinfowler.com/articles/serverless.html\"\u003eserverless architecture\u003c/a\u003e\u003c/strong\u003e approach replaces long-running virtual machines with ephemeral compute power that comes into existence on request and disappears immediately after use. Our teams like the serverless approach; it\u0027s working well for us and we consider it a valid architectural choice. Note that serverless doesn\u0027t have to be an all-or-nothing approach: some of our teams have deployed a new chunk of their systems using serverless while sticking to a traditional architectural approach for other pieces. Although \u003ca href\u003d\"/radar/platforms/aws-lambda\"\u003eAWS Lambda\u003c/a\u003e is almost synonymous with serverless, the other major cloud providers all have similar offerings, and we also recommend assessing niche players such as \u003ca href\u003d\"https://webtask.io/\"\u003ewebtask\u003c/a\u003e.\u003c/p\u003e","theta":"100","volume":"2017-03"},{"name":"Client-directed query","id":"1039","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"10","display_name":"Client-directed query","radius":"300","description":"\u003cp\u003eAlthough many problems that people encounter with RESTful approaches to APIs can be attributed to the \u003ca href\u003d\"/radar/techniques/anemic-rest\"\u003eanemic REST\u003c/a\u003e antipattern, some use cases warrant exploration of other approaches. In particular, organizations that have to support a long tail of client applications (and thus a likely proliferation of API versions even if they employ \u003ca href\u003d\"/radar/techniques/consumer-driven-contract-testing\"\u003econsumer-driven contracts\u003c/a\u003e)—and have a large portion of their APIs supporting the endless-list style of activity feeds—may hit some limits in RESTful architectures. These can sometimes be mitigated by employing the \u003cstrong\u003eclient-directed query\u003c/strong\u003e approach to client-server interaction. We see this approach being successfully used in both \u003ca href\u003d\"/radar/languages-and-frameworks/graphql\"\u003eGraphQL\u003c/a\u003e and \u003ca href\u003d\"https://github.com/Netflix/falcor\"\u003eFalcor\u003c/a\u003e, where clients have more control over both the contents and the granularity of the data returned to them. This does put more responsibility onto the service layer and can still lead to tight coupling to the underlying data model, but the benefits may be worth exploring if well-modeled RESTful APIs aren\u0027t working for you.\u003c/p\u003e","theta":"170","volume":"2017-03"},{"name":"Container security scanning","id":"1041","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"11","display_name":"Container security scanning","radius":"290","description":"\u003cp\u003eThe container revolution instigated by \u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e has massively reduced the friction in moving applications between environments but at the same time has blown a rather large hole in the traditional controls over what can go to production. The technique of \u003cstrong\u003econtainer security scanning\u003c/strong\u003e is a necessary response to this threat vector. Docker now provides its own \u003ca href\u003d\"https://blog.docker.com/2016/05/docker-security-scanning/\"\u003esecurity scanning tools\u003c/a\u003e, as does \u003ca href\u003d\"https://coreos.com/blog/vulnerability-analysis-for-containers/\"\u003eCoreOS\u003c/a\u003e, and we\u0027ve also had success with the \u003ca href\u003d\"https://benchmarks.cisecurity.org/\"\u003eCIS Security Benchmarks\u003c/a\u003e. Whichever approach you take, we believe the topic of automated container security validation is of high value and a necessary part of PaaS thinking.\u003c/p\u003e","theta":"160","volume":"2017-03"},{"name":"Conversationally aware APIs","id":"1098","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"12","display_name":"Conversationally aware APIs","radius":"300","description":"\u003cp\u003eTechnologies such as \u003ca href\u003d\"https://developer.amazon.com/alexa\"\u003eAmazon Alexa\u003c/a\u003e, \u003ca href\u003d\"https://voice.google.com\"\u003eGoogle Voice\u003c/a\u003e and Siri have dramatically lowered the bar for voice-based interaction with software. However, a more conversational style of input (voice or text) can be hard to build on top of many existing APIs, especially when it comes to a more stateful style of interaction where a follow-up interaction needs to be aware of the overall conversational context. In this style of interaction, for example, we\u0027d like to inquire about trains from Manchester to Glasgow and then being able to ask \"What time is the first departure?\" without having to give the context of the conversation again. Normally this context would be present in the initial response we send back to a browser, but in the case of voice interfaces we need to handle this context elsewhere. \u003cstrong\u003eConversationally aware APIs\u003c/strong\u003e can be an example of the \u003ca href\u003d\"/radar/techniques/bff-backend-for-frontends\"\u003ebackend for front-end pattern\u003c/a\u003e where the front-end is a voice or chat platform. This type of API can handle the specifics of this style of interaction by managing conversation states while calling underlying services on behalf of the voice front-end.\u003c/p\u003e","theta":"150","volume":"2017-03"},{"name":"Differential privacy","id":"1040","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"13","display_name":"Differential privacy","radius":"335","description":"\u003cp\u003eIt has long been known that \"anonymized\" bulk data sets can reveal information about individuals, especially when multiple data sets are cross-referenced together. With \u003ca href\u003d\"https://www.washingtonpost.com/news/the-switch/wp/2016/05/13/new-government-data-shows-a-staggering-number-of-americans-have-stopped-basic-online-activities/\"\u003eincreasing concern over personal privacy\u003c/a\u003e, some companies—including \u003ca href\u003d\"https://www.wired.com/2016/06/apples-differential-privacy-collecting-data/\"\u003eApple\u003c/a\u003e and \u003ca href\u003d\"http://research.google.com/pubs/pub42852.html\"\u003eGoogle\u003c/a\u003e—are turning to \u003cstrong\u003edifferential privacy\u003c/strong\u003e techniques in order to improve individual privacy while retaining the ability to perform useful analytics on large numbers of users. Differential privacy is a cryptographic technique that attempts to maximize the accuracy of statistical queries from a database while minimizing the chances of identifying its records. These results can be achieved by introducing a low amount of \"noise\" to the data, but it\u0027s important to note that this is an ongoing research area. Apple has announced plans to incorporate differential privacy into its products—and we wholeheartedly applaud its commitment to customers\u0027 privacy—but the usual Apple secrecy has left some security experts \u003ca href\u003d\"https://blog.cryptographyengineering.com/2016/06/15/what-is-differential-privacy/\"\u003escratching their heads\u003c/a\u003e. We continue to recommend \u003ca href\u003d\"http://martinfowler.com/bliki/Datensparsamkeit.html\"\u003eDatensparsamkeit\u003c/a\u003e as an alternative approach: simply storing the minimum data you actually need will achieve better privacy results in most cases.\u003c/p\u003e","theta":"140","volume":"2017-03"},{"name":"Micro frontends","id":"1035","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"14","display_name":"Micro frontends","radius":"310","description":"\u003cp\u003eWe\u0027ve seen significant benefit from introducing \u003ca href\u003d\"/radar/techniques/microservices\"\u003emicroservice architectures\u003c/a\u003e, which have allowed teams to scale delivery of independently deployed and maintained services. However, teams have often struggled to avoid the creation of front-end monoliths—large and sprawling browser applications that are as difficult to maintain and evolve as the monolithic server-side applications we\u0027ve abandoned. We\u0027re seeing an approach emerge that our teams call \u003cstrong\u003emicro frontends\u003c/strong\u003e. In this approach, a web application is broken up by its pages and features, with each feature being owned end-to-end by a single team. Multiple techniques exist to bring the application features—some old and some new—together as a cohesive user experience, but the goal remains to allow each feature to be developed, tested and deployed independently from others. The \u003ca href\u003d\"/radar/techniques/bff-backend-for-frontends\"\u003eBFF - backend for frontends\u003c/a\u003e approach works well here, with each team developing a BFF to support its set of application features.\u003c/p\u003e","theta":"130","volume":"2017-03"},{"name":"Platform engineering product teams","id":"1101","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"15","display_name":"Platform engineering product teams","radius":"300","description":"\u003cp\u003eThe adoption of cloud and DevOps, while increasing the productivity of teams who can now move more quickly with reduced dependency on centralized operations teams and infrastructure, also has constrained teams who lack the skills to self-manage a full application and operations stack. Some organizations have tackled this challenge by creating \u003cstrong\u003eplatform engineering product teams\u003c/strong\u003e. These teams operate an internal platform which enables delivery teams to self-service deploy and operate systems with reduced lead time and stack complexity. The emphasis here is on API-driven self-service and supporting tools, with delivery teams still responsible for supporting what they deploy onto the platform. Organizations that consider establishing such a platform team should be very cautious not to accidentally create a \u003ca href\u003d\"/radar/techniques/separate-devops-team\"\u003eseparate DevOps team\u003c/a\u003e, nor should they simply relabel their \u003ca href\u003d\"/radar/platforms/superficial-private-cloud\"\u003eexisting hosting and operations structure\u003c/a\u003e as a platform.\u003c/p\u003e","theta":"120","volume":"2017-03"},{"name":"Social code analysis","id":"1100","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"16","display_name":"Social code analysis","radius":"290","description":"\u003cp\u003e\u003cstrong\u003eSocial code analysis\u003c/strong\u003e enriches our understanding of the code quality by overlaying a developer\u0027s behavior with the structural analysis of the code. It uses data from version control systems, such as frequency and time of the change as well as the person making the change. You can choose to write your own scripts to analyze such data or use tools such as \u003ca href\u003d\"http://www.empear.com/\"\u003eCodeScene\u003c/a\u003e. CodeScene can help you gain a better understanding of your software systems by identifying hotspots and complex, hard-to-maintain subsystems, coupling between distributed subsystems through temporal coupling, as well as the view of Conway\u0027s law in your organization. We believe that with technology trends such as distributed systems, microservices and distributed teams the social dimension of our code is vital in our holistic understanding of our systems\u0027 health.\u003c/p\u003e","theta":"110","volume":"2017-03"},{"name":"VR beyond gaming","id":"1000","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"17","display_name":"VR beyond gaming","radius":"330","description":"\u003cp\u003eThe idea of virtual reality has been around for more than 50 years, and with successive advancements in computing technology many ideas have been hyped and explored. We believe that we\u0027ve reached a tipping point. Reasonably affordable consumer-oriented VR headsets were shipped to the market last year, and modern graphics cards provide sufficient power to create immersive experiences with them. The headsets are mainly targeted at video game enthusiasts, but we\u0027re convinced that they\u0027ll open the doors to many possibilities for \u003cstrong\u003eVR beyond gaming\u003c/strong\u003e. Teams without experience in building video games should not underestimate the effort and skill required to create good 3-D models and convincing textures.\u003c/p\u003e","theta":"100","volume":"2017-03"},{"name":"A single CI instance for all teams","id":"1004","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"18","display_name":"A single CI instance for all teams","radius":"380","description":"\u003cp\u003eWe\u0027re compelled to caution, again, against creating \u003cstrong\u003ea single CI instance for all teams\u003c/strong\u003e. While it\u0027s a nice idea in theory to consolidate and centralize Continuous Integration (CI) infrastructure, in reality we do not see enough maturity in the tools and products in this space to achieve the desired outcome. Software delivery teams which must use the centralized CI offering regularly have long delays depending on a central team to perform minor configuration tasks, or to troubleshoot problems in the shared infrastructure and tooling. At this stage, we continue to recommend that organizations limit their centralized investment to establishing patterns, guidelines and support for delivery teams to operate their own CI infrastructure.\u003c/p\u003e","theta":"168","volume":"2017-03"},{"name":"Anemic REST","id":"1045","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"19","display_name":"Anemic REST","radius":"375","description":"\u003cp\u003eWith the increasing popularity of the \u003ca href\u003d\"/radar/techniques/bff-backend-for-frontends\"\u003eBFF - Backend for frontends\u003c/a\u003e pattern and use of one-way data-binding frameworks like \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e, we\u0027ve noticed a backlash against REST-style architectures. Critics accuse REST of causing chatty, inefficient interactions among systems and failing to adapt as client needs evolve. They offer frameworks such as \u003ca href\u003d\"/radar/languages-and-frameworks/graphql\"\u003eGraphQL\u003c/a\u003e or \u003ca href\u003d\"https://netflix.github.io/falcor/\"\u003eFalcor\u003c/a\u003e as alternative data-fetch mechanisms that let the client specify the format of the data returned. But in our experience, it isn\u0027t REST that causes these problems. Rather, they stem from a failure to properly model the domain as a set of resources. Naively developing services that simply expose static, hierarchical data models via templated URLs result in an \u003cstrong\u003eanemic REST\u003c/strong\u003e implementation. In a richly modeled domain, REST should enable more than simple repetitive data fetching. In a fully evolved RESTful architecture, business events and abstract concepts are also modeled as resources, and the implementation should make effective use of hypertext, link relations and media types to maximize decoupling between services. This antipattern is closely related to the \u003ca href\u003d\"http://www.martinfowler.com/bliki/AnemicDomainModel.html\"\u003eAnemic Domain Model\u003c/a\u003e pattern and results in services that rank low in \u003ca href\u003d\"http://martinfowler.com/articles/richardsonMaturityModel.html\"\u003eRichardson Maturity Model\u003c/a\u003e. We have more advice for designing effective REST APIs in our \u003ca href\u003d\"https://www.thoughtworks.com/insights/blog/rest-api-design-resource-modeling\"\u003eInsights article\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e.\u003c/p\u003e","theta":"155","volume":"2017-03"},{"name":"Big Data envy","id":"1003","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"20","display_name":"Big Data envy","radius":"360","description":"\u003cp\u003eWe continue to see organizations chasing \"cool\" technologies, taking on unnecessary complexity and risk when a simpler choice would be better. One particular theme is using distributed, Big Data systems for relatively small data sets. This behavior prompts us to put \u003cstrong\u003eBig Data envy\u003c/strong\u003e on hold once more, with some additional data points from our recent experience. The \u003ca href\u003d\"http://cassandra.apache.org/\"\u003eApache Cassandra\u003c/a\u003e database promises massive scalability on commodity hardware, but we have seen teams overwhelmed by its architectural and operational complexity. Unless you have data volumes that require a 100+ node cluster, we recommend against using Cassandra. The operational team you\u0027ll need to keep the thing running just isn\u0027t worth it. While creating this edition of the Radar, we discussed several new database technologies, many offering \"10x\" performance improvements over existing systems. We\u0027re always skeptical until new technology—especially something as critical as a database—has been properly proven. \u003ca href\u003d\"/radar/tools/jepsen\"\u003eJepsen\u003c/a\u003e provides \u003ca href\u003d\"http://jepsen.io/analyses.html\"\u003eanalysis\u003c/a\u003e of database performance under difficult conditions and has found \u003ca href\u003d\"https://aphyr.com/posts/283-call-me-maybe-redis\"\u003enumerous\u003c/a\u003e \u003ca href\u003d\"https://aphyr.com/posts/284-call-me-maybe-mongodb\"\u003ebugs\u003c/a\u003e in various NoSQL databases. We recommend maintaining a healthy dose of skepticism and keeping an eye on sites such as Jepsen when you evaluate database tech.\u003c/p\u003e","theta":"142","volume":"2017-03"},{"name":"CI theatre","id":"1102","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"21","display_name":"CI theatre","radius":"375","description":"\u003cp\u003eWe\u0027ve long been advocates of \u003ca href\u003d\"https://martinfowler.com/articles/continuousIntegration.html\"\u003econtinuous integration\u003c/a\u003e (CI), and we were \u003ca href\u003d\"https://en.wikipedia.org/wiki/CruiseControl\"\u003epioneers\u003c/a\u003e in building CI server programs to automatically build projects on check-ins. Used well, these programs run as a daemon process on a \u003ca href\u003d\"http://www.martinfowler.com/articles/continuousIntegration.html#EveryoneCommitsToTheMainlineEveryDay\"\u003eshared project mainline that developers commit to daily\u003c/a\u003e. The CI server \u003ca href\u003d\"http://www.martinfowler.com/articles/continuousIntegration.html#EveryCommitShouldBuildTheMainlineOnAnIntegrationMachine\"\u003ebuilds the project\u003c/a\u003e and runs \u003ca href\u003d\"http://www.martinfowler.com/articles/continuousIntegration.html#MakeYourBuildSelf-testing\"\u003ecomprehensive tests\u003c/a\u003e to ensure the whole software system is integrated and is in an always-releasable state, thus satisfying the principles of \u003ca href\u003d\"https://continuousdelivery.com/\"\u003econtinuous delivery\u003c/a\u003e. Sadly, many developers simply set up a CI server and falsely assume they are \"doing CI\" when in reality they miss out on all the benefits. Common failure modes include: running CI against a shared mainline but with infrequent commits, so integration isn\u0027t really continuous; running a build with poor test coverage; allowing the build to stay red for long periods; or running CI against feature branches which results in \u003ca href\u003d\"http://paulhammant.com/2017/02/14/fake-news-via-continuous-isolation/\"\u003econtinuous isolation\u003c/a\u003e. The ensuing \" \u003cstrong\u003eCI theatre\u003c/strong\u003e\" might make people feel good, but would fail any credible \u003ca href\u003d\"https://martinfowler.com/bliki/ContinuousIntegrationCertification.html\"\u003eCI certification test\u003c/a\u003e.\u003c/p\u003e","theta":"129","volume":"2017-03"},{"name":"Enterprise-wide integration test environments","id":"1104","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"22","display_name":"Enterprise-wide integration test environments","radius":"375","description":"\u003cp\u003eWhen the enterprise-wide quarterly or monthly releases were considered best practice, it was necessary to maintain a complete environment for performing testing cycles prior to deployment to production. These \u003cstrong\u003eenterprise-wide integration test environments\u003c/strong\u003e (often referred to as SIT or Staging) are a common bottleneck for continuous delivery today. The environments themselves are fragile and expensive to maintain, often with components that need manual configuration by a separate environment management team. Testing in the staging environment provides unreliable and slow feedback, and testing effort is duplicated with what can be performed on components in isolation. We recommend that organizations incrementally create an independent path to production for key components. Important techniques include \u003ca href\u003d\"/radar/techniques/consumer-driven-contract-testing\"\u003econtract testing\u003c/a\u003e, \u003ca href\u003d\"/radar/techniques/decoupling-deployment-from-release\"\u003edecoupling deployment from release\u003c/a\u003e, \u003ca href\u003d\"/radar/techniques/focus-on-mean-time-to-recovery\"\u003efocus on mean time to recovery\u003c/a\u003e and \u003ca href\u003d\"/radar/techniques/qa-in-production\"\u003etesting in production\u003c/a\u003e.\u003c/p\u003e","theta":"116","volume":"2017-03"},{"name":"Spec-based codegen","id":"1127","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"23","display_name":"Spec-based codegen","radius":"375","description":"\u003cp\u003eBack in the days when SOAP held sway in the enterprise software industry, the practice of generating client code from WSDL specs was an accepted—even encouraged—practice. Unfortunately, the resulting code was often complex, untestable, difficult to modify and frequently didn\u0027t work across implementation platforms. With the advent of REST, we found it better to evolve API clients that use the \u003ca href\u003d\"https://martinfowler.com/bliki/TolerantReader.html\"\u003etolerant reader pattern\u003c/a\u003e for extracting and processing only the fields needed. Recently we have observed a disturbing return to old habits with developers generating code from API specifications written in \u003ca href\u003d\"/radar/tools/swagger\"\u003eSwagger\u003c/a\u003e or \u003ca href\u003d\"/radar/tools/raml\"\u003eRAML\u003c/a\u003e—a practice that we refer to as \u003cstrong\u003espec-based codegen\u003c/strong\u003e. Although such tools are very useful for driving the design of APIs and for extracting documentation, we caution against the tempting shortcut of simply generating client code directly from these specifications. The chances are that such code will be difficult to test and maintain.\u003c/p\u003e","theta":"103","volume":"2017-03"},{"name":"HSTS","id":"885","quadrant":"Platforms","ring":"Adopt","movement":"c","radarId":"24","display_name":"HSTS","radius":"120","description":"\u003cp\u003e\u003ca href\u003d\"https://www.owasp.org/index.php/HTTP_Strict_Transport_Security\"\u003eHTTP Strict Transport Security\u003c/a\u003e ( \u003cstrong\u003eHSTS\u003c/strong\u003e ) is a now widely supported policy that allows websites to protect themselves from downgrade attacks. A downgrade attack in the context of HTTPS is one that can cause users of your site to fall back to HTTP rather than HTTPS, allowing for further attacks such as man-in-the-middle attacks. With HSTS, the server sends a header that informs the browser that it should only use HTTPS to access the website. Browser support is now widespread enough that this easy-to-implement feature should be added to any site using HTTPS. Mozilla\u0027s \u003ca href\u003d\"https://observatory.mozilla.org/\"\u003eObservatory\u003c/a\u003e can help identify this and other useful headers and configuration options that improve security and privacy. When implementing HSTS, it is critical to verify that all resources load properly over HTTPS, because once HSTS is turned on, there is (almost) no turning back until the expiry time. The directive to include subdomains should be added but, again, a thorough verification that all subdomains support secure transport is required.\u003c/p\u003e","theta":"210","volume":"2017-03"},{"name":"Linux Security Modules","id":"795","quadrant":"Platforms","ring":"Adopt","movement":"t","radarId":"25","display_name":"Linux Security Modules","radius":"100","description":"\u003cp\u003eThe Principle of Least Privilege encourages us to restrict software components to access only the resources that they need. By default, however, a Linux process can do anything its running user can do—from binding to arbitrary ports to spawning new shells. The \u003cstrong\u003e\u003ca href\u003d\"https://www.kernel.org/doc/Documentation/security/LSM.txt\"\u003eLinux Security Modules\u003c/a\u003e\u003c/strong\u003e (LSM) framework, which allows for security extensions to be plugged into the kernel, has been used to implement MAC on Linux. SELinux and AppArmor are the predominant and best-known LSM-compatible implementations that ship with the kernel. We recommend that teams learn to use one of these security frameworks (which is why we placed it in the Adopt ring). They help teams assess questions about who has access to what resources on shared hosts, including contained services. This conservative approach to access management will help teams build security into their SDLC processes.\u003c/p\u003e","theta":"240","volume":"2017-03"},{"name":"Apache Mesos","id":"796","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"26","display_name":"Apache Mesos","radius":"210","description":"\u003cp\u003eWe\u0027ve continued to have positive experiences deploying the \u003cstrong\u003e\u003ca href\u003d\"http://mesos.apache.org/\"\u003eApache Mesos\u003c/a\u003e\u003c/strong\u003e platform to manage cluster resources for highly distributed systems. Mesos abstracts out underlying computing resources such as CPU and storage, aiming to provide efficient utilization while maintaining isolation. Mesos includes \u003ca href\u003d\"https://mesos.github.io/chronos/\"\u003eChronos\u003c/a\u003e for distributed and fault-tolerant execution of scheduled jobs, and \u003ca href\u003d\"https://mesosphere.github.io/marathon/\"\u003eMarathon\u003c/a\u003e for orchestrating long-running processes in containers.\u003c/p\u003e","theta":"192","volume":"2017-03"},{"name":"Auth0","id":"1006","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"27","display_name":"Auth0","radius":"250","description":"\u003cp\u003eWe have a growing belief that for most scenarios it is rarely worth rolling your own authentication code. Outsourced identity management speeds up delivery, reduces mistakes and tends to enable a faster response to newly discovered vulnerabilities. \u003cstrong\u003e\u003ca href\u003d\"https://auth0.com/\"\u003eAuth0\u003c/a\u003e\u003c/strong\u003e has particularly impressed us in this field for its ease of integration, range of protocols and connectors supported, and rich management API.\u003c/p\u003e","theta":"205","volume":"2017-03"},{"name":"AWS Device Farm","id":"1097","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"28","display_name":"AWS Device Farm","radius":"200","description":"\u003cp\u003eThe huge number of mobile devices makes it almost impossible for companies to test their mobile apps on all of them. Enter \u003cstrong\u003e\u003ca href\u003d\"https://aws.amazon.com/device-farm/\"\u003eAWS Device Farm\u003c/a\u003e\u003c/strong\u003e, an app-testing service that enables you to run and interact with your Android, iOS and web apps on a wide variety of physical devices that are hosted in the cloud simultaneously. Detailed logs, performance graphs and screenshots are generated during each run to provide general and device-specific feedback. The service offers a lot of flexibility by allowing the state and configuration of each device to be altered in order to reproduce very specific test scenarios. Our teams are using AWS Device Farm to run end-to-end tests on devices with the largest install base for their apps.\u003c/p\u003e","theta":"218","volume":"2017-03"},{"name":"AWS Lambda","id":"919","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"29","display_name":"AWS Lambda","radius":"215","description":"\u003cp\u003eOur teams continue to enjoy using \u003cstrong\u003e\u003ca href\u003d\"https://aws.amazon.com/lambda/\"\u003eAWS Lambda\u003c/a\u003e\u003c/strong\u003e and are beginning to use it to experiment with \u003ca href\u003d\"/radar/techniques/serverless-architecture\"\u003eserverless architectures\u003c/a\u003e, combining Lambda with the \u003ca href\u003d\"/radar/platforms/amazon-api-gateway\"\u003eAPI Gateway\u003c/a\u003e. We do recommend that Lambda functions contain only a moderate amount of code. Ensuring the quality of a solution based on a tangle of many large Lambda functions is difficult, and such a solution may not be cost-effective. For more complex needs, deployments based on containers or VMs are still preferable. In addition, we have run into significant problems using Java for Lambda functions, with erratic latencies up to several seconds as the Lambda container is started. Of course, you can sidestep this issue by using JavaScript or Python, and if Lambda functions do not contain a lot of code, the choice of programming language should not matter too much.\u003c/p\u003e","theta":"231","volume":"2017-03"},{"name":"OpenTracing","id":"1095","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"30","display_name":"OpenTracing","radius":"200","description":"\u003cp\u003eAs monolithic applications are being replaced with more complex \u003ca href\u003d\"/radar/techniques/microservices\"\u003e(micro)service\u003c/a\u003e ecosystems, tracing requests across multiple services is becoming the norm. With majority contribution from LightStep and Uber \u003ca href\u003d\"http://opentracing.io/\"\u003e\u003cstrong\u003eOpenTracing\u003c/strong\u003e\u003c/a\u003e is rapidly becoming the de facto standard for distributed tracing. There is a growing number of \u003ca href\u003d\"http://opentracing.io/documentation/pages/supported-tracers\"\u003etracers\u003c/a\u003e supporting OpenTracing standard, including \u003ca href\u003d\"/radar/tools/zipkin\"\u003eZipkin\u003c/a\u003e, \u003ca href\u003d\"/radar/languages-and-frameworks/instana\"\u003eInstana\u003c/a\u003e, and \u003ca href\u003d\"https://uber.github.io/jaeger/\"\u003eJaeger\u003c/a\u003e. OpenTracing currently provides vendor-neutral implementation in multiple languages including: Go, JavaScript, Java, Python, Objective-C, C#, C++, Ruby and PHP.\u003c/p\u003e","theta":"244","volume":"2017-03"},{"name":"Unity beyond gaming","id":"1061","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"31","display_name":"Unity beyond gaming","radius":"180","description":"\u003cp\u003eAfter experiencing years of growth as a platform for game development, \u003cstrong\u003e\u003ca href\u003d\"https://unity3d.com/\"\u003eUnity\u003c/a\u003e\u003c/strong\u003e has recently become the platform of choice for VR and AR application development. Whether you\u0027re creating a fully immersive world for the Oculus or HTC Vive headsets, a holographic layer for your newly spatial enterprise application or an AR feature set for your mobile app, Unity likely provides what you need to both prototype it and get it ready for prime time. Many of us at ThoughtWorks believe that VR and AR represent the next significant shift in the computing platform, and for now, Unity is the single most important tool in the toolbox we use to develop for this change. We\u0027ve used Unity to develop all our VR prototypes, as well as AR functionality for headsets and phone/tablet applications.\u003c/p\u003e","theta":"257","volume":"2017-03"},{"name":".NET Core","id":"866","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"32","display_name":".NET Core","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.microsoft.com/net/core\"\u003e.NET Core\u003c/a\u003e\u003c/strong\u003e is an open source modular product for creating applications that can be easily deployed in Windows, macOS and Linux. .NET Core makes it possible to build cross-platform web applications using \u003ca href\u003d\"http://www.asp.net/core\"\u003eASP.NET Core\u003c/a\u003e with a set of tools, libraries and frameworks—another choice for microservices architecture. The community around .NET Core and other related projects has been growing. New tools have appeared and evolved quickly, such as \u003ca href\u003d\"/radar/tools/visual-studio-code\"\u003eVisual Studio Code\u003c/a\u003e. There are \u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e \u003ca href\u003d\"https://www.microsoft.com/net/core#docker\"\u003eimages\u003c/a\u003e based on both Linux and Windows (\u003ca href\u003d\"/radar/platforms/microsoft-nano-server\"\u003eNano Server\u003c/a\u003e) with .NET Core that simplify applying a microservice architecture. CoreCLR and CoreFX appeared in the Radar in the past. However, a few months ago Microsoft \u003ca href\u003d\"https://blogs.msdn.microsoft.com/dotnet/2016/06/27/announcing-net-core-1-0\"\u003eannounced\u003c/a\u003e the release of .NET Core 1.0, the first stable version. We see good new opportunities, changes and a vibrant community as reasons to keep assessing this product.\u003c/p\u003e","theta":"184","volume":"2017-03"},{"name":"Amazon API Gateway","id":"989","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"33","display_name":"Amazon API Gateway","radius":"315","description":"\u003cp\u003e\u003ca href\u003d\"https://aws.amazon.com/api-gateway/\"\u003e\u003cstrong\u003eAmazon API Gateway\u003c/strong\u003e\u003c/a\u003e enables developers to expose API services to Internet clients. It offers the usual API gateway features including traffic management, monitoring, authentication and authorization. Our teams have had positive experiences using this service to front \u003ca href\u003d\"/radar/platforms/aws-lambda\"\u003eAWS Lambda\u003c/a\u003e as part of \u003ca href\u003d\"/radar/techniques/serverless-architecture\"\u003eserverless architectures\u003c/a\u003e. On the other hand, we have had more challenges using it as a more general purpose gateway to front HTTP/HTTPS endpoints running on EC2—where we have been stymied by a lack of interoperability with VPCs and difficulty in establishing client cert authentication with the gateway. Due to this mixed experience, we would like to advise teams to trial using AWS API Gateway with Lambda but assess suitability when using it in a more general setting.\u003c/p\u003e","theta":"188","volume":"2017-03"},{"name":"api.ai","id":"1085","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"34","display_name":"api.ai","radius":"300","description":"\u003cp\u003eIn parallel with the recent surge of chatbots and \u003ca href\u003d\"/radar/platforms/voice-platforms\"\u003evoice platforms\u003c/a\u003e, we\u0027ve seen a proliferation of tools and platforms such as \u003cstrong\u003e\u003ca href\u003d\"https://api.ai/\"\u003eapi.ai\u003c/a\u003e\u003c/strong\u003e that provide a service to extract intent from text and management of conversational flow that you can hook into. Recently acquired by Google, this \"natural-language-understanding as a service\" offering competes with other players in this space such as \u003ca href\u003d\"/radar/platforms/wit-ai\"\u003ewit.ai\u003c/a\u003e and Amazon\u0027s \u003ca href\u003d\"https://aws.amazon.com/lex/\"\u003eLex\u003c/a\u003e.\u003c/p\u003e","theta":"192","volume":"2017-03"},{"name":"Cassandra carefully","id":"1011","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"35","display_name":"Cassandra carefully","radius":"285","description":"\u003cp\u003eApache\u0027s \u003ca href\u003d\"http://cassandra.apache.org/\"\u003eCassandra\u003c/a\u003e database is a powerful, scalable Big Data solution for storing and processing large amounts of data, often using hundreds of nodes split over multiple worldwide locations. It\u0027s a great tool and we like it, but too often we see teams run into trouble using it. We recommend using \u003cstrong\u003eCassandra carefully\u003c/strong\u003e. Teams often misunderstand the use case for Cassandra, attempting to use it as a general-purpose data store when in fact it is optimized for fast reads on large data sets based on predefined keys or indexes. Its dependence on the storage schema can also make it difficult to evolve over time. Cassandra also has significant operational complexity and some rough edges, so unless you absolutely need the scaling it provides, a simpler solution is usually better. If you don\u0027t need Cassandra\u0027s specific use-case and scaling characteristics, you might just be choosing it out of \u003ca href\u003d\"/radar/techniques/big-data-envy\"\u003eBig Data envy\u003c/a\u003e. Careful use of Cassandra will include extensive automated testing, and we\u0027re happy to recommend \u003ca href\u003d\"https://github.com/jsevellec/cassandra-unit\"\u003eCassandraUnit\u003c/a\u003e as part of your testing strategy.\u003c/p\u003e","theta":"196","volume":"2017-03"},{"name":"Cloud-based image comprehension","id":"1093","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"36","display_name":"Cloud-based image comprehension","radius":"300","description":"\u003cp\u003eImage comprehension used to be a dark art and required a team of onsite data scientists. In recent years, however, we\u0027ve come closer to solving problems such as image and facial classification/categorization, facial comparisons, facial landmark identification, and facial recognition. \u003cstrong\u003eCloud-based image comprehension\u003c/strong\u003e provides access to machine-learning capabilities through services such as \u003ca href\u003d\"https://aws.amazon.com/rekognition/\"\u003eAmazon\u003c/a\u003e\u003ca href\u003d\"https://aws.amazon.com/rekognition/\"\u003eRekognition\u003c/a\u003e, \u003ca href\u003d\"https://www.microsoft.com/cognitive-services/en-us/computer-vision-api\"\u003eMicrosoft Computer Vision API\u003c/a\u003e and \u003ca href\u003d\"https://cloud.google.com/vision/\"\u003eGoogle Cloud Vision API\u003c/a\u003e which can supplement AR applications and anything involving photo tagging and classification.\u003c/p\u003e","theta":"200","volume":"2017-03"},{"name":"DataStax Enterprise Graph","id":"1087","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"37","display_name":"DataStax Enterprise Graph","radius":"300","description":"\u003cp\u003eWe\u0027ve had some early successes with \u003ca href\u003d\"http://www.datastax.com/products/datastax-enterprise-graph\"\u003e\u003cstrong\u003eDataStax Enterprise Graph\u003c/strong\u003e\u003c/a\u003e (DSE Graph) for handling large graph databases. Built on top of \u003ca href\u003d\"/radar/platforms/cassandra-carefully\"\u003eCassandra\u003c/a\u003e, DSE Graph targets the type of large data sets where our longtime favorite \u003ca href\u003d\"/radar/platforms/neo4j\"\u003eNeo4j\u003c/a\u003e begins to show some limitations. This scale has its trade-offs; for example, you lose the ACID transactions and run-time schema-free nature of Neo4j, but access to the underlying Cassandra tables, the integration of Spark for analytical workloads, and the powerful \u003ca href\u003d\"http://tinkerpop.apache.org/\"\u003eTinkerPop/Gremlin\u003c/a\u003e query language make this an option worth considering.\u003c/p\u003e","theta":"204","volume":"2017-03"},{"name":"Electron","id":"1012","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"38","display_name":"Electron","radius":"330","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://electron.atom.io/\"\u003eElectron\u003c/a\u003e\u003c/strong\u003e is a solid framework for building native desktop clients using web technologies such as HTML, CSS and JavaScript. Teams can leverage their web know-how to deliver polished cross-platform desktop clients without spending time learning another set of technologies.\u003c/p\u003e","theta":"208","volume":"2017-03"},{"name":"Ethereum","id":"1014","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"39","display_name":"Ethereum","radius":"338","description":"\u003cp\u003eThe hype seems to have peaked for blockchains and cryptocurrencies, as evidenced by the slowdown of previous firehose-scale announcements in this area, and we expect some of the more speculative efforts to die out over time. One of the blockchains, \u003ca href\u003d\"https://www.ethereum.org/\"\u003e\u003cstrong\u003eEthereum\u003c/strong\u003e\u003c/a\u003e, while not universally popular among diehard blockchain aficionados, appears in increasing numbers in new initiatives. Ethereum is a public blockchain with a built-in programming language allowing developers to build \"smart contracts\", which are algorithmic movements of ether (the Ethereum cryptocurrency) in response to activity happening on the blockchain. R3CEV, the consortium building blockchain tech for banks, built its first proofs of concept on Ethereum. Ethereum has been used to build a distributed autonomous organization (DAO)—one of the first \"algorithmic corporations\"—although a recent heist of \u003ca href\u003d\"http://www.coindesk.com/dao-attacked-code-issue-leads-60-million-ether-theft/\"\u003e$150 million in the ether\u003c/a\u003e demonstrates that the blockchains and cryptocurrencies are still the Wild West of the technology world.\u003c/p\u003e","theta":"212","volume":"2017-03"},{"name":"Hyperledger","id":"1075","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"40","display_name":"Hyperledger","radius":"330","description":"\u003cp\u003e\u003cstrong\u003eHyperledger\u003c/strong\u003e is a platform built around blockchain technologies. It consists of a blockchain implementation named Fabric and other associated tools. Disregarding the hype surrounding blockchain, our teams have found it easy to get started with these tools. The fact that it is an open source platform supported by the Linux Foundation also adds to our excitement about Hyperledger.\u003c/p\u003e","theta":"216","volume":"2017-03"},{"name":"IndiaStack","id":"1010","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"41","display_name":"IndiaStack","radius":"338","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://www.indiastack.org\"\u003eIndiaStack\u003c/a\u003e\u003c/strong\u003e is a set of Open APIs designed with the goal of transforming India from a data-poor to a data-rich country. The stack emphasizes layered innovation by specifying a minimal set of APIs and encourages the rest of the ecosystem to build custom applications on top of these APIs. \u003ca href\u003d\"http://www.indiastack.org/Resource#Aadhaar\"\u003eAadhaar\u003c/a\u003e serves as one of the foundation layers, providing authentication services for more than a billion Indian citizens. In addition, there are services to provide paperless transactions through digital signatures (eSign), unified online payment (UPI) and an electronic consent layer ((e-KYC)[https://uidai.gov.in/ecosystem/authentication-devices-documents/about-aadhaar-paperless-offline-e-kyc.html]) to securely provide Aadhaar details to service providers. We believe in the Open API–driven initiative to bring digital innovation, and the design principles behind IndiaStack could be used as a change agent for other regions/countries.\u003c/p\u003e","theta":"220","volume":"2017-03"},{"name":"Kafka Streams","id":"1058","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"42","display_name":"Kafka Streams","radius":"300","description":"\u003cp\u003e\u003cstrong\u003eKafka Streams\u003c/strong\u003e is a lightweight library for building streaming applications. It\u0027s been designed with the goal of simplifying stream processing enough to make it easily accessible as a mainstream application programming model for asynchronous services. It can be a good alternative in scenarios where you want to apply a stream processing model to your problem without embracing the complexity of running a cluster (usually introduced by full-fledged stream processing frameworks).\u003c/p\u003e","theta":"225","volume":"2017-03"},{"name":"Keycloak","id":"1086","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"43","display_name":"Keycloak","radius":"300","description":"\u003cp\u003eIn a \u003ca href\u003d\"/radar/techniques/microservices\"\u003emicroservices\u003c/a\u003e or any other distributed architecture, one of the most common needs is to secure the services or APIs through authentication and authorization features. This is where \u003cstrong\u003e\u003ca href\u003d\"http://www.keycloak.org/\"\u003eKeycloak\u003c/a\u003e\u003c/strong\u003e comes in. Keycloak is an open source identity and access management solution that makes it easy to secure applications or microservices with little to no code. Out of the box, it supports single sign-on, social login, and standard protocols such as OpenID Connect, OAuth2 and SAML.\u003c/p\u003e","theta":"229","volume":"2017-03"},{"name":"Mesosphere DCOS","id":"889","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"44","display_name":"Mesosphere DCOS","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://mesosphere.com/product/\"\u003eMesosphere DCOS\u003c/a\u003e\u003c/strong\u003e is a platform built on top of \u003ca href\u003d\"/radar/platforms/apache-mesos\"\u003eMesos\u003c/a\u003e that abstracts away your underlying infrastructure for containerized applications as well as for applications you don\u0027t want to run inside Docker. This may be overkill for more modest deployments, but we\u0027re beginning to see successes with both the commercial and \u003ca href\u003d\"https://dcos.io/\"\u003eopen source versions\u003c/a\u003e. We particularly like that it facilitates portability between different cloud providers as well as dedicated hardware, and that for containerized workloads you\u0027re not tied into one container orchestration framework. Although upgrades can be a little more complex than we would like, the overall stack is stabilizing nicely.\u003c/p\u003e","theta":"233","volume":"2017-03"},{"name":"Mosquitto","id":"1090","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"45","display_name":"Mosquitto","radius":"300","description":"\u003cp\u003eIn our experience—for Internet of Things (IoT) solutions where a lot of devices communicate with each other and/or a central data hub—the MQTT connectivity protocol has proven itself. We\u0027ve also come to like the \u003cstrong\u003e\u003ca href\u003d\"http://mosquitto.org/\"\u003eMosquitto\u003c/a\u003e\u003c/strong\u003e MQTT broker. It might not satisfy all demands, particularly with regard to scalability, but its compact nature and easy setup makes it ideal for development and testing purposes.\u003c/p\u003e","theta":"237","volume":"2017-03"},{"name":"Nuance Mix","id":"1017","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"46","display_name":"Nuance Mix","radius":"338","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://developer.nuance.com/public/index.php?task\u003dmix\"\u003eNuance Mix\u003c/a\u003e\u003c/strong\u003e is a framework for natural language processing from the company that created the speech-to-text technology behind Dragon Speaking and the first roll-out of Siri. This framework supports the creation of grammars that allow for free-form user interaction via voice. The developer defines a domain-specific grammar that the framework can train itself to understand. The outcomes are responses to user input that identify the user\u0027s intents and interaction concepts. At first, it is limited to phrases close to the ones used to train it, but over time it can start to identify meaning from more divergent phrasing. Though it is still in beta, the accuracy from early exploration has been compelling, and the eventual product is one to watch for application forms that could benefit from hands-free user interaction—including mobile, IoT, AR, VR and interactive spaces.\u003c/p\u003e","theta":"241","volume":"2017-03"},{"name":"OpenVR","id":"1053","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"47","display_name":"OpenVR","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/ValveSoftware/openvr\"\u003eOpenVR\u003c/a\u003e\u003c/strong\u003e is the underlying SDK in making many of the VR head-mounted displays (HMDs) work with Unity and will likely keep growing in importance. Much of the VR work at ThoughtWorks was built on top of OpenVR, because it will run on any HMD, unlike the other SDKs. Though it is not open source, it is free via the license. The Oculus SDK is more restrictive in its licensing and only works on Oculus devices. \u003ca href\u003d\"https://osvr.github.io/\"\u003eOSVR\u003c/a\u003e, while truly open source, doesn\u0027t seem to have as much adoption yet. If you\u0027re going to develop a VR application and target as many devices as possible—and not use Unity or Unreal to develop them—OpenVR is the most concrete and pragmatic solution right now.\u003c/p\u003e","theta":"245","volume":"2017-03"},{"name":"PlatformIO","id":"1089","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"48","display_name":"PlatformIO","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://platformio.org/\"\u003ePlatformIO\u003c/a\u003e\u003c/strong\u003e provides a rich ecosystem for IoT development by providing cross-platform builds, library management and good integration with existing IDEs. The intelligent code completion and Smart Code Linter with built-in terminal and serial port monitor greatly enhances the developer experience. It also organizes and maintains \u003ca href\u003d\"http://platformio.org/lib\"\u003ethousands of libraries\u003c/a\u003e and provides a clean dependency manager with semantic versioning to ease IoT development. We\u0027ve started using PlatformIO in a few IoT projects and we really like it for its simplicity and wide support of \u003ca href\u003d\"http://platformio.org/platforms\"\u003eplatforms\u003c/a\u003e and \u003ca href\u003d\"http://platformio.org/boards\"\u003eboards\u003c/a\u003e.\u003c/p\u003e","theta":"249","volume":"2017-03"},{"name":"Tango","id":"1088","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"49","display_name":"Tango","radius":"300","description":"\u003cp\u003eAlongside virtual reality (VR), which has a relatively high bar to entry due to hardware requirements and the effort to create virtual worlds, alternate reality (AR) and mixed reality (MR) also entered into the mainstream last year. Pokémon Go provided evidence that regular smartphones are sufficient to create compelling AR/MR experiences. \u003cstrong\u003e\u003ca href\u003d\"https://en.wikipedia.org/wiki/Tango_(platform)\"\u003eTango\u003c/a\u003e\u003c/strong\u003e is a new hardware sensor technology for mobile phones that further enhances the possibilities for AR/MR on phones. It allows apps to acquire detailed 3-D measurements of the user\u0027s surroundings so that virtual objects can be placed and rendered more convincingly on the camera feed. The first phones with Tango technology are now available.\u003c/p\u003e","theta":"253","volume":"2017-03"},{"name":"Voice platforms","id":"1091","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"50","display_name":"Voice platforms","radius":"300","description":"\u003cp\u003e\u003cstrong\u003eVoice platforms\u003c/strong\u003e such as \u003ca href\u003d\"https://developer.amazon.com/alexa\"\u003eAmazon Alexa\u003c/a\u003e and \u003ca href\u003d\"https://developers.google.com/actions/\"\u003eGoogle Home\u003c/a\u003e are riding high on the hype cycle; some even herald the ubiquity of the conversational voice interface. We\u0027re already integrating conversational UIs into products and seeing the impact of this new interaction in how we design interfaces. Alexa specifically was built from the ground up without a screen and treats the conversational UI as first-class. But it\u0027s still too early to believe the hype, and we expect more big players to get in the game.\u003c/p\u003e","theta":"257","volume":"2017-03"},{"name":"WebVR","id":"1094","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"51","display_name":"WebVR","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://webvr.info/\"\u003eWebVR\u003c/a\u003e\u003c/strong\u003e is an experimental JavaScript API that enables you to access VR devices through your browser. It has garnered support from the community and is available through nightly builds as well as in some release versions. If you are looking to build VR experiences in your browser, then this is a great place to start. This technology alongside complementary tools such \u003ca href\u003d\"/radar/languages-and-frameworks/three-js\"\u003eThree.js\u003c/a\u003e, \u003ca href\u003d\"https://aframe.io/\"\u003eA-Frame\u003c/a\u003e, \u003ca href\u003d\"https://github.com/facebookincubator/react-vr\"\u003eReactVR\u003c/a\u003e, \u003ca href\u003d\"https://github.com/argonjs/argon\"\u003eArgon.js\u003c/a\u003e and \u003ca href\u003d\"https://github.com/awe-media/awe.js\"\u003eAwe.js\u003c/a\u003e brings AR experiences to the browser. The flurry of tools in this space, alongside Internet commission standards, could help promote stronger adoption of AR and VR.\u003c/p\u003e","theta":"261","volume":"2017-03"},{"name":"wit.ai","id":"1069","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"52","display_name":"wit.ai","radius":"335","description":"\u003cp\u003eHype surrounding machine intelligence has reached a crescendo, but as with Big Data, useful frameworks and tools are waiting to be discovered among all the hot air. One such tool is \u003ca href\u003d\"https://wit.ai/\"\u003e\u003cstrong\u003ewit.ai\u003c/strong\u003e\u003c/a\u003e, a SaaS platform that allows developers to create conversational interfaces using natural language processing (NLP). Wit works with either text or speech inputs, helps developers manage conversational intent and allows custom business logic to be implemented using JavaScript. The system is free for commercial and noncommercial use and encourages the creation of open applications. Be aware that you must agree to let Wit use your data in order to improve the service and for its own analysis, so read the \u003ca href\u003d\"https://wit.ai/terms\"\u003eterms and conditions\u003c/a\u003e carefully. Another contender in this space is the \u003ca href\u003d\"https://dev.botframework.com/\"\u003eMicrosoft Bot Framework\u003c/a\u003e, but it\u0027s available only in limited preview form as of this writing. As with most things Microsoft, we expect the Bot Framework to evolve quickly, so it\u0027s worth keeping an eye on.\u003c/p\u003e","theta":"265","volume":"2017-03"},{"name":"CMS as a platform","id":"696","quadrant":"Platforms","ring":"Hold","movement":"c","radarId":"53","display_name":"CMS as a platform","radius":"385","description":"\u003cp\u003eWe are seeing too many organizations run into trouble as they attempt to use their \u003cstrong\u003eCMS as a platform\u003c/strong\u003e for delivering large and complex digital applications. This is often driven by the vendor-fueled hope of bypassing unresponsive IT organizations and enabling the business to drag and drop changes directly to production. While we are very supportive of providing content producers with the right tools and workflows, for applications with complex business logic we tend to recommend treating your CMS as a component of your platform (often in a hybrid or headless mode) cooperating cleanly with other services, rather than attempting to implement all of your functionality in the CMS itself.\u003c/p\u003e","theta":"210","volume":"2017-03"},{"name":"Overambitious API gateways","id":"931","quadrant":"Platforms","ring":"Hold","movement":"c","radarId":"54","display_name":"Overambitious API gateways","radius":"375","description":"\u003cp\u003eOne of our regular complaints is about business smarts implemented in middleware, resulting in transport software with ambitions to run critical application logic. Vendors in the highly competitive API gateway market continue to add features that differentiate their products. This results in \u003cstrong\u003eoverambitious API gateway\u003c/strong\u003e products whose functionality—on top of what is essentially a reverse proxy—encourages designs that are difficult to test and deploy. API gateways can provide utility in dealing with some generic concerns—for example, authentication and rate-limiting—but any domain smarts such as data transformation or rule processing should live in applications or services where they can be controlled by product teams working closely with the domains they support.\u003c/p\u003e","theta":"240","volume":"2017-03"},{"name":"fastlane","id":"1018","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"55","display_name":"fastlane","radius":"75","description":"\u003cp\u003eWeb application developers have it easy when it comes to simplifying and automating diverse application workflows; they can choose from a variety of solutions to help automate release processes. When developing for mobile, however, we\u0027re dealing with two operating systems with two different ways of building, testing, distribution, generating screenshots, signing and distributing applications. To help ease the pain, our teams have adopted \u003cstrong\u003e\u003ca href\u003d\"https://fastlane.tools/\"\u003efastlane\u003c/a\u003e\u003c/strong\u003e as the go-to tool to automate the release process for iOS and Android applications. Using simple configurations and multiple pipelines, they can achieve \u003ca href\u003d\"/radar/techniques/continuous-delivery-cd\"\u003econtinuous delivery\u003c/a\u003e for mobile development.\u003c/p\u003e","theta":"60","volume":"2017-03"},{"name":"Grafana","id":"1019","quadrant":"Tools","ring":"Adopt","movement":"c","radarId":"56","display_name":"Grafana","radius":"75","description":"\u003cp\u003eWhen combining modern techniques and architecture styles, such as \u003ca href\u003d\"/radar/techniques/microservices\"\u003emicroservices\u003c/a\u003e, \u003ca href\u003d\"/radar/techniques/devops\"\u003eDevOps\u003c/a\u003e and \u003ca href\u003d\"/radar/techniques/qa-in-production\"\u003eQA in production\u003c/a\u003e, development teams need increasingly sophisticated monitoring. Simply looking a graphs of disk usage and CPU utilization is not sufficient anymore, and many teams collect application and business-specific metrics using tools such a Graphite and Kibana. \u003cstrong\u003e\u003ca href\u003d\"http://grafana.org/\"\u003eGrafana\u003c/a\u003e\u003c/strong\u003e makes it easy to create useful and elegant dashboards for data from a number of sources. A particularly useful feature allows timescales of different graphs to be synchronized, which helps with spotting correlations in the underlying data. The templating system that is being added shows a lot promise and will likely make managing sets of similar services even easier. Based on its strengths, Grafana has become our default choice in this category.\u003c/p\u003e","theta":"30","volume":"2017-03"},{"name":"Airflow","id":"1125","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"57","display_name":"Airflow","radius":"210","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://airflow.incubator.apache.org/\"\u003eAirflow\u003c/a\u003e\u003c/strong\u003e is a tool to programmatically create, schedule and monitor data pipelines. By treating Directed Acyclic Graphs (DAGs) as code, it encourages maintainable, versionable and testable data pipelines. We\u0027ve leveraged this configuration in our projects to create dynamic pipelines that resulted in lean and explicit data workflows. Airflow makes it easy to define your operators and executors and to extend the library so that it fits the level of abstraction that suits your environment.\u003c/p\u003e","theta":"81","volume":"2017-03"},{"name":"Cake and Fake","id":"1123","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"58","display_name":"Cake and Fake","radius":"220","description":"\u003cp\u003eMSBuild has been the primary build system in the .NET ecosystem since its introduction in 2005; however, it suffers from many of the same weaknesses we\u0027ve previously called out in \u003ca href\u003d\"/radar/tools/maven\"\u003eMaven\u003c/a\u003e. The .NET community has started to develop alternatives to MSBuild which are easier to maintain and more flexible, and evolve more fluidly as a project grows. Two of these alternatives are \u003cstrong\u003e\u003ca href\u003d\"http://cakebuild.net/\"\u003eCake\u003c/a\u003e and \u003ca href\u003d\"https://fake.build/\"\u003eFake\u003c/a\u003e\u003c/strong\u003e. Cake uses a DSL built in C#, while Fake uses F#. Each has seen significant growth over the last year and has proven to be a viable alternative to MSBuild for orchestrating common build tasks in .NET projects.\u003c/p\u003e","theta":"72","volume":"2017-03"},{"name":"Galen","id":"1068","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"59","display_name":"Galen","radius":"250","description":"\u003cp\u003eTesting that layout and styling of responsive websites is working as expected across various form factors can be a slow and often manual process. \u003cstrong\u003e\u003ca href\u003d\"http://galenframework.com/\"\u003eGalen\u003c/a\u003e\u003c/strong\u003e helps ease this problem by providing a simple language, running on top of \u003ca href\u003d\"http://www.seleniumhq.org/\"\u003eSelenium\u003c/a\u003e, that allows you to specify expectations for the appearance of your website in various screen sizes. Although Galen suffers from the typical brittleness and speed issues of any end-to-end testing approach, we have found benefit in the early feedback on design issues.\u003c/p\u003e","theta":"63","volume":"2017-03"},{"name":"HashiCorp Vault","id":"969","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"60","display_name":"HashiCorp Vault","radius":"160","description":"\u003cp\u003eHaving a way to securely manage secrets is increasingly becoming a huge project issue. The old practice of keeping secrets in a file or in environment variables is becoming hard to manage, especially in environments with multiple applications and large numbers of \u003ca href\u003d\"/radar/techniques/microservices\"\u003emicroservices\u003c/a\u003e. \u003ca href\u003d\"https://github.com/hashicorp/vault\"\u003e\u003cstrong\u003eHashiCorp Vault\u003c/strong\u003e\u003c/a\u003e addresses the problem by providing mechanisms for securely accessing secrets through a unified interface. It has served us well on a number of projects, and our teams liked how easy it was to integrate Vault with their services. Storing and updating secrets is a bit cumbersome, because it relies on a command-line tool and a fair amount of discipline from the team.\u003c/p\u003e","theta":"54","volume":"2017-03"},{"name":"Pa11y","id":"1025","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"61","display_name":"Pa11y","radius":"190","description":"\u003cp\u003e\u003ca href\u003d\"http://pa11y.org/\"\u003e\u003cstrong\u003ePa11y\u003c/strong\u003e\u003c/a\u003e is an automatic accessibility tester that can run from the command line and be embedded into a build pipeline. Our teams have had success using Pa11y on a highly dynamic site by first creating a static HTML version, then running the accessibility tests against that. For many systems—especially government websites—accessibility testing is a requirement, and Pa11y makes it all a lot easier.\u003c/p\u003e","theta":"45","volume":"2017-03"},{"name":"Scikit-learn","id":"1033","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"62","display_name":"Scikit-learn","radius":"180","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://scikit-learn.org/stable/\"\u003eScikit-learn\u003c/a\u003e\u003c/strong\u003e is not a new tool (it is approaching its tenth birthday); what is new is the rate of adoption of machine-learning tools and techniques outside of academia and major tech companies. Providing a robust set of models and a rich set of functionality, Scikit-learn plays an important role in making machine-learning concepts and capabilities more accessible to a broader (and often non-expert) audience.\u003c/p\u003e","theta":"36","volume":"2017-03"},{"name":"Serverless Framework","id":"1120","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"63","display_name":"Serverless Framework","radius":"175","description":"\u003cp\u003eThe popular \u003cstrong\u003e\u003ca href\u003d\"https://serverless.com/\"\u003eServerless Framework\u003c/a\u003e\u003c/strong\u003e provides tooling for scaffolding and deployment of serverless applications, primarily using \u003ca href\u003d\"/radar/platforms/aws-lambda\"\u003eAWS Lambda\u003c/a\u003e and other AWS offerings. Serverless Framework provides template support for JavaScript, Python, Java and C#, and has an active community that contributes plugins that extend the framework. The framework also supports the Apache incubator project OpenWhisk as an alternative to AWS Lambda.\u003c/p\u003e","theta":"27","volume":"2017-03"},{"name":"Talisman","id":"1022","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"64","display_name":"Talisman","radius":"160","description":"\u003cp\u003eWith the maturity of tools such as \u003ca href\u003d\"/radar/tools/hashicorp-vault\"\u003eVault\u003c/a\u003e, there is no longer an excuse for storing secrets in code repositories, particularly since this often ends up being the soft underbelly of important systems. We\u0027ve previously mentioned repository-scanning tools such as \u003ca href\u003d\"/radar/tools/gitrob\"\u003eGitrob\u003c/a\u003e, but we are now pushing proactive tools such as (the ThoughtWorks-created) \u003cstrong\u003e\u003ca href\u003d\"https://github.com/thoughtworks/talisman\"\u003eTalisman\u003c/a\u003e\u003c/strong\u003e, which is a prepush hook for Git that scans commits for secrets matching predefined patterns.\u003c/p\u003e","theta":"18","volume":"2017-03"},{"name":"Terraform","id":"815","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"65","display_name":"Terraform","radius":"220","description":"\u003cp\u003eWith \u003cstrong\u003e\u003ca href\u003d\"https://www.terraform.io/\"\u003eTerraform\u003c/a\u003e\u003c/strong\u003e, you can manage cloud infrastructure by writing declarative definitions. The configuration of the servers instantiated by Terraform is usually left to tools like Puppet, Chef or Ansible. We like Terraform because the syntax of its files is quite readable and because it supports a number of cloud providers while making no attempt to provide an artificial abstraction across those providers. Following our first, more cautious, mention of Terraform almost two years ago, it has seen continued development and has evolved into a stable product that has proven its value in our projects. The issue with state file management can now be sidestepped by using what Terraform calls a \"remote state backend.\" We\u0027ve successfully used \u003ca href\u003d\"/radar/tools/consul\"\u003eConsul\u003c/a\u003e for that purpose.\u003c/p\u003e","theta":"9","volume":"2017-03"},{"name":"Amazon Rekognition","id":"1114","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"66","display_name":"Amazon Rekognition","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://aws.amazon.com/rekognition/\"\u003eAmazon Rekognition\u003c/a\u003e\u003c/strong\u003e is one of the cloud-based image comprehension tools we\u0027ve mentioned elsewhere in this Radar. What we like about it is that Amazon has taken a somewhat novel approach to making faces anonymous (using GUIDs) from AWS to accommodate some of the privacy concerns that come with facial recognition.\u003c/p\u003e","theta":"84","volume":"2017-03"},{"name":"Android-x86","id":"1030","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"67","display_name":"Android-x86","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://www.android-x86.org/\"\u003eAndroid-x86\u003c/a\u003e\u003c/strong\u003e is a port of the \u003ca href\u003d\"http://source.android.com/\"\u003eAndroid open source\u003c/a\u003e project to x86 platforms. The project started by hosting various patches from the community for x86 support but then later created its own codebase to provide support for different x86 platforms. We have seen significant time savings by utilizing Android-x86 in our CI servers instead of emulators for hermetic UI testing. However, for UI-specific tests targeting a particular device resolution—simulating low memory, bandwidth and battery—it is better to stick with emulators.\u003c/p\u003e","theta":"77","volume":"2017-03"},{"name":"Bottled Water","id":"1032","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"68","display_name":"Bottled Water","radius":"320","description":"\u003cp\u003eWith the growth of interest in streaming data architectures and the downstream data lakes they feed, we have seen an increased reliance on \"change data capture\" tooling to connect transactional data stores to stream-processing systems. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/confluentinc/bottledwater-pg\"\u003eBottled Water\u003c/a\u003e\u003c/strong\u003e is a welcome addition to this field, converting changes in \u003ca href\u003d\"/radar/platforms/postgresql-for-nosql\"\u003ePostgreSQL\u003c/a\u003e\u0027s write-ahead log into \u003ca href\u003d\"/radar/tools/apache-kafka\"\u003eKafka\u003c/a\u003e events. One downside of this approach, however, is that you are tied to low-level database events rather than the higher-level \u003ca href\u003d\"/radar/techniques/capture-domain-events-explicitly\"\u003ebusiness events\u003c/a\u003e we recommend as the foundation for an event-oriented architecture.\u003c/p\u003e","theta":"70","volume":"2017-03"},{"name":"Claudia","id":"1108","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"69","display_name":"Claudia","radius":"320","description":"\u003cp\u003eThe combination of \u003ca href\u003d\"/radar/platforms/aws-lambda\"\u003eAWS Lambda\u003c/a\u003e with \u003ca href\u003d\"/radar/platforms/amazon-api-gateway\"\u003eAmazon API Gateway\u003c/a\u003e has had a big impact on how we deploy services and APIs. However, even in this serverless configuration, the amount of configuration required to wire things together is not trivial. \u003cstrong\u003e\u003ca href\u003d\"https://claudiajs.com/\"\u003eClaudia\u003c/a\u003e\u003c/strong\u003e is a tool which automates deployment of AWS Lambda functions written in JavaScript and associated API Gateway configurations. It provides reasonable defaults, and our teams have found it allows them to get started quickly with Lambda-based microservices.\u003c/p\u003e","theta":"63","volume":"2017-03"},{"name":"Clojure.spec","id":"1031","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"70","display_name":"Clojure.spec","radius":"305","description":"\u003cp\u003eOne of those perpetual developer debates involves language typing: How much is just right? \u003ca href\u003d\"/radar/languages-and-frameworks/clojure\"\u003eClojure\u003c/a\u003e, the dynamically typed functional Lisp on the JVM, added a new entry into this discussion that blurs the lines. \u003cstrong\u003e\u003ca href\u003d\"https://clojure.org/about/spec\"\u003eClojure.spec\u003c/a\u003e\u003c/strong\u003e is a new facility built into Clojure that allows developers to wrap type and other verification criteria around data structures, such as allowable value ranges. Once they are established, Clojure uses these specifications to provide a slew of benefits: generated tests, validation, destructuring of data structures and others. Clojure.spec is a promising way to have the benefits of types and ranges where developers need them but not everywhere.\u003c/p\u003e","theta":"56","volume":"2017-03"},{"name":"InSpec","id":"1113","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"71","display_name":"InSpec","radius":"310","description":"\u003cp\u003eHow does a business hand autonomy to delivery teams while still making sure their deployed solutions are safe and compliant? How do you ensure that servers, once deployed, remain secure and compliant over their operational lifetime? These are the problems that \u003cstrong\u003eInSpec\u003c/strong\u003e tries to address. InSpec is an infrastructure testing tool inspired by \u003ca href\u003d\"/radar/tools/serverspec\"\u003eServerspec\u003c/a\u003e, but with modifications that make the tool more useful for security professionals who need to ensure compliance across thousands of servers. Individual tests can be combined into complete security profiles and run remotely from a command line. InSpec is useful for developers but extends to testing deployed production infrastructure continuously, moving toward \u003ca href\u003d\"/radar/techniques/qa-in-production\"\u003eQA in production\u003c/a\u003e.\u003c/p\u003e","theta":"49","volume":"2017-03"},{"name":"Molecule","id":"1116","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"72","display_name":"Molecule","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/metacloud/molecule\"\u003eMolecule\u003c/a\u003e\u003c/strong\u003e is designed to aid in the development and testing of \u003ca href\u003d\"/radar/tools/ansible\"\u003eAnsible\u003c/a\u003e roles. By building the scaffolding for running Ansible role tests on a virtual machine or container of choice, we don\u0027t have to setup our testing environment manually. Molecule leverages \u003ca href\u003d\"/radar/tools/vagrant\"\u003eVagrant\u003c/a\u003e, \u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e, and \u003ca href\u003d\"/radar/platforms/openstack\"\u003eOpenStack\u003c/a\u003e to manage virtual machines or containers, and supports \u003ca href\u003d\"/radar/tools/serverspec\"\u003eServerspec\u003c/a\u003e, \u003ca href\u003d\"/radar/tools/testinfra\"\u003eTestinfra\u003c/a\u003e, or \u003ca href\u003d\"https://github.com/aelsabbahy/goss\"\u003eGoss\u003c/a\u003e to run the tests. The default steps in the sequence facility model include: virtual machine management, Ansible linting, idempotence testing and convergence testing. Although it is a fairly young project, we see a great potential for its usage.\u003c/p\u003e","theta":"42","volume":"2017-03"},{"name":"Spacemacs","id":"1119","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"73","display_name":"Spacemacs","radius":"300","description":"\u003cp\u003eAs any Emacs fan will tell you, Emacs is more than a text editor; it is a platform for character-mapped applications. Over the past few years, there has been an explosion of new developments on this platform, but we think \u003cstrong\u003e\u003ca href\u003d\"https://www.spacemacs.org/\"\u003eSpacemacs\u003c/a\u003e\u003c/strong\u003e deserves particular attention. Spacemacs provides an introduction to the Emacs platform, with a new keyboard user-interface, simplified customization layers, and a curated distribution of Emacs packages. One of the project\u0027s aims is to be the best of worlds by combining the Vim UI with the \u003ca href\u003d\"https://martinfowler.com/bliki/InternalReprogrammability.html\"\u003einternal reprogrammability\u003c/a\u003e of Emacs. We consider developer productivity tools to be a vital part of effective software development, and if you haven\u0027t considered Emacs for a while, we suggest you take a look at how Spacemacs rethinks this classic development platform.\u003c/p\u003e","theta":"35","volume":"2017-03"},{"name":"spaCy","id":"1111","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"74","display_name":"spaCy","radius":"287","description":"\u003cp\u003e\u003ca href\u003d\"https://spacy.io/\"\u003e\u003cstrong\u003espaCy\u003c/strong\u003e\u003c/a\u003e is a Natural Language Processing (NLP) library written in Python. It is a high-performance library, intended for use by developers in production, and applies NLP models suited for processing text that often mixes in emoticons and inconsistent punctuation marks. Unlike other NLP frameworks, spaCy is a pluggable library and not a platform; it is aimed at production applications rather than model training for research. It plays well with \u003ca href\u003d\"/radar/platforms/tensorflow\"\u003eTensorFlow\u003c/a\u003e and the rest of the Python AI ecosystem. We\u0027ve used spaCy in the enterprise context to build a search engine that takes human language queries and helps users make business decisions.\u003c/p\u003e","theta":"28","volume":"2017-03"},{"name":"Spinnaker","id":"1110","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"75","display_name":"Spinnaker","radius":"290","description":"\u003cp\u003e\u003ca href\u003d\"http://techblog.netflix.com/2015/11/global-continuous-delivery-with.html\"\u003eNetflix\u003c/a\u003e has open sourced \u003ca href\u003d\"http://www.spinnaker.io/\"\u003e\u003cstrong\u003eSpinnaker\u003c/strong\u003e\u003c/a\u003e, its microservices continuous delivery (CD) platform. Compared to other CI/CD platforms, Spinnaker implements cluster management and deployment of baked images to the cloud as first-class features. It supports out-of-the-box deployment and cluster management for multiple cloud providers such as Google Cloud Platform, AWS and \u003ca href\u003d\"/radar/platforms/pivotal-cloud-foundry\"\u003ePivotal Cloud Foundry\u003c/a\u003e. You can integrate Spinnaker with Jenkins to run a Jenkins job build. We like Spinnaker\u0027s opinionated approach for deploying microservices to the cloud—with the exception that Spinnaker\u0027s pipelines are created via a user interface (UI) and cannot be configured as code.\u003c/p\u003e","theta":"21","volume":"2017-03"},{"name":"Testinfra","id":"1117","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"76","display_name":"Testinfra","radius":"310","description":"\u003cp\u003eGiven the wide use of infrastructure tools today, it should come as no surprise that infrastructure as code has increased in current projects. With this tendency comes the need for testing this code. With \u003cstrong\u003eTestinfra\u003c/strong\u003e you can test the actual state of your servers configured manually or by tools such as \u003ca href\u003d\"/radar/tools/ansible\"\u003eAnsible\u003c/a\u003e, \u003ca href\u003d\"/radar/tools/puppet\"\u003ePuppet\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e. Testinfra aims to be a \u003ca href\u003d\"/radar/tools/serverspec\"\u003eServerspec\u003c/a\u003e equivalent in Python and is written as a plugin to the Pytest test engine.\u003c/p\u003e","theta":"14","volume":"2017-03"},{"name":"Yarn","id":"1112","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"77","display_name":"Yarn","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://yarnpkg.com/en/\"\u003eYarn\u003c/a\u003e\u003c/strong\u003e is a new package manager that replaces the existing workflow for the npm client while remaining compatible with the npm registry. With the npm client, we may end up with a different tree structure under node_modules based on the order that dependencies are installed. This nondeterministic nature can cause \"works on my machine\" problems. By breaking the installation steps into resolution, fetching and linking, Yarn avoids these issues using deterministic algorithms and lockfiles and thus guarantees repeatable installations. We\u0027ve also seen significantly faster builds in our continuous integration (CI) environment because of Yarn caching all the packages it downloads.\u003c/p\u003e","theta":"7","volume":"2017-03"},{"name":"Ember.js","id":"879","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radarId":"78","display_name":"Ember.js","radius":"75","description":"\u003cp\u003eIf you are faced with building a single-page application (SPA) and trying to choose a framework to build with, \u003cstrong\u003e\u003ca href\u003d\"http://emberjs.com/\"\u003eEmber.js\u003c/a\u003e\u003c/strong\u003e has emerged as a leading choice. Our teams praise Ember for its highly productive developer experience, with far fewer surprises than other frameworks such as \u003ca href\u003d\"/radar/languages-and-frameworks/angularjs\"\u003eAngularJS\u003c/a\u003e. The Ember CLI build tooling is a haven in the storm of JavaScript build tools, and the Ember core team and community are highly active and responsive.\u003c/p\u003e","theta":"288","volume":"2017-03"},{"name":"Python 3","id":"679","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"79","display_name":"Python 3","radius":"90","description":"\u003cp\u003e\u003cstrong\u003ePython 3\u003c/strong\u003e introduced many useful features that are not backward compatible with Python 2.x. It also removed numerous Python 2.x features that were maintained for backward compatibility, making Python 3 easier to learn and use and more consistent with the rest of the language. Our experience using Python 3 in domains such as machine learning and web application development shows that both the language and most of its \u003ca href\u003d\"http://py3readiness.org/\"\u003esupporting libraries\u003c/a\u003e have matured for adoption. We were able to fork and patch minor issues of existing libraries or avoided using incompatible Python 2.x libraries that had been abandoned. If you are developing in Python we strongly encourage you to use Python 3.\u003c/p\u003e","theta":"306","volume":"2017-03"},{"name":"ReactiveX","id":"686","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"80","display_name":"ReactiveX","radius":"90","description":"\u003cp\u003eDistributed systems often utilize multithreading, event-based communication and nonblocking I/O to improve the overall system efficiency. These programming techniques impose challenges such as low-level threading, synchronization, thread safety, concurrent data structures, and non-blocking I/O. The open source \u003cstrong\u003e\u003ca href\u003d\"http://reactivex.io/\"\u003eReactiveX\u003c/a\u003e\u003c/strong\u003e library beautifully abstracts away these concerns, provides the required application plumbing, and extends the \u003ca href\u003d\"https://en.wikipedia.org/wiki/Observer_pattern\"\u003eobservable pattern\u003c/a\u003e on streams of asynchronous events. ReactiveX also has an active developer community and supports a growing list of languages, the most recent addition being \u003ca href\u003d\"https://github.com/ReactiveX/RxSwift\"\u003eRxSwift\u003c/a\u003e. It also implements binding to mobile and desktop platforms.\u003c/p\u003e","theta":"324","volume":"2017-03"},{"name":"Redux","id":"951","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radarId":"81","display_name":"Redux","radius":"120","description":"\u003cp\u003eWith the increasing complexity of single-page JavaScript applications, we have seen a more pressing need to make client-side state management predictable. \u003ca href\u003d\"http://redux.js.org/\"\u003e\u003cstrong\u003eRedux\u003c/strong\u003e\u003c/a\u003e, with its \u003ca href\u003d\"http://redux.js.org/docs/introduction/ThreePrinciples.html\"\u003ethree principles\u003c/a\u003e of restrictions for updating state, has proven to be invaluable in a number of projects we have implemented. \u003ca href\u003d\"https://egghead.io/courses/getting-started-with-redux\"\u003eGetting Started with Redux\u003c/a\u003e and \u003ca href\u003d\"https://egghead.io/courses/building-react-applications-with-idiomatic-redux\"\u003eidiomatic Redux\u003c/a\u003e tutorials are a good starting point for new and experienced users. Its minimal library design has spawned a rich set of tools, and we encourage you to check out the \u003ca href\u003d\"https://github.com/markerikson/redux-ecosystem-links\"\u003eredux-ecosystem-links\u003c/a\u003e project for examples, middleware and utility libraries. We also particularly like the testability story: Dispatching actions, state transitions and rendering can be unit-tested separately from one another and with minimal amounts of mocking.\u003c/p\u003e","theta":"342","volume":"2017-03"},{"name":"Avro","id":"1082","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"82","display_name":"Avro","radius":"200","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://avro.apache.org/\"\u003eAvro\u003c/a\u003e\u003c/strong\u003e is a framework for data serialization. By storing schema along with the message content, it encourages schema evolution. Producers can edit field names, add new fields or delete existing fields and Avro guarantees that the clients continue to consume the messages. Having a schema allows data to be written without overhead which results in compact data encoding and faster data processing. Although the exchange of structure-less messages between producer and consumer is flexible, we\u0027ve seen teams facing issues with incompatible unprocessed messages in the queue during deployments. We\u0027ve used Avro in a number of projects and would recommend using it over just sending unstructured messages.\u003c/p\u003e","theta":"280","volume":"2017-03"},{"name":"Elixir","id":"676","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"83","display_name":"Elixir","radius":"180","description":"\u003cp\u003eInterest in the \u003ca href\u003d\"http://elixir-lang.org/\"\u003e\u003cstrong\u003eElixir\u003c/strong\u003e\u003c/a\u003e programming language continues to build. Increasingly, we see it used in serious projects and hear feedback from developers who find its Actor model to be robust and very fast. Elixir, which is built on top of the Erlang virtual machine, is showing promise for creating highly concurrent and fault-tolerant systems. Elixir has distinctive features such as the Pipe operator, which allows developers to build a pipeline of functions as you would in the UNIX command shell. The shared byte code allows Elixir to interoperate with Erlang and leverage existing libraries while supporting tools such as the Mix build tool, the IEx interactive shell and the \u003ca href\u003d\"http://elixir-lang.org/docs/stable/ex_unit/ExUnit.html\"\u003eExUnit\u003c/a\u003e unit-testing framework.\u003c/p\u003e","theta":"290","volume":"2017-03"},{"name":"Enzyme","id":"1047","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"84","display_name":"Enzyme","radius":"250","description":"\u003cp\u003eWe\u0027ve been enjoying the rapid component-level UI testing that \u003ca href\u003d\"http://airbnb.io/enzyme/\"\u003e\u003cstrong\u003eEnzyme\u003c/strong\u003e\u003c/a\u003e provides for \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e applications. Unlike many other snapshot-based testing frameworks, Enzyme allows you to test without doing on-device rendering, which results in faster and more granular testing. This is a contributing factor in our ability to massively reduce the amount of functional testing we find we have to do in React applications.\u003c/p\u003e","theta":"300","volume":"2017-03"},{"name":"Hangfire","id":"1080","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"85","display_name":"Hangfire","radius":"180","description":"\u003cp\u003eOne common problem in application development is how to schedule tasks that run outside the main process periodically or when certain conditions are met. The problem gets more complicated when unexpected events, such as application shutdowns, occur. The \u003cstrong\u003e\u003ca href\u003d\"http://hangfire.io/\"\u003eHangfire\u003c/a\u003e\u003c/strong\u003e framework, as our teams discovered, can do this and much more in the .NET environment. Hangfire is both easy to use and flexible, and it embraces a functional style. Particularly interesting is its ability to save a task\u0027s state so it can resume when an application restarts after a crash or shutdown.\u003c/p\u003e","theta":"310","volume":"2017-03"},{"name":"Nightwatch","id":"1081","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"86","display_name":"Nightwatch","radius":"235","description":"\u003cp\u003e\u003ca href\u003d\"http://nightwatchjs.org/\"\u003e\u003cstrong\u003eNightwatch\u003c/strong\u003e\u003c/a\u003e is a framework that allows automated acceptance tests for browser-based apps to be created in JavaScript and run in \u003ca href\u003d\"/radar/platforms/node-js\"\u003eNode.js\u003c/a\u003e. Nightwatch allows tests to be defined using a fluent API which can then be executed against a Selenium/WebDriver server. In the case of single page apps or other JavaScript-heavy pages, this allows the automated tests to be created and run within the same language and environment as the bulk of the code.\u003c/p\u003e","theta":"320","volume":"2017-03"},{"name":"Phoenix","id":"1050","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"87","display_name":"Phoenix","radius":"210","description":"\u003cp\u003eSome of our ThoughtWorks teams have had very positive experiences with \u003cstrong\u003ePhoenix\u003c/strong\u003e , a server-side web MVC framework written in \u003ca href\u003d\"/radar/languages-and-frameworks/elixir\"\u003eElixir\u003c/a\u003e. In addition to being streamlined and easy to use, Phoenix takes advantage of Elixir to be extremely fast. For some developers, Phoenix evokes the joy they experienced when first discovering Ruby and Rails. Although the ecosystem of libraries for Phoenix is not as extensive as for some more mature frameworks, it should benefit from the continuing success and growth of support for Elixir.\u003c/p\u003e","theta":"330","volume":"2017-03"},{"name":"Quick and Nimble","id":"1059","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"88","display_name":"Quick and Nimble","radius":"200","description":"\u003cp\u003eMost of our iOS teams are now using the \u003cstrong\u003e\u003ca href\u003d\"https://github.com/Quick/Quick\"\u003eQuick\u003c/a\u003e and \u003ca href\u003d\"https://github.com/Quick/Nimble\"\u003eNimble\u003c/a\u003e\u003c/strong\u003e pairing for their unit tests. In the \u003ca href\u003d\"http://rspec.info/\"\u003eRSpec\u003c/a\u003e family of behavior-driven development (BDD) testing tools, it provides very readable tests (with describe blocks) across \u003ca href\u003d\"/radar/languages-and-frameworks/swift\"\u003eSwift\u003c/a\u003e and Objective-C and has good support for asynchronous testing.\u003c/p\u003e","theta":"340","volume":"2017-03"},{"name":"Vue.js","id":"1055","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"89","display_name":"Vue.js","radius":"200","description":"\u003cp\u003eIn the ever-changing world of front-end JavaScript frameworks, one of the emerging favorites appears to be \u003cstrong\u003e\u003ca href\u003d\"https://vuejs.org/\"\u003eVue.js\u003c/a\u003e.\u003c/strong\u003e Vue.js is a lightweight alternative to \u003ca href\u003d\"/radar/languages-and-frameworks/angularjs\"\u003eAngularJS\u003c/a\u003e. It is designed to be a very flexible—and a less opinionated—library that offers a set of tools for building interactive web interfaces around concepts such as modularity, components and reactive data flow. It has a low learning curve, which makes it interesting for less experienced developers and beginners. Note, though, that Vue.js is not a full-blown framework; it is focused on the view layer only and therefore is easy to integrate with other libraries or existing projects.\u003c/p\u003e","theta":"350","volume":"2017-03"},{"name":"Angular 2","id":"1070","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"90","display_name":"Angular 2","radius":"320","description":"\u003cp\u003eIn the previous Radar, we moved \u003ca href\u003d\"/radar/languages-and-frameworks/angularjs\"\u003eAngularJS\u003c/a\u003e into the Hold ring (where it remains in this edition). When it comes to \u003cstrong\u003eAngular 2\u003c/strong\u003e , we\u0027re seeing mixed messages. Over the past year some teams at ThoughtWorks have used Angular 2 successfully and consider it a solid choice. However, Angular 2 is a rewrite, not an evolution, of AngularJS, and switching from AngularJS to Angular 2 is not much different than switching from AngularJS to another framework. Given the, in our experience, superior contenders such as \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e, \u003ca href\u003d\"/radar/languages-and-frameworks/ember-js\"\u003eEmber.js\u003c/a\u003e and \u003ca href\u003d\"/radar/languages-and-frameworks/vue-js\"\u003eVue.js\u003c/a\u003e, we\u0027re still hesitant to give Angular 2 a strong recommendation. We do want to highlight, though, that it is not a bad choice, especially if you bought into TypeScript.\u003c/p\u003e","theta":"276","volume":"2017-03"},{"name":"Caffe","id":"1072","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"91","display_name":"Caffe","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"http://caffe.berkeleyvision.org/\"\u003e\u003cstrong\u003eCaffe\u003c/strong\u003e\u003c/a\u003e is an open source library for deep learning created by the \u003ca href\u003d\"http://bair.berkeley.edu/\"\u003eBerkeley Vision and Learning Center\u003c/a\u003e. It mostly focusses on convolutional networks for computer vision applications. Caffe is a solid and popular choice for computer vision-related tasks and you can download many successful models made by Caffe users from the Caffe Model Zoo for out-of-the-box use. Like \u003ca href\u003d\"/radar/languages-and-frameworks/keras\"\u003eKeras\u003c/a\u003e, Caffe is a Python-based API. In Keras, however, models and components are objects created directly in Python code, whereas Caffe models are described by \u003ca href\u003d\"https://developers.google.com/protocol-buffers/\"\u003eProtobuf\u003c/a\u003e configuration files. Either approach has its pros and cons, and converting between the two is also possible.\u003c/p\u003e","theta":"282","volume":"2017-03"},{"name":"DeepLearning.scala","id":"1074","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"92","display_name":"DeepLearning.scala","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/ThoughtWorksInc/DeepLearning.scala\"\u003eDeepLearning.scala\u003c/a\u003e\u003c/strong\u003e is an open source deep-learning toolkit in Scala created by our colleagues at ThoughtWorks. We\u0027re excited about this project because it uses differentiable functional programming to create and compose neural networks; a developer simply writes code in Scala with static typing. DeepLearning.scala currently supports basic types such as float, double, GPU-accelerated N-dimensional arrays as well as algebraic data types. We\u0027re looking forward to future releases of the toolkit which are said to support higher order functions and distributed training on \u003ca href\u003d\"/radar/platforms/apache-spark\"\u003eSpark\u003c/a\u003e.\u003c/p\u003e","theta":"288","volume":"2017-03"},{"name":"ECMAScript 2017","id":"1066","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"93","display_name":"ECMAScript 2017","radius":"290","description":"\u003cp\u003e\u003cstrong\u003eECMAScript 2017\u003c/strong\u003e —not to be confused with ES7 (a.k.a. ECMAScript 2016)—brings several noteworthy improvements to the language. Browsers are expected to implement this standard fully in the summer of 2017, but the \u003ca href\u003d\"/radar/tools/babel\"\u003eBabel\u003c/a\u003e JavaScript compiler already supports a number of the features today. If you make extensive use of JavaScript and your codebase is under active development, we recommend that you add Babel to your build pipeline and begin using the \u003ca href\u003d\"https://www.npmjs.com/package/babel-preset-es2017\"\u003esupported features\u003c/a\u003e.\u003c/p\u003e","theta":"294","volume":"2017-03"},{"name":"Instana","id":"1078","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"94","display_name":"Instana","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://www.instana.com/\"\u003eInstana\u003c/a\u003e\u003c/strong\u003e is yet another entrant into the crowded application performance management space. The fact that it\u0027s built from the ground up for cloud native architectures differentiates Instana from many of its competitors. Features include dynamic discovery, distributed tracing and service health plus the ability to \"time shift\" your view of your infrastructure to the moment an incident occurred. It remains to be seen whether this product can gain traction over the combination of open source projects—such as \u003ca href\u003d\"/radar/tools/consul\"\u003eConsul\u003c/a\u003e, \u003ca href\u003d\"/radar/tools/prometheus\"\u003ePrometheus\u003c/a\u003e and the implementations of \u003ca href\u003d\"/radar/platforms/opentracing\"\u003eOpenTracing\u003c/a\u003e—that do the same thing; however it\u0027s worth taking a look if you need an out-of-the-box solution.\u003c/p\u003e","theta":"300","volume":"2017-03"},{"name":"JuMP","id":"1052","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"95","display_name":"JuMP","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/JuliaOpt/JuMP.jl\"\u003eJuMP\u003c/a\u003e\u003c/strong\u003e is a domain-specific language for \u003ca href\u003d\"https://en.wikipedia.org/wiki/Mathematical_optimization\"\u003emathematical optimizations\u003c/a\u003e in \u003ca href\u003d\"http://julialang.org/\"\u003eJulia\u003c/a\u003e. JuMP defines a common API called \u003ca href\u003d\"https://github.com/JuliaOpt/MathProgBase.jl\"\u003eMathProgBase\u003c/a\u003e and enables users to write solver-agnostic code in Julia. Currently supported solvers include \u003ca href\u003d\"http://artelys.com/en/optimization-tools/knitro\"\u003eArtelys Knitro\u003c/a\u003e, \u003ca href\u003d\"https://projects.coin-or.org/Bonmin\"\u003eBonmin\u003c/a\u003e, \u003ca href\u003d\"https://projects.coin-or.org/Cbc\"\u003eCbc\u003c/a\u003e, \u003ca href\u003d\"https://projects.coin-or.org/Clp\"\u003eClp\u003c/a\u003e, \u003ca href\u003d\"https://projects.coin-or.org/Couenne\"\u003eCouenne\u003c/a\u003e, \u003ca href\u003d\"http://www-01.ibm.com/software/commerce/optimization/cplex-optimizer/\"\u003eCPLEX\u003c/a\u003e, \u003ca href\u003d\"https://github.com/ifa-ethz/ecos\"\u003eECOS\u003c/a\u003e, \u003ca href\u003d\"http://www.fico.com/en/products/fico-xpress-optimization-suite\"\u003eFICO Xpress\u003c/a\u003e, \u003ca href\u003d\"http://www.gnu.org/software/glpk/\"\u003eGLPK\u003c/a\u003e, \u003ca href\u003d\"http://www.gurobi.com\"\u003eGurobi\u003c/a\u003e, \u003ca href\u003d\"https://projects.coin-or.org/Ipopt\"\u003eIpopt\u003c/a\u003e, \u003ca href\u003d\"http://www.mosek.com/\"\u003eMOSEK\u003c/a\u003e, \u003ca href\u003d\"http://ab-initio.mit.edu/wiki/index.php/NLopt\"\u003eNLopt\u003c/a\u003e and \u003ca href\u003d\"https://github.com/cvxgrp/scs\"\u003eSCS\u003c/a\u003e. One other benefit is the implementation of automatic differentiation technique in reverse mode to compute derivatives so users are not limited to the standard operators like sin, cos, log and sqrt but can also implement their own custom objective functions in Julia.\u003c/p\u003e","theta":"306","volume":"2017-03"},{"name":"Keras","id":"1073","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"96","display_name":"Keras","radius":"290","description":"\u003cp\u003e\u003ca href\u003d\"https://keras.io/\"\u003e\u003cstrong\u003eKeras\u003c/strong\u003e\u003c/a\u003e is a high-level interface in Python for building neural networks. Created by a Google engineer, Keras is open source and runs on top of either \u003ca href\u003d\"/radar/platforms/tensorflow\"\u003eTensorFlow\u003c/a\u003e or \u003ca href\u003d\"http://github.com/Theano/Theano\"\u003eTheano\u003c/a\u003e. It provides an amazingly simple interface for creating powerful deep-learning algorithms to train on CPUs or GPUs. Keras is well designed with modularity, simplicity, and extensibility in mind. Unlike a library such as \u003ca href\u003d\"/radar/languages-and-frameworks/caffe\"\u003eCaffe\u003c/a\u003e, Keras supports more general network architectures such as recurrent nets, making it overall more useful for text analysis, NLP and general machine learning. If computer vision, or any other specialized branch of machine learning, is your primary concern, Caffe may be a more appropriate choice. However, if you\u0027re looking to learn a simple yet powerful framework, Keras should be your first choice.\u003c/p\u003e","theta":"312","volume":"2017-03"},{"name":"Knet.jl","id":"1079","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"97","display_name":"Knet.jl","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"http://knet.rtfd.org\"\u003e\u003cstrong\u003eKnet.jl\u003c/strong\u003e\u003c/a\u003e is the \u003ca href\u003d\"http://www.ku.edu.tr/en\"\u003eKoç University\u003c/a\u003e deep-learning framework implemented in \u003ca href\u003d\"http://julia.rtfd.org\"\u003eJulia\u003c/a\u003e by \u003ca href\u003d\"http://www.denizyuret.com\"\u003eDeniz Yuret\u003c/a\u003e and collaborators. Unlike gradient-generating compilers such as \u003ca href\u003d\"https://github.com/Theano/Theano\"\u003eTheano\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/tensorflow\"\u003eTensorFlow\u003c/a\u003e which force users into a restricted mini-language, Knet allows the definition and training of machine-learning models using the full power and expressiveness of Julia. Knet uses dynamic computational graphs generated at runtime for the automatic differentiation of almost any Julia code. We really like the support of GPU operations through the KnetArray type, and in case you don\u0027t have access to a GPU machine, the team behind Knet also maintains a \u003ca href\u003d\"http://knet.readthedocs.io/en/latest/install.html#using-amazon-aws\"\u003epreconfigured Amazon Machine Image (AMI)\u003c/a\u003e so you can evaluate it in the cloud.\u003c/p\u003e","theta":"318","volume":"2017-03"},{"name":"Kotlin","id":"1077","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"98","display_name":"Kotlin","radius":"290","description":"\u003cp\u003eThe \u003cstrong\u003e\u003ca href\u003d\"https://kotlinlang.org/\"\u003eKotlin\u003c/a\u003e\u003c/strong\u003e programming language is on many of our developers\u0027 bucket lists to assess this year, and some have already used it successfully in production. It is an open source JVM language from JetBrains. Our Swift mobile developers like it as it is syntactically closer to \u003ca href\u003d\"/radar/languages-and-frameworks/swift\"\u003eSwift\u003c/a\u003e and equally concise. Our Java developers have enjoyed its seamless interoperability with the Java language and tools and found it easier to learn than Scala. Kotlin supports functional programming concepts but with less features than Scala. Developers on our teams who like static typing with the compiler catching null pointer defects found themselves writing fewer boilerplate tests.\u003c/p\u003e","theta":"324","volume":"2017-03"},{"name":"Physical Web","id":"1054","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"99","display_name":"Physical Web","radius":"295","description":"\u003cp\u003eWe have been intrigued by the \u003cstrong\u003e\u003ca href\u003d\"https://google.github.io/physical-web/\"\u003ePhysical Web\u003c/a\u003e\u003c/strong\u003e standard created by Google. The idea of Physical Web is simple—beacons broadcast a URL—but the possibilities are broad. Basically, this is a way to annotate the physical world, tying objects and locations into the digital realm. The current transport mechanism is \u003ca href\u003d\"https://github.com/google/eddystone/tree/master/eddystone-url\"\u003eEddystone URLs\u003c/a\u003e over Bluetooth LE, and sample clients are available. Although there are obvious security concerns with following randomly discovered links, we are most interested in use cases with customized clients where you can filter or proxy the URLs as required.\u003c/p\u003e","theta":"330","volume":"2017-03"},{"name":"PostCSS","id":"1071","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"100","display_name":"PostCSS","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/postcss/postcss\"\u003ePostCSS\u003c/a\u003e\u003c/strong\u003e is a \u003ca href\u003d\"/radar/platforms/node-js\"\u003eNode.js\u003c/a\u003e-based JavaScript framework for operating on an abstract syntax tree-based representation of CSS documents with a rich ecosystem of plugins. Often incorrectly thought of as a preprocessor (such as SASS or Less), we find that the real power of PostCSS comes from the number of things that can be done with the rich set of plugins which includes linting (\u003ca href\u003d\"https://github.com/stylelint/stylelint\"\u003ethe stylelint plugin\u003c/a\u003e), cross-compilation (\u003ca href\u003d\"https://github.com/postcss/sugarss\"\u003ethe sugarss plugin\u003c/a\u003e), name-mangling to avoid selector collision (\u003ca href\u003d\"https://github.com/css-modules/postcss-modules\"\u003ethe modules plugin\u003c/a\u003e), boilerplate CSS code generation (\u003ca href\u003d\"https://github.com/postcss/autoprefixer\"\u003ethe autoprefixer plugin\u003c/a\u003e), \u003ca href\u003d\"http://cssnano.co/\"\u003eminification\u003c/a\u003e and many others. The different maturity levels of the plugins notwithstanding, PostCSS itself remains a simple and powerful framework for treating CSS like a full-fledged language for front-end development.\u003c/p\u003e","theta":"336","volume":"2017-03"},{"name":"Spring Cloud","id":"1083","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"101","display_name":"Spring Cloud","radius":"330","description":"\u003cp\u003eTeams building systems composed of microservices need to think about coordination techniques such as service discovery, load balancing, circuit breaking and health checking. Many of these techniques require teams to set up tooling, which is not always trivial. The \u003cstrong\u003e\u003ca href\u003d\"http://projects.spring.io/spring-cloud/\"\u003eSpring Cloud\u003c/a\u003e\u003c/strong\u003e project provides tools for developers so they can use these coordination techniques in the familiar Spring environment. These tools support \u003ca href\u003d\"/radar/tools/consul\"\u003eConsul\u003c/a\u003e, \u003ca href\u003d\"https://zookeeper.apache.org/\"\u003eZooKeeper\u003c/a\u003e and the \u003ca href\u003d\"/radar/platforms/netflix-oss-full-stack\"\u003eNetflix OSS full stack\u003c/a\u003e, all tools that we like. Simply put, it makes it easy to do the right thing with these tool sets. Although our usual concerns with Spring still stand, namely that it hides too much of the complexity, you should consider Spring Cloud if you are in the ecosystem and need to solve these problems.\u003c/p\u003e","theta":"342","volume":"2017-03"},{"name":"Three.js","id":"1060","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"102","display_name":"Three.js","radius":"310","description":"\u003cp\u003eDespite the fervor surrounding the spate of new headsets, we believe there are many VR and AR scenarios that make sense in the browser, particularly on mobile. Given this trend, we have seen an uptick in usage of \u003ca href\u003d\"https://threejs.org/\"\u003e\u003cstrong\u003eThree.js\u003c/strong\u003e\u003c/a\u003e, a powerful JavaScript visualization and 3D rendering framework. The growth in support for WebGL, which it is based on, has helped adoption, as has the vibrant community supporting this open source project.\u003c/p\u003e","theta":"348","volume":"2017-03"},{"name":"WebRTC","id":"1063","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"103","display_name":"WebRTC","radius":"320","description":"\u003cp\u003eWidespread adoption of AR/VR as a collaboration and communication medium requires a modern and readily available video streaming platform. \u003cstrong\u003e\u003ca href\u003d\"https://webrtc.org/\"\u003eWebRTC\u003c/a\u003e\u003c/strong\u003e is an emerging standard for real-time communication between browsers that enables video streaming within commonly available web technologies. The range of browsers that support this standard is increasing, but Microsoft and Apple have been slow to adopt WebRTC in their proprietary browsers. If momentum continues to build, WebRTC could form the future foundation for AR/VR collaboration on the web.\u003c/p\u003e","theta":"354","volume":"2017-03"},{"name":"AngularJS","id":"727","quadrant":"languages-and-frameworks","ring":"Hold","movement":"c","radarId":"104","display_name":"AngularJS","radius":"375","description":"\u003cp\u003e\u003ca href\u003d\"https://angularjs.org/\"\u003e\u003cstrong\u003eAngularJS\u003c/strong\u003e\u003c/a\u003e helped revolutionize the world of single-page JavaScript applications, and we have delivered many projects successfully with it over the years. However, we are no longer recommending it (v1) for teams starting fresh projects. We prefer the ramp-up speed and more maintainable codebases we are seeing with \u003ca href\u003d\"/radar/languages-and-frameworks/ember-js\"\u003eEmber\u003c/a\u003e and \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e, particularly in conjunction with \u003ca href\u003d\"/radar/languages-and-frameworks/redux\"\u003eRedux\u003c/a\u003e.\u003c/p\u003e","theta":"315","volume":"2017-03"}],"date":"2017-03"},{"blips":[{"name":"Lightweight Architecture Decision Records","id":"1034","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"1","display_name":"Lightweight Architecture Decision Records","radius":"80","description":"\u003cp\u003eMuch documentation can be replaced with highly readable code and tests. In a world of \u003ca href\u003d\"/radar/techniques/evolutionary-architecture\"\u003eevolutionary architecture\u003c/a\u003e, however, it\u0027s important to record certain design decisions for the benefit of future team members as well as for external oversight. \u003cstrong\u003eLightweight Architecture Decision Records\u003c/strong\u003e is a \u003ca href\u003d\"http://thinkrelevance.com/blog/2011/11/15/documenting-architecture-decisions\"\u003etechnique\u003c/a\u003e for capturing important architectural decisions along with their context and consequences. We recommend \u003ca href\u003d\"http://github.com/npryce/adr-tools\"\u003estoring these details in source control\u003c/a\u003e, instead of a wiki or website, as then they can provide a record that remains in sync with the code itself. For most projects, we see no reason why you wouldn\u0027t want to use this technique.\u003c/p\u003e","theta":"135","volume":"2017-11"},{"name":"Applying product management to internal platforms","id":"1133","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"2","display_name":"Applying product management to internal platforms","radius":"180","description":"\u003cp\u003eWe\u0027ve seen a steep increase in interest in the topic of digital platforms over the past 12 months. Companies looking to roll out new digital solutions quickly and efficiently are building internal platforms, which offer teams self-service access to the business APIs, tools, knowledge and support necessary to build and operate their own solutions. We find that these platforms are most effective when they\u0027re given the same respect as an external product offering. \u003cstrong\u003eApplying product management to internal platforms\u003c/strong\u003e means establishing empathy with internal consumers (read: developers) and collaborating with them on the design. Platform product managers establish roadmaps and ensure the platform delivers value to the business and enhances the developer experience. Some owners even create a brand identity for the internal platform and use that to market the benefits to their colleagues. Platform product managers look after the quality of the platform, gather usage metrics, and continuously improve it over time. Treating the platform as a product helps to create a thriving ecosystem and avoids the pitfall of building yet another stagnant, underutilized service-oriented architecture.\u003c/p\u003e","theta":"173","volume":"2017-11"},{"name":"Architectural fitness function","id":"1132","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"3","display_name":"Architectural fitness function","radius":"165","description":"\u003cp\u003eBorrowed from evolutionary computing, a fitness function is used to summarize how close a given design solution is to achieving the set aims. When defining an evolutionary algorithm, the designer seeks a ‘better’ algorithm; the fitness function defines what ‘better’ means in this context. An \u003cstrong\u003earchitectural fitness function\u003c/strong\u003e , as defined in \u003ca href\u003d\"http://www.thoughtworks.com/books/building-evolutionary-architectures\"\u003eBuilding Evolutionary Architectures\u003c/a\u003e, provides an objective integrity assessment of some architectural characteristics, which may encompass existing verification criteria, such as unit testing, metrics, monitors, and so on. We believe architects can communicate, validate and preserve architectural characteristics in an automated, continual manner, which is the key to building evolutionary architectures.\u003c/p\u003e","theta":"165","volume":"2017-11"},{"name":"Autonomous bubble pattern","id":"1128","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"4","display_name":"Autonomous bubble pattern","radius":"200","description":"\u003cp\u003eMany organizations we work with are trying hard to use modern engineering approaches to build new capabilities and features, while also having to coexist with a long tail of legacy systems. An old strategy that, based on our experience, has turned out to be increasingly helpful in these scenarios is \u003ca href\u003d\"http://dddcommunity.org/strategic-design/\"\u003eEric Evans\u0027s\u003c/a\u003e \u003cstrong\u003eAutonomous bubble pattern\u003c/strong\u003e. This approach involves creating a fresh context for new application development that is shielded from the entanglements of the legacy world. This is a step beyond just using an \u003ca href\u003d\"http://wiki.c2.com/?AnticorruptionLayer\"\u003eanticorruption layer\u003c/a\u003e. It gives the new bubble context full control over its backing data, which is then asynchronously kept up-to-date with the legacy systems. It requires some work to protect the boundaries of the bubble and keep both worlds consistent, but the resulting autonomy and reduction in development friction is a first bold step toward a modernized future architecture.\u003c/p\u003e","theta":"158","volume":"2017-11"},{"name":"Chaos Engineering","id":"1206","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"5","display_name":"Chaos Engineering","radius":"180","description":"\u003cp\u003eIn previous editions of the Radar, we\u0027ve talked about using \u003ca href\u003d\"/radar/tools/chaos-monkey\"\u003eChaos Monkey\u003c/a\u003e from Netflix to test how a running system is able to cope with outages in production by randomly disabling instances and measuring the results. \u003cstrong\u003eChaos Engineering\u003c/strong\u003e is the nascent term for the wider application of this technique. By running experiments on distributed systems in production, we\u0027re able to build confidence that those systems work as expected under turbulent conditions. A good place to start understanding this technique is the \u003ca href\u003d\"http://principlesofchaos.org/\"\u003ePrinciples of Chaos Engineering\u003c/a\u003e website.\u003c/p\u003e","theta":"150","volume":"2017-11"},{"name":"Decoupling secret management from source code","id":"1105","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"6","display_name":"Decoupling secret management from source code","radius":"170","description":"\u003cp\u003eIn previous Radars issues we mentioned tools such as \u003ca href\u003d\"https://www.agwa.name/projects/git-crypt/\"\u003egit-crypt\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/blackbox\"\u003eBlackbox\u003c/a\u003e that allow us to keep secrets safe inside the source code. \u003cstrong\u003eDecoupling secret management from source code\u003c/strong\u003e is our way to remind technologists that there are other options for storing secrets. For example, \u003ca href\u003d\"/radar/tools/hashicorp-vault\"\u003eHashiCorp vault\u003c/a\u003e, CI servers and configuration management tools provide mechanisms for storing secrets that are not linked to the source code of an application. Both approaches are viable and we recommend you use at least one of them in your projects.\u003c/p\u003e","theta":"143","volume":"2017-11"},{"name":"DesignOps","id":"1130","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"7","display_name":"DesignOps","radius":"220","description":"\u003cp\u003eInspired by the DevOps movement, \u003ca href\u003d\"http://airbnb.design/designops-airbnb/\"\u003e\u003cstrong\u003eDesignOps\u003c/strong\u003e\u003c/a\u003e is a cultural shift and a set of practices that allows people across an organization to continuously redesign products without compromising quality, service coherency or team autonomy. DesignOps advocates for the creation and evolution of a design infrastructure that minimizes the effort necessary to create new UI concepts and variations, and to establish a rapid and reliable feedback loop with end users. With tools such as \u003ca href\u003d\"http://github.com/storybooks/storybook\"\u003eStorybook\u003c/a\u003e promoting close collaboration, the need for upfront analysis and specification handoffs is reduced to the absolute minimum. With DesignOps, design is shifting from being a specific practice to being a part of everyone\u0027s job.\u003c/p\u003e","theta":"135","volume":"2017-11"},{"name":"Legacy in a box","id":"1106","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"8","display_name":"Legacy in a box","radius":"230","description":"\u003cp\u003eWorking with legacy code, especially large monoliths, is one of the most unsatisfying, high-friction \u003ca href\u003d\"https://thoughtworks.wistia.com/medias/ogq5b8d80y\"\u003eexperiences for developers\u003c/a\u003e. Although we caution against extending and actively maintaining legacy monoliths, they continue to be dependencies in our environments, and developers often underestimate the cost and time required to develop against these dependencies. To help reduce the friction, developers have used virtualized \u003ca href\u003d\"/radar/techniques/machine-image-as-a-build-artifact\"\u003emachine images\u003c/a\u003e or container images with \u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e containers to create immutable images of legacy systems and their configurations. The intent is to contain the \u003cstrong\u003elegacy in a box\u003c/strong\u003e for developers to run locally and remove the need for rebuilding, reconfiguring or sharing environments. In an ideal scenario, teams that own legacy systems generate the corresponding boxed legacy images through their build pipelines, and developers can then run and orchestrate these images in their allocated sandbox more reliably. Although this approach has reduced the overall time spent by each developer, it has had limited success when the teams owning the downstream dependencies have been reluctant to create container images for others to use.\u003c/p\u003e","theta":"128","volume":"2017-11"},{"name":"Micro frontends","id":"1035","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"9","display_name":"Micro frontends","radius":"190","description":"\u003cp\u003eWe\u0027ve seen significant benefits from introducing \u003ca href\u003d\"/radar/techniques/microservices\"\u003emicroservices\u003c/a\u003e architectures, which have allowed teams to scale the delivery of independently deployed and maintained services. Unfortunately, we\u0027ve also seen many teams create front-end monoliths — a single, large and sprawling browser application — on top of their back-end services. Our preferred (and proven) approach is to split the browser-based code into \u003cstrong\u003emicro frontends\u003c/strong\u003e. In this approach, the web application is broken down into its features, and each feature is owned, frontend to backend, by a different team. This ensures that every feature is developed, tested and deployed independently from other features. Multiple techniques exist to recombine the features — sometimes as pages, sometimes as components — into a cohesive user experience.\u003c/p\u003e","theta":"120","volume":"2017-11"},{"name":"Pipelines for infrastructure as code","id":"1131","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"10","display_name":"Pipelines for infrastructure as code","radius":"220","description":"\u003cp\u003eThe use of continuous delivery pipelines to orchestrate the release process for software has become a mainstream concept. However, automatically testing changes to infrastructure code isn’t as widely understood. Continuous integration (CI) and continuous delivery (CD) tools can be used to test server configuration (e.g., Chef cookbooks, Puppet modules, Ansible playbooks), server image building (e.g., Packer), environment provisioning (e.g., Terraform, CloudFormation) and integration of environments. The use of \u003cstrong\u003epipelines for infrastructure as code\u003c/strong\u003e enables errors to be found before changes are applied to operational environments — including environments used for development and testing. They also offer a way to ensure that infrastructure tooling is run consistently, from CI/CD agents, as opposed to being run from individual workstations. Some challenges remain, however, such as the longer feedback loops associated with standing up containers and virtual machines. Still, we\u0027ve found this to be a valuable technique.\u003c/p\u003e","theta":"113","volume":"2017-11"},{"name":"Serverless architecture","id":"999","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"11","display_name":"Serverless architecture","radius":"210","description":"\u003cp\u003eThe use of \u003ca href\u003d\"http://www.martinfowler.com/articles/serverless.html\"\u003e\u003cstrong\u003eserverless architecture\u003c/strong\u003e\u003c/a\u003e has very quickly become an accepted approach for organizations deploying cloud applications, with a plethora of choices available for deployment. Even traditionally conservative organizations are making partial use of some serverless technologies. Most of the discussion goes to Functions as a Service (e.g., \u003ca href\u003d\"/radar/platforms/aws-lambda\"\u003eAWS Lambda\u003c/a\u003e, \u003ca href\u003d\"http://cloud.google.com/functions/\"\u003eGoogle Cloud Functions\u003c/a\u003e, \u003ca href\u003d\"http://azure.microsoft.com/en-us/services/functions/\"\u003eAzure Functions\u003c/a\u003e) while the appropriate patterns for use are still emerging. Deploying serverless functions undeniably removes the nontrivial effort that traditionally goes into server and OS configuration and orchestration. Serverless functions, however, are not a fit for every requirement. At this stage, you must be prepared to fall back to deploying containers or even server instances for specific requirements. Meanwhile, the other components of a serverless architecture, such as Backend as a Service, have become almost a default choice.\u003c/p\u003e","theta":"105","volume":"2017-11"},{"name":"TDD\u0027ing containers","id":"1134","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"12","display_name":"TDD\u0027ing containers","radius":"190","description":"\u003cp\u003eMany development teams have adopted test-driven development practices for writing application code because of their benefits. Others have turned to containers to package and deploy their software, and it\u0027s accepted practice to use automated scripts to build the containers. What we’ve seen few teams do so far is combine the two trends and drive the writing of the container scripts using tests. With frameworks such as \u003ca href\u003d\"http://serverspec.org/\"\u003eServerspec\u003c/a\u003e and \u003ca href\u003d\"http://github.com/aelsabbahy/goss\"\u003eGoss\u003c/a\u003e, you can express the intended functionality for either isolated or orchestrated containers, with short feedback loops. This means that it’s possible to use the same principles we’ve championed for code by \u003cstrong\u003eTDD\u0027ing containers\u003c/strong\u003e. Our initial experience doing so has been very positive.\u003c/p\u003e","theta":"98","volume":"2017-11"},{"name":"Algorithmic IT operations","id":"1140","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"13","display_name":"Algorithmic IT operations","radius":"330","description":"\u003cp\u003eThe amount of data collected by IT operations has been increasing for years. For example, the trend toward microservices means that more applications are generating their own operational data, and tools such as Splunk, \u003ca href\u003d\"/radar/tools/prometheus\"\u003ePrometheus\u003c/a\u003e, or the ELK stack make it easier to store and process data later on, to gain operational insights. When combined with increasingly democratized machine learning tools, it’s inevitable that operators will start to incorporate statistical models and trained classification algorithms into their toolsets. Although these algorithms have been available for years, and various attempts have been made to automate service management, we\u0027re only just starting to understand how machines and humans can collaborate to identify outages earlier or pinpoint the source of failures. Although there is a risk of overhyping \u003cstrong\u003eAlgorithmic IT operations\u003c/strong\u003e , steady improvement in machine learning algorithms will inevitably change the role of humans in operating tomorrow\u0027s data centers.\u003c/p\u003e","theta":"170","volume":"2017-11"},{"name":"Ethereum for decentralized applications","id":"1188","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"14","display_name":"Ethereum for decentralized applications","radius":"290","description":"\u003cp\u003eBlockchains have been widely hyped as the panacea for all things fintech, from banking to digital currency to supply chain transparency. We’ve previously featured \u003ca href\u003d\"/radar/platforms/ethereum\"\u003eEthereum\u003c/a\u003e because of its feature set, which includes smart contracts. Now, we\u0027re seeing more development using \u003cstrong\u003eEthereum for decentralized applications\u003c/strong\u003e in \u003ca href\u003d\"http://www.stateofthedapps.com/\"\u003eother areas\u003c/a\u003e. Although this is still a very young technology, we\u0027re encouraged to see it being used to build decentralized applications beyond cryptocurrency and banking.\u003c/p\u003e","theta":"160","volume":"2017-11"},{"name":"Event streaming as the source of truth","id":"1139","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"15","display_name":"Event streaming as the source of truth","radius":"300","description":"\u003cp\u003eAs event streaming platforms, such as \u003ca href\u003d\"/radar/tools/apache-kafka\"\u003eApache Kafka\u003c/a\u003e, rise in popularity, many consider them as an advanced form of message queuing, used solely to transmit events. Even when used in this way, event streaming has its benefits over traditional message queuing. However, we\u0027re more interested in how people use \u003cstrong\u003eevent streaming as the source of truth\u003c/strong\u003e with platforms (Kafka in particular) as the primary store for data as immutable events. A service with an \u003ca href\u003d\"http://martinfowler.com/eaaDev/EventSourcing.html\"\u003eEvent Sourcing\u003c/a\u003e design, for example, can use Kafka as its event store; those events are then available for other services to consume. This technique has the potential to reduce duplicating efforts between local persistence and integration.\u003c/p\u003e","theta":"150","volume":"2017-11"},{"name":"Platform engineering product teams","id":"1101","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"16","display_name":"Platform engineering product teams","radius":"300","description":"\u003cp\u003eThe adoption of cloud and DevOps, while increasing the productivity of teams who can now move more quickly with reduced dependency on centralized operations teams and infrastructure, also has constrained teams who lack the skills to self-manage a full application and operations stack. Some organizations have tackled this challenge by creating \u003cstrong\u003eplatform engineering product teams\u003c/strong\u003e. These teams operate an internal platform which enables delivery teams to self-service deploy and operate systems with reduced lead time and stack complexity. The emphasis here is on API-driven self-service and supporting tools, with delivery teams still responsible for supporting what they deploy onto the platform. Organizations that consider establishing such a platform team should be very cautious not to accidentally create a \u003ca href\u003d\"/radar/techniques/separate-devops-team\"\u003eseparate DevOps team\u003c/a\u003e, nor should they simply relabel their \u003ca href\u003d\"/radar/platforms/superficial-private-cloud\"\u003eexisting hosting and operations structure\u003c/a\u003e as a platform.\u003c/p\u003e","theta":"140","volume":"2017-11"},{"name":"Polycloud","id":"1207","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"17","display_name":"Polycloud","radius":"310","description":"\u003cp\u003eThe major cloud providers (Amazon, Microsoft and Google) are locked in an aggressive race to maintain parity on core capabilities while their products are differentiated only marginally. This is causing a few organizations to adopt a \u003cstrong\u003ePolycloud\u003c/strong\u003e strategy — rather than going ‘all-in’ with one provider, they are passing different types of workloads to different providers in a best-of-breed approach. This may involve, for example, putting standard services on AWS, but using Google for machine learning, Azure for .NET applications that use SQLServer, or potentially using the Ethereum Consortium Blockchain solution. This is different than a cloud-agnostic strategy of aiming for portability across providers, which is costly and forces lowest-common-denominator thinking. Polycloud instead focuses on using the best that each cloud offers.\u003c/p\u003e","theta":"130","volume":"2017-11"},{"name":"Service mesh","id":"1138","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"18","display_name":"Service mesh","radius":"290","description":"\u003cp\u003eAs large organizations transition to more autonomous teams owning and operating their own microservices, how can they ensure the necessary consistency and compatibility between those services without relying on a centralized hosting infrastructure? To work together efficiently, even autonomous microservices need to align with some organizational standards. A \u003cstrong\u003eservice mesh\u003c/strong\u003e offers consistent discovery, security, tracing, monitoring and failure handling without the need for a shared asset such as an API gateway or ESB. A typical implementation involves lightweight reverse-proxy processes deployed alongside each service process, perhaps in a separate container. These proxies communicate with service registries, identity providers, log aggregators, and so on. Service interoperability and observability are gained through a shared implementation of this proxy but not a shared runtime instance. We\u0027ve advocated for a decentralized approach to microservice management for some time and are happy to see this consistent pattern emerge. Open source projects such as \u003ca href\u003d\"http://linkerd.io/\"\u003elinkerd\u003c/a\u003e and \u003ca href\u003d\"http://istio.io/\"\u003eIstio\u003c/a\u003e will continue to mature and make service meshes even easier to implement.\u003c/p\u003e","theta":"120","volume":"2017-11"},{"name":"Sidecars for endpoint security","id":"1136","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"19","display_name":"Sidecars for endpoint security","radius":"320","description":"\u003cp\u003eMicroservices architecture, with a large number of services exposing their assets and capabilities through APIs and an increased attack surface, demand a zero trust security architecture — ‘never trust, always verify’. However, enforcing security controls for communication between services is often neglected, due to increased service code complexity and lack of libraries and language support in a polyglot environment. To get around this complexity, some teams delegate security to an out-of-process sidecar — a process or a container that is deployed and scheduled with each service sharing the same execution context, host and identity. Sidecars implement security capabilities, such as transparent encryption of the communication and TLS (Transport Layer Security) termination, as well as authentication and authorization of the calling service or the end user. We recommend you look into using \u003ca href\u003d\"http://istio.io/\"\u003eIstio\u003c/a\u003e, \u003ca href\u003d\"http://linkerd.io/\"\u003elinkerd\u003c/a\u003e or \u003ca href\u003d\"http://github.com/envoyproxy/envoy\"\u003eEnvoy\u003c/a\u003e before implementing your own \u003cstrong\u003esidecars for endpoint security\u003c/strong\u003e.\u003c/p\u003e","theta":"110","volume":"2017-11"},{"name":"The three Rs of security","id":"1141","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"20","display_name":"The three Rs of security","radius":"300","description":"\u003cp\u003eTraditional approaches to enterprise security often emphasize locking things down and slowing the pace of change. However, we know that the more time an attacker has to compromise a system, the greater the potential damage. \u003ca href\u003d\"http://builttoadapt.io/the-three-r-s-of-enterprise-security-rotate-repave-and-repair-f64f6d6ba29d\"\u003eThe three Rs of enterprise security\u003c/a\u003e — rotate, repair and repave — take advantage of infrastructure automation and continuous delivery to eliminate opportunities for attack. Rotating credentials, applying patches as soon as they\u0027re available and rebuilding systems from a known, secure state — all within a matter of minutes or hours — makes it harder for attackers to succeed. \u003cstrong\u003eThe three Rs of security\u003c/strong\u003e technique is made feasible with the advent of modern cloud-native architectures. When applications are deployed as containers, and built and tested via a completely automated pipeline, a security patch is just another small release that can be sent through the pipeline with one click. Of course, in keeping with best distributed systems practices, developers need to design their applications to be resilient to unexpected server outages. This is similar to the impact of implementing \u003ca href\u003d\"/radar/tools/chaos-monkey\"\u003eChaos Monkey\u003c/a\u003e within your environment.\u003c/p\u003e","theta":"100","volume":"2017-11"},{"name":"A single CI instance for all teams","id":"1004","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"21","display_name":"A single CI instance for all teams","radius":"380","description":"\u003cp\u003eWe\u0027re compelled to caution, again, against creating \u003cstrong\u003ea single CI instance for all teams\u003c/strong\u003e. While it\u0027s a nice idea in theory to consolidate and centralize Continuous Integration (CI) infrastructure, in reality we do not see enough maturity in the tools and products in this space to achieve the desired outcome. Software delivery teams which must use the centralized CI offering regularly have long delays depending on a central team to perform minor configuration tasks, or to troubleshoot problems in the shared infrastructure and tooling. At this stage, we continue to recommend that organizations limit their centralized investment to establishing patterns, guidelines and support for delivery teams to operate their own CI infrastructure.\u003c/p\u003e","theta":"165","volume":"2017-11"},{"name":"CI theatre","id":"1102","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"22","display_name":"CI theatre","radius":"375","description":"\u003cp\u003eWe\u0027ve long been advocates of \u003ca href\u003d\"https://martinfowler.com/articles/continuousIntegration.html\"\u003econtinuous integration\u003c/a\u003e (CI), and we were \u003ca href\u003d\"https://en.wikipedia.org/wiki/CruiseControl\"\u003epioneers\u003c/a\u003e in building CI server programs to automatically build projects on check-ins. Used well, these programs run as a daemon process on a \u003ca href\u003d\"http://www.martinfowler.com/articles/continuousIntegration.html#EveryoneCommitsToTheMainlineEveryDay\"\u003eshared project mainline that developers commit to daily\u003c/a\u003e. The CI server \u003ca href\u003d\"http://www.martinfowler.com/articles/continuousIntegration.html#EveryCommitShouldBuildTheMainlineOnAnIntegrationMachine\"\u003ebuilds the project\u003c/a\u003e and runs \u003ca href\u003d\"http://www.martinfowler.com/articles/continuousIntegration.html#MakeYourBuildSelf-testing\"\u003ecomprehensive tests\u003c/a\u003e to ensure the whole software system is integrated and is in an always-releasable state, thus satisfying the principles of \u003ca href\u003d\"https://continuousdelivery.com/\"\u003econtinuous delivery\u003c/a\u003e. Sadly, many developers simply set up a CI server and falsely assume they are \"doing CI\" when in reality they miss out on all the benefits. Common failure modes include: running CI against a shared mainline but with infrequent commits, so integration isn\u0027t really continuous; running a build with poor test coverage; allowing the build to stay red for long periods; or running CI against feature branches which results in \u003ca href\u003d\"http://paulhammant.com/2017/02/14/fake-news-via-continuous-isolation/\"\u003econtinuous isolation\u003c/a\u003e. The ensuing \" \u003cstrong\u003eCI theatre\u003c/strong\u003e\" might make people feel good, but would fail any credible \u003ca href\u003d\"https://martinfowler.com/bliki/ContinuousIntegrationCertification.html\"\u003eCI certification test\u003c/a\u003e.\u003c/p\u003e","theta":"150","volume":"2017-11"},{"name":"Enterprise-wide integration test environments","id":"1104","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"23","display_name":"Enterprise-wide integration test environments","radius":"375","description":"\u003cp\u003eWhen the enterprise-wide quarterly or monthly releases were considered best practice, it was necessary to maintain a complete environment for performing testing cycles prior to deployment to production. These \u003cstrong\u003eenterprise-wide integration test environments\u003c/strong\u003e (often referred to as SIT or Staging) are a common bottleneck for continuous delivery today. The environments themselves are fragile and expensive to maintain, often with components that need manual configuration by a separate environment management team. Testing in the staging environment provides unreliable and slow feedback, and testing effort is duplicated with what can be performed on components in isolation. We recommend that organizations incrementally create an independent path to production for key components. Important techniques include \u003ca href\u003d\"/radar/techniques/consumer-driven-contract-testing\"\u003econtract testing\u003c/a\u003e, \u003ca href\u003d\"/radar/techniques/decoupling-deployment-from-release\"\u003edecoupling deployment from release\u003c/a\u003e, \u003ca href\u003d\"/radar/techniques/focus-on-mean-time-to-recovery\"\u003efocus on mean time to recovery\u003c/a\u003e and \u003ca href\u003d\"/radar/techniques/qa-in-production\"\u003etesting in production\u003c/a\u003e.\u003c/p\u003e","theta":"135","volume":"2017-11"},{"name":"Recreating ESB antipatterns with Kafka","id":"1142","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"24","display_name":"Recreating ESB antipatterns with Kafka","radius":"380","description":"\u003cp\u003eKafka is becoming very popular as a messaging solution, and along with it, \u003ca href\u003d\"/radar/platforms/kafka-streams\"\u003eKafka Streams\u003c/a\u003e is at the forefront of the wave of interest in streaming architectures. Unfortunately, as they start to embed Kafka at the heart of their data and application platforms, we\u0027re seeing some organizations \u003cstrong\u003erecreating ESB antipatterns with Kafka\u003c/strong\u003e by centralizing the Kafka ecosystem components — such as connectors and stream processors — instead of allowing these components to live with product or service teams. This reminds us of seriously problematic ESB antipatterns, where more and more logic, orchestration and transformation were thrust into a centrally managed ESB, creating a significant dependency on a centralized team. We\u0027re calling this out to dissuade further implementations of this flawed pattern.\u003c/p\u003e","theta":"120","volume":"2017-11"},{"name":"Spec-based codegen","id":"1127","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"25","display_name":"Spec-based codegen","radius":"375","description":"\u003cp\u003eBack in the days when SOAP held sway in the enterprise software industry, the practice of generating client code from WSDL specs was an accepted—even encouraged—practice. Unfortunately, the resulting code was often complex, untestable, difficult to modify and frequently didn\u0027t work across implementation platforms. With the advent of REST, we found it better to evolve API clients that use the \u003ca href\u003d\"https://martinfowler.com/bliki/TolerantReader.html\"\u003etolerant reader pattern\u003c/a\u003e for extracting and processing only the fields needed. Recently we have observed a disturbing return to old habits with developers generating code from API specifications written in \u003ca href\u003d\"/radar/tools/swagger\"\u003eSwagger\u003c/a\u003e or \u003ca href\u003d\"/radar/tools/raml\"\u003eRAML\u003c/a\u003e—a practice that we refer to as \u003cstrong\u003espec-based codegen\u003c/strong\u003e. Although such tools are very useful for driving the design of APIs and for extracting documentation, we caution against the tempting shortcut of simply generating client code directly from these specifications. The chances are that such code will be difficult to test and maintain.\u003c/p\u003e","theta":"105","volume":"2017-11"},{"name":"Kubernetes","id":"925","quadrant":"Platforms","ring":"Adopt","movement":"t","radarId":"26","display_name":"Kubernetes","radius":"75","description":"\u003cp\u003eSince we last mentioned \u003cstrong\u003eKubernetes\u003c/strong\u003e in the Radar, it has become the default solution for most of our clients when deploying containers into a cluster of machines. The alternatives didn’t capture as much mindshare, and in some cases our clients are even changing their ‘engine’ to Kubernetes. Kubernetes has become the container orchestration platform of choice for major public cloud platforms, including Microsoft\u0027s Azure Container Service and Google Cloud (see the \u003ca href\u003d\"/radar/platforms/gke\"\u003eGKE\u003c/a\u003e blip). And there are many useful products enriching the fast-growing Kubernetes ecosystem. Platforms that try to hide Kubernetes under an abstraction layer, however, have yet to prove themselves.\u003c/p\u003e","theta":"225","volume":"2017-11"},{"name":".NET Core","id":"866","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"27","display_name":".NET Core","radius":"250","description":"\u003cp\u003eWe\u0027re seeing increased adoption of \u003ca href\u003d\"http://www.microsoft.com/net/core\"\u003e\u003cstrong\u003e.NET Core\u003c/strong\u003e\u003c/a\u003e, the open source cross-platform software framework. .NET Core enables the development and deployment of .NET applications on Windows, macOS and Linux. With the release of \u003ca href\u003d\"https://docs.microsoft.com/en-us/dotnet/standard/net-standard?tabs\u003dnet-standard-2-0\"\u003e.NET Standard 2.0\u003c/a\u003e increasing the number of standard APIs across .NET platforms, the migration path to .NET Core has become clearer. Issues related to library support on .NET Core are becoming less problematic, and first-class \u003ca href\u003d\"http://www.jetbrains.com/rider/\"\u003ecross-platform tooling\u003c/a\u003e is now available, allowing for productive development on non-Windows platforms. Blessed Docker images are provided to make it easy to integrate .NET Core services into a containerized environment. Positive directions in the community and feedback from our projects indicate that .NET Core is ready for widespread use.\u003c/p\u003e","theta":"190","volume":"2017-11"},{"name":"AWS Device Farm","id":"1097","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"28","display_name":"AWS Device Farm","radius":"200","description":"\u003cp\u003eThe huge number of mobile devices makes it almost impossible for companies to test their mobile apps on all of them. Enter \u003cstrong\u003e\u003ca href\u003d\"https://aws.amazon.com/device-farm/\"\u003eAWS Device Farm\u003c/a\u003e\u003c/strong\u003e, an app-testing service that enables you to run and interact with your Android, iOS and web apps on a wide variety of physical devices that are hosted in the cloud simultaneously. Detailed logs, performance graphs and screenshots are generated during each run to provide general and device-specific feedback. The service offers a lot of flexibility by allowing the state and configuration of each device to be altered in order to reproduce very specific test scenarios. Our teams are using AWS Device Farm to run end-to-end tests on devices with the largest install base for their apps.\u003c/p\u003e","theta":"200","volume":"2017-11"},{"name":"Flood IO","id":"1190","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"29","display_name":"Flood IO","radius":"255","description":"\u003cp\u003eLoad testing became easier with the maturity of tools such as \u003ca href\u003d\"/radar/tools/gatling\"\u003eGatling\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/locust\"\u003eLocust\u003c/a\u003e. At the same time, elastic cloud infrastructures make it possible to simulate a large number of client instances. We\u0027re delighted to see Flood and other cloud platforms go further by leveraging these technologies. \u003ca href\u003d\"http://flood.io/\"\u003e\u003cstrong\u003eFlood IO\u003c/strong\u003e\u003c/a\u003e is an SaaS load-testing service that helps to distribute and execute testing scripts across hundreds of servers in the cloud. Our teams find it simple to migrate performance testing to Flood by reusing existing Gatling scripts.\u003c/p\u003e","theta":"210","volume":"2017-11"},{"name":"Google Cloud Platform","id":"1192","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"30","display_name":"Google Cloud Platform","radius":"255","description":"\u003cp\u003eAs \u003ca href\u003d\"http://cloud.google.com/free/ce1/\"\u003e\u003cstrong\u003eGoogle Cloud Platform\u003c/strong\u003e\u003c/a\u003e (GCP) has expanded in terms of available geographic regions and maturity of services, customers globally can now seriously consider it for their cloud strategy. In some areas, GCP has reached feature parity with its main competitor, Amazon Web Services, while in other areas it has differentiated itself — notably with accessible machine learning platforms, data engineering tools, and a workable Kubernetes as a service solution (\u003ca href\u003d\"/radar/platforms/gke\"\u003eGKE\u003c/a\u003e). In practice, our teams have nothing but praise for the developer experience working with the GCP tools and APIs.\u003c/p\u003e","theta":"220","volume":"2017-11"},{"name":"Keycloak","id":"1086","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"31","display_name":"Keycloak","radius":"190","description":"\u003cp\u003eIn a \u003ca href\u003d\"/radar/techniques/microservices\"\u003emicroservice\u003c/a\u003e, or any other distributed architecture, one of the most common needs is to secure the services or APIs through authentication and authorization features. This is where \u003ca href\u003d\"http://www.keycloak.org/\"\u003e\u003cstrong\u003eKeycloak\u003c/strong\u003e\u003c/a\u003e comes in. Keycloak is an open source identity and access management solution that makes it easy to secure applications or microservices with little to no code. It supports single sign-on, social login and standard protocols such as \u003ca href\u003d\"http://openid.net/connect/\"\u003eOpenID Connect\u003c/a\u003e, \u003ca href\u003d\"http://oauth.net/2/\"\u003eOAuth 2.0\u003c/a\u003e and \u003ca href\u003d\"http://en.wikipedia.org/wiki/Security_Assertion_Markup_Language\"\u003eSAML\u003c/a\u003e out of the box. Our teams have been using this tool and plan to keep using it for the foreseeable future. But it requires a little work to set up. Because configuration happens both at initialization and at runtime through APIs, it\u0027s necessary to write scripts to ensure deployments are repeatable.\u003c/p\u003e","theta":"230","volume":"2017-11"},{"name":"OpenTracing","id":"1095","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"32","display_name":"OpenTracing","radius":"200","description":"\u003cp\u003eAs monolithic applications are being replaced with more complex \u003ca href\u003d\"/radar/techniques/microservices\"\u003e(micro)service\u003c/a\u003e ecosystems, tracing requests across multiple services is becoming the norm. With majority contribution from LightStep and Uber \u003ca href\u003d\"http://opentracing.io/\"\u003e\u003cstrong\u003eOpenTracing\u003c/strong\u003e\u003c/a\u003e is rapidly becoming the de facto standard for distributed tracing. There is a growing number of \u003ca href\u003d\"http://opentracing.io/documentation/pages/supported-tracers\"\u003etracers\u003c/a\u003e supporting OpenTracing standard, including \u003ca href\u003d\"/radar/tools/zipkin\"\u003eZipkin\u003c/a\u003e, \u003ca href\u003d\"/radar/languages-and-frameworks/instana\"\u003eInstana\u003c/a\u003e, and \u003ca href\u003d\"https://uber.github.io/jaeger/\"\u003eJaeger\u003c/a\u003e. OpenTracing currently provides vendor-neutral implementation in multiple languages including: Go, JavaScript, Java, Python, Objective-C, C#, C++, Ruby and PHP.\u003c/p\u003e","theta":"240","volume":"2017-11"},{"name":"Unity beyond gaming","id":"1061","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"33","display_name":"Unity beyond gaming","radius":"180","description":"\u003cp\u003eIn previous Radars, we mentioned that \u003ca href\u003d\"http://unity3d.com/\"\u003eUnity\u003c/a\u003e has become the platform of choice for VR and AR application development because it provides the abstractions and tooling of a mature platform, while being more accessible than its main alternative, the Unreal Engine. With the recent introductions of ARKit for iOS and ARCore for Android, the two main mobile platforms now have powerful native SDKs for building augmented reality applications. Yet, we feel that many teams, especially those without deep experience in building games, will benefit from using an abstraction such as Unity, which is why we\u0027re calling out \u003cstrong\u003eUnity beyond gaming\u003c/strong\u003e. This allows developers unfamiliar with the technology to focus on one SDK. It also offers a solution for the huge number of devices, especially on the Android side, that are not supported by the native SDKs.\u003c/p\u003e","theta":"250","volume":"2017-11"},{"name":"WeChat","id":"1189","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"34","display_name":"WeChat","radius":"220","description":"\u003cp\u003e\u003cstrong\u003eWeChat\u003c/strong\u003e , often seen as a WhatsApp equivalent, is becoming the de facto business platform in China. Many people may not know but WeChat is also one of the most popular online payment platforms. With the app\u0027s built-in CMS and membership management, small businesses are now conducting their commerce entirely on WeChat. Through the Service Account feature, large organizations can interface their internal system to their employees. Given that more than 70 percent of Chinese people are using WeChat, it\u0027s an important consideration for businesses that want to expand into the China market.\u003c/p\u003e","theta":"260","volume":"2017-11"},{"name":"Azure Service Fabric","id":"1203","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"35","display_name":"Azure Service Fabric","radius":"331","description":"\u003cp\u003e\u003cstrong\u003eAzure Service Fabric\u003c/strong\u003e is a distributed systems platform built for microservices and containers. It’s comparable to container orchestrators such as \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e, but also works with plain old services. It can be used in a bewildering array of ways, starting from simple services in your language of choice to Docker containers or services built using an SDK. Since its release a couple of years ago, it has steadily added more features, including Linux container support. Kubernetes has been the poster child of container orchestration tools, but Service Fabric is the default choice for .NET applications. We\u0027re using it in a few projects at ThoughtWorks and we like what we’ve seen so far.\u003c/p\u003e","theta":"185","volume":"2017-11"},{"name":"Cloud Spanner","id":"1196","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"36","display_name":"Cloud Spanner","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"http://cloud.google.com/spanner/\"\u003e\u003cstrong\u003eCloud Spanner\u003c/strong\u003e\u003c/a\u003e is a fully managed relational database service offering high availability and strong consistency without compromising latency. Google has been working on a globally distributed database called Spanner for quite some time. It has recently released the service to the outside world as Cloud Spanner. You can scale your database instance from one to thousands of nodes across the globe without worrying about data consistency. By levering \u003ca href\u003d\"http://cloud.google.com/spanner/docs/true-time-external-consistency\"\u003eTrueTime\u003c/a\u003e, a highly available and distributed clock, Cloud Spanner provides strong consistency for reads and snapshots. You can use standard SQL to read data from Cloud Spanner, but for write operations you have to use their RPC API. Although not all services would require a global-scale distributed database, the general availability of Cloud Spanner is a big shift in the way we think about databases. And its design is influencing open source products such as \u003ca href\u003d\"http://github.com/cockroachdb/cockroach\"\u003eCockroachDB\u003c/a\u003e.\u003c/p\u003e","theta":"190","volume":"2017-11"},{"name":"Corda","id":"1202","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"37","display_name":"Corda","radius":"338","description":"\u003cp\u003eAfter thorough exploration, R3, an important player in the blockchain space, realized that blockchain doesn\u0027t fit their purpose well, so they created \u003cstrong\u003e\u003ca href\u003d\"http://www.corda.net\"\u003eCorda\u003c/a\u003e\u003c/strong\u003e. Corda is a distributed ledger technology (DLT) platform focused on the financial field. R3 have a very clear value proposition and know that their problem requires a pragmatic technology approach. This matches our own experience; current blockchain solutions may not be the reasonable choice for some business cases, due to mining costs and operational inefficiency. Although the development experience we have on Corda thus far has not been the smoothest, \u003ca href\u003d\"http://docs.corda.net/releases/release-V1.0/api-index.html#internal-apis-and-stability-guarantees\"\u003eAPIs are still unstable after v1.0 release\u003c/a\u003e, we expect to see the DLT space mature further.\u003c/p\u003e","theta":"195","volume":"2017-11"},{"name":"Cosmos DB","id":"1191","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"38","display_name":"Cosmos DB","radius":"331","description":"\u003cp\u003e\u003ca href\u003d\"http://docs.microsoft.com/en-us/azure/cosmos-db/introduction\"\u003e\u003cstrong\u003eCosmos DB\u003c/strong\u003e\u003c/a\u003e is Microsoft\u0027s globally distributed, multimodel database service, which became generally available earlier this year. While most modern NoSQL databases offer tunable consistency, Cosmos DB makes it a first-class citizen and offers five different consistency models. It\u0027s worth highlighting that it also supports multiple models — key value, document, column family and graph — all of which map to its internal data model, called atom-record-sequence (ARS). One interesting aspect of Cosmos DB is that it offers service level agreements (SLAs) on its latency, throughput, consistency and availability. With its wide range of applicability, it has set a high standard for other cloud vendors to match.\u003c/p\u003e","theta":"200","volume":"2017-11"},{"name":"DialogFlow","id":"1085","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"39","display_name":"DialogFlow","radius":"322","description":"\u003cp\u003eIn parallel with the recent surge of chatbots and \u003ca href\u003d\"/radar/platforms/voice-platforms\"\u003evoice platforms\u003c/a\u003e, we\u0027ve seen a proliferation of tools and platforms that provide a service to extract intent from text and management of conversational flows that you can hook into. \u003ca href\u003d\"http://github.com/dialogflow\"\u003e\u003cstrong\u003eDialogFlow\u003c/strong\u003e\u003c/a\u003e (formerly API.ai), which was acquired by Google, is one such ‘natural-language-understanding as a service’ offering that competes with \u003ca href\u003d\"/radar/platforms/wit-ai\"\u003ewit.ai\u003c/a\u003e and \u003ca href\u003d\"http://aws.amazon.com/lex/\"\u003eAmazon Lex\u003c/a\u003e among other players in this space.\u003c/p\u003e","theta":"205","volume":"2017-11"},{"name":"GKE","id":"1193","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"40","display_name":"GKE","radius":"310","description":"\u003cp\u003eWhile the software development ecosystem is converging on \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e as the orchestration platform for containers, running Kubernetes clusters remains operationally complex. \u003cstrong\u003eGKE\u003c/strong\u003e (Google Kubernetes Engine) is a managed Kubernetes solution for deploying containerized applications that alleviates the operational overhead of running and maintaining Kubernetes clusters. Our teams have had a good experience using GKE, with the platform doing the heavy lifting of applying security patches, monitoring and auto-repairing the nodes, and managing multicluster and multiregion networking. In our experience, Google\u0027s API-first approach in exposing platform capabilities, as well as using industry standards such as OAuth for service authorization, improve the developer experience. It\u0027s important to consider that GKE is under rapid development which, despite the developers\u0027 best efforts to abstract consumers from underlying changes, has impacted us temporarily in the past. We\u0027re expecting continuous improvement around maturity of \u003ca href\u003d\"/radar/tools/infrastructure-as-code\"\u003eInfrastructure as code\u003c/a\u003e with \u003ca href\u003d\"http://www.terraform.io/docs/providers/google/r/container_cluster.html\"\u003eTerraform on GKE\u003c/a\u003e and similar tools.\u003c/p\u003e","theta":"210","volume":"2017-11"},{"name":"Hyperledger","id":"1075","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"41","display_name":"Hyperledger","radius":"330","description":"\u003cp\u003e\u003cstrong\u003eHyperledger\u003c/strong\u003e is a platform built around blockchain technologies. It consists of a blockchain implementation named Fabric and other associated tools. Disregarding the hype surrounding blockchain, our teams have found it easy to get started with these tools. The fact that it is an open source platform supported by the Linux Foundation also adds to our excitement about Hyperledger.\u003c/p\u003e","theta":"215","volume":"2017-11"},{"name":"Kafka Streams","id":"1058","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"42","display_name":"Kafka Streams","radius":"290","description":"\u003cp\u003e\u003cstrong\u003eKafka Streams\u003c/strong\u003e is a lightweight library for building streaming applications. It\u0027s been designed with the goal of simplifying stream processing enough to make it easily accessible as a mainstream application programming model for asynchronous services. It can be a good alternative in scenarios where you want to apply a stream processing model to your problem, without embracing the complexity of running a cluster (usually introduced by full-fledged stream processing frameworks). New developments include ‘exactly once’ stream processing in a Kafka cluster. This was achieved by introducing idempotency in Kafka producers and allowing atomic writes across multiple partitions using the new Transactions API.\u003c/p\u003e","theta":"220","volume":"2017-11"},{"name":"Language Server Protocol","id":"1195","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"43","display_name":"Language Server Protocol","radius":"300","description":"\u003cp\u003eMuch of the power of sophisticated IDEs comes from their ability to parse a program into an abstract syntax tree (AST) and then use that AST for program analysis and manipulation. This supports features such as autocomplete, finding callers and refactoring. Language servers pull this capability into a process that allows any text editor to access an API to work with the AST. Microsoft has led the creation of the \u003ca href\u003d\"http://github.com/Microsoft/language-server-protocol\"\u003e\u003cstrong\u003eLanguage Server Protocol\u003c/strong\u003e\u003c/a\u003e (LSP), harvested from their OmniSharp and TypeScript Server projects.\u003ca href\u003d\"http://langserver.org#implementations-client\"\u003eAny editor\u003c/a\u003e that uses this protocol can work with any language that has an \u003ca href\u003d\"http://langserver.org#implementations-server\"\u003eLSP-compliant server\u003c/a\u003e. This means we can keep using our favorite editors without forgoing the rich text editing modes of many languages — much to the delight of our Emacs addicts.\u003c/p\u003e","theta":"225","volume":"2017-11"},{"name":"LoRaWAN","id":"1197","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"44","display_name":"LoRaWAN","radius":"333","description":"\u003cp\u003e\u003cstrong\u003eLoRaWAN\u003c/strong\u003e is a low-power wide-area network, designed for low-power consumption and communication over long distances using low bitrates. It provides for communication between devices and gateways, which can then forward the data to, for example, applications or servers. A typical usage is for a distributed set of sensors, or for Internet of Things (IoT) devices, for which long battery life and long-range communication is a must. LoRaWAN addresses two of the key problems with attempting to use normal Wi-Fi for such applications: range and power consumption. There are several implementations, a notable one being \u003ca href\u003d\"http://www.thethingsnetwork.org/\"\u003eThe Things Network\u003c/a\u003e, a free, open source implementation.\u003c/p\u003e","theta":"230","volume":"2017-11"},{"name":"MapD","id":"1204","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"45","display_name":"MapD","radius":"330","description":"\u003cp\u003e\u003ca href\u003d\"http://www.mapd.com/\"\u003e\u003cstrong\u003eMapD\u003c/strong\u003e\u003c/a\u003e is an in-memory columnar analytic database with SQL support that\u0027s built to run on GPU. We debated whether the database workload is actually I/O or computationally bound but there are instances where the parallelism of the GPU, combined with the large bandwidth of VRAM, can be quite useful. MapD transparently manages the most frequently used data in VRAM (such as columns involved in group-by, filters, calculations and join conditions) and stores the rest of the data in the main memory. With this memory management setup, MapD achieves significant query performance without the need of indexes. Although there are other GPU database vendors, MapD is leading this segment with the recent open source release of its core database and through the \u003ca href\u003d\"https://github.com/gpuopenanalytics\"\u003eGPU Open Analytics Initiative\u003c/a\u003e. If your analytical workload is computationally heavy, can exploit GPU parallelism and can fit in the main memory, we recommend assessing MapD.\u003c/p\u003e","theta":"235","volume":"2017-11"},{"name":"Mosquitto","id":"1090","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"46","display_name":"Mosquitto","radius":"300","description":"\u003cp\u003eIn our experience—for Internet of Things (IoT) solutions where a lot of devices communicate with each other and/or a central data hub—the MQTT connectivity protocol has proven itself. We\u0027ve also come to like the \u003cstrong\u003e\u003ca href\u003d\"http://mosquitto.org/\"\u003eMosquitto\u003c/a\u003e\u003c/strong\u003e MQTT broker. It might not satisfy all demands, particularly with regard to scalability, but its compact nature and easy setup makes it ideal for development and testing purposes.\u003c/p\u003e","theta":"240","volume":"2017-11"},{"name":"Netlify","id":"1201","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"47","display_name":"Netlify","radius":"320","description":"\u003cp\u003eWe like simple tools that solve one problem really well, and \u003ca href\u003d\"http://www.netlify.com/\"\u003e\u003cstrong\u003eNetlify\u003c/strong\u003e\u003c/a\u003e fits this description nicely. You can create static website content, check it into GitHub and then quickly and easily get your site live and available. There is a CLI available to control the process; content delivery networks (CDNs) are supported; it can work alongside tools such as \u003ca href\u003d\"http://gruntjs.com/\"\u003eGrunt\u003c/a\u003e; and, most importantly, Netlify supports HTTPS.\u003c/p\u003e","theta":"245","volume":"2017-11"},{"name":"PlatformIO","id":"1089","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"48","display_name":"PlatformIO","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://platformio.org/\"\u003ePlatformIO\u003c/a\u003e\u003c/strong\u003e provides a rich ecosystem for IoT development by providing cross-platform builds, library management and good integration with existing IDEs. The intelligent code completion and Smart Code Linter with built-in terminal and serial port monitor greatly enhances the developer experience. It also organizes and maintains \u003ca href\u003d\"http://platformio.org/lib\"\u003ethousands of libraries\u003c/a\u003e and provides a clean dependency manager with semantic versioning to ease IoT development. We\u0027ve started using PlatformIO in a few IoT projects and we really like it for its simplicity and wide support of \u003ca href\u003d\"http://platformio.org/platforms\"\u003eplatforms\u003c/a\u003e and \u003ca href\u003d\"http://platformio.org/boards\"\u003eboards\u003c/a\u003e.\u003c/p\u003e","theta":"250","volume":"2017-11"},{"name":"TensorFlow Serving","id":"1198","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"49","display_name":"TensorFlow Serving","radius":"310","description":"\u003cp\u003eMachine-learning models are starting to creep into everyday business applications. When enough training data is available, these algorithms can address problems that might have previously required complex statistical models or heuristics. As we move from experimental use to production, we need a reliable way to host and deploy the models that can be accessed remotely and scale with the number of consumers. \u003ca href\u003d\"http://www.tensorflow.org/serving/\"\u003e\u003cstrong\u003eTensorFlow Serving\u003c/strong\u003e\u003c/a\u003e addresses part of that problem by exposing a remote gRPC interface to an exported model; this allows a trained model to be deployed in a variety of ways. TensorFlow Serving also accepts a stream of models to incorporate continuous training updates, and its authors maintain a Dockerfile to ease the deployment process. Presumably, the choice of gRPC is to be consistent with the TensorFlow execution model; however, we’re generally wary of protocols that require code generation and native bindings.\u003c/p\u003e","theta":"255","volume":"2017-11"},{"name":"Voice platforms","id":"1091","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"50","display_name":"Voice platforms","radius":"300","description":"\u003cp\u003e\u003cstrong\u003eVoice platforms\u003c/strong\u003e such as \u003ca href\u003d\"https://developer.amazon.com/alexa\"\u003eAmazon Alexa\u003c/a\u003e and \u003ca href\u003d\"https://developers.google.com/actions/\"\u003eGoogle Home\u003c/a\u003e are riding high on the hype cycle; some even herald the ubiquity of the conversational voice interface. We\u0027re already integrating conversational UIs into products and seeing the impact of this new interaction in how we design interfaces. Alexa specifically was built from the ground up without a screen and treats the conversational UI as first-class. But it\u0027s still too early to believe the hype, and we expect more big players to get in the game.\u003c/p\u003e","theta":"260","volume":"2017-11"},{"name":"Windows Containers","id":"1200","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"51","display_name":"Windows Containers","radius":"335","description":"\u003cp\u003eMicrosoft is catching up in the container space with \u003ca href\u003d\"http://docs.microsoft.com/en-us/virtualization/windowscontainers/about/\"\u003e\u003cstrong\u003eWindows Containers\u003c/strong\u003e\u003c/a\u003e. At the time of writing, Microsoft provides two Windows OS images as Docker containers, \u003ca href\u003d\"http://hub.docker.com/r/microsoft/windowsservercore/\"\u003eWindows Server 2016 Server Core\u003c/a\u003e and \u003ca href\u003d\"http://hub.docker.com/r/microsoft/nanoserver/\"\u003eWindows Server 2016 Nano Server\u003c/a\u003e. Although there is room for improvement for Windows Containers, for instance, decreasing the large image sizes, and enriching ecosystem support and documentation, our teams have started using them in scenarios where other containers have been working successfully, such as \u003ca href\u003d\"/radar/techniques/docker-for-builds\"\u003ebuild agents\u003c/a\u003e.\u003c/p\u003e","theta":"265","volume":"2017-11"},{"name":"Overambitious API gateways","id":"931","quadrant":"Platforms","ring":"Hold","movement":"t","radarId":"52","display_name":"Overambitious API gateways","radius":"382","description":"\u003cp\u003eWe remain concerned about business logic and process orchestration implemented in middleware, especially where it requires expert skills and tooling while creating single points of scaling and control. Vendors in the highly competitive API gateway market are continuing this trend by adding features through which they attempt to differentiate their products. This results in \u003cstrong\u003eoverambitious API gateway\u003c/strong\u003e products whose functionality — on top of what is essentially a reverse proxy — encourages designs that continue to be difficult to test and deploy. API gateways do provide utility in dealing with some specific concerns — such as authentication and rate limiting — but any domain smarts should live in applications or services.\u003c/p\u003e","theta":"225","volume":"2017-11"},{"name":"fastlane","id":"1018","quadrant":"Tools","ring":"Adopt","movement":"c","radarId":"53","display_name":"fastlane","radius":"75","description":"\u003cp\u003eWeb application developers have it easy when it comes to simplifying and automating diverse application workflows; they can choose from a variety of solutions to help automate release processes. When developing for mobile, however, we\u0027re dealing with two operating systems with two different ways of building, testing, distribution, generating screenshots, signing and distributing applications. To help ease the pain, our teams have adopted \u003cstrong\u003e\u003ca href\u003d\"https://fastlane.tools/\"\u003efastlane\u003c/a\u003e\u003c/strong\u003e as the go-to tool to automate the release process for iOS and Android applications. Using simple configurations and multiple pipelines, they can achieve \u003ca href\u003d\"/radar/techniques/continuous-delivery-cd\"\u003econtinuous delivery\u003c/a\u003e for mobile development.\u003c/p\u003e","theta":"45","volume":"2017-11"},{"name":"Buildkite","id":"1146","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"54","display_name":"Buildkite","radius":"200","description":"\u003cp\u003eOur teams very much like the hosted CI/CD tool \u003ca href\u003d\"http://buildkite.com/\"\u003e\u003cstrong\u003eBuildkite\u003c/strong\u003e\u003c/a\u003e for its simplicity and quick setup. With Buildkite, you provide your own machines to execute builds — on premise or in the cloud — and install a lightweight agent application to connect the build agent to the hosted service. In many cases, having this level of control over the configuration of your build agents is a plus when compared to using hosted agents.\u003c/p\u003e","theta":"80","volume":"2017-11"},{"name":"CircleCI","id":"1147","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"55","display_name":"CircleCI","radius":"200","description":"\u003cp\u003e\u003ca href\u003d\"http://circleci.com/\"\u003e\u003cstrong\u003eCircleCI\u003c/strong\u003e\u003c/a\u003e is a continuous integration engine offered as SaaS and on premise. CircleCI has been the go-to SaaS CI tool for many of our development teams, who needed a low-friction and easy-to-setup build and deployment pipeline. CircleCI version 2.0 supports workflows of build jobs, with fan-in and fan-out flows and manual gates, as well as mobile development. It allows developers to run the pipelines locally and easily integrates with Slack and other notification and alerting systems. We recommend you take a closer look at the \u003ca href\u003d\"http://circleci.com/security/\"\u003esecurity practices of CircleCI\u003c/a\u003e, just as you would with any other SaaS product that hosts your company’s assets.\u003c/p\u003e","theta":"70","volume":"2017-11"},{"name":"gopass","id":"1145","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"56","display_name":"gopass","radius":"240","description":"\u003cp\u003e\u003ca href\u003d\"http://www.justwatch.com/gopass/\"\u003e\u003cstrong\u003egopass\u003c/strong\u003e\u003c/a\u003e is a password management solution for teams, built on GPG and \u003ca href\u003d\"/radar/tools/git\"\u003eGit\u003c/a\u003e. It\u0027s a descendant of \u003ca href\u003d\"http://www.passwordstore.org\"\u003epass\u003c/a\u003e and adds features such as: support for recipient management and multiple password stores in a single tree; an interactive search functionality; time-based one-time password (TOTP) support; and storage of binary data. Migration of your pass store is fairly straightforward, because gopass is largely compatible with the format pass uses. This also means integration into provisioning workflows can be achieved with a single call to a stored secret.\u003c/p\u003e","theta":"60","volume":"2017-11"},{"name":"Headless Chrome for front-end test","id":"1148","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"57","display_name":"Headless Chrome for front-end test","radius":"200","description":"\u003cp\u003eSince mid-2017, Chrome users have had the option of running the browser in headless mode. This feature is ideally suited to running front-end browser tests without the overhead of displaying actions on a screen. Previously, this was largely the province of PhantomJS but \u003ca href\u003d\"http://developers.google.com/web/updates/2017/06/headless-karma-mocha-chai\"\u003eHeadless Chrome\u003c/a\u003e is rapidly replacing the JavaScript-driven WebKit approach. Tests in Headless Chrome should run much faster, and behave more like a real browser, but our teams have found that it does use more memory than PhantomJS. With all these advantages, \u003cstrong\u003eHeadless Chrome for front-end test\u003c/strong\u003e is likely to become the de facto standard.\u003c/p\u003e","theta":"50","volume":"2017-11"},{"name":"jsoniter","id":"1144","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"58","display_name":"jsoniter","radius":"240","description":"\u003cp\u003eIf you\u0027re looking for a JSON encoder/decoder with high performance in Go and Java, check out the open source \u003ca href\u003d\"http://jsoniter.com/\"\u003e\u003cstrong\u003ejsoniter\u003c/strong\u003e\u003c/a\u003e library. The library is compatible with the \u003ca href\u003d\"http://golang.org/pkg/encoding/json/\"\u003estandard JSON encoding package in Go\u003c/a\u003e.\u003c/p\u003e","theta":"40","volume":"2017-11"},{"name":"Prometheus","id":"849","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"59","display_name":"Prometheus","radius":"200","description":"\u003cp\u003eWe\u0027ve seen both continuing improvements in and an uptick in adoption of \u003ca href\u003d\"http://prometheus.io/\"\u003e\u003cstrong\u003ePrometheus\u003c/strong\u003e\u003c/a\u003e, the monitoring and time series database tool originally developed by Soundcloud. Prometheus primarily supports a pull-based HTTP model but it also supports alerts, making it an active part of your operational toolset. As of this writing, Prometheus 2.0 is in prerelease, and continues to evolve. Prometheus developers have focused their efforts on core time series databases and the variety of metrics available. \u003ca href\u003d\"/radar/tools/grafana\"\u003eGrafana\u003c/a\u003e has become the dashboard visualization tool of choice for Prometheus users and support for Grafana ships with the tool. Our teams also find that Prometheus monitoring nicely complements the indexing and search capabilities of an Elastic Stack.\u003c/p\u003e","theta":"30","volume":"2017-11"},{"name":"Scikit-learn","id":"1033","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"60","display_name":"Scikit-learn","radius":"180","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://scikit-learn.org/stable/\"\u003eScikit-learn\u003c/a\u003e\u003c/strong\u003e is not a new tool (it is approaching its tenth birthday); what is new is the rate of adoption of machine-learning tools and techniques outside of academia and major tech companies. Providing a robust set of models and a rich set of functionality, Scikit-learn plays an important role in making machine-learning concepts and capabilities more accessible to a broader (and often non-expert) audience.\u003c/p\u003e","theta":"20","volume":"2017-11"},{"name":"Serverless Framework","id":"1120","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"61","display_name":"Serverless Framework","radius":"175","description":"\u003cp\u003eThe popular \u003cstrong\u003e\u003ca href\u003d\"https://serverless.com/\"\u003eServerless Framework\u003c/a\u003e\u003c/strong\u003e provides tooling for scaffolding and deployment of serverless applications, primarily using \u003ca href\u003d\"/radar/platforms/aws-lambda\"\u003eAWS Lambda\u003c/a\u003e and other AWS offerings. Serverless Framework provides template support for JavaScript, Python, Java and C#, and has an active community that contributes plugins that extend the framework. The framework also supports the Apache incubator project OpenWhisk as an alternative to AWS Lambda.\u003c/p\u003e","theta":"10","volume":"2017-11"},{"name":"Apex","id":"1150","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"62","display_name":"Apex","radius":"330","description":"\u003cp\u003e\u003ca href\u003d\"http://github.com/apex/apex\"\u003e\u003cstrong\u003eApex\u003c/strong\u003e\u003c/a\u003e is a tool to build, deploy and manage AWS Lambda functions with ease. With Apex, you can write functions in languages that are not yet natively supported in AWS, including Golang, Rust and others. This is made possible by a Node.js shim, which creates a child process and processes events through stdin and stdout. Apex has a lot of nice \u003ca href\u003d\"http://github.com/apex/apex#features\"\u003efeatures\u003c/a\u003e that improve the developer experience, and we particularly like the ability to test functions locally and perform a dry run of the changes before they\u0027re applied to AWS resources.\u003c/p\u003e","theta":"85","volume":"2017-11"},{"name":"assertj-swagger","id":"1157","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"63","display_name":"assertj-swagger","radius":"300","description":"\u003cp\u003eAn \u003ca href\u003d\"/radar/languages-and-frameworks/assertj\"\u003eAssertJ\u003c/a\u003e library, \u003ca href\u003d\"http://github.com/RobWin/assertj-swagger\"\u003e\u003cstrong\u003eassertj-swagger\u003c/strong\u003e\u003c/a\u003e enables you to validate an API implementation\u0027s compliance with its contract specification. Our teams use assertj-swagger to catch problems when the API endpoint implementation changes without updating its \u003ca href\u003d\"/radar/tools/swagger\"\u003eSwagger\u003c/a\u003e specification, or fails to publish the updated documentation.\u003c/p\u003e","theta":"79","volume":"2017-11"},{"name":"Cypress","id":"1149","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"64","display_name":"Cypress","radius":"300","description":"\u003cp\u003eFixing end-to-end test failures in CI can be a painful experience, especially in headless mode. \u003ca href\u003d\"http://www.cypress.io/\"\u003e\u003cstrong\u003eCypress\u003c/strong\u003e\u003c/a\u003e is a useful tool that helps developers build end-to-end tests easily and records all test steps as a video in an MP4 file. Instead of reproducing the issue in headless mode, developers can watch the testing video in order to fix it. Cypress is a powerful platform, not only a testing framework. Currently, we\u0027ve integrated its CLI with headless CI in our projects.\u003c/p\u003e","theta":"74","volume":"2017-11"},{"name":"Flow","id":"1163","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"65","display_name":"Flow","radius":"300","description":"\u003cp\u003e\u003ca href\u003d\"http://flow.org/\"\u003e\u003cstrong\u003eFlow\u003c/strong\u003e\u003c/a\u003e is a static type checker for JavaScript that allows you to add type checking across the codebase incrementally. Unlike Typescript, which is a different language, Flow can be added incrementally to an existing JavaScript codebase supporting the 5th, 6th and 7th editions of ECMAScript. We suggest adding Flow to your continuous integration pipeline, starting with the code that concerns you most. Flow adds to the clarity of the code, increases the reliability of refactoring and catches type-related bugs early during the build.\u003c/p\u003e","theta":"68","volume":"2017-11"},{"name":"InSpec","id":"1113","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"66","display_name":"InSpec","radius":"310","description":"\u003cp\u003eHow does a business hand autonomy to delivery teams while still making sure their deployed solutions are safe and compliant? How do you ensure that servers, once deployed, remain secure and compliant over their operational lifetime? These are the problems that \u003cstrong\u003eInSpec\u003c/strong\u003e tries to address. InSpec is an infrastructure testing tool inspired by \u003ca href\u003d\"/radar/tools/serverspec\"\u003eServerspec\u003c/a\u003e, but with modifications that make the tool more useful for security professionals who need to ensure compliance across thousands of servers. Individual tests can be combined into complete security profiles and run remotely from a command line. InSpec is useful for developers but extends to testing deployed production infrastructure continuously, moving toward \u003ca href\u003d\"/radar/techniques/qa-in-production\"\u003eQA in production\u003c/a\u003e.\u003c/p\u003e","theta":"62","volume":"2017-11"},{"name":"Jupyter","id":"1154","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"67","display_name":"Jupyter","radius":"300","description":"\u003cp\u003eOver the last couple of years, we\u0027ve noticed a steady rise in the popularity of analytics notebooks. These are Mathematica-inspired applications that combine text, visualization and code in a living, computational document. In a previous edition, we mentioned \u003ca href\u003d\"/radar/tools/gorilla-repl\"\u003eGorillaREPL\u003c/a\u003e, a Clojure variant of these. But increased interest in machine learning — along with the emergence of Python as the programming language of choice for practitioners in this field — has focused particular attention on Python notebooks, of which \u003ca href\u003d\"http://jupyter.org/\"\u003e\u003cstrong\u003eJupyter\u003c/strong\u003e\u003c/a\u003e seems to be gaining the most traction among ThoughtWorks teams.\u003c/p\u003e","theta":"57","volume":"2017-11"},{"name":"Kong API Gateway","id":"1159","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"68","display_name":"Kong API Gateway","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"http://getkong.org/\"\u003eKong\u003c/a\u003e is an \u003ca href\u003d\"http://github.com/Kong/kong\"\u003eopen source API gateway\u003c/a\u003e built and sponsored by Mashape, who also provide an enterprise offering integrating Kong with their proprietary API analytics and developer portal tools. They can be deployed in a variety of configurations, as an edge API gateway or an internal API proxy. \u003ca href\u003d\"http://openresty.org/en/\"\u003eOpenResty\u003c/a\u003e, through its Nginx modules, provides a strong and performant foundation, with Lua plugins for extensions. Kong can either use PostgreSQL for single region deployments or Cassandra for multiregion configurations. Our developers have enjoyed Kong\u0027s high performance, its API-first approach (which enables automation of its configuration) and its ease of deployment as a container. \u003cstrong\u003eKong API Gateway\u003c/strong\u003e , unlike \u003ca href\u003d\"/radar/platforms/overambitious-api-gateways\"\u003eoverambitious API gateways\u003c/a\u003e, has a smaller set of features but it implements the essential set of API gateway capabilities such as traffic control, security, logging, monitoring and authentication. We\u0027re excited to assess Kong in a sidecar configuration in the near future.\u003c/p\u003e","theta":"51","volume":"2017-11"},{"name":"kops","id":"1152","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"69","display_name":"kops","radius":"300","description":"\u003cp\u003e\u003ca href\u003d\"http://github.com/kubernetes/kops\"\u003e\u003cstrong\u003ekops\u003c/strong\u003e\u003c/a\u003e is a command line tool for creating and managing high-availability production \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e clusters. Initially targeting AWS, it now has experimental support for other providers. It can get you up and running fast, and even though a few features (such as rolling upgrades) have yet to be fully developed, we\u0027ve been impressed by the community.\u003c/p\u003e","theta":"45","volume":"2017-11"},{"name":"Lighthouse","id":"1158","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"70","display_name":"Lighthouse","radius":"300","description":"\u003cp\u003e\u003cstrong\u003eLighthouse\u003c/strong\u003e is a tool written by Google to assess web applications for adherence to \u003ca href\u003d\"/radar/techniques/progressive-web-applications\"\u003eProgressive Web App\u003c/a\u003e standards. This year\u0027s Lighthouse 2.0 release adds performance metrics and accessibility checks to the basic toolset. This added functionality has now been incorporated into the standard Chrome developer tools under the audit tab. Lighthouse 2.0 is yet another beneficiary of Chrome\u0027s headless mode. This provides an alternative to \u003ca href\u003d\"/radar/tools/pa11y\"\u003ePa11y\u003c/a\u003e and similar tools for running accessibility checks in a continuous integration pipeline, since the tool can be run from the command line or standalone as a Node.js application.\u003c/p\u003e","theta":"40","volume":"2017-11"},{"name":"Rendertron","id":"1156","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"71","display_name":"Rendertron","radius":"320","description":"\u003cp\u003eA perennial problem for JavaScript-heavy web applications is how to make the dynamic portion of those pages available to search engines. Historically, developers have resorted to a variety of tricks, including server-side rendering with \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e, external services or prerendering content. Now Google Chrome\u0027s new headless mode adds a new ‘trick’ to the toolbox — \u003ca href\u003d\"http://github.com/GoogleChrome/rendertron\"\u003e\u003cstrong\u003eRendertron\u003c/strong\u003e\u003c/a\u003e, a headless Chrome rendering solution. Rendertron wraps an instance of headless Chrome in a Docker container, ready to deploy as a standalone HTTP server. Bots that don\u0027t render JavaScript can be routed to this server to do the rendering for them. Although developers can always deploy their own headless Chrome proxy and associated routing machinery, Rendertron simplifies the configuration and deployment process, and provides example middleware code for detecting and routing bots.\u003c/p\u003e","theta":"34","volume":"2017-11"},{"name":"Sonobuoy","id":"1162","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"72","display_name":"Sonobuoy","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"http://heptio.com/opensource/#heptio-sonobuoy\"\u003e\u003cstrong\u003eSonobuoy\u003c/strong\u003e\u003c/a\u003e is a diagnostic tool for running end-to-end conformance tests on any \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e cluster in a nondestructive way. The team at \u003ca href\u003d\"http://heptio.com/\"\u003eHeptio\u003c/a\u003e, which was founded by two creators of the Kubernetes projects, built this tool to ensure that the wide array of Kubernetes distributions and configurations conform to the best practices, while following the open source standardization for interoperability of clusters. We\u0027re experimenting with Sonobuoy to run as part of our \u003ca href\u003d\"/radar/tools/infrastructure-as-code\"\u003einfrastructure as code\u003c/a\u003e build pipeline, as well as continuous monitoring of our Kubernetes installations, to validate the behavior and health of the whole cluster.\u003c/p\u003e","theta":"29","volume":"2017-11"},{"name":"spaCy","id":"1111","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"73","display_name":"spaCy","radius":"287","description":"\u003cp\u003e\u003ca href\u003d\"https://spacy.io/\"\u003e\u003cstrong\u003espaCy\u003c/strong\u003e\u003c/a\u003e is a Natural Language Processing (NLP) library written in Python. It is a high-performance library, intended for use by developers in production, and applies NLP models suited for processing text that often mixes in emoticons and inconsistent punctuation marks. Unlike other NLP frameworks, spaCy is a pluggable library and not a platform; it is aimed at production applications rather than model training for research. It plays well with \u003ca href\u003d\"/radar/platforms/tensorflow\"\u003eTensorFlow\u003c/a\u003e and the rest of the Python AI ecosystem. We\u0027ve used spaCy in the enterprise context to build a search engine that takes human language queries and helps users make business decisions.\u003c/p\u003e","theta":"23","volume":"2017-11"},{"name":"Spinnaker","id":"1110","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"74","display_name":"Spinnaker","radius":"290","description":"\u003cp\u003e\u003ca href\u003d\"http://techblog.netflix.com/2015/11/global-continuous-delivery-with.html\"\u003eNetflix\u003c/a\u003e has open sourced \u003ca href\u003d\"http://www.spinnaker.io/\"\u003e\u003cstrong\u003eSpinnaker\u003c/strong\u003e\u003c/a\u003e, its microservices continuous delivery (CD) platform. Compared to other CI/CD platforms, Spinnaker implements cluster management and deployment of baked images to the cloud as first-class features. It supports out-of-the-box deployment and cluster management for multiple cloud providers such as Google Cloud Platform, AWS and \u003ca href\u003d\"/radar/platforms/pivotal-cloud-foundry\"\u003ePivotal Cloud Foundry\u003c/a\u003e. You can integrate Spinnaker with Jenkins to run a Jenkins job build. We like Spinnaker\u0027s opinionated approach for deploying microservices to the cloud—with the exception that Spinnaker\u0027s pipelines are created via a user interface (UI) and cannot be configured as code.\u003c/p\u003e","theta":"17","volume":"2017-11"},{"name":"Spring Cloud Contract","id":"1155","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"75","display_name":"Spring Cloud Contract","radius":"300","description":"\u003cp\u003eIf you\u0027re implementing Java services using the \u003ca href\u003d\"http://spring.io/\"\u003eSpring\u003c/a\u003e framework, you may want to consider \u003ca href\u003d\"http://cloud.spring.io/spring-cloud-contract/\"\u003e\u003cstrong\u003eSpring Cloud Contract\u003c/strong\u003e\u003c/a\u003e for \u003ca href\u003d\"/radar/techniques/consumer-driven-contract-testing\"\u003econsumer-driven contract testing\u003c/a\u003e. The current ecosystem of this tool supports verification of the client calls and the server implementation against the contract. In comparison to \u003ca href\u003d\"/radar/tools/pact-pacto\"\u003ePact\u003c/a\u003e, an open source consumer-driven contract testing tool set, it lacks the brokering of the contracts and the support for other programming languages. However, it integrates well with the Spring ecosystem, for instance message routing with \u003ca href\u003d\"http://projects.spring.io/spring-integration/\"\u003eSpring Integration\u003c/a\u003e.\u003c/p\u003e","theta":"12","volume":"2017-11"},{"name":"Yarn","id":"1112","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"76","display_name":"Yarn","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://yarnpkg.com/en/\"\u003eYarn\u003c/a\u003e\u003c/strong\u003e is a new package manager that replaces the existing workflow for the npm client while remaining compatible with the npm registry. With the npm client, we may end up with a different tree structure under node_modules based on the order that dependencies are installed. This nondeterministic nature can cause \"works on my machine\" problems. By breaking the installation steps into resolution, fetching and linking, Yarn avoids these issues using deterministic algorithms and lockfiles and thus guarantees repeatable installations. We\u0027ve also seen significantly faster builds in our continuous integration (CI) environment because of Yarn caching all the packages it downloads.\u003c/p\u003e","theta":"6","volume":"2017-11"},{"name":"Python 3","id":"679","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radarId":"77","display_name":"Python 3","radius":"90","description":"\u003cp\u003e\u003cstrong\u003ePython 3\u003c/strong\u003e introduced many useful features that are not backward compatible with Python 2.x. It also removed numerous Python 2.x features that were maintained for backward compatibility, making Python 3 easier to learn and use and more consistent with the rest of the language. Our experience using Python 3 in domains such as machine learning and web application development shows that both the language and most of its \u003ca href\u003d\"http://py3readiness.org/\"\u003esupporting libraries\u003c/a\u003e have matured for adoption. We were able to fork and patch minor issues of existing libraries or avoided using incompatible Python 2.x libraries that had been abandoned. If you are developing in Python we strongly encourage you to use Python 3.\u003c/p\u003e","theta":"315","volume":"2017-11"},{"name":"Angular","id":"1070","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"78","display_name":"Angular","radius":"210","description":"\u003cp\u003eIn previous Radar editions, we\u0027ve been hesitant to give \u003cstrong\u003eAngular\u003c/strong\u003e a strong recommendation because it was essentially a new, and on the whole unexciting, framework, sharing only its name with AngularJS, an older framework we loved in days past. In the meantime, Angular, now in version 5, has improved steadily while providing backward compatibility along the way. Several of our teams have Angular applications in production and reportedly, they like what they see. For this reason, we\u0027re moving Angular into the Trial ring in this Radar, to signify that some of our teams now consider it a solid choice. Most of our teams, however, still prefer \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e, \u003ca href\u003d\"/radar/languages-and-frameworks/vue-js\"\u003eVue\u003c/a\u003e or \u003ca href\u003d\"/radar/languages-and-frameworks/ember-js\"\u003eEmber\u003c/a\u003e over Angular.\u003c/p\u003e","theta":"280","volume":"2017-11"},{"name":"AssertJ","id":"1165","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"79","display_name":"AssertJ","radius":"170","description":"\u003cp\u003e\u003ca href\u003d\"http://joel-costigliola.github.io/assertj/index.html\"\u003e\u003cstrong\u003eAssertJ\u003c/strong\u003e\u003c/a\u003e is a Java library that provides a \u003ca href\u003d\"http://martinfowler.com/bliki/FluentInterface.html\"\u003efluent interface\u003c/a\u003e for assertions, which makes it easy to convey intent within test code. AssertJ gives readable error messages, soft assertions, and improved collections and exception support. We\u0027re seeing some teams default to its use instead of JUnit combined with Hamcrest.\u003c/p\u003e","theta":"290","volume":"2017-11"},{"name":"Avro","id":"1082","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"80","display_name":"Avro","radius":"200","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://avro.apache.org/\"\u003eAvro\u003c/a\u003e\u003c/strong\u003e is a framework for data serialization. By storing schema along with the message content, it encourages schema evolution. Producers can edit field names, add new fields or delete existing fields and Avro guarantees that the clients continue to consume the messages. Having a schema allows data to be written without overhead which results in compact data encoding and faster data processing. Although the exchange of structure-less messages between producer and consumer is flexible, we\u0027ve seen teams facing issues with incompatible unprocessed messages in the queue during deployments. We\u0027ve used Avro in a number of projects and would recommend using it over just sending unstructured messages.\u003c/p\u003e","theta":"300","volume":"2017-11"},{"name":"CSS Grid Layout","id":"1166","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"81","display_name":"CSS Grid Layout","radius":"170","description":"\u003cp\u003eCSS is the preferred choice for laying out web pages, even when it did not provide much explicit support for creating layouts. Flexbox helped with simpler, one-dimensional layouts, but developers usually reached for libraries and toolkits for more complex layouts. \u003ca href\u003d\"http://www.w3.org/TR/css-grid-1\"\u003e\u003cstrong\u003eCSS Grid Layout\u003c/strong\u003e\u003c/a\u003e is a two-dimensional grid-based layout system that provides a mechanism to divide available space for layout into columns and rows using a set of predictable sizing behaviors. Grid does not require any libraries and plays well with Flexbox and other CSS display elements. However, since IE11 is only \u003ca href\u003d\"http://caniuse.com/#search\u003dcss%20grid%20layout\"\u003epartially supported\u003c/a\u003e, it ignores users who still depend on a Microsoft browser on Windows 7.\u003c/p\u003e","theta":"310","volume":"2017-11"},{"name":"CSS Modules","id":"1187","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"82","display_name":"CSS Modules","radius":"230","description":"\u003cp\u003eMost large CSS codebases require complex naming schemes to help avoid naming conflicts in the global namespace. \u003ca href\u003d\"http://github.com/css-modules/css-modules\"\u003e\u003cstrong\u003eCSS Modules\u003c/strong\u003e\u003c/a\u003e address these problems by creating a local scope for all class names in a single CSS file. This file is imported to a JavaScript module, where CSS classes are referenced as strings. Then, in the build pipeline (Webpack, Browserify, etc.), the class names are replaced with generated unique strings. This is a significant change in responsibilities. Previously, a human had to manage the global namespace, to avoid class naming conflicts; now that responsibility rests with the build tooling. A small downside we\u0027ve encountered with CSS Modules: functional tests are usually out of the local scope and can therefore not reference classes by the name defined in the CSS file. We recommend using IDs or data attributes instead.\u003c/p\u003e","theta":"320","volume":"2017-11"},{"name":"Jest","id":"1164","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"83","display_name":"Jest","radius":"165","description":"\u003cp\u003eOur teams are delighted with the results of using \u003ca href\u003d\"http://facebook.github.io/jest/\"\u003e\u003cstrong\u003eJest\u003c/strong\u003e\u003c/a\u003e for front-end testing. It provides a ‘zero-configuration’ experience and has out-of-the-box features such as mocking and code coverage. You can apply this testing framework not only to \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e applications, but also to other JavaScript frameworks. One of Jest\u0027s often hyped features is UI snapshot testing. Snapshot testing would be a good addition to the upper layer of the \u003ca href\u003d\"http://martinfowler.com/bliki/TestPyramid.html\"\u003etest pyramid\u003c/a\u003e, but remember, unit testing is still the solid foundation.\u003c/p\u003e","theta":"330","volume":"2017-11"},{"name":"Kotlin","id":"1077","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"84","display_name":"Kotlin","radius":"210","description":"\u003cp\u003eThe announcement of first-class Android support has given an extra boost to the rapidly progressing \u003cstrong\u003eKotlin\u003c/strong\u003e language, and we\u0027re closely following the progress of \u003ca href\u003d\"http://blog.jetbrains.com/kotlin/2017/04/kotlinnative-tech-preview-kotlin-without-a-vm/\"\u003eKotlin/Native\u003c/a\u003e — the LLVM-backed ability to compile to native executables. Null safety, data classes and the ease of creating DSLs are some of the benefits we\u0027ve enjoyed, along with the \u003ca href\u003d\"http://github.com/Kotlin/anko\"\u003eAnko\u003c/a\u003e library for Android development. Despite the downsides of slow initial compilation and reliance on IntelliJ for first-class IDE support, we recommend giving this fresh and concise modern language a try.\u003c/p\u003e","theta":"340","volume":"2017-11"},{"name":"Spring Cloud","id":"1083","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"85","display_name":"Spring Cloud","radius":"250","description":"\u003cp\u003e\u003ca href\u003d\"http://projects.spring.io/spring-cloud/\"\u003e\u003cstrong\u003eSpring Cloud\u003c/strong\u003e\u003c/a\u003e continues to evolve and add interesting new features. Support for binding to \u003ca href\u003d\"/radar/platforms/kafka-streams\"\u003eKafka Streams\u003c/a\u003e, for example, in the spring-cloud-streams project makes it relatively easy to build message driven applications with connectors for Kafka and RabbitMQ. The teams we have using it appreciate the simplicity it brings to using sometimes complex infrastructure, such as \u003ca href\u003d\"http://zookeeper.apache.org/\"\u003eZooKeeper\u003c/a\u003e, and support for common problems that we need to address when building distributed systems, tracing with the \u003ca href\u003d\"http://cloud.spring.io/spring-cloud-sleuth/\"\u003espring-cloud-sleuth\u003c/a\u003e for example. The usual caveats apply but we\u0027re successfully using it on multiple projects.\u003c/p\u003e","theta":"350","volume":"2017-11"},{"name":"Android Architecture Components","id":"1185","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"86","display_name":"Android Architecture Components","radius":"310","description":"\u003cp\u003eHistorically, Google\u0027s Android documentation examples lacked architecture and structure. This changes with the release of \u003cstrong\u003eAndroid Architecture Components\u003c/strong\u003e , a set of opinionated libraries that help developers create Android applications with better architecture. They address longstanding pain points of Android development: handling lifecycles; pagination; SQLite databases; and data persistence over configuration changes. The libraries don\u0027t need to be used together — you can pick the ones you need most and integrate them into your existing project.\u003c/p\u003e","theta":"274","volume":"2017-11"},{"name":"ARKit/ARCore","id":"1182","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"87","display_name":"ARKit/ARCore","radius":"285","description":"\u003cp\u003eWe\u0027ve seen a flurry of activity in mobile augmented reality much of it fueled by \u003cstrong\u003eARKit and ARCore\u003c/strong\u003e , the native AR libraries used by \u003ca href\u003d\"http://developer.apple.com/arkit/\"\u003eApple\u003c/a\u003e and \u003ca href\u003d\"http://developers.google.com/ar/\"\u003eGoogle\u003c/a\u003e, respectively. These libraries are bringing mobile AR technologies to the mainstream. However, the challenge will be for companies to find use cases that go beyond gimmicky and provide genuine solutions that actually enhance the user experience.\u003c/p\u003e","theta":"278","volume":"2017-11"},{"name":"Atlas and BeeHive","id":"1179","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"88","display_name":"Atlas and BeeHive","radius":"310","description":"\u003cp\u003eA multi-app strategy is really controversial, particularly at a time when fewer and fewer users are downloading new apps. Instead of introducing a new app and struggling with the download numbers, multiteams have to deliver functionality via a single app that is already widely installed, which creates an architectural challenge. \u003cstrong\u003e\u003ca href\u003d\"http://github.com/alibaba/atlas\"\u003eAtlas\u003c/a\u003e and \u003ca href\u003d\"http://github.com/alibaba/BeeHive\"\u003eBeeHive\u003c/a\u003e\u003c/strong\u003e are modularization solutions for Android and iOS apps, respectively. Atlas and BeeHive enable multiteams working on physically isolated modules to reassemble or dynamically load these modules from a facade app. Both are Alibaba open source projects, since Alibaba encountered the same problem of dwindling downloads and single-app architectural challenges.\u003c/p\u003e","theta":"282","volume":"2017-11"},{"name":"Caffe","id":"1072","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"89","display_name":"Caffe","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"http://caffe.berkeleyvision.org/\"\u003e\u003cstrong\u003eCaffe\u003c/strong\u003e\u003c/a\u003e is an open source library for deep learning created by the \u003ca href\u003d\"http://bair.berkeley.edu/\"\u003eBerkeley Vision and Learning Center\u003c/a\u003e. It mostly focusses on convolutional networks for computer vision applications. Caffe is a solid and popular choice for computer vision-related tasks and you can download many successful models made by Caffe users from the Caffe Model Zoo for out-of-the-box use. Like \u003ca href\u003d\"/radar/languages-and-frameworks/keras\"\u003eKeras\u003c/a\u003e, Caffe is a Python-based API. In Keras, however, models and components are objects created directly in Python code, whereas Caffe models are described by \u003ca href\u003d\"https://developers.google.com/protocol-buffers/\"\u003eProtobuf\u003c/a\u003e configuration files. Either approach has its pros and cons, and converting between the two is also possible.\u003c/p\u003e","theta":"287","volume":"2017-11"},{"name":"Clara rules","id":"1180","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"90","display_name":"Clara rules","radius":"285","description":"\u003cp\u003eOur first rule of thumb in selecting a rules engine is normally: you don\u0027t need a rules engine. We\u0027ve seen too many people tying themselves to a hard-to-test black-box rules engine for spurious reasons, when custom code would have been a better solution. That said, we\u0027ve had success using \u003ca href\u003d\"http://www.clara-rules.org/\"\u003e\u003cstrong\u003eClara rules\u003c/strong\u003e\u003c/a\u003e for scenarios where a rules engine does make sense. We like that it uses simple Clojure code to express and evaluate the rules, which means they are amenable to refactoring, testing and source control. Rather than chasing the illusion that business people should directly manipulate the rules, it drives collaboration between the business experts and developers.\u003c/p\u003e","theta":"291","volume":"2017-11"},{"name":"CSS-in-JS","id":"1186","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"91","display_name":"CSS-in-JS","radius":"285","description":"\u003cp\u003e\u003cstrong\u003eCSS in JS\u003c/strong\u003e is a technique of writing CSS styling in the JavaScript programming language. This encourages a common pattern of writing the styling with the JavaScript component it applies to, co-locating presentational and logical concerns. The new players — including \u003ca href\u003d\"http://github.com/cssinjs/jss\"\u003eJSS\u003c/a\u003e, \u003ca href\u003d\"http://github.com/emotion-js/emotion\"\u003eemotion\u003c/a\u003e and \u003ca href\u003d\"http://github.com/styled-components/styled-components\"\u003estyled-components\u003c/a\u003e — rely on the tooling to translate the CSS-in-JS code to separate CSS stylesheets, to make them suitable for browser consumption. This is the second-generation approach to writing CSS in JavaScript and unlike the previous approaches doesn’t rely on in-line styles. That means it provides the benefit of supporting all CSS features, sharing of CSS using the \u003ca href\u003d\"/radar/techniques/npm-for-all-the-things\"\u003enpm\u003c/a\u003e ecosystem and utilization of components across multiple platforms. Our teams have found \u003ca href\u003d\"http://github.com/styled-components/styled-components\"\u003estyled-components\u003c/a\u003e working well with component-based frameworks, such as \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e, and unit testing of CSS with \u003ca href\u003d\"http://github.com/styled-components/jest-styled-components\"\u003ejest-styled-components\u003c/a\u003e. This space is new and rapidly changing; the approach requires some effort for manual debugging of the generated class names in the browser, and it may not apply to some projects where the front-end architecture does not support reusing components and requires global styling.\u003c/p\u003e","theta":"295","volume":"2017-11"},{"name":"Digdag","id":"1176","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"92","display_name":"Digdag","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"http://www.digdag.io/\"\u003e\u003cstrong\u003eDigdag\u003c/strong\u003e\u003c/a\u003e is a tool for building, running, scheduling and monitoring complex data pipelines in the cloud. You can define these pipelines in YAML, using either the rich set of out-of-the-box operators or building your own through the API. Digdag has most of the common features in a data pipeline solution such as dependency management, modular workflow to promote reuse, secured secret management and multilingual support. The feature we\u0027re most excited about is polycloud support, which lets you move and join data across AWS RedShift, S3, and Google \u003ca href\u003d\"/radar/platforms/bigquery\"\u003eBigQuery\u003c/a\u003e. As more and more cloud providers offer competing data-processing solutions, we think Digdag (and similar tools) will be useful in leveraging the best option for the task.\u003c/p\u003e","theta":"300","volume":"2017-11"},{"name":"Druid","id":"1169","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"93","display_name":"Druid","radius":"285","description":"\u003cp\u003e\u003ca href\u003d\"http://github.com/jilen/druid\"\u003e\u003cstrong\u003eDruid\u003c/strong\u003e\u003c/a\u003e is a JDBC connection pool with rich monitoring features. It has a built-in SQL parser, which provides semantic monitoring of the SQL statements executing in the database. Injections or suspicious SQL statements will be blocked and logged directly from the JDBC layer. What’s more, queries can be merged based on their semantics. This is an Alibaba open source project, and reflects the lessons Alibaba learnt from operating their own database systems.\u003c/p\u003e","theta":"304","volume":"2017-11"},{"name":"ECharts","id":"1170","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"94","display_name":"ECharts","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"http://github.com/ecomfe/echarts\"\u003e\u003cstrong\u003eECharts\u003c/strong\u003e\u003c/a\u003e is a lightweight charting library with rich support for different types of charts and interactions. Since ECharts is entirely based on the \u003ca href\u003d\"http://developer.mozilla.org/en-US/docs/Web/API/Canvas_API\"\u003eCanvas API\u003c/a\u003e, it has incredible performance even when dealing with over 100k data points, and it\u0027s also been optimized for mobile usage. Together with its sibling project, \u003ca href\u003d\"http://echarts.baidu.com/echarts2/x/doc/index.html\"\u003eECharts-X\u003c/a\u003e, it can support 3D plotting. ECharts is a Baidu open source project.\u003c/p\u003e","theta":"308","volume":"2017-11"},{"name":"Gobot","id":"1168","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"95","display_name":"Gobot","radius":"335","description":"\u003cp\u003eThe ability to compile the \u003ca href\u003d\"/radar/languages-and-frameworks/go-language\"\u003eGo programming language\u003c/a\u003e to bare metal targets has raised interest among developers in using the language for embedded systems. \u003ca href\u003d\"http://gobot.io/\"\u003e\u003cstrong\u003eGobot\u003c/strong\u003e\u003c/a\u003e is a framework for robotics, physical computing, and the Internet of Things, written in the Go programming language and supporting a variety of platforms. We\u0027ve used the framework for experimental robotic projects where real-time response hasn\u0027t been a requirement, and we’ve created open source \u003ca href\u003d\"http://github.com/HendrikLouw/robocar\"\u003esoftware drivers\u003c/a\u003e with Gobot. Gobot HTTP APIs enable simple hardware integration with mobile devices to create richer applications.\u003c/p\u003e","theta":"312","volume":"2017-11"},{"name":"Instana","id":"1078","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"96","display_name":"Instana","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://www.instana.com/\"\u003eInstana\u003c/a\u003e\u003c/strong\u003e is yet another entrant into the crowded application performance management space. The fact that it\u0027s built from the ground up for cloud native architectures differentiates Instana from many of its competitors. Features include dynamic discovery, distributed tracing and service health plus the ability to \"time shift\" your view of your infrastructure to the moment an incident occurred. It remains to be seen whether this product can gain traction over the combination of open source projects—such as \u003ca href\u003d\"/radar/tools/consul\"\u003eConsul\u003c/a\u003e, \u003ca href\u003d\"/radar/tools/prometheus\"\u003ePrometheus\u003c/a\u003e and the implementations of \u003ca href\u003d\"/radar/platforms/opentracing\"\u003eOpenTracing\u003c/a\u003e—that do the same thing; however it\u0027s worth taking a look if you need an out-of-the-box solution.\u003c/p\u003e","theta":"317","volume":"2017-11"},{"name":"Keras","id":"1073","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"97","display_name":"Keras","radius":"290","description":"\u003cp\u003e\u003ca href\u003d\"https://keras.io/\"\u003e\u003cstrong\u003eKeras\u003c/strong\u003e\u003c/a\u003e is a high-level interface in Python for building neural networks. Created by a Google engineer, Keras is open source and runs on top of either \u003ca href\u003d\"/radar/platforms/tensorflow\"\u003eTensorFlow\u003c/a\u003e or \u003ca href\u003d\"http://github.com/Theano/Theano\"\u003eTheano\u003c/a\u003e. It provides an amazingly simple interface for creating powerful deep-learning algorithms to train on CPUs or GPUs. Keras is well designed with modularity, simplicity, and extensibility in mind. Unlike a library such as \u003ca href\u003d\"/radar/languages-and-frameworks/caffe\"\u003eCaffe\u003c/a\u003e, Keras supports more general network architectures such as recurrent nets, making it overall more useful for text analysis, NLP and general machine learning. If computer vision, or any other specialized branch of machine learning, is your primary concern, Caffe may be a more appropriate choice. However, if you’re looking to learn a simple yet powerful framework, Keras should be your first choice.\u003c/p\u003e","theta":"321","volume":"2017-11"},{"name":"LeakCanary","id":"1173","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"98","display_name":"LeakCanary","radius":"310","description":"\u003cp\u003eOur mobile teams have been excited about \u003ca href\u003d\"http://github.com/square/leakcanary\"\u003e\u003cstrong\u003eLeakCanary\u003c/strong\u003e\u003c/a\u003e, a tool for detecting annoying memory leaks in Android and Java. It\u0027s simple to hook up and provides notifications with a clear trace-back to the cause of the leak. Adding this to your toolkit can save tedious hours troubleshooting out-of-memory errors on multiple devices.\u003c/p\u003e","theta":"325","volume":"2017-11"},{"name":"PostCSS","id":"1071","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"99","display_name":"PostCSS","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/postcss/postcss\"\u003ePostCSS\u003c/a\u003e\u003c/strong\u003e is a \u003ca href\u003d\"/radar/platforms/node-js\"\u003eNode.js\u003c/a\u003e-based JavaScript framework for operating on an abstract syntax tree-based representation of CSS documents with a rich ecosystem of plugins. Often incorrectly thought of as a preprocessor (such as SASS or Less), we find that the real power of PostCSS comes from the number of things that can be done with the rich set of plugins which includes linting (\u003ca href\u003d\"https://github.com/stylelint/stylelint\"\u003ethe stylelint plugin\u003c/a\u003e), cross-compilation (\u003ca href\u003d\"https://github.com/postcss/sugarss\"\u003ethe sugarss plugin\u003c/a\u003e), name-mangling to avoid selector collision (\u003ca href\u003d\"https://github.com/css-modules/postcss-modules\"\u003ethe modules plugin\u003c/a\u003e), boilerplate CSS code generation (\u003ca href\u003d\"https://github.com/postcss/autoprefixer\"\u003ethe autoprefixer plugin\u003c/a\u003e), \u003ca href\u003d\"http://cssnano.co/\"\u003eminification\u003c/a\u003e and many others. The different maturity levels of the plugins notwithstanding, PostCSS itself remains a simple and powerful framework for treating CSS like a full-fledged language for front-end development.\u003c/p\u003e","theta":"330","volume":"2017-11"},{"name":"PyTorch","id":"1172","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"100","display_name":"PyTorch","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"http://pytorch.org/\"\u003e\u003cstrong\u003ePyTorch\u003c/strong\u003e\u003c/a\u003e is a complete rewrite of the \u003ca href\u003d\"http://torch.ch/\"\u003eTorch\u003c/a\u003e machine learning framework from Lua to Python. Although quite new and immature compared to \u003ca href\u003d\"/radar/platforms/tensorflow\"\u003eTensorflow\u003c/a\u003e, programmers find PyTorch much easier to work with. Because of its object-orientation and native Python implementation, models can be expressed more clearly and succinctly and debugged during execution. Although many of these frameworks have emerged recently, PyTorch has the backing of Facebook and broad range of partner organisations, including NVIDIA, which should ensure continuing support for CUDA architectures. ThoughtWorks teams find PyTorch useful for experimenting and developing models but still rely on TensorFlow’s performance for production-scale training and classification.\u003c/p\u003e","theta":"334","volume":"2017-11"},{"name":"single-spa","id":"1174","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"101","display_name":"single-spa","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"http://github.com/CanopyTax/single-spa\"\u003e\u003cstrong\u003esingle-spa\u003c/strong\u003e\u003c/a\u003e is a JavaScript metaframework that allows us to build \u003ca href\u003d\"/radar/techniques/micro-frontends\"\u003emicro frontends\u003c/a\u003e using different frameworks that can coexist in a single application. In general, we don\u0027t recommend using more than one framework for an application, but there are times when we can\u0027t avoid doing so. For instance, single-spa can be quite useful when you\u0027re working with a legacy application and you want to experiment by developing a new feature, with either a new version of the existing framework or a completely different one. Given the short life span of many JavaScript frameworks, we see a need for a solution that would allow for future framework changes and localized experimentation, without affecting the entire application. single-spa seems to be a good start in that direction.\u003c/p\u003e","theta":"338","volume":"2017-11"},{"name":"Solidity","id":"1183","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"102","display_name":"Solidity","radius":"310","description":"\u003cp\u003eProgramming for smart contracts requires a more expressive language than a \u003ca href\u003d\"http://en.bitcoin.it/wiki/Script\"\u003escripting system for transactions\u003c/a\u003e. \u003ca href\u003d\"http://github.com/ethereum/solidity\"\u003e\u003cstrong\u003eSolidity\u003c/strong\u003e\u003c/a\u003e is the most popular among the new programming languages designed for smart contracts. Solidity is a contract-oriented, statically typed language whose syntax is similar to JavaScript. It provides abstractions for writing self-enforcing business logic in smart contracts. The toolchain around Solidity is growing fast. Nowadays, Solidity is the primary choice on the \u003ca href\u003d\"/radar/platforms/ethereum\"\u003eEthereum\u003c/a\u003e platform. Given the immutable nature of deployed smart contracts, it should go without saying that rigorous testing and audit of dependencies is vital.\u003c/p\u003e","theta":"342","volume":"2017-11"},{"name":"TensorFlow Mobile","id":"1167","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"103","display_name":"TensorFlow Mobile","radius":"335","description":"\u003cp\u003e\u003cstrong\u003eTensorFlow Mobile\u003c/strong\u003e makes it possible for developers to incorporate a wide range of comprehension and classification techniques into their iOS or Android applications. This is particularly useful given the range of sensor data available on mobile phones. Pretrained TensorFlow models can be loaded into a mobile application and applied to inputs such as live video frames, text or speech. Mobile phones present a surprisingly opportune platform for implementing these computational models. TensorFlow models are exported and loaded as protobuf files, which can present some problems for implementers. Protobuf\u0027s binary format can make it hard to examine models and requires that you link the correct protobuf library version to your mobile app. But local model execution offers an attractive alternative to \u003ca href\u003d\"/radar/platforms/tensorflow-serving\"\u003eTensorFlow Serving\u003c/a\u003e without the communication overhead of remote execution.\u003c/p\u003e","theta":"347","volume":"2017-11"},{"name":"Truffle","id":"1181","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"104","display_name":"Truffle","radius":"335","description":"\u003cp\u003e\u003ca href\u003d\"http://truffleframework.com/\"\u003e\u003cstrong\u003eTruffle\u003c/strong\u003e\u003c/a\u003e is a development framework that brings a modern web development experience to the \u003ca href\u003d\"/radar/platforms/ethereum\"\u003eEthereum\u003c/a\u003e platform. It takes over the job of smart contract compiling, library linking and deployment, as well as dealing with artifacts in different blockchain networks. One of the reasons we love Truffle is that it encourages people to write tests for their smart contracts. You need to take tests really seriously as smart contract programming is often related to money. With its built-in testing framework and integration with \u003ca href\u003d\"http://github.com/ethereumjs/testrpc\"\u003eTestRPC\u003c/a\u003e, Truffle makes it possible to write the contract in a TDD way. We expect to see more technologies similar to Truffle to promote continuous integration in the blockchain area.\u003c/p\u003e","theta":"351","volume":"2017-11"},{"name":"Weex","id":"1171","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"105","display_name":"Weex","radius":"335","description":"\u003cp\u003e\u003ca href\u003d\"http://github.com/alibaba/weex\"\u003e\u003cstrong\u003eWeex\u003c/strong\u003e\u003c/a\u003e is a framework for building cross-platform mobile apps by using the \u003ca href\u003d\"/radar/languages-and-frameworks/vue-js\"\u003eVue.js\u003c/a\u003e component syntax. For those who prefer the simplicity of Vue.js, Weex is a viable option for native mobile apps, but it also works very well for more complicated apps. We see many successes for fairly complicated mobile apps built on this framework, including \u003ca href\u003d\"http://www.tmall.com/\"\u003eTMall\u003c/a\u003e and \u003ca href\u003d\"http://world.taobao.com/\"\u003eTaobao\u003c/a\u003e, two of the most popular mobile apps in China. Weex was developed by Alibaba, and is now an \u003ca href\u003d\"http://github.com/apache/incubator-weex\"\u003eApache incubator project\u003c/a\u003e.\u003c/p\u003e","theta":"355","volume":"2017-11"}],"date":"2017-11"},{"blips":[{"name":"Lightweight Architecture Decision Records","id":"1034","quadrant":"Techniques","ring":"Adopt","movement":"c","radarId":"1","display_name":"Lightweight Architecture Decision Records","radius":"80","description":"\u003cp\u003eMuch documentation can be replaced with highly readable code and tests. In a world of \u003ca href\u003d\"/radar/techniques/evolutionary-architecture\"\u003eevolutionary architecture\u003c/a\u003e, however, it\u0027s important to record certain design decisions for the benefit of future team members as well as for external oversight. \u003cstrong\u003eLightweight Architecture Decision Records\u003c/strong\u003e is a \u003ca href\u003d\"http://thinkrelevance.com/blog/2011/11/15/documenting-architecture-decisions\"\u003etechnique\u003c/a\u003e for capturing important architectural decisions along with their context and consequences. We recommend \u003ca href\u003d\"http://github.com/npryce/adr-tools\"\u003estoring these details in source control\u003c/a\u003e, instead of a wiki or website, as then they can provide a record that remains in sync with the code itself. For most projects, we see no reason why you wouldn\u0027t want to use this technique.\u003c/p\u003e","theta":"135","volume":"2018-05"},{"name":"Applying product management to internal platforms","id":"1133","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"2","display_name":"Applying product management to internal platforms","radius":"180","description":"\u003cp\u003eWe\u0027ve seen a steep increase in interest in the topic of digital platforms over the past 12 months. Companies looking to roll out new digital solutions quickly and efficiently are building internal platforms, which offer teams self-service access to the business APIs, tools, knowledge and support necessary to build and operate their own solutions. We find that these platforms are most effective when they\u0027re given the same respect as an external product offering. \u003cstrong\u003eApplying product management to internal platforms\u003c/strong\u003e means establishing empathy with internal consumers (read: developers) and collaborating with them on the design. Platform product managers establish roadmaps and ensure the platform delivers value to the business and enhances the developer experience. Some owners even create a brand identity for the internal platform and use that to market the benefits to their colleagues. Platform product managers look after the quality of the platform, gather usage metrics, and continuously improve it over time. Treating the platform as a product helps to create a thriving ecosystem and avoids the pitfall of building yet another stagnant, underutilized service-oriented architecture.\u003c/p\u003e","theta":"171","volume":"2018-05"},{"name":"Architectural fitness function","id":"1132","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"3","display_name":"Architectural fitness function","radius":"165","description":"\u003cp\u003eBorrowed from evolutionary computing, a fitness function is used to summarize how close a given design solution is to achieving the set aims. When defining an evolutionary algorithm, the designer seeks a ‘better’ algorithm; the fitness function defines what ‘better’ means in this context. An \u003cstrong\u003earchitectural fitness function\u003c/strong\u003e , as defined in \u003ca href\u003d\"http://www.thoughtworks.com/books/building-evolutionary-architectures\"\u003eBuilding Evolutionary Architectures\u003c/a\u003e, provides an objective integrity assessment of some architectural characteristics, which may encompass existing verification criteria, such as unit testing, metrics, monitors, and so on. We believe architects can communicate, validate and preserve architectural characteristics in an automated, continual manner, which is the key to building evolutionary architectures.\u003c/p\u003e","theta":"162","volume":"2018-05"},{"name":"Autonomous bubble pattern","id":"1128","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"4","display_name":"Autonomous bubble pattern","radius":"200","description":"\u003cp\u003eMany organizations we work with are trying hard to use modern engineering approaches to build new capabilities and features, while also having to coexist with a long tail of legacy systems. An old strategy that, based on our experience, has turned out to be increasingly helpful in these scenarios is \u003ca href\u003d\"http://dddcommunity.org/strategic-design/\"\u003eEric Evans\u0027s\u003c/a\u003e \u003cstrong\u003eAutonomous bubble pattern\u003c/strong\u003e. This approach involves creating a fresh context for new application development that is shielded from the entanglements of the legacy world. This is a step beyond just using an \u003ca href\u003d\"http://wiki.c2.com/?AnticorruptionLayer\"\u003eanticorruption layer\u003c/a\u003e. It gives the new bubble context full control over its backing data, which is then asynchronously kept up-to-date with the legacy systems. It requires some work to protect the boundaries of the bubble and keep both worlds consistent, but the resulting autonomy and reduction in development friction is a first bold step toward a modernized future architecture.\u003c/p\u003e","theta":"153","volume":"2018-05"},{"name":"Chaos Engineering","id":"1206","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"5","display_name":"Chaos Engineering","radius":"180","description":"\u003cp\u003eIn previous editions of the Radar, we\u0027ve talked about using \u003ca href\u003d\"/radar/tools/chaos-monkey\"\u003eChaos Monkey\u003c/a\u003e from Netflix to test how a running system is able to cope with outages in production by randomly disabling instances and measuring the results. \u003cstrong\u003eChaos Engineering\u003c/strong\u003e is the nascent term for the wider application of this technique. By running experiments on distributed systems in production, we\u0027re able to build confidence that those systems work as expected under turbulent conditions. A good place to start understanding this technique is the \u003ca href\u003d\"http://principlesofchaos.org/\"\u003ePrinciples of Chaos Engineering\u003c/a\u003e website.\u003c/p\u003e","theta":"144","volume":"2018-05"},{"name":"Domain-scoped events","id":"1216","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"6","display_name":"Domain-scoped events","radius":"175","description":"\u003cp\u003eIt’s important to remember that encapsulation applies to events and event-driven architectures just as it applies to other areas of software. In particular, think about the scope of an event and whether we expect it to be consumed within the same application, the same domain or across an entire organization. A \u003cstrong\u003edomain-scoped event\u003c/strong\u003e will be consumed within the same domain as it’s published, as such we expect the consumer to have access to a certain context, resources or references in order to act on the event. If the consumption is happening more widely within an organization, the contents of the event might well need to be different, and we need to take care not to \"leak\" implementation details that other domains then come to depend upon.\u003c/p\u003e","theta":"135","volume":"2018-05"},{"name":"Hosted identity management as a service","id":"1209","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"7","display_name":"Hosted identity management as a service","radius":"240","description":"\u003cp\u003eIdentity management is a critical platform component. External users on mobile apps need to be authenticated, developers need to be given access to delivery infrastructure components, and microservices may need to identify themselves to other microservices. You should ask yourself whether identity management should be “self-hosted”. In our experience, a \u003cstrong\u003ehosted identity management as a service\u003c/strong\u003e (SaaS) solution is preferable. We believe that top-tier hosted providers such as \u003ca href\u003d\"/radar/platforms/auth0\"\u003eAuth0\u003c/a\u003e and \u003ca href\u003d\"http://www.okta.com/\"\u003eOkta\u003c/a\u003e can provide better uptime and security SLAs. That said, sometimes self-hosting the solution is a realistic decision, especially for enterprises that have the operational discipline and resources to do so safely. Large enterprise identity solutions typically offer a much more expansive range of capabilities such as centralized entitlements, governance reporting and separation of duties management among others. However, these concerns are typically more relevant for employee identities, especially in regulated enterprises with legacy systems.\u003c/p\u003e","theta":"126","volume":"2018-05"},{"name":"Micro frontends","id":"1035","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"8","display_name":"Micro frontends","radius":"190","description":"\u003cp\u003eWe\u0027ve seen significant benefits from introducing \u003ca href\u003d\"/radar/techniques/microservices\"\u003emicroservices\u003c/a\u003e architectures, which have allowed teams to scale the delivery of independently deployed and maintained services. Unfortunately, we\u0027ve also seen many teams create front-end monoliths — a single, large and sprawling browser application — on top of their back-end services. Our preferred (and proven) approach is to split the browser-based code into \u003cstrong\u003emicro frontends\u003c/strong\u003e. In this approach, the web application is broken down into its features, and each feature is owned, frontend to backend, by a different team. This ensures that every feature is developed, tested and deployed independently from other features. Multiple techniques exist to recombine the features — sometimes as pages, sometimes as components — into a cohesive user experience.\u003c/p\u003e","theta":"117","volume":"2018-05"},{"name":"Pipelines for infrastructure as code","id":"1131","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"9","display_name":"Pipelines for infrastructure as code","radius":"220","description":"\u003cp\u003eThe use of continuous delivery pipelines to orchestrate the release process for software has become a mainstream concept. However, automatically testing changes to infrastructure code isn’t as widely understood. Continuous integration (CI) and continuous delivery (CD) tools can be used to test server configuration (e.g., Chef cookbooks, Puppet modules, Ansible playbooks), server image building (e.g., Packer), environment provisioning (e.g., Terraform, CloudFormation) and integration of environments. The use of \u003cstrong\u003epipelines for infrastructure as code\u003c/strong\u003e enables errors to be found before changes are applied to operational environments — including environments used for development and testing. They also offer a way to ensure that infrastructure tooling is run consistently, from CI/CD agents, as opposed to being run from individual workstations. Some challenges remain, however, such as the longer feedback loops associated with standing up containers and virtual machines. Still, we\u0027ve found this to be a valuable technique.\u003c/p\u003e","theta":"108","volume":"2018-05"},{"name":"Polycloud","id":"1207","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"10","display_name":"Polycloud","radius":"200","description":"\u003cp\u003eOrganizations are becoming more comfortable with the \u003cstrong\u003ePolycloud\u003c/strong\u003e strategy — rather than going \"all-in\" with one provider, they are passing different types of workloads to different providers based on their own strategy. Some of them apply the best-of-breed approach, for example: putting standard services on AWS, but using Google for machine learning and data-oriented applications and Azure for Microsoft Windows applications. For some organizations this is a cultural and business decision. Retail businesses, for example, often refuse to store their data on Amazon and they distribute load to different providers based on their data. This is different to a cloud-agnostic strategy of aiming for portability across providers, which is costly and forces lowest-common-denominator thinking. Polycloud instead focuses on using the best match that each cloud provider offers.\u003c/p\u003e","theta":"99","volume":"2018-05"},{"name":"BeyondCorp","id":"1211","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"11","display_name":"BeyondCorp","radius":"285","description":"\u003cp\u003ePreviously in the Radar, we’ve discussed the rise of the \u003ca href\u003d\"/radar/techniques/perimeterless-enterprise\"\u003eperimeterless enterprise\u003c/a\u003e. Now, some organizations are doing away with implicitly trusted intranets altogether and treating all communication as if it was being transmitted through the public internet. A set of practices, collectively labeled \u003ca href\u003d\"http://cloud.google.com/beyondcorp/\"\u003e\u003cstrong\u003eBeyondCorp\u003c/strong\u003e\u003c/a\u003e, have been described by Google engineers in a set of publications. Collectively, these practices — including managed devices, 802.1x networking and standard access proxies protecting individual services — make this a viable approach to network security in large enterprises.\u003c/p\u003e","theta":"174","volume":"2018-05"},{"name":"Embedded mobile mocks","id":"1212","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"12","display_name":"Embedded mobile mocks","radius":"300","description":"\u003cp\u003eWhen developing mobile applications, our teams often find themselves without an external server for testing apps. Setting up an over-the-wire mock may be a good fit for this particular problem. Developing the HTTP mocks and compiling them into the mobile binary for testing — \u003cstrong\u003eembedded mobile mocks\u003c/strong\u003e — enables teams to test their mobile apps when disconnected and with no external dependencies. This technique may require creating an opinionated library based on both the networking library used by the mobile app and your usage of the underlying library.\u003c/p\u003e","theta":"167","volume":"2018-05"},{"name":"Ethereum for decentralized applications","id":"1188","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"13","display_name":"Ethereum for decentralized applications","radius":"290","description":"\u003cp\u003eBlockchains have been widely hyped as the panacea for all things fintech, from banking to digital currency to supply chain transparency. We’ve previously featured \u003ca href\u003d\"/radar/platforms/ethereum\"\u003eEthereum\u003c/a\u003e because of its feature set, which includes smart contracts. Now, we\u0027re seeing more development using \u003cstrong\u003eEthereum for decentralized applications\u003c/strong\u003e in \u003ca href\u003d\"http://www.stateofthedapps.com/\"\u003eother areas\u003c/a\u003e. Although this is still a very young technology, we\u0027re encouraged to see it being used to build decentralized applications beyond cryptocurrency and banking.\u003c/p\u003e","theta":"160","volume":"2018-05"},{"name":"Event streaming as the source of truth","id":"1139","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"14","display_name":"Event streaming as the source of truth","radius":"300","description":"\u003cp\u003eAs event streaming platforms, such as \u003ca href\u003d\"/radar/tools/apache-kafka\"\u003eApache Kafka\u003c/a\u003e, rise in popularity, many consider them as an advanced form of message queuing, used solely to transmit events. Even when used in this way, event streaming has its benefits over traditional message queuing. However, we\u0027re more interested in how people use \u003cstrong\u003eevent streaming as the source of truth\u003c/strong\u003e with platforms (Kafka in particular) as the primary store for data as immutable events. A service with an \u003ca href\u003d\"http://martinfowler.com/eaaDev/EventSourcing.html\"\u003eEvent Sourcing\u003c/a\u003e design, for example, can use Kafka as its event store; those events are then available for other services to consume. This technique has the potential to reduce duplicating efforts between local persistence and integration.\u003c/p\u003e","theta":"153","volume":"2018-05"},{"name":"GraphQL for server side resource aggregation","id":"1213","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"15","display_name":"GraphQL for server side resource aggregation","radius":"320","description":"\u003cp\u003eOne pattern that comes up again and again when building microservice-style architectures is how to handle the aggregation of many resources server-side. In recent years, we\u0027ve seen the emergence of a number of patterns such as \u003ca href\u003d\"/radar/techniques/bff-backend-for-frontends\"\u003eBackend for Frontend (BFF)\u003c/a\u003e and tools such as \u003ca href\u003d\"http://netflix.github.io/falcor/\"\u003eFalcor\u003c/a\u003e to address this. Our teams have started using \u003cstrong\u003eGraphQL for server-side resource aggregation\u003c/strong\u003e instead. This differs from the usual mode of using \u003ca href\u003d\"/radar/languages-and-frameworks/graphql\"\u003eGraphQL\u003c/a\u003e where clients directly query a GraphQL server. When using this technique, the services continue to expose RESTful APIs but under-the-hood aggregate services use GraphQL resolvers as the implementation for stitching resources from other services. This technique simplifies the internal implementation of aggregate services or BFFs by using GraphQL.\u003c/p\u003e","theta":"146","volume":"2018-05"},{"name":"Infrastructure configuration scanner","id":"1231","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"16","display_name":"Infrastructure configuration scanner","radius":"290","description":"\u003cp\u003eFor some time now we\u0027ve recommended increased delivery team ownership of their entire stack, including infrastructure. This means increased responsibility in the delivery team itself for configuring infrastructure in a safe, secure, and compliant way. When adopting cloud strategies, most organizations default to a tightly locked-down and centrally managed configuration to reduce risk, but this also creates substantial productivity bottlenecks. An alternative approach is to allow teams to manage their own configuration, and use an \u003cstrong\u003eInfrastructure configuration scanner\u003c/strong\u003e to ensure the configuration is set in a safe and secure way. \u003ca href\u003d\"http://github.com/iagcl/watchmen\"\u003eWatchmen\u003c/a\u003e is an interesting tool, built to provide rule-driven assurance of AWS account configurations that are owned and operated independently by delivery teams. \u003ca href\u003d\"/radar/tools/scout2\"\u003eScout2\u003c/a\u003e is another example of configuration scanning to support secure compliance.\u003c/p\u003e","theta":"139","volume":"2018-05"},{"name":"Jupyter for automated testing","id":"1214","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"17","display_name":"Jupyter for automated testing","radius":"305","description":"\u003cp\u003eWe\u0027re seeing some interesting reports of using \u003cstrong\u003eJupyter for automated testing\u003c/strong\u003e. The ability to mix code, comments and output in the same document reminds us of FIT, \u003ca href\u003d\"http://fitnesse.org/\"\u003eFitNesse\u003c/a\u003e and \u003ca href\u003d\"http://concordion.org/\"\u003eConcordion\u003c/a\u003e. This flexible approach is particularly useful if your tests are data heavy or rely on some statistical analysis such as performance testing. Python provides all the power you need, but as tests grow in complexity, a way to manage suites of notebooks would be helpful.\u003c/p\u003e","theta":"132","volume":"2018-05"},{"name":"Log level per request","id":"1210","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"18","display_name":"Log level per request","radius":"310","description":"\u003cp\u003eOne problem with observability in a highly distributed microservices architecture is the choice between logging everything — and taking up huge amounts of storage space — or randomly sampling logs and potentially missing important events. Recently, we’ve noticed a technique that offers a compromise between these two solutions. Set the \u003cstrong\u003elog level per request\u003c/strong\u003e via a parameter passed in through the tracing header. Using a tracing framework, possibly based on the \u003ca href\u003d\"/radar/platforms/opentracing\"\u003eOpenTracing\u003c/a\u003e standard, you can pass a correlation id from service to service in a single transaction. You can even inject other data, such as the desired log level, at the initiating transaction and pass it along with the tracing information. This ensures that the additional data collected corresponds to a single user transaction as it flows through the system. This is also a useful technique for debugging, since services might be paused or otherwise modified on a transaction-by-transaction basis.\u003c/p\u003e","theta":"125","volume":"2018-05"},{"name":"Security Chaos Engineering","id":"1215","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"19","display_name":"Security Chaos Engineering","radius":"290","description":"\u003cp\u003eWe’ve previously talked about the technique of \u003ca href\u003d\"/radar/techniques/chaos-engineering\"\u003eChaos Engineering\u003c/a\u003e in the Radar and the Simian Army suite of tools from Netflix that we’ve used to run experiments to test the resilience of production infrastructure. \u003cstrong\u003eSecurity Chaos Engineering\u003c/strong\u003e broadens the scope of this technique to the realm of security. We deliberately introduce false positives into production networks and other infrastructure — build-time dependencies, for example — to check whether procedures in place are capable of identifying security failures under controlled conditions. Although useful, this technique should be used with care to avoid desensitizing teams to security problems.\u003c/p\u003e","theta":"118","volume":"2018-05"},{"name":"Service mesh","id":"1138","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"20","display_name":"Service mesh","radius":"290","description":"\u003cp\u003eAs large organizations transition to more autonomous teams owning and operating their own microservices, how can they ensure the necessary consistency and compatibility between those services without relying on a centralized hosting infrastructure? To work together efficiently, even autonomous microservices need to align with some organizational standards. A \u003cstrong\u003eservice mesh\u003c/strong\u003e offers consistent discovery, security, tracing, monitoring and failure handling without the need for a shared asset such as an API gateway or ESB. A typical implementation involves lightweight reverse-proxy processes deployed alongside each service process, perhaps in a separate container. These proxies communicate with service registries, identity providers, log aggregators, and so on. Service interoperability and observability are gained through a shared implementation of this proxy but not a shared runtime instance. We\u0027ve advocated for a decentralized approach to microservice management for some time and are happy to see this consistent pattern emerge. Open source projects such as \u003ca href\u003d\"http://linkerd.io/\"\u003elinkerd\u003c/a\u003e and \u003ca href\u003d\"http://istio.io/\"\u003eIstio\u003c/a\u003e will continue to mature and make service meshes even easier to implement.\u003c/p\u003e","theta":"111","volume":"2018-05"},{"name":"Sidecars for endpoint security","id":"1136","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"21","display_name":"Sidecars for endpoint security","radius":"320","description":"\u003cp\u003eMicroservices architecture, with a large number of services exposing their assets and capabilities through APIs and an increased attack surface, demand a zero trust security architecture — ‘never trust, always verify’. However, enforcing security controls for communication between services is often neglected, due to increased service code complexity and lack of libraries and language support in a polyglot environment. To get around this complexity, some teams delegate security to an out-of-process sidecar — a process or a container that is deployed and scheduled with each service sharing the same execution context, host and identity. Sidecars implement security capabilities, such as transparent encryption of the communication and TLS (Transport Layer Security) termination, as well as authentication and authorization of the calling service or the end user. We recommend you look into using \u003ca href\u003d\"http://istio.io/\"\u003eIstio\u003c/a\u003e, \u003ca href\u003d\"http://linkerd.io/\"\u003elinkerd\u003c/a\u003e or \u003ca href\u003d\"http://github.com/envoyproxy/envoy\"\u003eEnvoy\u003c/a\u003e before implementing your own \u003cstrong\u003esidecars for endpoint security\u003c/strong\u003e.\u003c/p\u003e","theta":"104","volume":"2018-05"},{"name":"The three Rs of security","id":"1141","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"22","display_name":"The three Rs of security","radius":"300","description":"\u003cp\u003eTraditional approaches to enterprise security often emphasize locking things down and slowing the pace of change. However, we know that the more time an attacker has to compromise a system, the greater the potential damage. \u003ca href\u003d\"http://builttoadapt.io/the-three-r-s-of-enterprise-security-rotate-repave-and-repair-f64f6d6ba29d\"\u003eThe three Rs of enterprise security\u003c/a\u003e — rotate, repair and repave — take advantage of infrastructure automation and continuous delivery to eliminate opportunities for attack. Rotating credentials, applying patches as soon as they\u0027re available and rebuilding systems from a known, secure state — all within a matter of minutes or hours — makes it harder for attackers to succeed. \u003cstrong\u003eThe three Rs of security\u003c/strong\u003e technique is made feasible with the advent of modern cloud-native architectures. When applications are deployed as containers, and built and tested via a completely automated pipeline, a security patch is just another small release that can be sent through the pipeline with one click. Of course, in keeping with best distributed systems practices, developers need to design their applications to be resilient to unexpected server outages. This is similar to the impact of implementing \u003ca href\u003d\"/radar/tools/chaos-monkey\"\u003eChaos Monkey\u003c/a\u003e within your environment.\u003c/p\u003e","theta":"97","volume":"2018-05"},{"name":"Generic cloud usage","id":"1217","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"23","display_name":"Generic cloud usage","radius":"375","description":"\u003cp\u003eThe major cloud providers continue to add new features to their clouds at a rapid pace, and under the banner of \u003ca href\u003d\"/radar/techniques/polycloud\"\u003ePolycloud\u003c/a\u003e we\u0027ve suggested using multiple clouds in parallel, to mix and match services based on the strengths of each provider’s offerings. Increasingly, we\u0027re seeing organizations prepare to use multiple clouds — not to benefit from individual provider’s strengths, though, but to avoid vendor \"lock-in\" at all costs. This, of course, leads to \u003cstrong\u003egeneric cloud usage\u003c/strong\u003e , only using features that are present across all providers, which reminds us of the lowest common denominator scenario we saw 10 years ago when companies avoided many advanced features in relational databases in an effort to remain vendor neutral. The problem of lock-in is real. However, instead of treating it with a sledgehammer approach, we recommend looking at this problem from the perspective of exit costs and relate those to the benefits of using cloud-specific features.\u003c/p\u003e","theta":"150","volume":"2018-05"},{"name":"Recreating ESB antipatterns with Kafka","id":"1142","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"24","display_name":"Recreating ESB antipatterns with Kafka","radius":"380","description":"\u003cp\u003eKafka is becoming very popular as a messaging solution, and along with it, \u003ca href\u003d\"/radar/platforms/kafka-streams\"\u003eKafka Streams\u003c/a\u003e is at the forefront of the wave of interest in streaming architectures. Unfortunately, as they start to embed Kafka at the heart of their data and application platforms, we\u0027re seeing some organizations \u003cstrong\u003erecreating ESB antipatterns with Kafka\u003c/strong\u003e by centralizing the Kafka ecosystem components — such as connectors and stream processors — instead of allowing these components to live with product or service teams. This reminds us of seriously problematic ESB antipatterns, where more and more logic, orchestration and transformation were thrust into a centrally managed ESB, creating a significant dependency on a centralized team. We\u0027re calling this out to dissuade further implementations of this flawed pattern.\u003c/p\u003e","theta":"120","volume":"2018-05"},{"name":".NET Core","id":"866","quadrant":"Platforms","ring":"Adopt","movement":"t","radarId":"25","display_name":".NET Core","radius":"75","description":"\u003cp\u003eOur teams have confirmed that \u003ca href\u003d\"http://www.microsoft.com/net/core\"\u003e\u003cstrong\u003e.NET Core\u003c/strong\u003e\u003c/a\u003e has reached a level of maturity that makes it the default for .NET server applications. The open source .NET Core framework enables the development and deployment of .NET applications on Windows, macOS and Linux with first-class cross-platform tooling. Microsoft provides blessed Docker images which make it easy to deploy .NET Core applications in a containerized environment. Positive directions in the community and feedback from our projects indicate that .NET Core is the future for .NET development.\u003c/p\u003e","theta":"210","volume":"2018-05"},{"name":"Kubernetes","id":"925","quadrant":"Platforms","ring":"Adopt","movement":"c","radarId":"26","display_name":"Kubernetes","radius":"75","description":"\u003cp\u003eSince we last mentioned \u003cstrong\u003eKubernetes\u003c/strong\u003e in the Radar, it has become the default solution for most of our clients when deploying containers into a cluster of machines. The alternatives didn’t capture as much mindshare, and in some cases our clients are even changing their ‘engine’ to Kubernetes. Kubernetes has become the container orchestration platform of choice for major public cloud platforms, including Microsoft\u0027s Azure Container Service and Google Cloud (see the \u003ca href\u003d\"/radar/platforms/gke\"\u003eGKE\u003c/a\u003e blip). And there are many useful products enriching the fast-growing Kubernetes ecosystem. Platforms that try to hide Kubernetes under an abstraction layer, however, have yet to prove themselves.\u003c/p\u003e","theta":"240","volume":"2018-05"},{"name":"Azure","id":"473","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"27","display_name":"Azure","radius":"160","description":"\u003cp\u003eMicrosoft has steadily improved \u003ca href\u003d\"http://azure.microsoft.com\"\u003e\u003cstrong\u003eAzure\u003c/strong\u003e\u003c/a\u003e and today not much separates the core cloud experience provided by the major cloud providers – Amazon, Google and Microsoft. The cloud providers seem to agree and seek to differentiate themselves in other areas such as features, services and cost structure. Microsoft is the provider who shows real interest in the legal requirements of European companies. They’ve a nuanced and plausible strategy, including unique offerings such as \u003ca href\u003d\"http://azure.microsoft.com/en-us/global-infrastructure/germany/\"\u003eAzure Germany\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/azure-stack\"\u003eAzure Stack\u003c/a\u003e, which gives some certainty to European companies in anticipation of the \u003ca href\u003d\"http://www.thoughtworks.com/insights/blog/gdpr-it-s-time-rethink-your-approach-privacy\"\u003eGDPR\u003c/a\u003e and possible legislative changes in the United States.\u003c/p\u003e","theta":"189","volume":"2018-05"},{"name":"Contentful","id":"1254","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"28","display_name":"Contentful","radius":"240","description":"\u003cp\u003eHeadless Content Management Systems (CMSes) are becoming a common component of digital platforms. \u003ca href\u003d\"http://www.contentful.com/\"\u003e\u003cstrong\u003eContentful\u003c/strong\u003e\u003c/a\u003e is a modern headless CMS that our teams have successfully integrated into their development workflows. We particularly like its API-first approach and implementing \u003ca href\u003d\"http://www.contentful.com/r/knowledgebase/cms-as-code/\"\u003eCMS as Code\u003c/a\u003e. It supports powerful content modelling primitives as code and content model evolution scripts, which allow treating it as other data store schemas and applying \u003ca href\u003d\"http://martinfowler.com/articles/evodb.html\"\u003eevolutionary database design\u003c/a\u003e practices to CMS development. Other notable features that we’ve liked include inclusion of two CDNs by default to deliver media assets and JSON documents, good support for localization, and the ability — albeit with some effort — to integrate with \u003ca href\u003d\"/radar/platforms/auth0\"\u003eAuth0\u003c/a\u003e.\u003c/p\u003e","theta":"198","volume":"2018-05"},{"name":"EMQ","id":"1253","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"29","display_name":"EMQ","radius":"230","description":"\u003cp\u003e\u003ca href\u003d\"http://emqtt.io\"\u003e\u003cstrong\u003eEMQ\u003c/strong\u003e\u003c/a\u003e is a scalable open source multiplatform MQTT broker. It’s written in \u003ca href\u003d\"http://github.com/erlang/otp\"\u003eErlang/OTP\u003c/a\u003e for higher performance, handling millions of concurrent connections. It supports multiple protocols including \u003ca href\u003d\"http://mqtt.org/\"\u003eMQTT\u003c/a\u003e, \u003ca href\u003d\"http://mqtt.org/2013/12/mqtt-for-sensor-networks-mqtt-sn\"\u003eMQTT Sensor Networks\u003c/a\u003e, \u003ca href\u003d\"http://coap.technology/\"\u003eCoAP\u003c/a\u003e as well as \u003ca href\u003d\"http://tools.ietf.org/html/rfc6455\"\u003eWebSockets\u003c/a\u003e, making it suitable for both IoT and mobile devices. We’ve started using EMQ in our projects and have enjoyed its ease of installation and use, its ability to route messages to different destinations including \u003ca href\u003d\"/radar/tools/apache-kafka\"\u003eKafka\u003c/a\u003e and PostgreSQL, as well as its API-driven approach for its monitoring and configuration.\u003c/p\u003e","theta":"207","volume":"2018-05"},{"name":"Flood IO","id":"1190","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"30","display_name":"Flood IO","radius":"255","description":"\u003cp\u003eLoad testing became easier with the maturity of tools such as \u003ca href\u003d\"/radar/tools/gatling\"\u003eGatling\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/locust\"\u003eLocust\u003c/a\u003e. At the same time, elastic cloud infrastructures make it possible to simulate a large number of client instances. We\u0027re delighted to see Flood and other cloud platforms go further by leveraging these technologies. \u003ca href\u003d\"http://flood.io/\"\u003e\u003cstrong\u003eFlood IO\u003c/strong\u003e\u003c/a\u003e is an SaaS load-testing service that helps to distribute and execute testing scripts across hundreds of servers in the cloud. Our teams find it simple to migrate performance testing to Flood by reusing existing Gatling scripts.\u003c/p\u003e","theta":"216","volume":"2018-05"},{"name":"GKE","id":"1193","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"31","display_name":"GKE","radius":"180","description":"\u003cp\u003eWhile the software development ecosystem is converging on \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e as the orchestration platform for containers, running Kubernetes clusters remains operationally complex. Google Kubernetes Engine ( \u003cstrong\u003eGKE\u003c/strong\u003e ) is a managed Kubernetes solution for deploying containerized applications that alleviates the operational overhead of running and maintaining Kubernetes clusters. Our teams have had a good experience using GKE, with the platform doing the heavy lifting of applying security patches, monitoring and auto-repairing the nodes, and managing multicluster and multiregion networking. In our experience, Google\u0027s API-first approach in exposing platform capabilities, as well as using industry standards such as \u003ca href\u003d\"/radar/platforms/oauth\"\u003eOAuth\u003c/a\u003e for service authorisation, improve the developer experience. It\u0027s important to consider that GKE is under rapid development with many of its APIs in beta release which, despite the developers\u0027 best efforts to abstract consumers from underlying changes, can impact you. We\u0027re expecting continuous improvement around maturity of \u003ca href\u003d\"/radar/tools/infrastructure-as-code\"\u003einfrastructure as code\u003c/a\u003e with \u003ca href\u003d\"http://www.terraform.io/docs/providers/google/r/container_cluster.html\"\u003eTerraform on GKE\u003c/a\u003e and similar tools.\u003c/p\u003e","theta":"225","volume":"2018-05"},{"name":"Google Cloud Platform","id":"1192","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"32","display_name":"Google Cloud Platform","radius":"255","description":"\u003cp\u003eAs \u003ca href\u003d\"http://cloud.google.com/free/ce1/\"\u003e\u003cstrong\u003eGoogle Cloud Platform\u003c/strong\u003e\u003c/a\u003e (GCP) has expanded in terms of available geographic regions and maturity of services, customers globally can now seriously consider it for their cloud strategy. In some areas, GCP has reached feature parity with its main competitor, Amazon Web Services, while in other areas it has differentiated itself — notably with accessible machine learning platforms, data engineering tools, and a workable Kubernetes as a service solution (\u003ca href\u003d\"/radar/platforms/gke\"\u003eGKE\u003c/a\u003e). In practice, our teams have nothing but praise for the developer experience working with the GCP tools and APIs.\u003c/p\u003e","theta":"234","volume":"2018-05"},{"name":"Keycloak","id":"1086","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"33","display_name":"Keycloak","radius":"190","description":"\u003cp\u003eIn a \u003ca href\u003d\"/radar/techniques/microservices\"\u003emicroservice\u003c/a\u003e, or any other distributed architecture, one of the most common needs is to secure the services or APIs through authentication and authorization features. This is where \u003ca href\u003d\"http://www.keycloak.org/\"\u003e\u003cstrong\u003eKeycloak\u003c/strong\u003e\u003c/a\u003e comes in. Keycloak is an open source identity and access management solution that makes it easy to secure applications or microservices with little to no code. It supports single sign-on, social login and standard protocols such as \u003ca href\u003d\"http://openid.net/connect/\"\u003eOpenID Connect\u003c/a\u003e, \u003ca href\u003d\"http://oauth.net/2/\"\u003eOAuth 2.0\u003c/a\u003e and \u003ca href\u003d\"http://en.wikipedia.org/wiki/Security_Assertion_Markup_Language\"\u003eSAML\u003c/a\u003e out of the box. Our teams have been using this tool and plan to keep using it for the foreseeable future. But it requires a little work to set up. Because configuration happens both at initialization and at runtime through APIs, it\u0027s necessary to write scripts to ensure deployments are repeatable.\u003c/p\u003e","theta":"243","volume":"2018-05"},{"name":"Kong API Gateway","id":"1159","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"34","display_name":"Kong API Gateway","radius":"180","description":"\u003cp\u003e\u003ca href\u003d\"http://getkong.org/\"\u003eKong\u003c/a\u003e is an \u003ca href\u003d\"http://github.com/Kong/kong\"\u003eopen source API gateway\u003c/a\u003e which also comes as an \u003ca href\u003d\"http://konghq.com/kong-enterprise-edition/\"\u003eenterprise product\u003c/a\u003e integrating with proprietary API analytics and a developer portal. Kong can be deployed, in a variety of configurations, as an edge API gateway, as an internal API proxy, or even as a sidecar in a \u003ca href\u003d\"/radar/techniques/service-mesh\"\u003eservice mesh\u003c/a\u003e configuration. \u003ca href\u003d\"http://openresty.org/en/\"\u003eOpenResty\u003c/a\u003e, through its Nginx modules, provides a strong and performant foundation, with Lua plugins for extensions. Kong can either use PostgreSQL for single-region deployments or Cassandra for multiregion configurations. Our developers have enjoyed Kong\u0027s high performance, its API-first approach (which enables automation of its configuration) and its ease of deployment as a container. \u003cstrong\u003eKong API Gateway\u003c/strong\u003e , unlike \u003ca href\u003d\"/radar/platforms/overambitious-api-gateways\"\u003eoverambitious API gateways\u003c/a\u003e, has a smaller set of features but it implements the essential set of API gateway capabilities such as traffic control, security, logging, monitoring and authentication.\u003c/p\u003e","theta":"252","volume":"2018-05"},{"name":"WeChat","id":"1189","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"35","display_name":"WeChat","radius":"220","description":"\u003cp\u003e\u003cstrong\u003eWeChat\u003c/strong\u003e , often seen as a WhatsApp equivalent, is becoming the de facto business platform in China. Many people may not know but WeChat is also one of the most popular online payment platforms. With the app\u0027s built-in CMS and membership management, small businesses are now conducting their commerce entirely on WeChat. Through the Service Account feature, large organizations can interface their internal system to their employees. Given that more than 70 percent of Chinese people are using WeChat, it\u0027s an important consideration for businesses that want to expand into the China market.\u003c/p\u003e","theta":"261","volume":"2018-05"},{"name":"AWS Fargate","id":"1255","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"36","display_name":"AWS Fargate","radius":"285","description":"\u003cp\u003e\u003ca href\u003d\"http://aws.amazon.com/fargate/\"\u003e\u003cstrong\u003eAWS Fargate\u003c/strong\u003e\u003c/a\u003e is a recent entry into the docker-as-a-service space, currently limited to the US-East-1 region. For teams using \u003ca href\u003d\"/radar/platforms/aws-ecs\"\u003eAWS Elastic Container Service\u003c/a\u003e (ECS), AWS Fargate is a good alternative without having to manage, provision and configure any underlying EC2 instances or clusters. Fargate allows defining (ECS or \u003ca href\u003d\"http://aws.amazon.com/eks/\"\u003eEKS – ECS for Kubernetes\u003c/a\u003e) tasks as a Fargate type, and they will run on the AWS Fargate infrastructure. If you like the focus on business functionality that \u003ca href\u003d\"/radar/platforms/aws-lambda\"\u003eAWS Lambda\u003c/a\u003e gives you, Fargate is the closest you can get when applications can\u0027t be deployed as single functions.\u003c/p\u003e","theta":"185","volume":"2018-05"},{"name":"Azure Service Fabric","id":"1203","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"37","display_name":"Azure Service Fabric","radius":"285","description":"\u003cp\u003e\u003cstrong\u003eAzure Service Fabric\u003c/strong\u003e is a distributed systems platform built for microservices and containers. It can act as a PaaS with its reliable services, or like a container orchestrator with its ability to manage containers. What distinguishes Service Fabric though are programming models such as \u003ca href\u003d\"https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-reliable-actors-introduction\"\u003eReliable Actors\u003c/a\u003e built on top of reliable services. When it comes to IoT use cases, for example, Reliable Actors offers some compelling advantages — in addition to the reliability and platform benefits of being on Service Fabric, you also get its state management and replication capabilities. In keeping with continued focus on open source software (OSS), Microsoft will be transitioning Service Fabric to an \u003ca href\u003d\"https://blogs.msdn.microsoft.com/azureservicefabric/2018/03/14/service-fabric-is-going-open-source/\"\u003eopen development process on Github\u003c/a\u003e. All this makes Azure Service Fabric worth trialling — particularly for organizations who are invested in the .NET framework.\u003c/p\u003e","theta":"190","volume":"2018-05"},{"name":"Azure Stack","id":"1258","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"38","display_name":"Azure Stack","radius":"300","description":"\u003cp\u003eCloud computing brings significant benefits over self-hosted virtualized solutions but sometimes data simply cannot leave an organization’s premises, usually for latency or regulatory reasons. For European companies, the current political climate also raises more concerns about placing data in the hands of US-based entities. With \u003ca href\u003d\"http://azure.microsoft.com/en-us/overview/azure-stack/\"\u003e\u003cstrong\u003eAzure Stack\u003c/strong\u003e\u003c/a\u003e, Microsoft adds an interesting offering as a middle ground between full-featured public clouds and simple on-premises virtualization: a slimmed-down version of the software that runs Microsoft’s Azure Global cloud is combined with a rack of preconfigured commodity hardware from the usual suspects like HP and Lenovo, providing an organization with the core Azure experience on premises. By default, support is split between Microsoft and the hardware vendors (and they promise to cooperate), but system integrators can offer complete Azure Stack solutions, too.\u003c/p\u003e","theta":"195","volume":"2018-05"},{"name":"Cloud Spanner","id":"1196","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"39","display_name":"Cloud Spanner","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"http://cloud.google.com/spanner/\"\u003e\u003cstrong\u003eCloud Spanner\u003c/strong\u003e\u003c/a\u003e is a fully managed relational database service offering high availability and strong consistency without compromising latency. Google has been working on a globally distributed database called Spanner for quite some time. It has recently released the service to the outside world as Cloud Spanner. You can scale your database instance from one to thousands of nodes across the globe without worrying about data consistency. By levering \u003ca href\u003d\"http://cloud.google.com/spanner/docs/true-time-external-consistency\"\u003eTrueTime\u003c/a\u003e, a highly available and distributed clock, Cloud Spanner provides strong consistency for reads and snapshots. You can use standard SQL to read data from Cloud Spanner, but for write operations you have to use their RPC API. Although not all services would require a global-scale distributed database, the general availability of Cloud Spanner is a big shift in the way we think about databases. And its design is influencing open source products such as \u003ca href\u003d\"http://github.com/cockroachdb/cockroach\"\u003eCockroachDB\u003c/a\u003e.\u003c/p\u003e","theta":"201","volume":"2018-05"},{"name":"Corda","id":"1202","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"40","display_name":"Corda","radius":"338","description":"\u003cp\u003eAfter thorough exploration, R3, an important player in the blockchain space, realized that blockchain doesn\u0027t fit their purpose well, so they created \u003cstrong\u003e\u003ca href\u003d\"http://www.corda.net\"\u003eCorda\u003c/a\u003e\u003c/strong\u003e. Corda is a distributed ledger technology (DLT) platform focused on the financial field. R3 have a very clear value proposition and know that their problem requires a pragmatic technology approach. This matches our own experience; current blockchain solutions may not be the reasonable choice for some business cases, due to mining costs and operational inefficiency. Although the development experience we have on Corda thus far has not been the smoothest, \u003ca href\u003d\"http://docs.corda.net/releases/release-V1.0/api-index.html#internal-apis-and-stability-guarantees\"\u003eAPIs are still unstable after v1.0 release\u003c/a\u003e, we expect to see the DLT space mature further.\u003c/p\u003e","theta":"206","volume":"2018-05"},{"name":"Cosmos DB","id":"1191","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"41","display_name":"Cosmos DB","radius":"331","description":"\u003cp\u003e\u003ca href\u003d\"http://docs.microsoft.com/en-us/azure/cosmos-db/introduction\"\u003e\u003cstrong\u003eCosmos DB\u003c/strong\u003e\u003c/a\u003e is Microsoft\u0027s globally distributed, multimodel database service, which became generally available earlier this year. While most modern NoSQL databases offer tunable consistency, Cosmos DB makes it a first-class citizen and offers five different consistency models. It\u0027s worth highlighting that it also supports multiple models — key value, document, column family and graph — all of which map to its internal data model, called atom-record-sequence (ARS). One interesting aspect of Cosmos DB is that it offers service level agreements (SLAs) on its latency, throughput, consistency and availability. With its wide range of applicability, it has set a high standard for other cloud vendors to match.\u003c/p\u003e","theta":"211","volume":"2018-05"},{"name":"Godot","id":"1261","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"42","display_name":"Godot","radius":"320","description":"\u003cp\u003eAs AR and VR continue to gain traction, we continue to explore tools with which we can create immersive virtual worlds. Our positive experience with \u003ca href\u003d\"/radar/platforms/unity-beyond-gaming\"\u003eUnity\u003c/a\u003e, one of the two major gaming engines, led us to feature it in previous Radars. We still like Unity but are also excited about \u003ca href\u003d\"http://godotengine.org/\"\u003e\u003cstrong\u003eGodot\u003c/strong\u003e\u003c/a\u003e, a relatively new entrant to the field. Godot is open source software and although not as fully featured as the big commercial engines, it comes with a more modern software design and less clutter. Offering C# and Python further lowers the barrier to entry for developers outside the gaming industry. Godot version 3, released earlier this year, \u003ca href\u003d\"http://godotengine.org/article/update-on-recent-vr-developments\"\u003eadds support for VR\u003c/a\u003e and support for AR is on the horizon.\u003c/p\u003e","theta":"217","volume":"2018-05"},{"name":"Interledger","id":"1257","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"43","display_name":"Interledger","radius":"320","description":"\u003cp\u003eMost people may know the \"Internet of money\" through \u003ca href\u003d\"http://bitcoin.org/en/\"\u003eBitcoin\u003c/a\u003e. In fact, this idea can be traced to the early stages of the Web. HTTP even reserved a \u003ca href\u003d\"http://httpstatusdogs.com/402-payment-required\"\u003estatus code\u003c/a\u003e for digital payment. The challenging part of this idea is to transfer value between different ledgers in different entities. \u003ca href\u003d\"http://en.wikipedia.org/wiki/Blockchain\"\u003eBlockchain\u003c/a\u003e technology promotes this idea through building a distributed shared ledger. The current challenge is how to achieve interoperability between different blockchain ledgers and interoperability with traditional centralized ledgers. \u003ca href\u003d\"http://interledger.org/\"\u003e\u003cstrong\u003eInterledger\u003c/strong\u003e\u003c/a\u003e is a protocol to connect different ledgers. This protocol uses connectors and a cryptographic mechanism such as \u003ca href\u003d\"http://en.bitcoin.it/wiki/Hashed_Timelock_Contracts\"\u003eHTLC\u003c/a\u003e to route secure payments across ledgers. It’s not hard to join the payment network through its suites. Interledger was first initiated by Ripple and is now steadily developed by a W3C community group.\u003c/p\u003e","theta":"222","volume":"2018-05"},{"name":"Language Server Protocol","id":"1195","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"44","display_name":"Language Server Protocol","radius":"300","description":"\u003cp\u003eMuch of the power of sophisticated IDEs comes from their ability to parse a program into an abstract syntax tree (AST) and then use that AST for program analysis and manipulation. This supports features such as autocomplete, finding callers and refactoring. Language servers pull this capability into a process that allows any text editor to access an API to work with the AST. Microsoft has led the creation of the \u003ca href\u003d\"http://github.com/Microsoft/language-server-protocol\"\u003e\u003cstrong\u003eLanguage Server Protocol\u003c/strong\u003e\u003c/a\u003e (LSP), harvested from their OmniSharp and TypeScript Server projects.\u003ca href\u003d\"http://langserver.org#implementations-client\"\u003eAny editor\u003c/a\u003e that uses this protocol can work with any language that has an \u003ca href\u003d\"http://langserver.org#implementations-server\"\u003eLSP-compliant server\u003c/a\u003e. This means we can keep using our favorite editors without forgoing the rich text editing modes of many languages — much to the delight of our Emacs addicts.\u003c/p\u003e","theta":"227","volume":"2018-05"},{"name":"LoRaWAN","id":"1197","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"45","display_name":"LoRaWAN","radius":"333","description":"\u003cp\u003e\u003cstrong\u003eLoRaWAN\u003c/strong\u003e is a low-power wide-area network, designed for low-power consumption and communication over long distances using low bitrates. It provides for communication between devices and gateways, which can then forward the data to, for example, applications or servers. A typical usage is for a distributed set of sensors, or for Internet of Things (IoT) devices, for which long battery life and long-range communication is a must. LoRaWAN addresses two of the key problems with attempting to use normal Wi-Fi for such applications: range and power consumption. There are several implementations, a notable one being \u003ca href\u003d\"http://www.thethingsnetwork.org/\"\u003eThe Things Network\u003c/a\u003e, a free, open source implementation.\u003c/p\u003e","theta":"232","volume":"2018-05"},{"name":"Mongoose OS","id":"1256","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"46","display_name":"Mongoose OS","radius":"320","description":"\u003cp\u003eWith an accelerated growth of connected embedded devices and wider accessibility of hardware, \u003ca href\u003d\"http://mongoose-os.com/\"\u003e\u003cstrong\u003eMongoose OS\u003c/strong\u003e\u003c/a\u003e fills a noticeable gap for embedded software developers: the gap between Arduino firmware suitable for prototyping and bare-metal microcontrollers\u0027 native SDKs. Mongoose OS is a microcontroller operating system that comes with a set of libraries and a development framework to support typical Internet of Things (IoT) applications with connectivity to generic \u003ca href\u003d\"http://mqtt.org/\"\u003eMQTT\u003c/a\u003e servers and popular IoT cloud platforms such as \u003ca href\u003d\"http://cloud.google.com/iot-core\"\u003eGoogle Cloud IoT Core\u003c/a\u003e and \u003ca href\u003d\"http://aws.amazon.com/iot/\"\u003eAWS IoT\u003c/a\u003e by default. In fact, Google recommends a \u003ca href\u003d\"http://cloud.google.com/solutions/iot/kit/\"\u003eMongoose starter kit\u003c/a\u003e for its Cloud IoT Core. We’ve had a seamless experience using Mongoose OS in our embedded projects building connected workspaces. We especially liked its built-in security at the individual device level and OTA firmware updates, among other \u003ca href\u003d\"http://mongoose-os.com/features.html\"\u003efeatures\u003c/a\u003e. At the time of writing, only a limited number of microcontrollers and boards are supported with more popular ARM-based microcontrollers still under development.\u003c/p\u003e","theta":"238","volume":"2018-05"},{"name":"Netlify","id":"1201","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"47","display_name":"Netlify","radius":"320","description":"\u003cp\u003eWe like simple tools that solve one problem really well, and \u003ca href\u003d\"http://www.netlify.com/\"\u003e\u003cstrong\u003eNetlify\u003c/strong\u003e\u003c/a\u003e fits this description nicely. You can create static website content, check it into GitHub and then quickly and easily get your site live and available. There is a CLI available to control the process; content delivery networks (CDNs) are supported; it can work alongside tools such as \u003ca href\u003d\"http://gruntjs.com/\"\u003eGrunt\u003c/a\u003e; and, most importantly, Netlify supports HTTPS.\u003c/p\u003e","theta":"243","volume":"2018-05"},{"name":"TensorFlow Serving","id":"1198","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"48","display_name":"TensorFlow Serving","radius":"310","description":"\u003cp\u003eMachine-learning models are starting to creep into everyday business applications. When enough training data is available, these algorithms can address problems that might have previously required complex statistical models or heuristics. As we move from experimental use to production, we need a reliable way to host and deploy the models that can be accessed remotely and scale with the number of consumers. \u003ca href\u003d\"http://www.tensorflow.org/serving/\"\u003e\u003cstrong\u003eTensorFlow Serving\u003c/strong\u003e\u003c/a\u003e addresses part of that problem by exposing a remote gRPC interface to an exported model; this allows a trained model to be deployed in a variety of ways. TensorFlow Serving also accepts a stream of models to incorporate continuous training updates, and its authors maintain a Dockerfile to ease the deployment process. Presumably, the choice of gRPC is to be consistent with the TensorFlow execution model; however, we’re generally wary of protocols that require code generation and native bindings.\u003c/p\u003e","theta":"248","volume":"2018-05"},{"name":"TICK Stack","id":"1260","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"49","display_name":"TICK Stack","radius":"300","description":"\u003cp\u003e\u003ca href\u003d\"http://www.influxdata.com/time-series-platform/\"\u003e\u003cstrong\u003eTICK Stack\u003c/strong\u003e\u003c/a\u003e is a platform composed of open source components which makes collection, storage, graphing and alerting on-time series data such as metrics and events easy. The components of the TICK Stack are: Telegraf, a server agent for collecting and reporting metrics; InfluxDB, a high-performance time series database; Chronograf, a user interface for the platform; and Kapacitor, a data-processing engine that can process, stream and batch data from InfluxDB. Unlike \u003ca href\u003d\"/radar/tools/prometheus\"\u003ePrometheus\u003c/a\u003e, which is based on the Pull model, the TICK Stack is based on the Push model of collecting data. The heart of the system is the InfluxDB component which is one of the best time series databases. This stack is backed by InfluxData and needs the enterprise version for features such as DB clustering, but it’s still a fairly good choice for monitoring. We’re using it in a few places in production and have had good experiences with it.\u003c/p\u003e","theta":"254","volume":"2018-05"},{"name":"Web Bluetooth","id":"1259","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"50","display_name":"Web Bluetooth","radius":"320","description":"\u003cp\u003e\u003ca href\u003d\"http://github.com/WebBluetoothCG/web-bluetooth\"\u003e\u003cstrong\u003eWeb Bluetooth\u003c/strong\u003e\u003c/a\u003e allows us to control any Bluetooth Low Energy device directly from the browser. This allows us to target scenarios that previously could only be solved with a native app. The specification is published by the Web Bluetooth Community Group and describes an API to discover and communicate with devices over the Bluetooth 4 wireless standard. Right now, Chrome is the only major browser which currently supports this specification. With \u003ca href\u003d\"http://google.github.io/physical-web/\"\u003ePhysical Web\u003c/a\u003e and Web Bluetooth, we now have other avenues for getting users to interact with devices without them having to install yet another app on their phone. This is an exciting space which is worth keeping an eye on.\u003c/p\u003e","theta":"259","volume":"2018-05"},{"name":"Windows Containers","id":"1200","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"51","display_name":"Windows Containers","radius":"290","description":"\u003cp\u003eMicrosoft is catching up in the container space with \u003ca href\u003d\"http://docs.microsoft.com/en-us/virtualization/windowscontainers/about/\"\u003e\u003cstrong\u003eWindows Containers\u003c/strong\u003e\u003c/a\u003e enabling running Windows applications as containers on Windows-based environments. At the time of writing, Microsoft provides two Windows OS images as Docker containers — \u003ca href\u003d\"http://hub.docker.com/r/microsoft/windowsservercore/\"\u003eWindows Server 2016 Server Core\u003c/a\u003e and \u003ca href\u003d\"http://hub.docker.com/r/microsoft/nanoserver/\"\u003eWindows Server 2016 Nano Server\u003c/a\u003e — that can run as a \u003ca href\u003d\"http://docs.microsoft.com/en-us/virtualization/windowscontainers/about/#windows-container-types\"\u003eWindows Server Container\u003c/a\u003e with Docker. Our teams have started using Windows containers in scenarios where \u003ca href\u003d\"/radar/techniques/docker-for-builds\"\u003ebuild agents\u003c/a\u003e and similar containers have been working successfully. Microsoft is aware that there’s room for improvements such as decreasing the large image sizes and enriching ecosystem support and documentation.\u003c/p\u003e","theta":"264","volume":"2018-05"},{"name":"Overambitious API gateways","id":"931","quadrant":"Platforms","ring":"Hold","movement":"c","radarId":"52","display_name":"Overambitious API gateways","radius":"382","description":"\u003cp\u003eWe remain concerned about business logic and process orchestration implemented in middleware, especially where it requires expert skills and tooling while creating single points of scaling and control. Vendors in the highly competitive API gateway market are continuing this trend by adding features through which they attempt to differentiate their products. This results in \u003cstrong\u003eoverambitious API gateway\u003c/strong\u003e products whose functionality — on top of what is essentially a reverse proxy — encourages designs that continue to be difficult to test and deploy. API gateways do provide utility in dealing with some specific concerns — such as authentication and rate limiting — but any domain smarts should live in applications or services.\u003c/p\u003e","theta":"225","volume":"2018-05"},{"name":"Appium Test Distribution","id":"1221","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"53","display_name":"Appium Test Distribution","radius":"190","description":"\u003cp\u003eWe\u0027ve featured \u003ca href\u003d\"/radar/tools/appium\"\u003eAppium\u003c/a\u003e in the Radar in the past. It\u0027s one of the most popular mobile test automation frameworks. As we scale our test suite, being able to run our tests in parallel against an array of devices is key in having short feedback loops. \u003ca href\u003d\"http://github.com/saikrishna321/AppiumTestDistribution\"\u003e\u003cstrong\u003eAppium Test Distribution\u003c/strong\u003e\u003c/a\u003e solves this problem very effectively with its ability to run tests in parallel as well as run the same tests on multiple devices. Among other things, it distinguishes itself by its ability to add and remove devices in which tests run without any manual setup required and with its ability to run tests on remote devices. We\u0027ve used it in a few projects at ThoughtWorks over the last couple of years and it worked very well for us.\u003c/p\u003e","theta":"83","volume":"2018-05"},{"name":"BackstopJS","id":"1237","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"54","display_name":"BackstopJS","radius":"200","description":"\u003cp\u003eWe\u0027ve been enjoying \u003cstrong\u003e\u003ca href\u003d\"http://github.com/garris/BackstopJS\"\u003eBackstopJS\u003c/a\u003e\u003c/strong\u003e for visual regression testing of web applications. The configurable viewports and ability to adjust tolerances are particularly useful, as is the visual comparison tool, which makes it easier to spot minor variations. It has good scriptability and the option to run in \u003ca href\u003d\"/radar/tools/headless-chrome-for-front-end-test\"\u003eHeadless Chrome\u003c/a\u003e, PhantomJS and SlimerJS. We find it particularly helpful when running it against \u003ca href\u003d\"/radar/techniques/living-css-style-guides\"\u003eliving component style guides\u003c/a\u003e.\u003c/p\u003e","theta":"78","volume":"2018-05"},{"name":"Buildkite","id":"1146","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"55","display_name":"Buildkite","radius":"200","description":"\u003cp\u003eOur teams very much like the hosted CI/CD tool \u003ca href\u003d\"http://buildkite.com/\"\u003e\u003cstrong\u003eBuildkite\u003c/strong\u003e\u003c/a\u003e for its simplicity and quick setup. With Buildkite, you provide your own machines to execute builds — on premise or in the cloud — and install a lightweight agent application to connect the build agent to the hosted service. In many cases, having this level of control over the configuration of your build agents is a plus when compared to using hosted agents.\u003c/p\u003e","theta":"71","volume":"2018-05"},{"name":"CircleCI","id":"1147","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"56","display_name":"CircleCI","radius":"200","description":"\u003cp\u003e\u003ca href\u003d\"http://circleci.com/\"\u003e\u003cstrong\u003eCircleCI\u003c/strong\u003e\u003c/a\u003e is a continuous integration engine offered as SaaS and on premise. CircleCI has been the go-to SaaS CI tool for many of our development teams, who needed a low-friction and easy-to-setup build and deployment pipeline. CircleCI version 2.0 supports workflows of build jobs, with fan-in and fan-out flows and manual gates, as well as mobile development. It allows developers to run the pipelines locally and easily integrates with Slack and other notification and alerting systems. We recommend you take a closer look at the \u003ca href\u003d\"http://circleci.com/security/\"\u003esecurity practices of CircleCI\u003c/a\u003e, just as you would with any other SaaS product that hosts your company’s assets.\u003c/p\u003e","theta":"65","volume":"2018-05"},{"name":"CVXPY","id":"1219","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"57","display_name":"CVXPY","radius":"220","description":"\u003cp\u003eIt’s surprising how many problems can be expressed as \u003ca href\u003d\"http://en.wikipedia.org/wiki/Mathematical_optimization\"\u003emathematical optimization problems\u003c/a\u003e and often \u003ca href\u003d\"http://en.wikipedia.org/wiki/Convex_optimization\"\u003econvex problems\u003c/a\u003e that can be efficiently solved. \u003ca href\u003d\"http://www.cvxpy.org\"\u003e\u003cstrong\u003eCVXPY\u003c/strong\u003e\u003c/a\u003e is an open source Python-embedded modeling language for convex optimization problems. It’s maintained by academics at Stanford University and offers a batteries-included install for several open source and commercial solvers. The documentation includes many examples which should inspire developers to use it. It’s particularly useful for prototyping solutions even though commercially licensed solvers, such \u003ca href\u003d\"http://www.gurobi.com/\"\u003eGurobi\u003c/a\u003e or \u003ca href\u003d\"http://www.ibm.com/analytics/data-science/prescriptive-analytics/cplex-optimizer\"\u003eIBM CPLEX\u003c/a\u003e, may be required. In most cases though, it suffices by itself. However, the same group has written many extension packages such as \u003ca href\u003d\"http://stanford.edu/%7Eboyd/papers/dccp.html\"\u003eDCCP\u003c/a\u003e and related software such as \u003ca href\u003d\"http://cvxopt.org/\"\u003eCVXOPT\u003c/a\u003e based on recent advances in optimization.\u003c/p\u003e","theta":"58","volume":"2018-05"},{"name":"gopass","id":"1145","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"58","display_name":"gopass","radius":"240","description":"\u003cp\u003e\u003ca href\u003d\"http://www.justwatch.com/gopass/\"\u003e\u003cstrong\u003egopass\u003c/strong\u003e\u003c/a\u003e is a password management solution for teams, built on GPG and \u003ca href\u003d\"/radar/tools/git\"\u003eGit\u003c/a\u003e. It\u0027s a descendant of \u003ca href\u003d\"http://www.passwordstore.org\"\u003epass\u003c/a\u003e and adds features such as: support for recipient management and multiple password stores in a single tree; an interactive search functionality; time-based one-time password (TOTP) support; and storage of binary data. Migration of your pass store is fairly straightforward, because gopass is largely compatible with the format pass uses. This also means integration into provisioning workflows can be achieved with a single call to a stored secret.\u003c/p\u003e","theta":"52","volume":"2018-05"},{"name":"Headless Chrome for front-end test","id":"1148","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"59","display_name":"Headless Chrome for front-end test","radius":"200","description":"\u003cp\u003eSince mid-2017, Chrome users have had the option of running the browser in headless mode. This feature is ideally suited to running front-end browser tests without the overhead of displaying actions on a screen. Previously, this was largely the province of PhantomJS but \u003ca href\u003d\"http://developers.google.com/web/updates/2017/06/headless-karma-mocha-chai\"\u003eHeadless Chrome\u003c/a\u003e is rapidly replacing the JavaScript-driven WebKit approach. Tests in Headless Chrome should run much faster, and behave more like a real browser, but our teams have found that it does use more memory than PhantomJS. With all these advantages, \u003cstrong\u003eHeadless Chrome for front-end test\u003c/strong\u003e is likely to become the de facto standard.\u003c/p\u003e","theta":"45","volume":"2018-05"},{"name":"Helm","id":"1222","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"60","display_name":"Helm","radius":"190","description":"\u003cp\u003e\u003ca href\u003d\"http://helm.sh\"\u003e\u003cstrong\u003eHelm\u003c/strong\u003e\u003c/a\u003e is a package manager for \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e. The set of Kubernetes resources that together define an application is packaged as charts. These charts can describe a single resource, such as a Redis pod, or a full stack of a web application: HTTP servers, databases and caches. Helm, by default, comes with a repository of curated Kubernetes applications that are maintained in the official \u003ca href\u003d\"http://github.com/kubernetes/charts\"\u003echarts repository\u003c/a\u003e. It’s also easy to set up a private chart repository for internal usage. Helm has two components: a command line utility called Helm and a cluster component called Tiller. Securing a Kubernetes cluster is a wide and nuanced topic, but we highly recommend setting up Tiller in a role-based access control (RBAC) environment. We’ve used Helm in a number of client projects and it’s dependency management, templating and hook mechanism has greatly simplified the application lifecycle management in Kubernetes.\u003c/p\u003e","theta":"39","volume":"2018-05"},{"name":"Jupyter","id":"1154","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"61","display_name":"Jupyter","radius":"190","description":"\u003cp\u003eOver the last couple of years, we\u0027ve noticed a steady rise in the popularity of analytics notebooks. These are Mathematica-inspired applications that combine text, visualization and code in a living, computational document. Increased interest in machine learning — along with the emergence of Python as the programming language of choice for practitioners in this field — has focused particular attention on Python notebooks, of which \u003ca href\u003d\"http://jupyter.org/\"\u003e\u003cstrong\u003eJupyter\u003c/strong\u003e\u003c/a\u003e seems to be gaining the most traction among ThoughtWorks teams. People seem to keep finding creative uses for Jupyter beyond a simple analytics tool. For example, see \u003ca href\u003d\"/radar/techniques/jupyter-for-automated-testing\"\u003eJupyter for automated testing\u003c/a\u003e.\u003c/p\u003e","theta":"33","volume":"2018-05"},{"name":"kops","id":"1152","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"62","display_name":"kops","radius":"180","description":"\u003cp\u003e\u003ca href\u003d\"http://github.com/kubernetes/kops\"\u003e\u003cstrong\u003ekops\u003c/strong\u003e\u003c/a\u003e is a command line tool for creating and managing high-availability production \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e clusters. kops has become our go-to tool to self-manage Kubernetes clusters on \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e, not the least because of its rapidly growing open source community. It also supports installing, upgrading and managing Kubernetes clusters on \u003ca href\u003d\"/radar/platforms/google-cloud-platform\"\u003eGoogle Cloud\u003c/a\u003e. Our experience with kops on Google, however, is very limited because of our preference for \u003ca href\u003d\"/radar/platforms/gke\"\u003eGKE\u003c/a\u003e, the managed Kubernetes offering. We recommend using kops in reusable scripts to create \u003ca href\u003d\"/radar/tools/infrastructure-as-code\"\u003einfrastructure as code\u003c/a\u003e. We\u0027re interested to see how kops continues to evolve to support managed Kubernetes clusters such as \u003ca href\u003d\"http://aws.amazon.com/eks/\"\u003eEKS\u003c/a\u003e, Amazon\u0027s own managed Kubernetes service.\u003c/p\u003e","theta":"26","volume":"2018-05"},{"name":"Patroni","id":"1218","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"63","display_name":"Patroni","radius":"210","description":"\u003cp\u003e\u003ca href\u003d\"http://github.com/zalando/patroni\"\u003e\u003cstrong\u003ePatroni\u003c/strong\u003e\u003c/a\u003e is a template for \u003ca href\u003d\"http://www.postgresql.org/docs/9.5/static/high-availability.html\"\u003ePostgreSQL high availability\u003c/a\u003e. Born out of the need to provide automatic failure for PostgreSQL, Patroni is a Python-based PostgreSQL controller that leverages a distributed configuration store (such as \u003ca href\u003d\"http://coreos.com/etcd/\"\u003eetcd\u003c/a\u003e, \u003ca href\u003d\"http://zookeeper.apache.org/\"\u003eZooKeeper\u003c/a\u003e, or \u003ca href\u003d\"/radar/tools/consul\"\u003eConsul\u003c/a\u003e) to manage the state of the PostgreSQL cluster. Patroni supports both streaming and synchronous replication models and provides a rich set of REST APIs for dynamic configuration of the PostgreSQL cluster. If you want to achieve high availability in a distributed PostgreSQL setup, you have to consider many edge cases, and we like the fact that Patroni provides a template to achieve most of the common use cases.\u003c/p\u003e","theta":"20","volume":"2018-05"},{"name":"WireMock","id":"1220","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"64","display_name":"WireMock","radius":"200","description":"\u003cp\u003eA key driver for architectures based on \u003ca href\u003d\"http://martinfowler.com/microservices/\"\u003emicroservices\u003c/a\u003e is independent evolvability of services. For example, when two services depend on each other, the testing process for one usually involves stubs and mocks for the other one. These can be written by hand, but as with mocking in unit tests, a framework helps developers focus on the actual test scenario. We have known of \u003ca href\u003d\"http://wiremock.org/\"\u003e\u003cstrong\u003eWireMock\u003c/strong\u003e\u003c/a\u003e for a while but we’ve preferred running tests with \u003ca href\u003d\"/radar/tools/mountebank\"\u003emountebank\u003c/a\u003e. Over the past year, though, WireMock has really caught up and we now recommend it as a good alternative.\u003c/p\u003e","theta":"13","volume":"2018-05"},{"name":"Yarn","id":"1112","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"65","display_name":"Yarn","radius":"210","description":"\u003cp\u003e\u003ca href\u003d\"http://yarnpkg.com/en/\"\u003e\u003cstrong\u003eYarn\u003c/strong\u003e\u003c/a\u003e is a fast, reliable and secured package manager for JavaScript. Using a lock file and a deterministic algorithm, Yarn is able to guarantee that an installation that worked on one system will work exactly the same way on any other system. By efficiently queuing up requests, Yarn maximizes network utilization and as a result we’ve seen faster package downloads. Yarn continues to be our tool of choice for JavaScript package management in spite of the latest improvements in npm (version 5).\u003c/p\u003e","theta":"7","volume":"2018-05"},{"name":"Apex","id":"1150","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"66","display_name":"Apex","radius":"330","description":"\u003cp\u003e\u003ca href\u003d\"http://github.com/apex/apex\"\u003e\u003cstrong\u003eApex\u003c/strong\u003e\u003c/a\u003e is a tool to build, deploy and manage AWS Lambda functions with ease. With Apex, you can write functions in languages that are not yet natively supported in AWS, including Golang, Rust and others. This is made possible by a Node.js shim, which creates a child process and processes events through stdin and stdout. Apex has a lot of nice \u003ca href\u003d\"http://github.com/apex/apex#features\"\u003efeatures\u003c/a\u003e that improve the developer experience, and we particularly like the ability to test functions locally and perform a dry run of the changes before they\u0027re applied to AWS resources.\u003c/p\u003e","theta":"84","volume":"2018-05"},{"name":"ArchUnit","id":"1228","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"67","display_name":"ArchUnit","radius":"290","description":"\u003cp\u003e\u003ca href\u003d\"http://www.archunit.org/\"\u003e\u003cstrong\u003eArchUnit\u003c/strong\u003e\u003c/a\u003e is a Java testing library for checking architecture characteristics such as package and class dependencies, annotation verification and even layer consistency. The fact that it runs as unit tests, within your existing test setup, pleases us, even though it\u0027s available for Java architectures only. The ArchUnit test suite can be incorporated into a CI environment or a deployment pipeline, making it easier to implement \u003ca href\u003d\"/radar/techniques/architectural-fitness-function\"\u003efitness functions\u003c/a\u003e in an \u003ca href\u003d\"http://evolutionaryarchitecture.com/\"\u003eevolutionary architecture\u003c/a\u003e way.\u003c/p\u003e","theta":"78","volume":"2018-05"},{"name":"cfn_nag","id":"1229","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"68","display_name":"cfn_nag","radius":"300","description":"\u003cp\u003eThe cloud and continuous delivery had a dramatic effect on infrastructure security. When following \u003ca href\u003d\"/radar/tools/infrastructure-as-code\"\u003einfrastructure as code\u003c/a\u003e, the entire infrastructure — which includes networks, firewalls and accounts — is defined in scripts and configuration files, and with \u003ca href\u003d\"/radar/tools/immutable-servers\"\u003ePhoenix Servers\u003c/a\u003e and \u003ca href\u003d\"/radar/techniques/phoenix-environments\"\u003eEnvironments\u003c/a\u003e, the infrastructure is recreated in each deployment, often many times a day. In such a scenario, testing the infrastructure after it\u0027s created is neither sufficient nor feasible. A tool that helps address this problem is \u003cstrong\u003e\u003ca href\u003d\"http://github.com/stelligent/cfn_nag\"\u003ecfn_nag\u003c/a\u003e\u003c/strong\u003e. It scans the \u003ca href\u003d\"http://aws.amazon.com/cloudformation/\"\u003eCloudFormation\u003c/a\u003e templates used with \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e for patterns that may indicate insecure infrastructure, and it does so before the infrastructure is created. Running a tool such as cfn_nag in a build pipeline is fast and it can detect a number of problems before they even reach a cloud environment.\u003c/p\u003e","theta":"72","volume":"2018-05"},{"name":"Conduit","id":"1225","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"69","display_name":"Conduit","radius":"305","description":"\u003cp\u003e\u003ca href\u003d\"http://github.com/runconduit/conduit\"\u003e\u003cstrong\u003eConduit\u003c/strong\u003e\u003c/a\u003e is a lightweight \u003ca href\u003d\"/radar/techniques/service-mesh\"\u003eservice mesh\u003c/a\u003e for \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e. Conduit embraces the out-of-process architecture with data plane proxy written in Rust and a control plane in \u003ca href\u003d\"/radar/languages-and-frameworks/go-language\"\u003eGo\u003c/a\u003e. The data plane proxy runs as a sidecar for all TCP traffic in the Kubernetes cluster and the control plane runs in a separate namespace in Kubernetes exposing REST APIs to control the behavior of the data plane proxy. By proxying all requests, Conduit provides a wealth of metrics for monitoring and observability of interactions in the service mesh for HTTP, HTTP/2 and gRPC traffic. Even though Conduit is relatively new to this space, we recommend it because it’s simple to install and operate.\u003c/p\u003e","theta":"66","volume":"2018-05"},{"name":"Cypress","id":"1149","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"70","display_name":"Cypress","radius":"300","description":"\u003cp\u003eFixing end-to-end test failures in CI can be a painful experience, especially in headless mode. \u003ca href\u003d\"http://www.cypress.io/\"\u003e\u003cstrong\u003eCypress\u003c/strong\u003e\u003c/a\u003e is a useful tool that helps developers build end-to-end tests easily and records all test steps as a video in an MP4 file. Instead of reproducing the issue in headless mode, developers can watch the testing video in order to fix it. Cypress is a powerful platform, not only a testing framework. Currently, we\u0027ve integrated its CLI with headless CI in our projects.\u003c/p\u003e","theta":"60","volume":"2018-05"},{"name":"Dependabot","id":"1224","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"71","display_name":"Dependabot","radius":"300","description":"\u003cp\u003eKeeping dependencies up to date is a chore, but it\u0027s important to manage upgrades frequently and incrementally. We want the process to be as painless and automated as possible. Our teams have often hand-rolled scripts to automate parts of the process; now, however, we integrate commercial offerings to do that work. \u003ca href\u003d\"http://dependabot.com/\"\u003e\u003cstrong\u003eDependabot\u003c/strong\u003e\u003c/a\u003e is a service that integrates with your GitHub repositories and automatically checks your project dependencies for new versions. When required, Dependabot will open a pull request with upgraded dependencies. Using features of your CI server, you can automatically test upgrades for compatibility and automatically merge compatible upgrades to master. There are alternatives to Dependabot, including \u003ca href\u003d\"http://renovateapp.com\"\u003eRenovate\u003c/a\u003e for JavaScript projects and \u003ca href\u003d\"http://depfu.com/\"\u003eDepfu\u003c/a\u003e for JavaScript and Ruby projects. Our teams, however, recommend Dependabot because of its multilanguage support and ease of use.\u003c/p\u003e","theta":"54","volume":"2018-05"},{"name":"Flow","id":"1163","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"72","display_name":"Flow","radius":"300","description":"\u003cp\u003e\u003ca href\u003d\"http://flow.org/\"\u003e\u003cstrong\u003eFlow\u003c/strong\u003e\u003c/a\u003e is a static type checker for JavaScript that allows you to add type checking across the codebase incrementally. Unlike Typescript, which is a different language, Flow can be added incrementally to an existing JavaScript codebase supporting the 5th, 6th and 7th editions of ECMAScript. We suggest adding Flow to your continuous integration pipeline, starting with the code that concerns you most. Flow adds to the clarity of the code, increases the reliability of refactoring and catches type-related bugs early during the build.\u003c/p\u003e","theta":"48","volume":"2018-05"},{"name":"Headless Firefox","id":"1233","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"73","display_name":"Headless Firefox","radius":"310","description":"\u003cp\u003eWhen developing front-end applications, we\u0027ve mentioned \u003ca href\u003d\"/radar/tools/headless-chrome-for-front-end-test\"\u003eHeadless Chrome\u003c/a\u003e as a better alternative to PhantomJS for front-end testing in a previous edition of the Radar. Now we suggest assessing \u003ca href\u003d\"http://developer.mozilla.org/en-US/Firefox/Headless_mode\"\u003e\u003cstrong\u003eHeadless Firefox\u003c/strong\u003e\u003c/a\u003e as a viable option in this area. In the same way as Headless Chrome, Firefox in a headless mode runs the browser without the visible UI components, executing the UI tests suite much faster.\u003c/p\u003e","theta":"42","volume":"2018-05"},{"name":"nsp","id":"1235","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"74","display_name":"nsp","radius":"300","description":"\u003cp\u003e\u003ca href\u003d\"http://www.npmjs.com/package/nsp\"\u003e\u003cstrong\u003ensp\u003c/strong\u003e\u003c/a\u003e is a command line tool to identify known vulnerabilities in Node.js applications. By running the check command on the root of a Node.js project, nsp generates the vulnerabilities report by checking against the \u003ca href\u003d\"http://nodesecurity.io/advisories/\"\u003epublished advisories\u003c/a\u003e. nsp provides a way to customize the check command to hide all vulnerabilities below the given \u003ca href\u003d\"http://nvd.nist.gov/vuln-metrics/cvss\"\u003eCVSS\u003c/a\u003e score or exit with an error code if at least one finding has a CVSS score above the given value. Once the advisories are saved through the gather command, nsp can also be used in offline mode.\u003c/p\u003e","theta":"36","volume":"2018-05"},{"name":"Parcel","id":"1234","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"75","display_name":"Parcel","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"https://en.parceljs.org/\"\u003e\u003cstrong\u003eParcel\u003c/strong\u003e\u003c/a\u003e is a web application bundler similar to \u003ca href\u003d\"/radar/tools/webpack\"\u003eWebpack\u003c/a\u003e or \u003ca href\u003d\"http://browserify.org/\"\u003eBrowserify\u003c/a\u003e. We’ve featured Webpack previously in our Radar and it continues to be a great tool. Parcel distinguishes itself from its rivals through developer experience and speed. It has all the standard bundling features and provides true zero-configuration experience, making it really easy to get started with and use. It has fast bundle times and beats its competitors in many benchmarks. Parcel has gained a lot of community interest and is worth keeping an eye on.\u003c/p\u003e","theta":"30","volume":"2018-05"},{"name":"Scout2","id":"1223","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"76","display_name":"Scout2","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"http://nccgroup.github.io/Scout2/\"\u003e\u003cstrong\u003eScout2\u003c/strong\u003e\u003c/a\u003e is a security auditing tool for \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e environments. Instead of manually navigating through web pages, you can rely on Scout2 to fetch all the configuration data of an AWS environment for you; it even generates an attack surface report. Scout2 ships with preconfigured rules and can be easily extended to support more services and test cases. Since Scout2 only performs AWS API calls to fetch configuration data and identify security gaps, it is not necessary to complete and submit the AWS Vulnerability / Penetration Testing Request Form.\u003c/p\u003e","theta":"24","volume":"2018-05"},{"name":"Sentry","id":"1232","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"77","display_name":"Sentry","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"https://sentry.io/welcome/\"\u003e\u003cstrong\u003eSentry\u003c/strong\u003e\u003c/a\u003e is an error-tracking tool that helps monitor and fix errors in real time. Error tracking and management tools such as Sentry distinguish themselves from traditional logging solutions such as the \u003ca href\u003d\"https://www.elastic.co/elk-stack\"\u003eELK Stack\u003c/a\u003e in their focus on discovering, investigating and fixing errors. Sentry has been around for some time and is quite popular — error-tracking tools are increasingly useful with the current focus on \"mean time to recovery\". Sentry — with its integration options with Github, Hipchat, Heroku, Slack, among other platforms — enables us to keep a close eye on our apps. It can provide error notifications following a release, enable us to track whether new commits actually fix the issue and alert us if an issue comes back due to a regression.\u003c/p\u003e","theta":"18","volume":"2018-05"},{"name":"Sonobuoy","id":"1162","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"78","display_name":"Sonobuoy","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"https://github.com/heptio/sonobuoy\"\u003e\u003cstrong\u003eSonobuoy\u003c/strong\u003e\u003c/a\u003e is a diagnostic tool for running end-to-end conformance tests on any \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e cluster in a nondestructive way. The team at \u003ca href\u003d\"http://heptio.com/\"\u003eHeptio\u003c/a\u003e, which was founded by two creators of the Kubernetes projects, built this tool to ensure that the wide array of Kubernetes distributions and configurations conform to the best practices, while following the open source standardization for interoperability of clusters. We\u0027re experimenting with Sonobuoy to run as part of our \u003ca href\u003d\"/radar/tools/infrastructure-as-code\"\u003einfrastructure as code\u003c/a\u003e build pipeline, as well as continuous monitoring of our Kubernetes installations, to validate the behavior and health of the whole cluster.\u003c/p\u003e","theta":"12","volume":"2018-05"},{"name":"Swashbuckle for .NET Core","id":"1236","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"79","display_name":"Swashbuckle for .NET Core","radius":"300","description":"\u003cp\u003eIn the current state of technology services, exposing RESTFul APIs is increasingly adopted and API documentation is very important for consumers. In this space, \u003ca href\u003d\"/radar/tools/swagger\"\u003eSwagger\u003c/a\u003e has been largely used across teams and we would like to highlight \u003cstrong\u003e\u003ca href\u003d\"http://github.com/domaindrivendev/Swashbuckle.AspNetCore\"\u003eSwashbuckle for .NET Core\u003c/a\u003e\u003c/strong\u003e. Swashbuckle for .NET Core is a tool that generates living API documentation in Swagger, based on the code for \u003ca href\u003d\"/radar/platforms/net-core\"\u003e.NET Core\u003c/a\u003e projects. When using it, you can also explore and test operations of APIs through its UI.\u003c/p\u003e","theta":"6","volume":"2018-05"},{"name":"AssertJ","id":"1165","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"80","display_name":"AssertJ","radius":"75","description":"\u003cp\u003e\u003ca href\u003d\"http://joel-costigliola.github.io/assertj/index.html\"\u003e\u003cstrong\u003eAssertJ\u003c/strong\u003e\u003c/a\u003e is a Java library that provides a \u003ca href\u003d\"http://martinfowler.com/bliki/FluentInterface.html\"\u003efluent interface\u003c/a\u003e for assertions, which makes it easy to convey intent within test code. AssertJ gives readable error messages, soft assertions and improved collections and exception support. Many of our teams choose AssertJ as their default assertion library instead of JUnit combined with \u003ca href\u003d\"http://hamcrest.org/JavaHamcrest/\"\u003eJava Hamcrest\u003c/a\u003e.\u003c/p\u003e","theta":"292","volume":"2018-05"},{"name":"Enzyme","id":"1047","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"81","display_name":"Enzyme","radius":"75","description":"\u003cp\u003e\u003ca href\u003d\"http://airbnb.io/enzyme/\"\u003e\u003cstrong\u003eEnzyme\u003c/strong\u003e\u003c/a\u003e has become the defacto standard for unit testing \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e UI components. Unlike many other snapshot-based testing utilities, Enzyme enables you to test without doing on-device rendering, which results in faster and more granular testing. This is a contributing factor in our ability to massively reduce the amount of functional testing we find we have to do in React applications. In many of our projects it’s used within a unit testing framework such as \u003ca href\u003d\"/radar/languages-and-frameworks/jest\"\u003eJest\u003c/a\u003e.\u003c/p\u003e","theta":"315","volume":"2018-05"},{"name":"Kotlin","id":"1077","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"82","display_name":"Kotlin","radius":"75","description":"\u003cp\u003e\u003cstrong\u003eKotlin\u003c/strong\u003e has experienced an \u003ca href\u003d\"http://sogrady-media.redmonk.com/sogrady/files/2018/03/lang.rank_.118.png\"\u003eaccelerated rate of adoption\u003c/a\u003e and rapid growth of tooling support. Some of the reasons behind its popularity are its concise syntax, null safety, ease of transition from Java and interoperability with other JVM-based languages in general, and that it doubles as a great introductory language to functional programming. With JetBrains adding the ability to compile Kotlin to \u003ca href\u003d\"http://kotlinlang.org/docs/reference/native-overview.html\"\u003enative binaries\u003c/a\u003e on multiple platforms, as well as \u003ca href\u003d\"http://kotlinlang.org/docs/reference/js-overview.html\"\u003etranspile to JavaScript\u003c/a\u003e, we believe it has the potential of much wider use by the larger community of mobile and native application developers. Although at the time of writing, some of the tooling such as static and coverage code analysis have yet to mature, given our experience of using Kotlin in many production applications, we believe Kotlin is ready for general adoption.\u003c/p\u003e","theta":"337","volume":"2018-05"},{"name":"Apollo","id":"1239","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"83","display_name":"Apollo","radius":"235","description":"\u003cp\u003eSince it was first introduced in the Radar, we’ve seen a steady adoption of \u003ca href\u003d\"/radar/languages-and-frameworks/graphql\"\u003eGraphQL\u003c/a\u003e, particularly as a remote interface for a \u003ca href\u003d\"/radar/techniques/bff-backend-for-frontends\"\u003eBackend for Frontend (BFF)\u003c/a\u003e. As they gain more experience, our teams have reached consensus on Apollo, a GraphQL client, as the preferred way to access GraphQL data from a \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e application. Although the \u003ca href\u003d\"http://www.apollographql.com/client\"\u003e\u003cstrong\u003eApollo\u003c/strong\u003e\u003c/a\u003e project also provides a server framework and a GraphQL gateway, the Apollo client simplifies the problem of binding UI components to data served by any GraphQL backend. Notably, Apollo is used by Amazon AWS in their recent launch of the new \u003ca href\u003d\"http://aws.amazon.com/appsync/\"\u003eAWS AppSync service\u003c/a\u003e.\u003c/p\u003e","theta":"285","volume":"2018-05"},{"name":"CSS Grid Layout","id":"1166","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"84","display_name":"CSS Grid Layout","radius":"170","description":"\u003cp\u003eCSS is the preferred choice for laying out web pages, even when it did not provide much explicit support for creating layouts. Flexbox helped with simpler, one-dimensional layouts, but developers usually reached for libraries and toolkits for more complex layouts. \u003ca href\u003d\"http://www.w3.org/TR/css-grid-1\"\u003e\u003cstrong\u003eCSS Grid Layout\u003c/strong\u003e\u003c/a\u003e is a two-dimensional grid-based layout system that provides a mechanism to divide available space for layout into columns and rows using a set of predictable sizing behaviors. Grid does not require any libraries and plays well with Flexbox and other CSS display elements. However, since IE11 is only \u003ca href\u003d\"http://caniuse.com/#search\u003dcss%20grid%20layout\"\u003epartially supported\u003c/a\u003e, it ignores users who still depend on a Microsoft browser on Windows 7.\u003c/p\u003e","theta":"300","volume":"2018-05"},{"name":"CSS Modules","id":"1187","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"85","display_name":"CSS Modules","radius":"230","description":"\u003cp\u003eMost large CSS codebases require complex naming schemes to help avoid naming conflicts in the global namespace. \u003ca href\u003d\"http://github.com/css-modules/css-modules\"\u003e\u003cstrong\u003eCSS Modules\u003c/strong\u003e\u003c/a\u003e address these problems by creating a local scope for all class names in a single CSS file. This file is imported to a JavaScript module, where CSS classes are referenced as strings. Then, in the build pipeline (Webpack, Browserify, etc.), the class names are replaced with generated unique strings. This is a significant change in responsibilities. Previously, a human had to manage the global namespace, to avoid class naming conflicts; now that responsibility rests with the build tooling. A small downside we\u0027ve encountered with CSS Modules: functional tests are usually out of the local scope and can therefore not reference classes by the name defined in the CSS file. We recommend using IDs or data attributes instead.\u003c/p\u003e","theta":"315","volume":"2018-05"},{"name":"Hyperledger Composer","id":"1240","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"86","display_name":"Hyperledger Composer","radius":"190","description":"\u003cp\u003eThe \u003ca href\u003d\"/radar/platforms/hyperledger\"\u003eHyperledger\u003c/a\u003e project has grown into a broader collaboration and now contains a series of subprojects. It supports Blockchain implementations for different purposes; for example, \u003ca href\u003d\"http://github.com/hyperledger/burrow\"\u003eBurrow\u003c/a\u003e is dedicated to build a permissioned \u003ca href\u003d\"/radar/platforms/ethereum\"\u003eEthereum\u003c/a\u003e and \u003ca href\u003d\"http://github.com/hyperledger/indy-node\"\u003eIndy\u003c/a\u003e is more focused on digital identity. Among these platforms, \u003ca href\u003d\"http://github.com/hyperledger/fabric\"\u003eFabric\u003c/a\u003e is the most mature one. Most of time when people talk about adopting Hyperledger they are actually thinking about Hyperledger Fabric. However, the programming abstraction of \u003ca href\u003d\"http://hyperledger-fabric.readthedocs.io/en/latest/chaincode.html\"\u003echaincode\u003c/a\u003e is relatively low level given it manipulates the state of the ledger directly. Moreover, it always takes a lot of time to set up infrastructure before writing the first line of blockchain code. \u003ca href\u003d\"http://hyperledger.github.io/composer/latest/\"\u003e\u003cstrong\u003eHyperledger Composer\u003c/strong\u003e\u003c/a\u003e, which builds on top of Fabric, accelerates the process of turning ideas into software. Composer provides DSLs to model business assets, define access control and build a business network. By using Composer you could quickly validate your idea through a browser without setting up any infrastructure. Just remember that the Composer itself isn\u0027t Blockchain — you still need to deploy it on Fabric.\u003c/p\u003e","theta":"330","volume":"2018-05"},{"name":"OpenZeppelin","id":"1238","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"87","display_name":"OpenZeppelin","radius":"190","description":"\u003cp\u003eSecurity is the cornerstone of the blockchain economy. In the last issue of the Radar, we highlighted the importance of testing and auditing smart contracts dependencies. \u003ca href\u003d\"https://openzeppelin.org/\"\u003e\u003cstrong\u003eOpenZeppelin\u003c/strong\u003e\u003c/a\u003e is a framework to help build secure smart contracts in \u003ca href\u003d\"/radar/languages-and-frameworks/solidity\"\u003eSolidity\u003c/a\u003e. The team behind OpenZeppelin summed up a series of \u003ca href\u003d\"https://blog.zeppelin.solutions/onward-with-ethereum-smart-contract-security-97a827e47702\"\u003epitfalls and best practices\u003c/a\u003e around smart contracts\u0027 security and embedded these experiences into the source code. The framework is well reviewed and validated by the open source community. We recommend the use of OpenZeppelin instead of writing your own implementation of the \u003ca href\u003d\"https://github.com/ethereum/EIPs/issues/20\"\u003eERC20\u003c/a\u003e/\u003ca href\u003d\"https://github.com/ethereum/EIPs/issues/721\"\u003eERC721\u003c/a\u003e token. OpenZeppelin is also integrated with \u003ca href\u003d\"/radar/languages-and-frameworks/truffle\"\u003eTruffle\u003c/a\u003e.\u003c/p\u003e","theta":"345","volume":"2018-05"},{"name":"Android Architecture Components","id":"1185","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"88","display_name":"Android Architecture Components","radius":"310","description":"\u003cp\u003eHistorically, Google\u0027s Android documentation examples lacked architecture and structure. This changes with the release of \u003cstrong\u003eAndroid Architecture Components\u003c/strong\u003e , a set of opinionated libraries that help developers create Android applications with better architecture. They address longstanding pain points of Android development: handling lifecycles; pagination; SQLite databases; and data persistence over configuration changes. The libraries don\u0027t need to be used together — you can pick the ones you need most and integrate them into your existing project.\u003c/p\u003e","theta":"275","volume":"2018-05"},{"name":"Atlas and BeeHive","id":"1179","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"89","display_name":"Atlas and BeeHive","radius":"310","description":"\u003cp\u003eA multi-app strategy is really controversial, particularly at a time when fewer and fewer users are downloading new apps. Instead of introducing a new app and struggling with the download numbers, multiteams have to deliver functionality via a single app that is already widely installed, which creates an architectural challenge. \u003cstrong\u003e\u003ca href\u003d\"http://github.com/alibaba/atlas\"\u003eAtlas\u003c/a\u003e and \u003ca href\u003d\"http://github.com/alibaba/BeeHive\"\u003eBeeHive\u003c/a\u003e\u003c/strong\u003e are modularization solutions for Android and iOS apps, respectively. Atlas and BeeHive enable multiteams working on physically isolated modules to reassemble or dynamically load these modules from a facade app. Both are Alibaba open source projects, since Alibaba encountered the same problem of dwindling downloads and single-app architectural challenges.\u003c/p\u003e","theta":"280","volume":"2018-05"},{"name":"Clara rules","id":"1180","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"90","display_name":"Clara rules","radius":"285","description":"\u003cp\u003eOur first rule of thumb in selecting a rules engine is normally: you don\u0027t need a rules engine. We\u0027ve seen too many people tying themselves to a hard-to-test black-box rules engine for spurious reasons, when custom code would have been a better solution. That said, we\u0027ve had success using \u003ca href\u003d\"http://www.clara-rules.org/\"\u003e\u003cstrong\u003eClara rules\u003c/strong\u003e\u003c/a\u003e for scenarios where a rules engine does make sense. We like that it uses simple Clojure code to express and evaluate the rules, which means they are amenable to refactoring, testing and source control. Rather than chasing the illusion that business people should directly manipulate the rules, it drives collaboration between the business experts and developers.\u003c/p\u003e","theta":"285","volume":"2018-05"},{"name":"Flutter","id":"1246","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"91","display_name":"Flutter","radius":"330","description":"\u003cp\u003e\u003ca href\u003d\"http://flutter.io/\"\u003e\u003cstrong\u003eFlutter\u003c/strong\u003e\u003c/a\u003e is a cross-platform framework that enables you to write native mobile apps in \u003ca href\u003d\"/radar/languages-and-frameworks/google-dart\"\u003eDart\u003c/a\u003e. It benefits from Dart and can be compiled into native code and communicates with the target platform without bridge and context switching — something that can cause performance bottlenecks in frameworks such as \u003ca href\u003d\"/radar/languages-and-frameworks/react-native\"\u003eReact Native\u003c/a\u003e or \u003ca href\u003d\"/radar/languages-and-frameworks/weex\"\u003eWeex\u003c/a\u003e. Flutter’s hot-reload feature is impressive and provides superfast visual feedback when editing code. Currently Flutter is still in beta, but we’ll continue keeping an eye on it to see how its ecosystem matures.\u003c/p\u003e","theta":"290","volume":"2018-05"},{"name":"Gobot","id":"1168","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"92","display_name":"Gobot","radius":"335","description":"\u003cp\u003eThe ability to compile the \u003ca href\u003d\"/radar/languages-and-frameworks/go-language\"\u003eGo programming language\u003c/a\u003e to bare metal targets has raised interest among developers in using the language for embedded systems. \u003ca href\u003d\"http://gobot.io/\"\u003e\u003cstrong\u003eGobot\u003c/strong\u003e\u003c/a\u003e is a framework for robotics, physical computing, and the Internet of Things, written in the Go programming language and supporting a variety of platforms. We\u0027ve used the framework for experimental robotic projects where real-time response hasn\u0027t been a requirement, and we’ve created open source \u003ca href\u003d\"http://github.com/HendrikLouw/robocar\"\u003esoftware drivers\u003c/a\u003e with Gobot. Gobot HTTP APIs enable simple hardware integration with mobile devices to create richer applications.\u003c/p\u003e","theta":"295","volume":"2018-05"},{"name":"Hyperapp","id":"1262","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"93","display_name":"Hyperapp","radius":"290","description":"\u003cp\u003eGiven the number of JavaScript application frameworks we’ve featured in the Radar over the years we asked ourselves, do we really need to call out another one? We decided that \u003ca href\u003d\"http://hyperapp.js.org/\"\u003e\u003cstrong\u003eHyperapp\u003c/strong\u003e\u003c/a\u003e is worth a look because of its minimalist approach. It has a very small footprint, less than 1KB, and yet covers all the essential functionality for writing a web application. This is only possible with an elegant design that reduces everything to the absolute minimum, which in turn makes it easier to understand and use the framework. Despite being relatively new, it has attracted a good-size community and we recommend to at least consider it when picking a framework for a new application.\u003c/p\u003e","theta":"300","volume":"2018-05"},{"name":"PyTorch","id":"1172","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"94","display_name":"PyTorch","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"http://pytorch.org/\"\u003e\u003cstrong\u003ePyTorch\u003c/strong\u003e\u003c/a\u003e is a complete rewrite of the \u003ca href\u003d\"http://torch.ch/\"\u003eTorch\u003c/a\u003e machine learning framework from Lua to Python. Although quite new and immature compared to \u003ca href\u003d\"/radar/platforms/tensorflow\"\u003eTensorflow\u003c/a\u003e, programmers find PyTorch much easier to work with. Because of its object-orientation and native Python implementation, models can be expressed more clearly and succinctly and debugged during execution. Although many of these frameworks have emerged recently, PyTorch has the backing of Facebook and broad range of partner organisations, including NVIDIA, which should ensure continuing support for CUDA architectures. ThoughtWorks teams find PyTorch useful for experimenting and developing models but still rely on TensorFlow’s performance for production-scale training and classification.\u003c/p\u003e","theta":"305","volume":"2018-05"},{"name":"Rasa","id":"1249","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"95","display_name":"Rasa","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://rasa.com/\"\u003eRasa\u003c/a\u003e\u003c/strong\u003e is a new entrant in the area of chatbots. Instead of using a simple decision tree it uses neural networks to map intent and internal state to a response. Rasa integrates with natural language processing solutions such as \u003ca href\u003d\"/radar/tools/spacy\"\u003espaCy\u003c/a\u003e; and, unlike other solutions we\u0027ve featured in the Radar, Rasa is \u003ca href\u003d\"http://github.com/RasaHQ\"\u003eopen source software\u003c/a\u003e and can be self-hosted, which makes it a viable solution when ownership of data is of concern. Our experiences with using Rasa Stack for an internal application have been positive.\u003c/p\u003e","theta":"310","volume":"2018-05"},{"name":"Reactor","id":"1243","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"96","display_name":"Reactor","radius":"300","description":"\u003cp\u003e\u003ca href\u003d\"http://projectreactor.io\"\u003e\u003cstrong\u003eReactor\u003c/strong\u003e\u003c/a\u003e is a library for building non-blocking applications on the JVM — version 8 and above — based on the \u003ca href\u003d\"http://www.reactive-streams.org/\"\u003eReactive Streams\u003c/a\u003e specification. Reactive programming emphasizes moving from imperative logic to asynchronous, non-blocking and functional style code, especially when dealing with external resources. Reactor implements the reactive stream specification and provides two publisher APIs — Flux (0 to N elements) and Mono (0 or 1 element) — to effectively model push-based stream processing. Reactor project is well suited for microservices architecture and offers back pressure–ready network engines for HTTP, WebSockets, TCP and UDP traffic.\u003c/p\u003e","theta":"315","volume":"2018-05"},{"name":"RIBs","id":"1241","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"97","display_name":"RIBs","radius":"320","description":"\u003cp\u003e\u003ca href\u003d\"http://github.com/uber/RIBs\"\u003e\u003cstrong\u003eRIBs\u003c/strong\u003e\u003c/a\u003e — which is short for router, interactor and builder — is a cross-platform architecture mobile framework from Uber. The key idea of RIBs is to decouple business logic from the view tree, and thus ensure the app is driven by business logic. By applying consistent architecture patterns across native Android and iOS, RIBs provides clear statement management and good testability. We advise putting business logic in the back-end service rather than leak it into the view, so if you do have a complicated mobile application, RIBs can help manage this complexity.\u003c/p\u003e","theta":"320","volume":"2018-05"},{"name":"Solidity","id":"1183","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"98","display_name":"Solidity","radius":"310","description":"\u003cp\u003eProgramming for smart contracts requires a more expressive language than a \u003ca href\u003d\"http://en.bitcoin.it/wiki/Script\"\u003escripting system for transactions\u003c/a\u003e. \u003ca href\u003d\"http://github.com/ethereum/solidity\"\u003e\u003cstrong\u003eSolidity\u003c/strong\u003e\u003c/a\u003e is the most popular among the new programming languages designed for smart contracts. Solidity is a contract-oriented, statically typed language whose syntax is similar to JavaScript. It provides abstractions for writing self-enforcing business logic in smart contracts. The toolchain around Solidity is growing fast. Nowadays, Solidity is the primary choice on the \u003ca href\u003d\"/radar/platforms/ethereum\"\u003eEthereum\u003c/a\u003e platform. Given the immutable nature of deployed smart contracts, it should go without saying that rigorous testing and audit of dependencies is vital.\u003c/p\u003e","theta":"325","volume":"2018-05"},{"name":"SwiftNIO","id":"1245","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"99","display_name":"SwiftNIO","radius":"320","description":"\u003cp\u003eWe’re in favor of asynchronous and \u003ca href\u003d\"/radar/languages-and-frameworks/reactivex\"\u003ereactive styles of programming\u003c/a\u003e especially for network I/O-bound distributed systems. Reactive libraries often sit on top of a lower level nonblocking communication framework such as \u003ca href\u003d\"http://netty.io/\"\u003eNetty\u003c/a\u003e. Recently \u003ca href\u003d\"http://github.com/apple/swift-nio\"\u003e\u003cstrong\u003eSwiftNIO\u003c/strong\u003e\u003c/a\u003e, an open source nonblocking networking framework from Apple, has grabbed our attention. SwiftNIO is similar to Netty but written in Swift. It’s currently supported on MacOS and Ubuntu and implements HTTP as a higher-level protocol. We’re excited to see the usage of this framework and integration of it into higher-level application frameworks and other protocols.\u003c/p\u003e","theta":"330","volume":"2018-05"},{"name":"Tensorflow Eager Execution","id":"1248","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"100","display_name":"Tensorflow Eager Execution","radius":"290","description":"\u003cp\u003eIn the last issue we featured \u003ca href\u003d\"/radar/languages-and-frameworks/pytorch\"\u003ePyTorch\u003c/a\u003e, a deep-learning modeling framework that allows an imperative programming style. Now \u003cstrong\u003e\u003ca href\u003d\"http://www.tensorflow.org/programmers_guide/eager\"\u003eTensorFlow Eager Execution\u003c/a\u003e\u003c/strong\u003e provides this imperative style in \u003ca href\u003d\"/radar/platforms/tensorflow\"\u003eTensorFlow\u003c/a\u003e by enabling execution of modeling statements outside of the context of a session. This improvement could provide the ease of debugging and finer-grained model control of PyTorch with the widespread popularity and performance of TensorFlow models. The feature is still quite new so we’re anxious to see how it performs and how it’ll be received by the TensorFlow community.\u003c/p\u003e","theta":"335","volume":"2018-05"},{"name":"TensorFlow Lite","id":"1244","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"101","display_name":"TensorFlow Lite","radius":"290","description":"\u003cp\u003e\u003ca href\u003d\"http://www.tensorflow.org/mobile/tflite/\"\u003e\u003cstrong\u003eTensorFlow Lite\u003c/strong\u003e\u003c/a\u003e is the designated successor of \u003ca href\u003d\"/radar/languages-and-frameworks/tensorflow-mobile\"\u003eTensorFlow Mobile\u003c/a\u003e, which we mentioned in our previous Radar. Like Mobile it is a lightweight solution tuned and optimized for mobile devices (Android and iOS). We expect the standard use case to be the deployment of pretrained models into mobile apps but TensorFlow Lite also supports on-device learning which opens further areas of application.\u003c/p\u003e","theta":"340","volume":"2018-05"},{"name":"troposphere","id":"1242","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"102","display_name":"troposphere","radius":"290","description":"\u003cp\u003eWe’re trying out \u003ca href\u003d\"http://github.com/cloudtools/troposphere\"\u003e\u003cstrong\u003etroposphere\u003c/strong\u003e\u003c/a\u003e as a way of defining the \u003ca href\u003d\"/radar/tools/infrastructure-as-code\"\u003einfrastructure as code\u003c/a\u003e on AWS for our projects where \u003ca href\u003d\"http://aws.amazon.com/cloudformation/\"\u003eAWS\u003c/a\u003e \u003ca href\u003d\"http://aws.amazon.com/cloudformation/\"\u003eCloudFormation\u003c/a\u003e is used instead of \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e. troposphere is a Python library that allows us to write Python code to generate CloudFormation JSON descriptions. What we like about troposphere is that it facilitates catching JSON errors early, applying type checking, and unit testing and DRY composition of AWS resources.\u003c/p\u003e","theta":"345","volume":"2018-05"},{"name":"Truffle","id":"1181","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"103","display_name":"Truffle","radius":"335","description":"\u003cp\u003e\u003ca href\u003d\"http://truffleframework.com/\"\u003e\u003cstrong\u003eTruffle\u003c/strong\u003e\u003c/a\u003e is a development framework that brings a modern web development experience to the \u003ca href\u003d\"/radar/platforms/ethereum\"\u003eEthereum\u003c/a\u003e platform. It takes over the job of smart contract compiling, library linking and deployment, as well as dealing with artifacts in different blockchain networks. One of the reasons we love Truffle is that it encourages people to write tests for their smart contracts. You need to take tests really seriously as smart contract programming is often related to money. With its built-in testing framework and integration with \u003ca href\u003d\"http://github.com/ethereumjs/testrpc\"\u003eTestRPC\u003c/a\u003e, Truffle makes it possible to write the contract in a TDD way. We expect to see more technologies similar to Truffle to promote continuous integration in the blockchain area.\u003c/p\u003e","theta":"350","volume":"2018-05"},{"name":"WebAssembly","id":"1250","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"104","display_name":"WebAssembly","radius":"290","description":"\u003cp\u003e\u003ca href\u003d\"http://webassembly.org/\"\u003e\u003cstrong\u003eWebAssembly\u003c/strong\u003e\u003c/a\u003e is a big step forward in the capabilities of the browser as a code execution environment. Supported by all major browsers and backward compatible, it\u0027s a binary compilation format designed to run in the browser at near native speeds. It opens up the range of languages you can use to write front-end functionality, with early focus on C, C++ and Rust, and it\u0027s also an LLVM compilation target. When run in the sandbox, it can interact with JavaScript and shares the same permissions and security model. When used with \u003ca href\u003d\"http://hacks.mozilla.org/2018/01/making-webassembly-even-faster-firefoxs-new-streaming-and-tiering-compiler/\"\u003eFirefox’s new streaming compiler\u003c/a\u003e, it also results in faster page initialization. Although it\u0027s still early days, this W3C standard is definitely one to start exploring.\u003c/p\u003e","theta":"355","volume":"2018-05"}],"date":"2018-05"},{"blips":[{"name":"Event Storming","id":"883","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"1","display_name":"Event Storming","radius":"90","description":"\u003cp\u003eWhen organizations move toward \u003ca href\u003d\"https://martinfowler.com/articles/microservices.html\"\u003emicroservices\u003c/a\u003e, one of the main drivers is the hope for faster time to market. However, this aspiration only tends to be realized when services (and their supporting teams) are cleanly sliced along long-lived business domain boundaries. Otherwise meaningful features will naturally require tight coordination between multiple teams and services, introducing natural friction in competing roadmap prioritization. The solution to this problem is good domain modeling, and \u003cstrong\u003eevent storming\u003c/strong\u003e has rapidly become one of our favorite methods for rapidly identifying the key concepts in a problem space and aligning a variety of stakeholders in the best way to slice potential solutions.\u003c/p\u003e","theta":"135","volume":"2018-11"},{"name":"1% canary","id":"1302","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"2","display_name":"1% canary","radius":"240","description":"\u003cp\u003eFast feedback is one of our \u003ca href\u003d\"https://www.thoughtworks.com/insights/blog/what-are-our-core-values-and-practices-building-software\"\u003ecore values\u003c/a\u003e for building software. For many years, we\u0027ve used the \u003ca href\u003d\"https://martinfowler.com/bliki/CanaryRelease.html\"\u003ecanary release\u003c/a\u003e approach to encourage early feedback on new software versions, while reducing the risk through incremental rollout to selected users. One of the questions regarding this technique is how to segment users. Canary releases to a very small segment (say 1%) of users can be a catalyst for change. While starting with a very small segment of users enables teams to get comfortable with the technique, capturing fast user feedback enables diverse teams to observe the impact of new releases and learn and adjust course as necessary—a priceless change in engineering culture. We call this, the mighty \u003cstrong\u003e1% canary\u003c/strong\u003e.\u003c/p\u003e","theta":"173","volume":"2018-11"},{"name":"Bounded Buy","id":"1317","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"3","display_name":"Bounded Buy","radius":"170","description":"\u003cp\u003eMost organizations that don\u0027t have the resources to custom-build their software will select out-of-the-box or SaaS solutions to meet their requirements. All too often, however, these solutions tend to aggressively expand their scope to entangle themselves into every part of your business. This blurs integration boundaries and makes change less predictable and slow. To mitigate this risk, we recommend that organizations develop a clear target capability model and then employ a strategy we call \u003cstrong\u003eBounded Buy\u003c/strong\u003e —that is, only select vendor products that are modular and decoupled and can be contained within the \u003ca href\u003d\"https://martinfowler.com/bliki/BoundedContext.html\"\u003eBounded Context\u003c/a\u003e of a single business capability. This modularity and independent deliverability should be included in the acceptance criteria for a \u003ca href\u003d\"https://www.slideshare.net/tgriffo/agile-australia-2017-hypothesisdriven-cots-software-selection-tiago-griffo\"\u003evendor selection process\u003c/a\u003e.\u003c/p\u003e","theta":"165","volume":"2018-11"},{"name":"Crypto shredding","id":"1300","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"4","display_name":"Crypto shredding","radius":"190","description":"\u003cp\u003eMaintaining proper control over sensitive data is difficult, especially when—for backup and recovery purposes—data is copied outside of a master system of record. \u003cstrong\u003eCrypto shredding\u003c/strong\u003e is the practice of rendering sensitive data unreadable by deliberately overwriting or deleting encryption keys used to secure that data. For example, an entire table of customer personal details could be encrypted using random keys for each record, with a different table storing the keys. If a customer exercised their \"right to be forgotten,\" we can simply delete the appropriate key, effectively \"shredding\" the encrypted data. This technique can be useful where we\u0027re confident of maintaining appropriate control of a smaller set of encryption keys but less confident about control over a larger data set.\u003c/p\u003e","theta":"158","volume":"2018-11"},{"name":"Four key metrics","id":"1298","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"5","display_name":"Four key metrics","radius":"180","description":"\u003cp\u003eThe \u003ca href\u003d\"https://devops-research.com/research.html\"\u003eState of DevOps\u003c/a\u003e report, first published in 2014, states that high-performing teams create high-performing organizations. Recently, the team behind the report released \u003ca href\u003d\"https://itrevolution.com/book/accelerate/\"\u003eAccelerate\u003c/a\u003e, which describes the scientific method they\u0027ve used in the report. A key takeaway of both are the \u003cstrong\u003efour key metrics\u003c/strong\u003e to support software delivery performance: lead time, deployment frequency, mean time to restore (MTTR), and change fail percentage. As a consultancy that has helped many organizations transform, these metrics have come up time and time again as a way to help organizations determine whether they\u0027re improving the overall performance. Each metric creates a virtuous cycle and focuses the teams on continuous improvement: to reduce lead time, you reduce wasteful activities which, in turn, lets you deploy more frequently; deployment frequency forces your teams to improve their practices and automation; your speed to recover from failure is improved by better practices, automation and monitoring which reduces the frequency of failures.\u003c/p\u003e","theta":"150","volume":"2018-11"},{"name":"Multi-account cloud setup","id":"1299","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"6","display_name":"Multi-account cloud setup","radius":"210","description":"\u003cp\u003eOn-demand self-service is a key characteristic (and benefit) of cloud computing. When large-scale service landscapes are deployed using a single account, rules and processes around usage of that account become necessary, often involving approval steps that increase turnaround time. A better approach is a \u003cstrong\u003emulti-account cloud setup\u003c/strong\u003e where several accounts are used, in the extreme one account per team. This does add overhead in other places, for example, ensuring shared billing, enabling communication between VPCs and managing the relationship with the cloud provider. However, it often accelerates development and it usually improves security, because single-service accounts are easier to audit and, in the case of a breach, the impact is greatly reduced. Having multiple accounts also reduces stickiness, because an account provides a good boundary for services that can be moved en bloc to another cloud provider.\u003c/p\u003e","theta":"143","volume":"2018-11"},{"name":"Observability as code","id":"1301","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"7","display_name":"Observability as code","radius":"240","description":"\u003cp\u003eThe observability is an integral part of operating a distributed and \u003ca href\u003d\"https://martinfowler.com/articles/microservices.html\"\u003emicroservices architecture\u003c/a\u003e. We rely on different system outputs such as distributed tracing, aggregate logs and metrics to infer the internal state of the distributed components, diagnose where the problems are and get to the root cause. An important aspect of an observability ecosystem is monitoring—visualizing and analyzing the system\u0027s output—and alerting when unexpected conditions are detected. Traditionally, configuration of monitoring dashboards and setting up alerts is done through GUI-based point-and-click systems. This approach leads to nonrepeatable dashboard configurations, no ability to continuously test and adjust alerts to avoid alert fatigue or missing out on important alerts, and drift from organizational best practices. We highly recommend treating your observability ecosystem configurations as code, called \u003cstrong\u003eobservability as code\u003c/strong\u003e , and adopt \u003ca href\u003d\"/radar/tools/infrastructure-as-code\"\u003einfrastructure as code\u003c/a\u003e for your monitoring and alerting infrastructure. Choose observability products that support configuration through version-controlled code and execution of APIs or commands via infrastructure CD pipelines. Observability as code is an often-forgotten aspect of infrastructure as code and, we believe, crucial enough to be called out.\u003c/p\u003e","theta":"135","volume":"2018-11"},{"name":"Risk-commensurate vendor strategy","id":"1345","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"8","display_name":"Risk-commensurate vendor strategy","radius":"230","description":"\u003cp\u003eOften, in an effort to outsource risk to their suppliers, businesses look for \"one throat to choke\" on their most critical and risky system implementations. Unfortunately, this gives them fewer solution choices and less flexibility. Instead, businesses should look to maintain the greatest vendor independence where the business risk exposure is highest. We see a new \u003cstrong\u003erisk-commensurate vendor strategy\u003c/strong\u003e emerging that encourages investment to maintain vendor independence for highly critical business systems. Less critical business functions can take advantage of the streamlined delivery of a vendor-native solution because it allows them to absorb more easily the impact of losing that vendor. This trade-off has become apparent as the major cloud providers have expanded their range of service offerings. For example, using AWS Secret Management Service can speed up initial development and has the benefit of ecosystem integration, but it will also add more inertia if you ever need to migrate to a different cloud provider than it would if you had implemented, for example, \u003ca href\u003d\"/radar/tools/hashicorp-vault\"\u003eVault\u003c/a\u003e.\u003c/p\u003e","theta":"128","volume":"2018-11"},{"name":"Run cost as architecture fitness function","id":"1338","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"9","display_name":"Run cost as architecture fitness function","radius":"190","description":"\u003cp\u003eWe still see teams who aren\u0027t tracking the cost of running their applications as closely as they should as their software architecture or usage evolves. This is particularly true when they\u0027re using \u003ca href\u003d\"/radar/techniques/serverless-architecture\"\u003eserverless\u003c/a\u003e, which developers assume will provide lower costs since you\u0027re not paying for unused server cycles. However, the major cloud providers are pretty savvy at setting their pricing models, and heavily used serverless functions, although very useful for rapid iteration, can get expensive quickly when compared with dedicated cloud (or on-premise) servers. We advise teams to frame a system\u0027s \u003cstrong\u003erun cost as architecture fitness function\u003c/strong\u003e , which means: track the cost of running your services against the value delivered; when you see deviations from what was expected or acceptable, have a discussion about whether it\u0027s time to evolve your architecture.\u003c/p\u003e","theta":"120","volume":"2018-11"},{"name":"Secrets as a service","id":"1303","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"10","display_name":"Secrets as a service","radius":"170","description":"\u003cp\u003eWe\u0027ve long cautioned people about the temptation to check secrets into their source code repositories. Previously, we\u0027ve recommended \u003ca href\u003d\"/radar/techniques/decoupling-secret-management-from-source-code\"\u003edecoupling secret management from source code\u003c/a\u003e. However, now we\u0027re seeing a set of good tools emerge that offer \u003cstrong\u003esecrets as a service\u003c/strong\u003e. With this approach, rather than hardwiring secrets or configuring them as part of the environment, applications retrieve them from a separate process. Tools such as \u003ca href\u003d\"/radar/tools/hashicorp-vault\"\u003eVault\u003c/a\u003e by HashiCorp let you manage secrets separately from the application and enforce policies such as frequent rotation externally.\u003c/p\u003e","theta":"113","volume":"2018-11"},{"name":"Security Chaos Engineering","id":"1215","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"11","display_name":"Security Chaos Engineering","radius":"230","description":"\u003cp\u003eAlthough we\u0027ve had mostly new blips in this edition of the Radar, we think it\u0027s worth continuing to call out the usefulness of \u003cstrong\u003eSecurity Chaos Engineering\u003c/strong\u003e. We\u0027ve moved it to Trial because the teams using this technique are confident that the security policies they have in place are robust enough to handle common security failure modes. Still, proceed with caution when using this technique—we don\u0027t want our teams to become desensitized to these issues.\u003c/p\u003e","theta":"105","volume":"2018-11"},{"name":"Versioning data for reproducible analytics","id":"1314","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"12","display_name":"Versioning data for reproducible analytics","radius":"190","description":"\u003cp\u003eWhen it comes to large-scale data analysis or machine intelligence problems, being able to reproduce different versions of analysis done on different data sets and parameters is immensely valuable. To achieve reproducible analysis, both the data and the model (including algorithm choice, parameters and hyperparameters) need to be version controlled. \u003cstrong\u003eVersioning data for reproducible analytics\u003c/strong\u003e is a relatively trickier problem than versioning models because of the data size. Tools such as \u003ca href\u003d\"https://dvc.org/\"\u003eDVC\u003c/a\u003e help in versioning data by allowing users to commit and push data files to a remote cloud storage bucket using a git-like workflow. This makes it easy for collaborators to pull a specific version of data to reproduce an analysis.\u003c/p\u003e","theta":"98","volume":"2018-11"},{"name":"Chaos Katas","id":"1309","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"13","display_name":"Chaos Katas","radius":"310","description":"\u003cp\u003e\u003cstrong\u003eChaos Katas\u003c/strong\u003e is a technique that our teams have developed to train and upskill infrastructure and platform engineers. It combines \u003ca href\u003d\"/radar/techniques/chaos-engineering\"\u003eChaos Engineering\u003c/a\u003e techniques—that is, creating failures and outages in a controlled environment—with the systematic teaching and training approach of \u003ca href\u003d\"https://en.wikipedia.org/wiki/Kata\"\u003eKata\u003c/a\u003e. Here, Kata refers to code patterns that trigger controlled failures, allowing engineers to discover the problem, recover from the failure, run postmortem and find the root cause. Repeated execution of Katas helps engineers to internalize their new skills.\u003c/p\u003e","theta":"168","volume":"2018-11"},{"name":"Distroless Docker images","id":"1330","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"14","display_name":"Distroless Docker images","radius":"300","description":"\u003cp\u003eWhen building \u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e images for our applications, we\u0027re often concerned with two things: the security and the size of the image. Traditionally, we\u0027ve used \u003ca href\u003d\"/radar/techniques/container-security-scanning\"\u003econtainer security scanning\u003c/a\u003e tools to detect and patch \u003ca href\u003d\"https://cve.mitre.org/\"\u003ecommon vulnerabilities and exposures\u003c/a\u003e and small distributions such as \u003ca href\u003d\"https://alpinelinux.org/\"\u003eAlpine Linux\u003c/a\u003e to address the image size and distribution performance. In this Radar, we\u0027re excited about addressing the security and size of containers with a new technique called \u003cstrong\u003edistroless docker images\u003c/strong\u003e , pioneered by Google. With this technique, the footprint of the image is reduced to the application, its resources and language runtime dependencies, without operating system distribution. The advantages of this technique include reduced noise of security scanners, smaller security attack surface, reduced overhead of patching vulnerabilities and even smaller image size for higher performance. Google has published a set of \u003ca href\u003d\"https://github.com/GoogleContainerTools/distroless\"\u003edistroless container images\u003c/a\u003e for different languages. You can create distroless application images using the Google build tool \u003ca href\u003d\"https://bazel.build/\"\u003eBazel\u003c/a\u003e, which has rules for creating distroless containers or simply use multistage Dockerfiles. Note that distroless containers by default don\u0027t have a shell for debugging. However, you can easily find debug versions of distroless containers online, including a \u003ca href\u003d\"https://busybox.net/downloads/BusyBox.html\"\u003ebusybox shell\u003c/a\u003e.\u003c/p\u003e","theta":"155","volume":"2018-11"},{"name":"Incremental delivery with COTS","id":"1308","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"15","display_name":"Incremental delivery with COTS","radius":"290","description":"\u003cp\u003eAt ThoughtWorks, as early adopters and leaders in the agile space, we\u0027ve been proponents of the practice of incremental delivery. We\u0027ve also advised many clients to look at off-the-shelf software through a \"Can this be released incrementally?\" lens. This has often been difficult because of the big-bang approach of most vendors which usually involves migrating large amounts of data. Recently, however, we\u0027ve also had success using \u003cstrong\u003eincremental delivery with COTS\u003c/strong\u003e (commercial off-the-shelf), launching specific business processes incrementally to smaller subsets of users. We recommend you assess whether you can apply this practice to the vendor software of your choice, to help reduce the risks involved in big-bang deliveries.\u003c/p\u003e","theta":"142","volume":"2018-11"},{"name":"Infrastructure configuration scanner","id":"1231","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"16","display_name":"Infrastructure configuration scanner","radius":"285","description":"\u003cp\u003eFor some time now we\u0027ve recommended increased delivery team ownership of their entire stack, including infrastructure. This means increased responsibility in the delivery team itself for configuring infrastructure in a safe, secure, and compliant way. When adopting cloud strategies, most organizations default to a tightly locked-down and centrally managed configuration to reduce risk, but this also creates substantial productivity bottlenecks. An alternative approach is to allow teams to manage their own configuration, and use an \u003cstrong\u003eInfrastructure configuration scanner\u003c/strong\u003e to ensure the configuration is set in a safe and secure way. \u003ca href\u003d\"http://github.com/iagcl/watchmen\"\u003eWatchmen\u003c/a\u003e is an interesting tool, built to provide rule-driven assurance of AWS account configurations that are owned and operated independently by delivery teams. \u003ca href\u003d\"/radar/tools/scout2\"\u003eScout2\u003c/a\u003e is another example of configuration scanning to support secure compliance.\u003c/p\u003e","theta":"129","volume":"2018-11"},{"name":"Pre-commit downstream build checks","id":"1307","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"17","display_name":"Pre-commit downstream build checks","radius":"300","description":"\u003cp\u003eIn more complex architectures and deployments, it may not be immediately obvious that a build that depends on the code currently being checked in is broken. Developers trying to fix a broken build could find themselves working against a moving target, as the build is continually triggered by upstream dependencies. \u003cstrong\u003ePre-commit downstream build checks\u003c/strong\u003e is a very simple technique: have a pre-commit or pre-push script check the status of these downstream builds and alert the developer beforehand that a build is broken.\u003c/p\u003e","theta":"116","volume":"2018-11"},{"name":"Service mesh","id":"1138","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"18","display_name":"Service mesh","radius":"290","description":"\u003cp\u003eAs large organizations transition to more autonomous teams owning and operating their own microservices, how can they ensure the necessary consistency and compatibility between those services without relying on a centralized hosting infrastructure? To work together efficiently, even autonomous microservices need to align with some organizational standards. A \u003cstrong\u003eservice mesh\u003c/strong\u003e offers consistent discovery, security, tracing, monitoring and failure handling without the need for a shared asset such as an API gateway or ESB. A typical implementation involves lightweight reverse-proxy processes deployed alongside each service process, perhaps in a separate container. These proxies communicate with service registries, identity providers, log aggregators and other services. Service interoperability and observability are gained through a shared implementation of this proxy but not a shared runtime instance. We\u0027ve advocated for a decentralized approach to microservices management for some time and are happy to see this consistent pattern emerge. Open source projects such as \u003ca href\u003d\"http://linkerd.io/\"\u003eLinkerd\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/istio\"\u003eIstio\u003c/a\u003e will continue to mature and make service meshes even easier to implement.\u003c/p\u003e","theta":"103","volume":"2018-11"},{"name":"\"Handcranking\" of Hadoop clusters using config management tools","id":"1304","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"19","display_name":"\"Handcranking\" of Hadoop clusters using config management tools","radius":"375","description":"\u003cp\u003eWhen organizations choose a \u003ca href\u003d\"https://hadoop.apache.org/\"\u003evanilla Hadoop\u003c/a\u003e or \u003ca href\u003d\"https://spark.apache.org/\"\u003eSpark\u003c/a\u003e distribution instead of one of the vendor distributions, they have to decide how they want to provision and manage the cluster. Occasionally, we see \u003cstrong\u003e\"handcranking\" of Hadoop clusters using config management tools\u003c/strong\u003e such as \u003ca href\u003d\"https://www.ansible.com/\"\u003eAnsible\u003c/a\u003e, \u003ca href\u003d\"https://www.chef.io/\"\u003eChef\u003c/a\u003e and others. Although these tools are great at provisioning immutable infrastructure components, they\u0027re not very useful when you have to manage stateful systems and can often lead to significant effort trying to manage and evolve clusters using these tools. We instead recommend using tools such as \u003ca href\u003d\"https://ambari.apache.org/\"\u003eAmbari\u003c/a\u003e to provision and manage your stateful Hadoop or Spark clusters.\u003c/p\u003e","theta":"169","volume":"2018-11"},{"name":"Generic cloud usage","id":"1217","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"20","display_name":"Generic cloud usage","radius":"375","description":"\u003cp\u003eThe major cloud providers have become increasingly competitive in their pricing and the rapid pace of releasing new features. This leaves consumers in a difficult place when choosing and committing to a provider. Increasingly, we\u0027re seeing organizations prepare to use \"any cloud\" and to avoid vendor lock-in at all costs. This, of course, leads to \u003cstrong\u003egeneric cloud usage\u003c/strong\u003e. We see organizations limiting their use of the cloud to only those features common across all cloud providers—thereby missing out on the providers\u0027 unique benefits. We see organizations making large investments in home-grown abstraction layers that are too complex to build and too costly to maintain to stay cloud agnostic. The problem of lock-in is real. We recommend approaching this problem with a multicloud strategy that evaluates the migration cost and effort of capabilities from one cloud to another, against the benefits of using cloud-specific features. We recommend increasing the portability of the workloads by shipping the applications as widely adopted \u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e containers: use open source security and identity protocols to easily migrate the identity of the workloads, a \u003ca href\u003d\"/radar/techniques/risk-commensurate-vendor-strategy\"\u003erisk-commensurate vendor strategy\u003c/a\u003e to maintain cloud independence only where necessary and \u003ca href\u003d\"/radar/techniques/polycloud\"\u003ePolycloud\u003c/a\u003e to mix and match services from different providers where it makes sense. In short, shift your approach from a generic cloud usage to a sensible multicloud strategy.\u003c/p\u003e","theta":"158","volume":"2018-11"},{"name":"Layered microservices architecture","id":"1312","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"21","display_name":"Layered microservices architecture","radius":"375","description":"\u003cp\u003eA defining characteristic of a \u003ca href\u003d\"https://martinfowler.com/articles/microservices.html\"\u003emicroservices architecture\u003c/a\u003e is that system components and services are organized around business capabilities. Regardless of size, microservices encapsulate a meaningful grouping of functionality and information to allow for the independent delivery of business value. This is in contrast to earlier approaches in service architecture which organized services according to technical characteristics. We\u0027ve observed a number of organizations who\u0027ve adopted a \u003cstrong\u003elayered microservices architecture\u003c/strong\u003e , which in some ways is a contradiction in terms. These organizations have fallen back to arranging services primarily according to a technical role, for example, experience APIs, process APIs or system APIs. It\u0027s too easy for technology teams to be assigned by layer, so delivering any valuable business change requires slow and expensive coordination between multiple teams. We caution against the effects of this layering and recommend arranging services and teams primarily according to business capability.\u003c/p\u003e","theta":"147","volume":"2018-11"},{"name":"Master data management","id":"1341","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"22","display_name":"Master data management","radius":"375","description":"\u003cp\u003e\u003cstrong\u003eMaster data management\u003c/strong\u003e (MDM) is a classic example of the enterprise \"silver bullet\" solution: it promises to solve an apparently related class of problems in one go. Through creating a centralized single point of change, coordination, test and deployment, MDM solutions negatively impact an organization\u0027s ability to respond to business change. Implementations tend to be long and complex, as organizations try to capture and map all \"master\" data into the MDM while integrating the MDM solution into all consuming or producing systems.\u003c/p\u003e","theta":"135","volume":"2018-11"},{"name":"Microservice envy","id":"791","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"23","display_name":"Microservice envy","radius":"365","description":"\u003cp\u003e\u003ca href\u003d\"https://martinfowler.com/articles/microservices.html\"\u003eMicroservices\u003c/a\u003e has emerged as a leading architectural technique in modern cloud-based systems, but we still think teams should proceed carefully when making this choice. \u003cstrong\u003eMicroservice envy\u003c/strong\u003e tempts teams to complicate their architecture by having lots of services simply because it\u0027s a fashionable architecture choice. Platforms such as \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e make it much easier to deploy complex sets of microservices, and vendors are pushing their solutions to managing microservices, potentially leading teams further down this path. It\u0027s important to remember that microservices trade development complexity for operational complexity and require a solid foundation of automated testing, continuous delivery and DevOps culture.\u003c/p\u003e","theta":"124","volume":"2018-11"},{"name":"Request-response events in user-facing workflows","id":"1313","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"24","display_name":"Request-response events in user-facing workflows","radius":"375","description":"\u003cp\u003eOn a number of occasions we have seen system designs that use \u003cstrong\u003erequest-response events in user-facing workflows\u003c/strong\u003e. In these cases, the UI is blocked or the user has to wait for a new page to load until a corresponding response message to a request message is received. The main reasons cited for designs like this are performance or a unified approach to communication between backends for synchronous and asynchronous use cases. We feel that the increased complexity—in development, testing and operations—far outweighs the benefit of having a unified approach, and we strongly suggest to use synchronous HTTP requests when synchronous communication between backend services is needed. When implemented well, communication using HTTP rarely is a bottleneck in a distributed system.\u003c/p\u003e","theta":"113","volume":"2018-11"},{"name":"RPA","id":"1310","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"25","display_name":"RPA","radius":"375","description":"\u003cp\u003eRobotic process automation ( \u003cstrong\u003eRPA\u003c/strong\u003e ) is a key part of many digital transformation initiatives, as it promises to deliver cost savings without having to modernize the underlying architecture and systems. The problem with this approach of focusing only on automating business processes, without addressing the underlying software systems or capabilities, is that this can make it even harder to change the underlying systems by introducing additional coupling. This makes any future attempts to address the legacy IT landscape even more difficult. Very few systems can afford to ignore change and hence RPA efforts need to be coupled with appropriate legacy modernization strategies.\u003c/p\u003e","theta":"102","volume":"2018-11"},{"name":"Apache Atlas","id":"1316","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"26","display_name":"Apache Atlas","radius":"250","description":"\u003cp\u003eWith the growing and diverse data needs of enterprises comes a growing need for metadata management. \u003ca href\u003d\"https://atlas.apache.org/\"\u003e\u003cstrong\u003eApache Atlas\u003c/strong\u003e\u003c/a\u003e is a metadata management framework that fits the data governance needs of enterprises. Atlas provides capabilities to model types for metadata, classify data assets, track the data lineage and enable data discovery. However, when building a metadata management platform, we need to be careful not to repeat the mistakes of \u003ca href\u003d\"/radar/techniques/master-data-management\"\u003emaster data management\u003c/a\u003e.\u003c/p\u003e","theta":"191","volume":"2018-11"},{"name":"AWS","id":"9022","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"27","display_name":"AWS","radius":"160","description":"\u003cp\u003eWe first placed \u003cstrong\u003eAWS\u003c/strong\u003e in Adopt seven years ago, and the breadth, depth and reliability of its services have improved in leaps and bounds since then. However, we\u0027re now moving AWS back into Trial, not because of any deficiencies in its offering, but because its competitors, \u003ca href\u003d\"/radar/platforms/google-cloud-platform\"\u003eGCP\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/azure\"\u003eAzure\u003c/a\u003e, have matured considerably and selecting a cloud provider has become increasingly complex. We reserve Adopt for when we see a clear winner in a field. For many years, AWS was the default choice, but we now feel that organizations should make a balanced selection across cloud providers that takes into account their geographic and regulatory footprint, their strategic alignment (or lack thereof) with the providers, and, of course, the fit between their most important needs and the cloud providers\u0027 differentiating products.\u003c/p\u003e","theta":"202","volume":"2018-11"},{"name":"Azure","id":"473","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"28","display_name":"Azure","radius":"160","description":"\u003cp\u003eMicrosoft has steadily improved \u003ca href\u003d\"http://azure.microsoft.com\"\u003e\u003cstrong\u003eAzure\u003c/strong\u003e\u003c/a\u003e and today not much separates the core cloud experience provided by the major cloud providers—Amazon, Google and Microsoft. The cloud providers seem to agree and seek to differentiate themselves in other areas such as features, services and cost structure. Microsoft is the provider who shows real interest in the legal requirements of European companies. They’ve a nuanced and plausible strategy, including unique offerings such as \u003ca href\u003d\"http://azure.microsoft.com/en-us/global-infrastructure/germany/\"\u003eAzure Germany\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/azure-stack\"\u003eAzure Stack\u003c/a\u003e, which gives some certainty to European companies in anticipation of the \u003ca href\u003d\"http://www.thoughtworks.com/insights/blog/gdpr-it-s-time-rethink-your-approach-privacy\"\u003eGDPR\u003c/a\u003e and possible legislative changes in the United States.\u003c/p\u003e","theta":"213","volume":"2018-11"},{"name":"Contentful","id":"1254","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"29","display_name":"Contentful","radius":"210","description":"\u003cp\u003eHeadless content management systems (CMSes) are becoming a common component of digital platforms. \u003ca href\u003d\"http://www.contentful.com/\"\u003e\u003cstrong\u003eContentful\u003c/strong\u003e\u003c/a\u003e is a modern headless CMS that our teams have successfully integrated into their development workflows. We particularly like its API-first approach and implementing \u003ca href\u003d\"http://www.contentful.com/r/knowledgebase/cms-as-code/\"\u003eCMS as code\u003c/a\u003e. It supports powerful content modeling primitives as code and content model evolution scripts, which allow treating it as other data store schemas and applying \u003ca href\u003d\"http://martinfowler.com/articles/evodb.html\"\u003eevolutionary database design\u003c/a\u003e practices to CMS development. Other notable features that we\u0027ve liked include inclusion of two CDNs to deliver media assets and JSON documents, good support for localization and the ability—albeit with some effort—to integrate with \u003ca href\u003d\"/radar/platforms/auth0\"\u003eAuth0\u003c/a\u003e.\u003c/p\u003e","theta":"225","volume":"2018-11"},{"name":"Google Cloud Platform","id":"1192","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"30","display_name":"Google Cloud Platform","radius":"160","description":"\u003cp\u003eAs \u003ca href\u003d\"http://cloud.google.com/free/ce1/\"\u003e\u003cstrong\u003eGoogle Cloud Platform\u003c/strong\u003e\u003c/a\u003e (GCP) has expanded in terms of available geographic regions and maturity of services, customers globally can now seriously consider it for their cloud strategy. In some areas, GCP has reached feature parity with its main competitor, Amazon Web Services, while in other areas it has differentiated itself—notably with accessible machine learning platforms, data engineering tools, and a workable Kubernetes as a service solution (\u003ca href\u003d\"/radar/platforms/gke\"\u003eGKE\u003c/a\u003e). In practice, our teams have nothing but praise for the developer experience working with the GCP tools and APIs.\u003c/p\u003e","theta":"236","volume":"2018-11"},{"name":"Shared VPC","id":"1328","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"31","display_name":"Shared VPC","radius":"240","description":"\u003cp\u003eAs we\u0027ve gained more experience with the public cloud across organizations large and small, certain patterns have emerged. One of those patterns is a virtual private cloud network managed at the organizational level and divided into smaller subnets under the control of each delivery team. This is closely related to the idea of \u003ca href\u003d\"/radar/techniques/multi-account-cloud-setup\"\u003emultiaccount cloud setup\u003c/a\u003e and helps to \u003ca href\u003d\"/radar/techniques/partition-infrastructure-along-team-bounds\"\u003epartition an infrastructure along team bounds\u003c/a\u003e. After configuring this setup many times using VPCs, subnets, security groups and NACLs, we really like Google\u0027s notion of the \u003ca href\u003d\"https://cloud.google.com/vpc/docs/shared-vpc\"\u003e\u003cstrong\u003eshared VPC\u003c/strong\u003e\u003c/a\u003e. Shared VPC makes organizations, projects, VPCs and subnets first-class entities in network configurations. VPCs can be managed by an organization\u0027s administrators who can delegate subnet administration to projects. Projects can then be explicitly associated with subnets in the VPC. This simplifies configuration and makes security and access control more transparent.\u003c/p\u003e","theta":"247","volume":"2018-11"},{"name":"TICK Stack","id":"1260","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"32","display_name":"TICK Stack","radius":"190","description":"\u003cp\u003e\u003ca href\u003d\"http://www.influxdata.com/time-series-platform/\"\u003e\u003cstrong\u003eTICK Stack\u003c/strong\u003e\u003c/a\u003e is a collection of open source components that combine to deliver a platform for easily storing, visualizing and monitoring time series data such as metrics and events. The components are: \u003ca href\u003d\"https://www.influxdata.com/time-series-platform/telegraf/\"\u003eTelegraf\u003c/a\u003e, a server agent for collecting and reporting metrics; \u003ca href\u003d\"https://www.influxdata.com/time-series-platform/influxdb/\"\u003eInfluxDB\u003c/a\u003e, a high-performance time series database; \u003ca href\u003d\"https://www.influxdata.com/time-series-platform/chronograf/\"\u003eChronograf\u003c/a\u003e, a user interface for the platform; and \u003ca href\u003d\"https://www.influxdata.com/time-series-platform/kapacitor/\"\u003eKapacitor\u003c/a\u003e, a data-processing engine that can process, stream and batch data from InfluxDB. Unlike \u003ca href\u003d\"/radar/tools/prometheus\"\u003ePrometheus\u003c/a\u003e, which is based on the pull model, TICK Stack is based on the push model of collecting data. The heart of the system is the InfluxDB component, which is one of the best time series databases. The stack is backed by InfluxData and although you need the enterprise version for features such as database clustering, it\u0027s still a fairly good choice for monitoring. We\u0027re using it in a few places in production and have had good experiences with it.\u003c/p\u003e","theta":"258","volume":"2018-11"},{"name":"Azure DevOps","id":"1329","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"33","display_name":"Azure DevOps","radius":"335","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://azure.microsoft.com/en-us/services/devops/\"\u003eAzure DevOps\u003c/a\u003e\u003c/strong\u003e services include a set of managed services such as hosted Git repos, CI and CD pipelines and artifact repository. Azure DevOps services have replaced \u003ca href\u003d\"https://docs.microsoft.com/en-us/azure/devops/user-guide/what-happened-vsts?view\u003dvsts\"\u003eVisual Studio Team Services\u003c/a\u003e. We\u0027ve had a good experience in starting projects quickly with Azure DevOps services—managing, building and releasing applications to \u003ca href\u003d\"/radar/platforms/azure\"\u003eAzure\u003c/a\u003e. We\u0027ve also run into a few challenges—such as lack of full support for CI and CD pipeline as code, slow build agent startup time, separation of build and release into different pipelines—and experienced a few downtimes. We\u0027re hoping that Azure DevOps services improve over time to provide a good developer experience when hosting applications on Azure, with a frictionless experience integrating with other Azure services.\u003c/p\u003e","theta":"186","volume":"2018-11"},{"name":"CockroachDB","id":"1340","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"34","display_name":"CockroachDB","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.cockroachlabs.com/product/cockroachdb/\"\u003eCockroachDB\u003c/a\u003e\u003c/strong\u003e is an open source distributed database inspired by the white paper \u003ca href\u003d\"https://storage.googleapis.com/pub-tools-public-publication-data/pdf/39966.pdf\"\u003eSpanner: Google\u0027s distributed database\u003c/a\u003e. In CockroachDB, data is automatically divided into ranges, usually 64MB, and distributed across nodes in the cluster. Each range has a consensus group and, because it uses the \u003ca href\u003d\"https://raft.github.io/\"\u003eRaft consensus algorithm\u003c/a\u003e, the data is always kept in sync. With its unique design, CockroachDB provides distributed transactions and geo-partitioning while still supporting SQL. Unlike \u003ca href\u003d\"/radar/platforms/cloud-spanner\"\u003eSpanner\u003c/a\u003e, which relies on \u003ca href\u003d\"https://cloud.google.com/spanner/docs/true-time-external-consistency\"\u003eTrueTime\u003c/a\u003e with atomic clock for linearizability, CockroachDB uses \u003ca href\u003d\"https://en.wikipedia.org/wiki/Network_Time_Protocol\"\u003eNTP\u003c/a\u003e for clock synchronization and provides serializability as the default isolation level. If you\u0027re working with structured data that fits in a single node, then choose a traditional relational database. However, if your data needs to scale across nodes, be consistent and survive failures, then we recommend you take a closer look at CockroachDB.\u003c/p\u003e","theta":"192","volume":"2018-11"},{"name":"Debezium","id":"1288","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"35","display_name":"Debezium","radius":"290","description":"\u003cp\u003e\u003cstrong\u003eDebezium\u003c/strong\u003e is a \u003ca href\u003d\"https://en.wikipedia.org/wiki/Change_data_capture\"\u003echange data capture (CDC)\u003c/a\u003e platform that can stream database changes onto \u003ca href\u003d\"/radar/tools/apache-kafka\"\u003eKafka\u003c/a\u003e topics. CDC is a popular technique with multiple use cases, including replicating data to other databases, feeding analytics systems, extracting microservices from monoliths and invalidating caches. We\u0027re always on the lookout for tools or platforms in this space (we talked about \u003ca href\u003d\"/radar/tools/bottled-water\"\u003eBottled Water\u003c/a\u003e in a previous Radar) and Debezium is an excellent choice. It uses a log-based CDC approach which means it works by reacting to changes in the database\u0027s log files. Debezium uses Kafka Connect which makes it highly scalable and resilient to failures and has CDC connectors for multiple databases including Postgres, Mysql and MongoDB. We\u0027re using it in a few projects and it has worked very well for us.\u003c/p\u003e","theta":"198","volume":"2018-11"},{"name":"Glitch","id":"1339","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"36","display_name":"Glitch","radius":"300","description":"\u003cp\u003eWe\u0027ve been intrigued by \u003cstrong\u003e\u003ca href\u003d\"https://glitch.com/\"\u003eGlitch\u003c/a\u003e\u003c/strong\u003e, which is a collaborative online development environment that lets you easily copy and adapt (or \"remix\") existing web apps or create your own. Rooted in the \"tinkerer\" ethos, it\u0027s ideal for people learning to code but it has the capability to support more complex applications. The main focus is on JavaScript and \u003ca href\u003d\"/radar/platforms/node-js\"\u003eNode.js\u003c/a\u003e, but it also has limited support for other languages. With integrated live editing, hosting, sharing and automatic source versioning, Glitch offers a refreshing and distinctive take on collaborative programming.\u003c/p\u003e","theta":"204","volume":"2018-11"},{"name":"Google Cloud Dataflow","id":"1336","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"37","display_name":"Google Cloud Dataflow","radius":"285","description":"\u003cp\u003e\u003ca href\u003d\"https://cloud.google.com/dataflow/\"\u003e\u003cstrong\u003eGoogle Cloud Dataflow\u003c/strong\u003e\u003c/a\u003e is useful in traditional ETL scenarios for reading data from a source, transforming it and then storing it to a sink, with configurations and scaling being managed by dataflow. Dataflow supports Java, Python and Scala and provides wrappers for connections to various types of data sources. However, the current version won’t let you add additional libraries, which may make it unsuitable for certain data manipulations. You also can’t change the dataflow DAG dynamically. Hence, if your ETL has conditional execution flows based on parameters, you may not be able to use dataflow without workarounds.\u003c/p\u003e","theta":"210","volume":"2018-11"},{"name":"gVisor","id":"1335","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"38","display_name":"gVisor","radius":"335","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/google/gvisor\"\u003egVisor\u003c/a\u003e\u003c/strong\u003e is a user-space kernel for containers. It limits the host kernel surface accessible to the application without taking away access to all the features it expects. Unlike existing sandbox technologies, such as virtualized hardware (\u003ca href\u003d\"https://www.linux-kvm.org\"\u003eKVM\u003c/a\u003e and \u003ca href\u003d\"https://www.xenproject.org\"\u003eXen\u003c/a\u003e) or rule-based execution (\u003ca href\u003d\"https://www.kernel.org/doc/Documentation/prctl/seccomp_filter.txt\"\u003eseccomp\u003c/a\u003e, \u003ca href\u003d\"https://selinuxproject.org\"\u003eSELinux\u003c/a\u003e and \u003ca href\u003d\"https://wiki.ubuntu.com/AppArmor\"\u003eAppArmor\u003c/a\u003e), gVisor takes a distinct approach to container sandboxing by intercepting application system calls and acting as the guest kernel without the need for translation through virtualized hardware. gVisor includes an \u003ca href\u003d\"https://www.opencontainers.org\"\u003eOpen Container Initiative (OCI)\u003c/a\u003e runtime called runsc that integrates with \u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e and provides experimental support for \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e. gVisor is a relatively new project and we recommend assessing it for your container security landscape.\u003c/p\u003e","theta":"216","volume":"2018-11"},{"name":"IPFS","id":"1333","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"39","display_name":"IPFS","radius":"290","description":"\u003cp\u003eIn most cases, blockchain is not the right place to store a \u003ca href\u003d\"https://en.wikipedia.org/wiki/Binary_large_object\"\u003eblob\u003c/a\u003e file (e.g., image or audio). When developing \u003ca href\u003d\"/radar/techniques/ethereum-for-decentralized-applications\"\u003eDApp\u003c/a\u003e, one option is to put blob files in some off-chain centralized data storage, which usually signals lack of trust. Another option is to store them on InterPlanetary File System (\u003cstrong\u003e\u003ca href\u003d\"https://ipfs.io/\"\u003eIPFS\u003c/a\u003e\u003c/strong\u003e), which is a content-addressed, versioned, peer-to-peer file system. It’s designed to distribute high volumes of data with high efficiency and removed from any centralized authority. Files are stored on peers that don’t need to trust each other. IPFS keeps every version of a file so you never lose important files. We see IPFS as a good complement to blockchain technology. Beyond its blockchain application, IPFS has an ambitious goal to decentralize the Internet infrastructure.\u003c/p\u003e","theta":"222","volume":"2018-11"},{"name":"Istio","id":"1199","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"40","display_name":"Istio","radius":"290","description":"\u003cp\u003eWhen building and operating a \u003ca href\u003d\"https://martinfowler.com/articles/microservices.html\"\u003emicroservices\u003c/a\u003e ecosystem, one of the early questions to answer is how to implement cross-cutting concerns such as service discovery, service-to-service and origin-to-service security, observability (including telemetry and distributed tracing), rolling releases and resiliency. Over the last couple of years, our default answer to this question has been using a \u003ca href\u003d\"/radar/techniques/service-mesh\"\u003eservice mesh\u003c/a\u003e technique. A service mesh offers the implementation of these cross-cutting capabilities as an infrastructure layer that is configured as code. The policy configurations can be consistently applied to the whole ecosystem of microservices; enforced on both in and out of mesh traffic (via the mesh proxy as a gateway) as well as on the traffic at each service (via the same mesh proxy as a sidecar container). While we\u0027re keeping a close eye on the progress of different open source service mesh projects such as \u003ca href\u003d\"https://linkerd.io/\"\u003eLinkerd\u003c/a\u003e, we\u0027ve successfully used \u003cstrong\u003e\u003ca href\u003d\"https://istio.io/\"\u003eIstio\u003c/a\u003e\u003c/strong\u003e in production with a surprisingly easy-to-configure operating model.\u003c/p\u003e","theta":"228","volume":"2018-11"},{"name":"Knative","id":"1337","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"41","display_name":"Knative","radius":"320","description":"\u003cp\u003eAs application developers, we love to focus on solving core business problems and let the underlying platform handle the boring but difficult tasks of deploying, scaling and managing applications. Although \u003ca href\u003d\"/radar/techniques/serverless-architecture\"\u003eserverless architecture\u003c/a\u003e is a step in that direction, most of the popular offerings are tied to a proprietary implementation, which means vendor lock-in. \u003ca href\u003d\"https://cloud.google.com/knative/\"\u003e\u003cstrong\u003eKnative\u003c/strong\u003e\u003c/a\u003e tries to address this by being an open source serverless platform that integrates well with the popular \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e ecosystem. With Knative you can model computations on request in a supported framework of your choice (including Ruby on Rails, Django and Spring among others); subscribe, deliver and manage events; integrate with familiar CI and CD tools; and build containers from source. By providing a set of middleware components for building source-centric and container-based applications that can be elastically scaled, Knative is an attractive platform that deserves to be assessed for your serverless needs.\u003c/p\u003e","theta":"234","volume":"2018-11"},{"name":"Pulumi","id":"1283","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"42","display_name":"Pulumi","radius":"295","description":"\u003cp\u003eWe\u0027re quite interested in \u003ca href\u003d\"https://pulumi.io/\"\u003e\u003cstrong\u003ePulumi\u003c/strong\u003e\u003c/a\u003e, a promising entrant in cloud infrastructure automation. Pulumi distinguishes itself by allowing configurations to be written in \u003ca href\u003d\"/radar/languages-and-frameworks/typescript\"\u003eTypeScript\u003c/a\u003e/JavaScript, \u003ca href\u003d\"/radar/languages-and-frameworks/python-3\"\u003ePython\u003c/a\u003e, and Go—no YAML required. Pulumi is tightly focused on cloud-native architectures—including containers, serverless functions and data services—and provides good support for Kubernetes.\u003c/p\u003e","theta":"240","volume":"2018-11"},{"name":"Quorum","id":"1297","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"43","display_name":"Quorum","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"/radar/platforms/ethereum\"\u003eEthereum\u003c/a\u003e is the leading developer ecosystem in blockchain tech. We\u0027ve seen emerging solutions that aim to spread this technology into enterprise environments that usually require network permissioning and transaction privacy as well as higher throughput and lower latency. \u003ca href\u003d\"https://www.jpmorgan.com/global/Quorum\"\u003e\u003cstrong\u003eQuorum\u003c/strong\u003e\u003c/a\u003e is one of these solutions. Originally developed by J.P. Morgan, Quorum positions itself as \"an enterprise-focused version of Ethereum.\" Unlike the \u003ca href\u003d\"https://github.com/hyperledger/burrow\"\u003eHyperledger Burrow\u003c/a\u003e node, which creates a new Ethereum virtual machine (EVM), Quorum forks code from Ethereum\u0027s official client so that it can evolve alongside Ethereum. Although it keeps most features of the Ethereum ledger, Quorum changes the consensus protocol from PoW to more efficient ones and adds private transaction support. With Quorum, developers can use their Ethereum knowledge of using, for example, \u003ca href\u003d\"/radar/languages-and-frameworks/solidity\"\u003eSolidity\u003c/a\u003e and \u003ca href\u003d\"/radar/languages-and-frameworks/truffle\"\u003eTruffle\u003c/a\u003e contracts to build enterprise blockchain applications. However, based on our experience, Quorum is not yet enterprise ready; for example, it lacks access control for private contracts, doesn\u0027t work well with load balancers and only has partial database support, all of which will lead to significant deployment and design burden. We recommend that you\u0027re cautious in implementing Quorum while keeping an eye on its development.\u003c/p\u003e","theta":"246","volume":"2018-11"},{"name":"Resin.io","id":"1332","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"44","display_name":"Resin.io","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://resin.io/\"\u003eResin.io\u003c/a\u003e\u003c/strong\u003e is an Internet of Things (IoT) platform that does one thing and does it well: it deploys containers onto devices. Developers use a software as a service (SaaS) portal to manage devices and assign applications, defined by Dockerfiles, to them. The platform can build containers for various hardware types and deploys the images over the air. For the containers, Resin.io uses \u003ca href\u003d\"https://www.balena.io/\"\u003ebalena\u003c/a\u003e, an engine based on the Moby framework created by \u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e. The platform is still under development, has some rough edges and lacks some features (e.g., working with private registries), but the current feature set, including the option to ssh into a container on a device from the web portal, points toward a promising future.\u003c/p\u003e","theta":"252","volume":"2018-11"},{"name":"Rook","id":"1334","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"45","display_name":"Rook","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://rook.io/\"\u003eRook\u003c/a\u003e\u003c/strong\u003e is an open source cloud native storage orchestrator for \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e. Rook integrates with \u003ca href\u003d\"/radar/platforms/ceph\"\u003eCeph\u003c/a\u003e and brings File, Block and Object storage systems into the Kubernetes cluster, running them seamlessly alongside other applications and services that are consuming the storage. By using Kubernetes operators, Rook orchestrates Ceph at the control plane and stays clear of the data path between applications and Ceph. Storage is one of the important components of cloud-native computing and we believe that Rook, though still an incubating-level project at \u003ca href\u003d\"https://www.cncf.io/\"\u003eCNCF\u003c/a\u003e, takes us a step closer to self-sufficiency and portability across public cloud and on-premise deployments.\u003c/p\u003e","theta":"258","volume":"2018-11"},{"name":"SPIFFE","id":"1331","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"46","display_name":"SPIFFE","radius":"310","description":"\u003cp\u003eMaking key elements of Google\u0027s groundbreaking, high-scale platform available as open source offerings appears to have become a trend. In the same way that HBASE drew on BigTable and \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e drew on Borg, \u003ca href\u003d\"https://spiffe.io/\"\u003e\u003cstrong\u003eSPIFFE\u003c/strong\u003e\u003c/a\u003e is now drawing upon Google\u0027s LOAS to bring to life a critical cloud-native concept called workload identity. The SPIFFE standards are backed by the OSS \u003ca href\u003d\"https://github.com/spiffe/spire\"\u003eSPIFFE Runtime Environment (SPIRE)\u003c/a\u003e, which automatically delivers cryptographically provable identities to software workloads. Although SPIRE isn\u0027t quite ready for production use, we see tremendous value in a platform-agnostic way to make strong identity assertions between workloads in modern, distributed IT infrastructures. SPIRE supports many use cases, including identity translation, OAuth client authentication, mTLS \"encryption everywhere,\" and workload observability. \u003ca href\u003d\"/radar/platforms/istio\"\u003eIstio\u003c/a\u003e uses SPIFFE by default.\u003c/p\u003e","theta":"264","volume":"2018-11"},{"name":"Data-hungry packages","id":"1342","quadrant":"Platforms","ring":"Hold","movement":"t","radarId":"47","display_name":"Data-hungry packages","radius":"375","description":"\u003cp\u003e\u003cstrong\u003eData-hungry packages\u003c/strong\u003e are solutions that require absorption of data into themselves in order to function. In some cases they may even require that they become the \"master\" for that data. Once the data is owned by the package, that software becomes the only way to update, change or access the data. The data-hungry package might solve a particular business problem such as ERP. However, inventory or finance \"data demands\" placed upon an organization will often require complex integration and changes to systems that lie well outside of the original scope.\u003c/p\u003e","theta":"210","volume":"2018-11"},{"name":"Low-code platforms","id":"1343","quadrant":"Platforms","ring":"Hold","movement":"t","radarId":"48","display_name":"Low-code platforms","radius":"375","description":"\u003cp\u003e\u003cstrong\u003eLow-code platforms\u003c/strong\u003e use graphical user interfaces and configuration in order to create applications. Unfortunately, low-code environments are promoted with the idea that this means you no longer need skilled development teams. Such suggestions ignore the fact that writing code is just a small part of what needs to happen to create high-quality software—practices such as source control, testing and careful design of solutions are just as important. Although these platforms have their uses, we suggest approaching them with caution, especially when they come with extravagant claims for lower cost and higher productivity.\u003c/p\u003e","theta":"240","volume":"2018-11"},{"name":"acs-engine","id":"1269","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"49","display_name":"acs-engine","radius":"210","description":"\u003cp\u003eAzure Container Service Engine (\u003ca href\u003d\"https://github.com/Azure/acs-engine\"\u003e\u003cstrong\u003eacs-engine\u003c/strong\u003e\u003c/a\u003e) is an Azure Resource Manager (ARM) template generator. The required configurations of the cluster are defined in a JSON file; acs-engine reads these \u003ca href\u003d\"https://github.com/Azure/acs-engine/blob/master/docs/clusterdefinition.md\"\u003ecluster definitions\u003c/a\u003e and generates a number of files that can be consumed by ARM. The tool also provides flexibility to choose different orchestrators—including \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e, \u003ca href\u003d\"https://dcos.io/\"\u003eDC/OS\u003c/a\u003e, \u003ca href\u003d\"https://www.openshift.com/\"\u003eOpenShift\u003c/a\u003e, \u003ca href\u003d\"https://docs.docker.com/engine/swarm/\"\u003eSwarm mode\u003c/a\u003e and Swarm—and to configure features and agents of the cluster. We’ve been using acs-engine in a number of projects and would recommend it for managing clusters in Azure Container Service.\u003c/p\u003e","theta":"84","volume":"2018-11"},{"name":"Archery","id":"1274","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"50","display_name":"Archery","radius":"230","description":"\u003cp\u003eWe\u0027re seeing significant advances in security tooling integration with modern software delivery processes. \u003ca href\u003d\"https://archerysec.info/\"\u003e\u003cstrong\u003eArchery\u003c/strong\u003e\u003c/a\u003e is an open source tool with an active community that\u0027s doing a good job of pulling together a collection of other tools, including \u003ca href\u003d\"/radar/tools/zap\"\u003eZap\u003c/a\u003e. Designed primarily for web applications, Archery makes it easy to integrate security tooling into your build and deployment systems. Its dashboards also let you track vulnerabilities as well as application and network scans.\u003c/p\u003e","theta":"78","volume":"2018-11"},{"name":"ArchUnit","id":"1228","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"51","display_name":"ArchUnit","radius":"230","description":"\u003cp\u003e\u003ca href\u003d\"http://www.archunit.org/\"\u003e\u003cstrong\u003eArchUnit\u003c/strong\u003e\u003c/a\u003e is a Java testing library for checking architecture characteristics such as package and class dependencies, annotation verification and even layer consistency. We like that it runs as unit tests within your existing test setup, even though it supports only Java-based architectures. The ArchUnit test suite can be incorporated into a CI environment or a deployment pipeline, making it easier to implement \u003ca href\u003d\"/radar/techniques/architectural-fitness-function\"\u003efitness functions\u003c/a\u003e in an \u003ca href\u003d\"http://evolutionaryarchitecture.com/\"\u003eevolutionary architecture\u003c/a\u003e way.\u003c/p\u003e","theta":"72","volume":"2018-11"},{"name":"Cypress","id":"1149","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"52","display_name":"Cypress","radius":"210","description":"\u003cp\u003eRunning end-to-end tests can present challenges, such as the long duration of the running process, the flakiness of some tests and the challenges of fixing failures in CI when running tests in headless mode. Our teams have had very good experiences with \u003ca href\u003d\"http://www.cypress.io/\"\u003e\u003cstrong\u003eCypress\u003c/strong\u003e\u003c/a\u003e by solving common issues such as lack of performance and long wait time for responses and resources to load. Cypress is a useful tool that helps developers build end-to-end tests and records all test steps as a video in an MP4 file to make it easier to identify errors.\u003c/p\u003e","theta":"66","volume":"2018-11"},{"name":"git-secrets","id":"1270","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"53","display_name":"git-secrets","radius":"210","description":"\u003cp\u003eSecurity continues to be paramount, and inadvertently checking credentials and other secrets into source control is a major attack vector. \u003ca href\u003d\"https://github.com/awslabs/git-secrets\"\u003e\u003cstrong\u003egit-secrets\u003c/strong\u003e\u003c/a\u003e is a simple tool that prevents you from committing passwords and other sensitive information to a git repository. It can also scan all historical revisions before making a repository public, if you want to ensure you\u0027ve never accidentally checked in a credential. git-secrets comes with built-in support for common \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e keys and credentials and can be set up quickly for other providers too.\u003c/p\u003e","theta":"60","volume":"2018-11"},{"name":"Headless Firefox","id":"1233","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"54","display_name":"Headless Firefox","radius":"190","description":"\u003cp\u003e\u003ca href\u003d\"http://developer.mozilla.org/en-US/Firefox/Headless_mode\"\u003e\u003cstrong\u003eHeadless Firefox\u003c/strong\u003e\u003c/a\u003e has the same maturity as that of \u003ca href\u003d\"/radar/tools/headless-chrome-for-front-end-test\"\u003eHeadless Chrome for front-end test\u003c/a\u003e. Similar to Headless Chrome, with Firefox in headless mode we now get to enjoy browser tests without the visible UI components, executing the UI tests suite much faster.\u003c/p\u003e","theta":"54","volume":"2018-11"},{"name":"LocalStack","id":"1271","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"55","display_name":"LocalStack","radius":"230","description":"\u003cp\u003eOne of the challenges of using cloud services is being able to develop and test locally using those services. \u003ca href\u003d\"https://github.com/localstack/localstack\"\u003e\u003cstrong\u003eLocalStack\u003c/strong\u003e\u003c/a\u003e solves this problem for \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e by providing local \u003ca href\u003d\"https://martinfowler.com/bliki/TestDouble.html\"\u003etest double\u003c/a\u003e implementations of a wide range of AWS services, including S3, Kinesis, DynamoDB and Lambda. It builds on top of existing best-of-breed tools such as \u003ca href\u003d\"https://github.com/mhart/kinesalite\"\u003eKinesalite\u003c/a\u003e, \u003ca href\u003d\"https://github.com/mhart/dynalite\"\u003eDynalite\u003c/a\u003e and \u003ca href\u003d\"https://github.com/spulec/moto\"\u003eMoto\u003c/a\u003e and adds isolated processes and error injection functionality. LocalStack is very easy to use and ships with a simple JUnit runner and a JUnit 5 extension. We\u0027re using it in a few of our projects and have been impressed with it.\u003c/p\u003e","theta":"48","volume":"2018-11"},{"name":"Mermaid","id":"1268","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"56","display_name":"Mermaid","radius":"220","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://mermaidjs.github.io\"\u003eMermaid\u003c/a\u003e\u003c/strong\u003e lets you generate diagrams from a markdown-like markup language. Born out of need to simplify documentation, Mermaid has grown into a larger ecosystem with plugins for \u003ca href\u003d\"https://marketplace.atlassian.com/apps/1214124/mermaid-plugin-for-confluence?hosting\u003dserver\u0026tab\u003doverview\"\u003eConfluence\u003c/a\u003e, \u003ca href\u003d\"https://marketplace.visualstudio.com/items?itemName\u003dvstirbu.vscode-mermaid-preview\"\u003eVisual Studio Code\u003c/a\u003e and \u003ca href\u003d\"https://rubygems.org/gems/jekyll-mermaid/versions/1.0.0\"\u003eJekyll\u003c/a\u003e to name a few. To see how it works, you can use the \u003ca href\u003d\"https://mermaidjs.github.io/mermaid-live-editor/\"\u003eLive Editor\u003c/a\u003e on GitHub. Mermaid also has a convenient command line interface that lets you generate SVG, PNG and PDF files as output from definition files. We\u0027ve been using Mermaid in many projects and we like the simplicity of describing graphs and flowcharts with markdown and checking in the definition files with the code repository.\u003c/p\u003e","theta":"42","volume":"2018-11"},{"name":"Prettier","id":"1267","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"57","display_name":"Prettier","radius":"200","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://prettier.io/\"\u003ePrettier\u003c/a\u003e\u003c/strong\u003e is an opinionated, automated code formatter for JavaScript (with growing support for other languages). By enforcing its own opinionated formatting style it increases consistency and readability and reduces developer effort both on formatting and engaging in wasteful team debates about code style. Even though you may disagree with the stylistic choices enforced by Prettier, we find that the benefits to the team generally outweigh small style issues. Prettier can be used with a precommit hook or an IDE plugin. As with any formatter, a one-time reformatting of your codebase can confuse your version control history, but we feel that\u0027s a minor drawback. We particularly like the way Prettier flips the linter-based approach and, borrowing from \u003ca href\u003d\"https://golang.org/cmd/gofmt/\"\u003egofmt\u003c/a\u003e, instead of validating your code, it ensures that your code will always be valid.\u003c/p\u003e","theta":"36","volume":"2018-11"},{"name":"Rider","id":"1275","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"58","display_name":"Rider","radius":"210","description":"\u003cp\u003eWe\u0027ve covered \u003ca href\u003d\"/radar/tools/visual-studio-code\"\u003eVisual Studio Code\u003c/a\u003e in the Radar since 2015, but it isn\u0027t the only cross-platform .NET Core IDE kid on the block anymore. Recently, \u003ca href\u003d\"https://www.jetbrains.com/rider/\"\u003e\u003cstrong\u003eRider\u003c/strong\u003e\u003c/a\u003e, which is part of the IDEA platform developed by JetBrains, has gained adoption, especially by those used to the speed and dexterity provided by \u003ca href\u003d\"https://www.jetbrains.com/resharper/\"\u003eReSharper\u003c/a\u003e, which drives the refactoring in Rider. Rider, however, does more than ReSharper to bring the full IDEA platform to .NET and increase developer productivity. Regardless of your preferred platform, it\u0027s worth exploring Rider as it currently has the productivity edge on Visual Studio Code. It\u0027s also great to see the ecosystem alive and well, as competition ensures these tools continue to improve.\u003c/p\u003e","theta":"30","volume":"2018-11"},{"name":"Snyk","id":"1263","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"59","display_name":"Snyk","radius":"225","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://snyk.io/\"\u003eSnyk\u003c/a\u003e\u003c/strong\u003e helps you find, fix and monitor known vulnerabilities in npm, Ruby, Python, Scala, Golang, .NET, PHP, Java and Docker dependency trees. When added to your build pipeline, Snyk continuously monitors and tests the library dependency tree against a hosted vulnerability database and suggests the minimal direct dependency version upgrade needed for remediation.\u003c/p\u003e","theta":"24","volume":"2018-11"},{"name":"UI dev environments","id":"1272","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"60","display_name":"UI dev environments","radius":"200","description":"\u003cp\u003eAs more and more teams embrace \u003ca href\u003d\"/radar/techniques/designops\"\u003eDesignOps\u003c/a\u003e, practices and tooling in this space mature, too. Many of our teams now work with what could be called \u003cstrong\u003eUI dev environments\u003c/strong\u003e , which provide a comprehensive environment for quickly iterating on UI components, focusing on collaboration between user experience designers and developers. We now have a few options in this space: \u003ca href\u003d\"https://storybook.js.org/\"\u003eStorybook\u003c/a\u003e, \u003ca href\u003d\"https://react-styleguidist.js.org/\"\u003ereact-styleguidist\u003c/a\u003e, \u003ca href\u003d\"https://github.com/c8r\"\u003eCompositor\u003c/a\u003e and \u003ca href\u003d\"https://mdxjs.com/\"\u003eMDX\u003c/a\u003e. You can use these tools standalone in component library or design system development as well as embedded in a web application project. Rather than spinning up the app, plus a \u003ca href\u003d\"/radar/techniques/bff-backend-for-frontends\"\u003eBFF\u003c/a\u003e, plus services simply to add a feature to a component, you can start up the Storybook dev server instead.\u003c/p\u003e","theta":"18","volume":"2018-11"},{"name":"Visual Studio Code","id":"909","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"61","display_name":"Visual Studio Code","radius":"180","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://code.visualstudio.com/\"\u003eVisual Studio Code\u003c/a\u003e\u003c/strong\u003e is Microsoft\u0027s free IDE editor, available across platforms. We\u0027ve had good experience using this for front-end development using React and \u003ca href\u003d\"/radar/languages-and-frameworks/typescript\"\u003eTypeScript\u003c/a\u003e, and back-end languages such as GoLang, without having to switch between different editors. The tooling, language support and extensions for Visual Studio Code continue to soar and get better. We\u0027d particularly like to call out \u003ca href\u003d\"/radar/tools/visual-studio-live-share\"\u003eVisual Studio Live Share\u003c/a\u003e for real-time collaboration and remote pairing. While complex projects in statically typed languages, such as Java, .NET or C++, will likely find better support from the more mature IDEs from Microsoft or Jetbrains, we find that Visual Studio Code is increasingly becoming a tool of choice among infrastructure and front-end development teams.\u003c/p\u003e","theta":"12","volume":"2018-11"},{"name":"Visual Studio Live Share","id":"1265","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"62","display_name":"Visual Studio Live Share","radius":"190","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://marketplace.visualstudio.com/items?itemName\u003dMS-vsliveshare.vsliveshare-pack\"\u003eVisual Studio Live Share\u003c/a\u003e\u003c/strong\u003e is a suite of extensions for \u003ca href\u003d\"/radar/tools/visual-studio-code\"\u003eVisual Studio Code\u003c/a\u003e and Visual Studio. The real-time collaboration for editing and debugging of code, voice calls, sharing a terminal and exposing local ports have reduced some of the obstacles we\u0027d otherwise encounter when pairing remotely. In particular, we like that Live Share allows developers to collaborate with each other, while continuing to use their preconfigured editor, which includes themes, key maps and extensions.\u003c/p\u003e","theta":"6","volume":"2018-11"},{"name":"Bitrise","id":"1287","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"63","display_name":"Bitrise","radius":"300","description":"\u003cp\u003eBuilding, testing and deploying mobile applications entails a number of complex steps, especially when we consider a pipeline from source code repositories to app stores. All these steps can be automated with scripts and build pipelines in generic CI/CD tools. However, for teams that focus on mobile development, and have little or no requirement to integrate with build pipelines for back-end systems, a domain-specific tool can reduce the complexity and maintenance overhead. \u003ca href\u003d\"https://www.bitrise.io\"\u003e\u003cstrong\u003eBitrise\u003c/strong\u003e\u003c/a\u003e is easy to set up and provides a comprehensive set of prebuilt steps for most mobile development needs.\u003c/p\u003e","theta":"84","volume":"2018-11"},{"name":"Codefresh","id":"1291","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"64","display_name":"Codefresh","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"https://codefresh.io/\"\u003e\u003cstrong\u003eCodefresh\u003c/strong\u003e\u003c/a\u003e is a hosted CI server similar to \u003ca href\u003d\"/radar/tools/circleci\"\u003eCircleCI\u003c/a\u003e or \u003ca href\u003d\"/radar/tools/buildkite\"\u003eBuildkite\u003c/a\u003e. It\u0027s container-centric, making Dockerfiles and container-hosting clusters first-class entities. We like that the tool encourages a pipelined delivery approach and supports branching and merging. Early reports from our teams are positive, but we\u0027ve yet to see how it works for larger projects and complex pipelines.\u003c/p\u003e","theta":"78","volume":"2018-11"},{"name":"Grafeas","id":"1280","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"65","display_name":"Grafeas","radius":"295","description":"\u003cp\u003eWe\u0027re continually on the lookout for tools and techniques that allow delivery teams to work independently from the rest of a larger organization while staying within its security and risk guardrails. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/grafeas/grafeas\"\u003eGrafeas\u003c/a\u003e\u003c/strong\u003e is such a tool. It lets organizations publish authoritative metadata about software artifacts—Docker images, libraries, packages—that is then accessible from build scripts or other automated compliance controls. The access control mechanisms allow for a separation of responsibility between the teams that publish approvals or vulnerabilities and the teams that build and deploy software. Although several organizations, including Google and JFrog, use Grafeas in their workflows, note that the tool is still in alpha.\u003c/p\u003e","theta":"71","volume":"2018-11"},{"name":"Heptio Ark","id":"1281","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"66","display_name":"Heptio Ark","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/heptio/ark\"\u003eHeptio Ark\u003c/a\u003e\u003c/strong\u003e is a tool for managing disaster recovery for \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e clusters and persistent volumes. Ark is easy to use and configure and lets you back up and restore your clusters through a series of checkpoints. With Ark you can significantly reduce recovery time in case of an infrastructure failure, easily migrate Kubernetes resources from one cluster to another and replicate the production environment for testing and troubleshooting. Ark supports key backup \u003ca href\u003d\"https://github.com/heptio/ark/blob/master/docs/support-matrix.md\"\u003estorage providers\u003c/a\u003e (including AWS, Azure and Google Cloud) and, as of version 0.6.0, a plugin system that adds compatibility for additional backup and volume storage platforms. Managed Kubernetes environments, such as \u003ca href\u003d\"/radar/platforms/gke\"\u003eGKE\u003c/a\u003e, provide these services out of the box. However, if you\u0027re operating Kubernetes either on premise or in the cloud, take a closer look at Heptio Ark for disaster recovery.\u003c/p\u003e","theta":"65","volume":"2018-11"},{"name":"Jaeger","id":"1285","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"67","display_name":"Jaeger","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/jaegertracing/jaeger\"\u003eJaeger\u003c/a\u003e\u003c/strong\u003e is an open source distributed tracing system. Similar to \u003ca href\u003d\"/radar/tools/zipkin\"\u003eZipkin\u003c/a\u003e, it\u0027s been inspired by the Google \u003ca href\u003d\"https://ai.google/research/pubs/pub36356\"\u003eDapper\u003c/a\u003e paper and complies with \u003ca href\u003d\"https://opentracing.io/\"\u003eOpenTracing\u003c/a\u003e. Jaeger is a younger open source project than Zipkin, but it\u0027s gained popularity quickly due to a larger number of supported languages for the client libraries and easy installation on \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e. We\u0027ve used Jaeger successfully with \u003ca href\u003d\"/radar/platforms/istio\"\u003eIstio\u003c/a\u003e, integrating application traces with \u003ca href\u003d\"https://www.envoyproxy.io/\"\u003eEnvoy\u003c/a\u003e on Kubernetes, and like its \u003ca href\u003d\"https://github.com/jaegertracing/jaeger-ui\"\u003eUI\u003c/a\u003e. With Jaeger joining \u003ca href\u003d\"https://www.cncf.io/blog/2017/09/13/cncf-hosts-jaeger/\"\u003eCNCF\u003c/a\u003e, we anticipate a larger community engagement effort and deeper integration with other CNCF projects.\u003c/p\u003e","theta":"58","volume":"2018-11"},{"name":"kube-bench","id":"1305","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"68","display_name":"kube-bench","radius":"290","description":"\u003cp\u003e\u003ca href\u003d\"https://github.com/aquasecurity/kube-bench\"\u003e\u003cstrong\u003ekube-bench\u003c/strong\u003e\u003c/a\u003e is an example of an \u003ca href\u003d\"/radar/techniques/infrastructure-configuration-scanner\"\u003einfrastructure configuration scanner\u003c/a\u003e that automates checking your Kubernetes configuration against the \u003ca href\u003d\"https://www.cisecurity.org/benchmark/kubernetes/\"\u003eCIS benchmark for K8s\u003c/a\u003e. It covers user authentication, permissions and secure data among other areas. Our teams have found kube-bench valuable in the identification of vulnerable configurations.\u003c/p\u003e","theta":"52","volume":"2018-11"},{"name":"Ocelot","id":"1290","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"69","display_name":"Ocelot","radius":"295","description":"\u003cp\u003e\u003ca href\u003d\"http://threemammals.com/ocelot\"\u003e\u003cstrong\u003eOcelot\u003c/strong\u003e\u003c/a\u003e is a .NET API gateway. After three years of development, Ocelot has built a relatively complete feature set and an active community. Although there is no dearth of excellent API gateways (e.g., \u003ca href\u003d\"/radar/tools/kong-api-gateway\"\u003eKong\u003c/a\u003e), the .NET community appears to prefer Ocelot when building microservices. Part of the reason is that Ocelot integrates well with the .NET ecosystem (e.g., with IdentityServer). Another reason may be that the .NET community has extended Ocelot to support communication protocols such as gRPC, Orleans and WebSocket.\u003c/p\u003e","theta":"45","volume":"2018-11"},{"name":"Optimal Workshop","id":"1282","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"70","display_name":"Optimal Workshop","radius":"300","description":"\u003cp\u003eUX research demands data collection and analysis to make better decisions about the products we need to build. \u003ca href\u003d\"https://www.optimalworkshop.com\"\u003e\u003cstrong\u003eOptimal Workshop\u003c/strong\u003e\u003c/a\u003e is a suite of tools that helps to do this digitally. Features such as first-click or card sorting help to both validate prototypes and improve website navigation and information display. For distributed teams, in particular, benefit from Optimal Workshop as it lets them conduct remote research.\u003c/p\u003e","theta":"39","volume":"2018-11"},{"name":"Stanford CoreNLP","id":"1289","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"71","display_name":"Stanford CoreNLP","radius":"300","description":"\u003cp\u003eWe have more and more projects that require unstructured data processing. To extract meaningful business information from text data is a key technique. \u003ca href\u003d\"https://stanfordnlp.github.io/CoreNLP/\"\u003e\u003cstrong\u003eStanford CoreNLP\u003c/strong\u003e\u003c/a\u003e is a Java-based set of natural language processing tools. It supports named-entity recognition, relationship extraction, sentiment analysis and text classification as well as multiple languages, including English, Chinese and Arabic. We also find tools usable to label corpus and training models for our scenario. With Stanford CoreNLP, we were able to use the latest research in the field of NLP to solve various business problems.\u003c/p\u003e","theta":"33","volume":"2018-11"},{"name":"Terragrunt","id":"1266","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"72","display_name":"Terragrunt","radius":"300","description":"\u003cp\u003eWe widely use \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e as code to configure a cloud infrastructure. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/gruntwork-io/terragrunt\"\u003eTerragrunt\u003c/a\u003e\u003c/strong\u003e is a thin wrapper for Terraform that implements the practices advocated by the \u003ca href\u003d\"https://www.oreilly.com/library/view/terraform-up-and/9781491977071/\"\u003eTerraform: Up and Running\u003c/a\u003e book. We\u0027ve found Terragrunt helpful as it encourages versioned modules and reusability for different environments with some handy features, including recursive code execution in subdirectories. We\u0027d like to see the tool evolve to support CD practices natively, where all code can be packaged, versioned and reused across different environments on CD pipelines. Our team achieves this today with workarounds.\u003c/p\u003e","theta":"26","volume":"2018-11"},{"name":"TestCafe","id":"1278","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"73","display_name":"TestCafe","radius":"310","description":"\u003cp\u003eOur teams are reporting good success with \u003cstrong\u003e\u003ca href\u003d\"https://devexpress.github.io/testcafe/\"\u003eTestCafe\u003c/a\u003e\u003c/strong\u003e, a JavaScript-based browser test automation tool. TestCafe allows you to write tests in JavaScript or \u003ca href\u003d\"/radar/languages-and-frameworks/typescript\"\u003eTypeScript\u003c/a\u003e and runs tests in any browser that supports JavaScript. TestCafe has several useful features including out-of-the-box parallel execution and HTTP request mocking. TestCafe uses an asynchronous execution model with no explicit wait times, which results in much more stable test suites.\u003c/p\u003e","theta":"20","volume":"2018-11"},{"name":"Traefik","id":"1153","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"74","display_name":"Traefik","radius":"285","description":"\u003cp\u003e\u003ca href\u003d\"https://traefik.io/\"\u003e\u003cstrong\u003eTraefik\u003c/strong\u003e\u003c/a\u003e is an open-source reverse proxy and load balancer. If you\u0027re looking for an edge proxy that provides simple routing without all the features of \u003ca href\u003d\"https://nginx.org\"\u003eNGINX\u003c/a\u003e and \u003ca href\u003d\"https://haproxy.org\"\u003eHAProxy\u003c/a\u003e, Traefik is a good choice. The router provides a reload-less reconfiguration, metrics, monitoring and circuit breakers that are essential when running microservices. It also integrates nicely with \u003ca href\u003d\"/radar/tools/let-s-encrypt\"\u003eLet\u0027s Encrypt\u003c/a\u003e to provide SSL termination. When compared to Traefik, tools such as NGINX and HAProxy may require additional tooling to templatize configuration in response to scaling, adding or removing microservices and may, at times, require a restart which can be annoying in production environments.\u003c/p\u003e","theta":"13","volume":"2018-11"},{"name":"Wallaby.js","id":"1284","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"75","display_name":"Wallaby.js","radius":"310","description":"\u003cp\u003eWe all obsess about fast feedback during test-driven development and we\u0027re always looking for new ways to make this even faster. \u003ca href\u003d\"https://wallabyjs.com/\"\u003e\u003cstrong\u003eWallaby.js\u003c/strong\u003e\u003c/a\u003e is a commercial extension for popular editors that provides continuous execution of JavaScript unit tests, highlighting the results in line next to your code. The tool identifies and runs the minimum set of tests affected by each code change and lets you run tests continuously as you type.\u003c/p\u003e","theta":"7","volume":"2018-11"},{"name":"Jepsen","id":"950","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"76","display_name":"Jepsen","radius":"220","description":"\u003cp\u003eWith the increased adoption of a \u003ca href\u003d\"https://martinfowler.com/microservices/\"\u003emicroservices\u003c/a\u003e architecture, we\u0027re building more distributed applications than before. Although there are many benefits of a decoupled architecture, the complexity and the effort involved in proving the correctness of the overall system has dramatically increased. \u003ca href\u003d\"https://github.com/aphyr/jepsen\"\u003e\u003cstrong\u003eJepsen\u003c/strong\u003e\u003c/a\u003e provides much needed tooling to verify correctness in coordination of task schedulers, test eventual consistency, \u003ca href\u003d\"https://jepsen.io/consistency/models/linearizable\"\u003elinearizability\u003c/a\u003e and \u003ca href\u003d\"https://jepsen.io/consistency/models/serializable\"\u003eserializability\u003c/a\u003e characteristics of distributed databases. We\u0027ve used Jepsen in a few projects and we like the fact that we can test drive configurations, inject and correct faults, and verify the state of the system after recovery.\u003c/p\u003e","theta":"288","volume":"2018-11"},{"name":"MMKV","id":"1296","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"77","display_name":"MMKV","radius":"240","description":"\u003cp\u003eAn open source framework developed by \u003ca href\u003d\"/radar/platforms/wechat\"\u003eWeChat\u003c/a\u003e, \u003cstrong\u003e\u003ca href\u003d\"https://github.com/Tencent/MMKV\"\u003eMMKV\u003c/a\u003e\u003c/strong\u003e provides fast key-value storage for mobile apps. It uses iOS memory-mapping features to avoid the need to explicitly save changes and is extremely fast and performant. In the event of an unexpected crash, MMKV allows the app to restore the data quickly.\u003c/p\u003e","theta":"306","volume":"2018-11"},{"name":"MockK","id":"1315","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"78","display_name":"MockK","radius":"200","description":"\u003cp\u003e\u003ca href\u003d\"https://mockk.io\"\u003e\u003cstrong\u003eMockK\u003c/strong\u003e\u003c/a\u003e is a library for mocking written in \u003ca href\u003d\"/radar/languages-and-frameworks/kotlin\"\u003eKotlin\u003c/a\u003e. Its main philosophy is to provide first-class support for Kotlin language features such as \u003ca href\u003d\"https://kotlinlang.org/docs/reference/coroutines-overview.html\"\u003eCoroutines\u003c/a\u003e or lambda blocks. As a native library, it helps our teams to write clean and concise code on testing Kotlin applications instead of using incommodious wrappers of Mockito or PowerMock.\u003c/p\u003e","theta":"324","volume":"2018-11"},{"name":"TypeScript","id":"681","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"79","display_name":"TypeScript","radius":"180","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.typescriptlang.org/\"\u003eTypeScript\u003c/a\u003e\u003c/strong\u003e is a carefully considered language and its consistently improving tools and IDE support continues to impress us. With a \u003ca href\u003d\"https://definitelytyped.org/\"\u003egood repository\u003c/a\u003e of TypeScript-type definitions, we benefit from all the rich JavaScript libraries while gaining type safety. This is particularly important as our browser-based code base continues to grow. The type safety in TypeScript lets you use IDEs and other tools to provide deeper context into your code and make changes and refactor code with safety. TypeScript, being a superset of JavaScript, and documentation and the community has helped ease the learning curve.\u003c/p\u003e","theta":"342","volume":"2018-11"},{"name":"Apache Beam","id":"1320","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"80","display_name":"Apache Beam","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://beam.apache.org/\"\u003eApache Beam\u003c/a\u003e\u003c/strong\u003e is an open source unified programming model for defining and executing both batch and streaming data-parallel processing pipelines. Beam provides a portable API layer for describing these pipelines independent of execution engines (or runners) such as \u003ca href\u003d\"https://spark.apache.org/\"\u003eApache Spark\u003c/a\u003e, \u003ca href\u003d\"https://flink.apache.org/\"\u003eApache Flink\u003c/a\u003e or \u003ca href\u003d\"/radar/platforms/google-cloud-dataflow\"\u003eGoogle Cloud Dataflow\u003c/a\u003e. Different runners have different capabilities and providing a portable API is a difficult task. Beam tries to strike a delicate balance by actively pulling innovations from these runners into the Beam model and also working with the community to influence the roadmap of these runners. Beam has a rich set of \u003ca href\u003d\"http://beam.apache.org/documentation/io/built-in/\"\u003ebuilt-in I/O transformations\u003c/a\u003e that cover most of the data pipeline needs and it also provides a mechanism to implement \u003ca href\u003d\"http://beam.apache.org/documentation/io/authoring-overview/\"\u003ecustom transformations\u003c/a\u003e for specific use cases. The portable API and extensible IO transformations make a compelling case for assessing Apache Beam for data pipeline needs.\u003c/p\u003e","theta":"276","volume":"2018-11"},{"name":"Camunda","id":"1327","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"81","display_name":"Camunda","radius":"330","description":"\u003cp\u003eWe tend to be quite skeptical of business process model and notation (BPMN) tools in general as they\u0027re often associated with low-code environments and their downsides. Although the OSS BPMN framework \u003cstrong\u003e\u003ca href\u003d\"https://camunda.com/\"\u003eCamunda\u003c/a\u003e\u003c/strong\u003e provides some of this whizziness, it also offers workflow and decision engines that can be directly integrated as a library in your Java code. This makes it easy to test, version and refactor workflows. Camunda also integrates with Spring and Spring Boot, among other frameworks, making it a solid choice.\u003c/p\u003e","theta":"282","volume":"2018-11"},{"name":"Flutter","id":"1246","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"82","display_name":"Flutter","radius":"335","description":"\u003cp\u003e\u003ca href\u003d\"http://flutter.io/\"\u003e\u003cstrong\u003eFlutter\u003c/strong\u003e\u003c/a\u003e is a cross-platform framework that enables you to write native mobile apps in \u003ca href\u003d\"/radar/languages-and-frameworks/google-dart\"\u003eDart\u003c/a\u003e. It benefits from Dart and can be compiled into native code and communicates with the target platform without bridge and context switching—something that can cause performance bottlenecks in frameworks such as \u003ca href\u003d\"/radar/languages-and-frameworks/react-native\"\u003eReact Native\u003c/a\u003e or \u003ca href\u003d\"/radar/languages-and-frameworks/weex\"\u003eWeex\u003c/a\u003e. Flutter\u0027s hot-reload feature is impressive and provides superfast visual feedback when editing code. Currently, Flutter is still in beta, but we\u0027ll continue keeping an eye on it to see how its ecosystem matures.\u003c/p\u003e","theta":"288","volume":"2018-11"},{"name":"Ktor","id":"1295","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"83","display_name":"Ktor","radius":"295","description":"\u003cp\u003e\u003ca href\u003d\"/radar/languages-and-frameworks/kotlin\"\u003eKotlin\u003c/a\u003e is no longer just a great fit for mobile app development. New tools and frameworks have emerged that demonstrate the value of the language for web application development as well. \u003cstrong\u003e\u003ca href\u003d\"https://ktor.io\"\u003eKtor\u003c/a\u003e\u003c/strong\u003e is one such framework. In contrast to other web frameworks that support Kotlin, Ktor is written in Kotlin, using language features such as \u003ca href\u003d\"https://kotlinlang.org/docs/reference/coroutines-overview.html\"\u003ecoroutines\u003c/a\u003e which allows for an asynchronous non-blocking implementation. The flexibility to incorporate different tools for logging, DI or a templates engine—in addition to its lightweight architecture—makes Ktor an interesting option for our teams for creating RESTful services.\u003c/p\u003e","theta":"294","volume":"2018-11"},{"name":"Nameko","id":"1318","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"84","display_name":"Nameko","radius":"295","description":"\u003cp\u003eOne insight we gained after talking with our teams is that \u003ca href\u003d\"/radar/languages-and-frameworks/python-3\"\u003ePython\u003c/a\u003e is making a comeback across many technology domains. In fact, it\u0027s well on its way to become the \u003ca href\u003d\"https://spectrum.ieee.org/at-work/innovation/the-2018-top-programming-languages\"\u003emost-used programming language\u003c/a\u003e. In part, this is driven by its adoption by data scientists and in machine learning, but we also see teams adopting it to build microservices. \u003ca href\u003d\"https://www.nameko.io/\"\u003e\u003cstrong\u003eNameko\u003c/strong\u003e\u003c/a\u003e is a super-lightweight microservices framework and an alternative to \u003ca href\u003d\"http://flask.pocoo.org/\"\u003eFlask\u003c/a\u003e for writing services. Unlike Flask, Nameko only has a limited set of features that includes WebSocket, HTTP and AMQP support. We also like its focus on testability. If you don\u0027t need features such as templating that Flask provides, then Nameko is worth a look.\u003c/p\u003e","theta":"300","volume":"2018-11"},{"name":"Polly.js","id":"1319","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"85","display_name":"Polly.js","radius":"330","description":"\u003cp\u003e\u003ca href\u003d\"https://netflix.github.io/pollyjs/\"\u003e\u003cstrong\u003ePolly.js\u003c/strong\u003e\u003c/a\u003e is a simple tool that helps teams test JavaScript websites and applications. Our teams particularly like that it enables them to intercept and stub HTTP interactions which allows for easier and faster testing of JavaScript code without having to spin up dependent services or components.\u003c/p\u003e","theta":"306","volume":"2018-11"},{"name":"PredictionIO","id":"1325","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"86","display_name":"PredictionIO","radius":"290","description":"\u003cp\u003e\u003ca href\u003d\"http://predictionio.apache.org/\"\u003e\u003cstrong\u003ePredictionIO\u003c/strong\u003e\u003c/a\u003e is an open source machine-learning server. Developers and data scientists can use it to build intelligent applications for prediction. Like all intelligent applications, PredictionIO has three parts: data collection and storage, model training, and model deployment and expose service. Developers could focus on implementing data-processing logic, model algorithm and prediction logic based on the corresponding interfaces and liberate themselves from data storage and model training deployment. In our experience, PredictionIO can support both small and large volumes of data with low concurrency. We mostly use PredictionIO to build predictive services for small and medium-sized enterprises or as a proof of concept when building more complex, customized prediction engines.\u003c/p\u003e","theta":"312","volume":"2018-11"},{"name":"Puppeteer","id":"1324","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"87","display_name":"Puppeteer","radius":"320","description":"\u003cp\u003eIn the previous Radar we mentioned \u003ca href\u003d\"/radar/tools/headless-chrome-for-front-end-test\"\u003eHeadless Chrome for front-end test\u003c/a\u003e. With the adoption of \u003ca href\u003d\"http://devtools.chrome.com\"\u003eChrome DevTools Protocol\u003c/a\u003e (CDP) by other browsers a new set of libraries is emerging for browser automation and testing. CDP allows for fine-grained control over the browser even in headless mode. New high-level libraries are being created using CDP for testing and automation. \u003cstrong\u003e\u003ca href\u003d\"https://pptr.dev\"\u003ePuppeteer\u003c/a\u003e\u003c/strong\u003e is one of these new libraries. It can drive headless Chrome through a single-page application, obtain time-trace for performance diagnostics and more. Our teams found it faster and also more flexible than alternatives based on WebDriver.\u003c/p\u003e","theta":"318","volume":"2018-11"},{"name":"Q#","id":"1322","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"88","display_name":"Q#","radius":"335","description":"\u003cp\u003eQuantum computing currently exists in a twilight zone of being available for testing without having arrived yet. While we\u0027re still waiting for the hardware to arrive, we can experiment with and learn from languages and simulators. Although IBM and others have been making good progress, we\u0027ve paid particular attention to Microsoft\u0027s efforts based around the \u003ca href\u003d\"https://docs.microsoft.com/en-us/quantum/quantum-qr-intro?view\u003dqsharp-preview\"\u003e\u003cstrong\u003eQ#\u003c/strong\u003e\u003c/a\u003e language and its simulator (32 qubits locally and 40 on Azure). If you want to start wrapping your head around the potential future of programming, check out their set of \u003ca href\u003d\"https://github.com/Microsoft/Quantum\"\u003esamples on GitHub\u003c/a\u003e.\u003c/p\u003e","theta":"324","volume":"2018-11"},{"name":"SAFE stack","id":"1323","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"89","display_name":"SAFE stack","radius":"300","description":"\u003cp\u003eThe \u003cstrong\u003eSAFE stack\u003c/strong\u003e —short for \u003ca href\u003d\"https://suave.io/\"\u003eSuave\u003c/a\u003e, \u003ca href\u003d\"https://azure.microsoft.com\"\u003eAzure\u003c/a\u003e, \u003ca href\u003d\"http://fable.io/\"\u003eFable\u003c/a\u003e, and \u003ca href\u003d\"https://github.com/elmish/elmish\"\u003eElmish\u003c/a\u003e—brings a number of technologies into a coherent stack for web development. It\u0027s built around the F# programming language, both on the server side and in the browser, and therefore has a focus on functional, type-safe programming with an asynchronous approach. It offers productivity features such as hot reloading and lets you substitute parts of the stack, for example, the server-side web framework or the cloud provider.\u003c/p\u003e","theta":"330","volume":"2018-11"},{"name":"Spek","id":"1326","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"90","display_name":"Spek","radius":"300","description":"\u003cp\u003eThe adoption of a new language typically spawns the emergence of new tools that support mature engineering practices such as test automation. \u003ca href\u003d\"/radar/languages-and-frameworks/kotlin\"\u003eKotlin\u003c/a\u003e is no exception. \u003ca href\u003d\"https://spekframework.org\"\u003e\u003cstrong\u003eSpek\u003c/strong\u003e\u003c/a\u003e is a testing framework—inspired by well-known tools such as \u003ca href\u003d\"https://cucumber.io/\"\u003eCucumber\u003c/a\u003e, \u003ca href\u003d\"http://rspec.info/\"\u003eRSpec\u003c/a\u003e and \u003ca href\u003d\"https://jasmine.github.io/\"\u003eJasmine\u003c/a\u003e—that writes tests in Gherkin and Specification, allowing teams to bring mature practices such as \u003ca href\u003d\"https://dannorth.net/introducing-bdd\"\u003ebehaviour-driven development\u003c/a\u003e into the Kotlin space.\u003c/p\u003e","theta":"336","volume":"2018-11"},{"name":"troposphere","id":"1242","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"91","display_name":"troposphere","radius":"290","description":"\u003cp\u003eWe\u0027re trying out \u003ca href\u003d\"http://github.com/cloudtools/troposphere\"\u003e\u003cstrong\u003etroposphere\u003c/strong\u003e\u003c/a\u003e as a way of defining the \u003ca href\u003d\"/radar/tools/infrastructure-as-code\"\u003einfrastructure as code\u003c/a\u003e on AWS for our projects that use \u003ca href\u003d\"http://aws.amazon.com/cloudformation/\"\u003eAWS\u003c/a\u003e \u003ca href\u003d\"http://aws.amazon.com/cloudformation/\"\u003eCloudFormation\u003c/a\u003e instead of \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e. troposphere is a Python library that allows us to write Python code to generate CloudFormation JSON descriptions. What we like about troposphere is that it facilitates catching JSON errors early, applying type checking, and unit testing and DRY composition of AWS resources.\u003c/p\u003e","theta":"342","volume":"2018-11"},{"name":"WebAssembly","id":"1250","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"92","display_name":"WebAssembly","radius":"285","description":"\u003cp\u003e\u003ca href\u003d\"http://webassembly.org/\"\u003e\u003cstrong\u003eWebAssembly\u003c/strong\u003e\u003c/a\u003e is a big step forward in the capabilities of the browser as a code execution environment. Supported by all major browsers and backward compatible, it\u0027s a binary compilation format designed to run in the browser at near native speeds. It opens up the range of languages you can use to write front-end functionality, with early focus on C, C++ and Rust, and it\u0027s also an LLVM compilation target. When run in the sandbox, it can interact with JavaScript and shares the same permissions and security model. When used with \u003ca href\u003d\"http://hacks.mozilla.org/2018/01/making-webassembly-even-faster-firefoxs-new-streaming-and-tiering-compiler/\"\u003eFirefox\u0027s new streaming compiler\u003c/a\u003e, it also results in faster page initialization. Although it\u0027s still early days, this W3C standard is definitely one to start exploring.\u003c/p\u003e","theta":"348","volume":"2018-11"},{"name":"WebFlux","id":"1321","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"93","display_name":"WebFlux","radius":"295","description":"\u003cp\u003eSpring Framework 5, released over a year ago, embraces \u003ca href\u003d\"https://www.reactive-streams.org/\"\u003ereactive streams\u003c/a\u003e, a standard for asynchronous stream processing with non-blocking backpressure. The \u003ca href\u003d\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html\"\u003e\u003cstrong\u003eWebFlux\u003c/strong\u003e\u003c/a\u003e module introduces a reactive alternative to the traditional Spring MVC module for writing web applications in the Spring ecosystem. After working with it on a number of applications, our teams have come away impressed and report that the reactive (functional) approach improves code readability and system throughput. They do note, though, that adopting WebFlux requires a significant shift in thinking and recommend to factor this into the decision to choose WebFlux over Spring MVC.\u003c/p\u003e","theta":"354","volume":"2018-11"}],"date":"2018-11"},{"blips":[{"name":"Four key metrics","id":"1298","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"1","display_name":"Four key metrics","radius":"55","description":"\u003cp\u003eThe thorough \u003ca href\u003d\"https://devops-research.com/research.html\"\u003eState of DevOps\u003c/a\u003e reports have focused on data-driven and statistical analysis of high-performing organizations. The result of this multiyear research, published in \u003ca href\u003d\"https://itrevolution.com/book/accelerate/\"\u003eAccelerate\u003c/a\u003e, demonstrates a direct link between organizational performance and software delivery performance. The researchers have determined that only \u003cstrong\u003efour key metrics\u003c/strong\u003e differentiate between low, medium and high performers: lead time, deployment frequency, mean time to restore (MTTR) and change fail percentage. Indeed, we\u0027ve found that these four key metrics are a simple and yet powerful tool to help leaders and teams focus on measuring and improving what matters. A good place to start is to instrument the build pipelines so you can capture the four key metrics and make the software delivery value stream visible. \u003ca href\u003d\"https://www.gocd.org/\"\u003eGoCD pipelines,\u003c/a\u003e for example, provide the ability to measure these four key metrics as a first-class citizen of the \u003ca href\u003d\"https://www.gocd.org/analytics.html\"\u003eGoCD analytics\u003c/a\u003e.\u003c/p\u003e","theta":"138","volume":"2019-04"},{"name":"Micro frontends","id":"1035","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"2","display_name":"Micro frontends","radius":"95","description":"\u003cp\u003eWe\u0027ve seen significant benefits from introducing \u003ca href\u003d\"https://martinfowler.com/articles/microservices.html\"\u003emicroservices\u003c/a\u003e, which have allowed teams to scale the delivery of independently deployed and maintained services. Unfortunately, we\u0027ve also seen many teams create a frontend monolith — a large, entangled browser application that sits on top of the backend services — largely neutralizing the benefits of microservices. Since we first described \u003cstrong\u003emicro frontends\u003c/strong\u003e as a technique to address this issue, we\u0027ve had almost universally positive experiences with the approach and have found a number of patterns to use micro frontends even as more and more code shifts from the server to the web browser. So far, \u003ca href\u003d\"/radar/platforms/web-components-standard\"\u003eweb components\u003c/a\u003e have been elusive in this field, though.\u003c/p\u003e","theta":"150","volume":"2019-04"},{"name":"Opinionated and automated code formatting","id":"201904060","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"3","display_name":"Opinionated and automated code formatting","radius":"105","description":"\u003cp\u003eFor as long as we can remember, what style to use for formatting code has been a matter of personal taste, company policy and heated debate. Finally, the industry appears to be tiring of this endless argument and teams are freeing up surprisingly large amounts of time by forgoing these discussions and just adopting \u003cstrong\u003eopinionated and automated code formatting\u003c/strong\u003e tools. Even if you don\u0027t agree 100% with the opinions of the various tools, the benefits of focusing on what your code does rather than how it looks is something most teams should be able to get behind. \u003ca href\u003d\"/radar/tools/prettier\"\u003ePrettier\u003c/a\u003e has been getting our vote for JavaScript, but similar tools, such as \u003ca href\u003d\"https://github.com/ambv/black\"\u003eBlack\u003c/a\u003e for Python, are available for many other languages and are increasingly being built-in as we see with \u003ca href\u003d\"https://golang.org/cmd/gofmt/\"\u003eGolang\u003c/a\u003e and \u003ca href\u003d\"https://elixir-lang.org/blog/2018/01/17/elixir-v1-6-0-released/\"\u003eElixir\u003c/a\u003e. The key here is not to spend hours discussing which rules to enforce, but instead pick a tool that is opinionated, minimally configurable and automated — ideally as a pre-commit hook.\u003c/p\u003e","theta":"135","volume":"2019-04"},{"name":"Polyglot programming","id":"9215","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"4","display_name":"Polyglot programming","radius":"55","description":"\u003cp\u003eWe put \u003cstrong\u003epolyglot programming\u003c/strong\u003e on Trial in one of our first Radars to suggest that choosing the right language for the job could significantly boost productivity, and there were new language entrants that were worthy of consideration. We want to reraise this suggestion because we\u0027re seeing a new push to standardize language stacks by both developers and enterprises. While we acknowledge that placing no restrictions on language uses can create more problems than it solves, promoting a few languages that support different ecosystems or language features is important for both enterprises to accelerate processes and go live more quickly and developers to have the right tools to solve the problem at hand.\u003c/p\u003e","theta":"120","volume":"2019-04"},{"name":"Secrets as a service","id":"1303","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"5","display_name":"Secrets as a service","radius":"75","description":"\u003cp\u003eHumans and machines use secrets throughout the value stream of building and operating software. The build pipelines need secrets to interface with secure infrastructures such as container registries, the applications use API keys as secrets to get access to business capabilities, and the service-to-service communications are secured using certificates and keys as secrets. You can set and retrieve these secrets in different ways. We\u0027ve long cautioned developers about using source code management for storing secrets. We\u0027ve recommended \u003ca href\u003d\"/radar/techniques/decoupling-secret-management-from-source-code\"\u003edecoupling secret management from source code\u003c/a\u003e and using tools such as \u003ca href\u003d\"/radar/tools/git-secrets\"\u003egit-secrets\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/talisman\"\u003eTalisman\u003c/a\u003e to avoid storing secrets in the source code. We\u0027ve been using \u003cstrong\u003esecrets as a service\u003c/strong\u003e as a default technique for storing and accessing secrets. With this technique you can use tools such as \u003ca href\u003d\"/radar/tools/hashicorp-vault\"\u003eVault\u003c/a\u003e or \u003ca href\u003d\"https://aws.amazon.com/kms/\"\u003eAWS Key Management Service (KMS)\u003c/a\u003e to read/write secrets over an HTTPS endpoint with fine-grained levels of access control. Secrets as a service uses external identity providers such as \u003ca href\u003d\"https://aws.amazon.com/iam/\"\u003eAWS IAM\u003c/a\u003e to identify the actors who request access to secrets. Actors authenticate themselves with the secrets service. For this process to work, it\u0027s important to automate bootstrapping the identity of the actors, services and applications. Platforms based on \u003ca href\u003d\"/radar/platforms/spiffe\"\u003eSPIFFE\u003c/a\u003e have improved the automation of assigning identities to services.\u003c/p\u003e","theta":"108","volume":"2019-04"},{"name":"Chaos Engineering","id":"1206","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"6","display_name":"Chaos Engineering","radius":"210","description":"\u003cp\u003eIn the last year we\u0027ve seen \u003cstrong\u003eChaos Engineering\u003c/strong\u003e move from a much talked-about idea to an accepted, mainstream approach to improving and assuring distributed system resilience. As organizations large and small begin to implement Chaos Engineering as an operational process, we\u0027re learning how to apply these techniques safely at scale. The approach is definitely not for everyone, and to be effective and safe, it requires organizational support at scale. Industry acceptance and available expertise will definitely increase with the appearance of commercial services such as \u003ca href\u003d\"/radar/tools/gremlin\"\u003eGremlin\u003c/a\u003e and deployment tools such as \u003ca href\u003d\"/radar/tools/spinnaker\"\u003eSpinnaker\u003c/a\u003e implementing some Chaos Engineering tools.\u003c/p\u003e","theta":"168","volume":"2019-04"},{"name":"Container security scanning","id":"1041","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"7","display_name":"Container security scanning","radius":"190","description":"\u003cp\u003eThe container revolution around \u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e has massively reduced the friction in moving applications between environments, fueling increased adoption of continuous delivery and continuous deployments. The latter, especially, has blown a rather large hole in the traditional controls over what can go to production. The technique of \u003cstrong\u003econtainer security scanning\u003c/strong\u003e is a necessary response to this threat vector. Tools in the build pipeline automatically check containers flowing through the pipeline against known vulnerabilities. Since our first mention of this technique, the tool landscape has matured and the technique has proven useful on development efforts with our clients.\u003c/p\u003e","theta":"155","volume":"2019-04"},{"name":"Continuous delivery for machine learning (CD4ML)","id":"201904066","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"8","display_name":"Continuous delivery for machine learning (CD4ML)","radius":"170","description":"\u003cp\u003e\u003cstrong\u003eContinuous delivery for machine learning (CD4ML)\u003c/strong\u003e apply continuous delivery practices to developing machine learning models so that they are always ready for production. This technique addresses two main problems of traditional machine learning model development: long cycle time between training models and deploying them to production, which often includes manually converting the model to production-ready code; and using production models that had been trained with stale data.\u003c/p\u003e\n\n\u003cp\u003eA continuous delivery pipeline of a machine learning model has two triggers: (1) changes to the structure of the model and (2) changes to the training and test data sets. For this to work we need to both version \u003ca href\u003d\"/radar/techniques/versioning-data-for-reproducible-analytics\"\u003ethe data sets\u003c/a\u003e and the model\u0027s source code. The pipeline often includes steps such as testing the model against the test data set, applying automatic conversion of the model (if necessary) with tools such as \u003ca href\u003d\"https://www.h2o.ai/\"\u003eH2O\u003c/a\u003e, and deploying the model to production to deliver value.\u003c/p\u003e","theta":"142","volume":"2019-04"},{"name":"Crypto shredding","id":"1300","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"9","display_name":"Crypto shredding","radius":"190","description":"\u003cp\u003eMaintaining proper control over sensitive data is difficult, especially when it\u0027s copied outside of a master system of record for backup and recovery purposes. \u003cstrong\u003eCrypto shredding\u003c/strong\u003e is the practice of rendering sensitive data unreadable by deliberately overwriting or deleting encryption keys used to secure that data. Considering there are systems, such as audit application or blockchain, that should not or could not delete historical records, this technique is quite useful for privacy protection and \u003ca href\u003d\"https://www.thoughtworks.com/insights/blog/gdpr-it-s-time-rethink-your-approach-privacy\"\u003eGDPR\u003c/a\u003e compliance.\u003c/p\u003e","theta":"129","volume":"2019-04"},{"name":"Infrastructure configuration scanner","id":"1231","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"10","display_name":"Infrastructure configuration scanner","radius":"190","description":"\u003cp\u003eFor some time now we\u0027ve recommended that delivery teams take ownership of their entire stack, including infrastructure. This means increased responsibility in the delivery team itself for configuring the infrastructure in a safe, secure and compliant way. When adopting cloud strategies, most organizations default to a tightly locked-down and centrally managed configuration to reduce risk, but this also creates substantial productivity bottlenecks. An alternative approach is to allow teams to manage their own configuration and use an \u003cstrong\u003einfrastructure configuration scanner\u003c/strong\u003e to ensure the configuration is safe and secure. Options include open-source scanners such as \u003ca href\u003d\"https://github.com/toniblyx/prowler\"\u003eprowler\u003c/a\u003e for \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/kube-bench\"\u003ekube-bench\u003c/a\u003e for \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e installations. For more continuous detection, take a look at cloud platforms such as AWS Config Rules among other commercial services.\u003c/p\u003e","theta":"116","volume":"2019-04"},{"name":"Service mesh","id":"1138","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"11","display_name":"Service mesh","radius":"220","description":"\u003cp\u003e\u003cstrong\u003eService mesh\u003c/strong\u003e is an approach to operating a secure, fast and reliable microservices ecosystem. It has been an important stepping stone in making it easier to adopt microservices at scale. It offers discovery, security, tracing, monitoring and failure handling. It provides these cross-functional capabilities without the need for a shared asset such as an API gateway or baking libraries into each service. A typical implementation involves lightweight reverse-proxy processes, aka sidecars, deployed alongside each service process in a separate container. Sidecars intercept the inbound and outbound traffic of each service and provide cross-functional capabilities mentioned above. This approach has relieved the distributed service teams from building and updating the capabilities that the mesh offers as code in their services. This has lead to an even easier adoption of \u003ca href\u003d\"/radar/techniques/polyglot-programming\"\u003epolyglot programming\u003c/a\u003e in a microservices ecosystem. Our teams have been successfully using this approach with open source projects such as \u003ca href\u003d\"/radar/platforms/istio\"\u003eIstio\u003c/a\u003e and we will continue to monitor other open service mesh implementations such as \u003ca href\u003d\"http://linkerd.io/\"\u003eLinkerd\u003c/a\u003e closely.\u003c/p\u003e","theta":"103","volume":"2019-04"},{"name":"Ethical OS","id":"201904064","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"12","display_name":"Ethical OS","radius":"300","description":"\u003cp\u003eAs developers at ThoughtWorks we\u0027re acutely aware of the ethics of the work we do. As society becomes ever more reliant on technology, it\u0027s important that we consider ethics when making decisions as software development teams. Several toolkits have emerged that can help us think through some of the future implications of the software we\u0027re building. They include \u003ca href\u003d\"http://tarotcardsoftech.artefactgroup.com/\"\u003eTarot Cards of Tech\u003c/a\u003e and \u003cstrong\u003e\u003ca href\u003d\"https://ethicalos.org/\"\u003eEthical OS\u003c/a\u003e\u003c/strong\u003e, which we\u0027ve had good feedback on. Ethical OS is a thinking framework and a set of tools that drive discussions around the ethics of building software. The framework is a collaboration between the Institute for the Future and the Tech and Society Solutions Lab. It\u0027s based on a practical set of risk zones, such as addiction and the \u003ca href\u003d\"https://eand.co/the-dopamine-economy-336b239272ef\"\u003edopamine economy\u003c/a\u003e, plus a number of scenarios to drive conversation and discussion.\u003c/p\u003e","theta":"162","volume":"2019-04"},{"name":"Smart contracts","id":"201904055","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"13","display_name":"Smart contracts","radius":"335","description":"\u003cp\u003eThe more experience we gain with using distributed ledger technologies (DLTs), the more we encounter the rough edges around the current state of \u003cstrong\u003e\u003ca href\u003d\"https://en.wikipedia.org/wiki/Smart_contract\"\u003esmart contracts\u003c/a\u003e\u003c/strong\u003e. Committing automated, irrefutable, irreversible contracts on ledger sounds great in theory. The problems arise when you consider how to use modern software delivery techniques to developing them, as well as the differences between implementations. Immutable data is one thing, but immutable business logic is something else entirely! It\u0027s really important to think about whether to include logic in a smart contract. We\u0027ve also found very different operational characteristics between different implementations. For example, even though contracts can evolve, different platforms support this evolution to a greater or lesser extent. Our advice is to think long and hard before committing business logic to a smart contract and to weigh the merits of the different platforms before you do.\u003c/p\u003e","theta":"144","volume":"2019-04"},{"name":"Transfer learning for NLP","id":"201904062","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"14","display_name":"Transfer learning for NLP","radius":"300","description":"\u003cp\u003eTransfer learning has been quite effective within the field of computer vision, speeding the time to train a model by reusing existing models. Those of us who work in machine learning are excited that the same techniques can be applied to natural language processing (NLP) with the publication of \u003ca href\u003d\"https://arxiv.org/abs/1801.06146\"\u003eULMFiT\u003c/a\u003e and open source pretrained models and code examples. We think \u003cstrong\u003etransfer learning for NLP\u003c/strong\u003e will significantly reduce the effort to create systems dealing with text classification.\u003c/p\u003e","theta":"126","volume":"2019-04"},{"name":"Wardley mapping","id":"201904065","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"15","display_name":"Wardley mapping","radius":"320","description":"\u003cp\u003eWe\u0027re usually wary of covering diagrammatic techniques, but \u003cstrong\u003e\u003ca href\u003d\"https://medium.com/wardleymaps\"\u003eWardley mapping\u003c/a\u003e\u003c/strong\u003e is an interesting approach to start conversations around the evolution of an organization\u0027s software estate. At their simplest, they\u0027re used to visualize the value chains that exist within an organization, starting with customers\u0027 needs and progressively plotting the different capabilities and systems used to deliver on those needs along with the evolution of those capabilities and systems. The value of this technique is the process of collaborating to create the maps rather than the artefact itself. We recommend getting the right people in the room to produce them, and then treat them as living, evolving things rather than a complete artefact.\u003c/p\u003e","theta":"108","volume":"2019-04"},{"name":"Productionizing Jupyter Notebooks","id":"201904057","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"16","display_name":"Productionizing Jupyter Notebooks","radius":"375","description":"\u003cp\u003e\u003ca href\u003d\"/radar/tools/jupyter\"\u003eJupyter Notebooks\u003c/a\u003e have gained in popularity among data scientists who use them for exploratory analyses, early-stage development and knowledge sharing. This rise in popularity has led to the trend of \u003cstrong\u003eproductionizing Jupyter Notebooks\u003c/strong\u003e, by providing the tools and support to execute them at scale. Although we wouldn\u0027t want to discourage anyone from using their tools of choice, we don\u0027t recommend using Jupyter Notebooks for building scalable, maintainable and long-lived production code — they lack effective version control, error handling, modularity and extensibility among other basic capabilities required for building scalable, production-ready code. Instead, we encourage developers and data scientists to work together to find solutions that empower data scientists to build production-ready machine learning models using \u003ca href\u003d\"/radar/techniques/continuous-delivery-for-machine-learning-cd4ml-models\"\u003econtinuous delivery\u003c/a\u003e practices with the right programming frameworks. We caution against productionization of Jupyter Notebooks to overcome inefficiencies in continuous delivery pipelines for machine learning, or inadequate automated testing.\u003c/p\u003e","theta":"162","volume":"2019-04"},{"name":"Puncturing encapsulation with change data capture","id":"201904058","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"17","display_name":"Puncturing encapsulation with change data capture","radius":"375","description":"\u003cp\u003e\u003ca href\u003d\"https://en.wikipedia.org/wiki/Change_data_capture\"\u003eChange data capture\u003c/a\u003e (CDC) is a very powerful technique for pulling database changes out of a system and performing some actions on that data. One of the most popular ways of doing this is to use the database\u0027s transaction log to identify changes and then publish those changes directly onto an event bus that can be consumed by other services. This works very well for use cases such as \u003ca href\u003d\"https://martinfowler.com/articles/break-monolith-into-microservices.html\"\u003ebreaking monoliths into microservices\u003c/a\u003e but when used for first-class integration between microservices, this leads to puncturing encapsulation and leaking the source service\u0027s data layer into the event contract. We\u0027ve talked about \u003ca href\u003d\"/radar/techniques/domain-scoped-events\"\u003edomain scoped events\u003c/a\u003e and other techniques that emphasize the importance of having our events model our domain properly. We\u0027re seeing some projects use CDC for publishing row-level change events and directly consuming these events in other services. This \u003cstrong\u003epuncturing of encapsulation with change data capture\u003c/strong\u003e can be a slippery slope leading to fragile integrations and we would like to call this out with this blip.\u003c/p\u003e","theta":"144","volume":"2019-04"},{"name":"Release train","id":"201904097","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"18","display_name":"Release train","radius":"375","description":"\u003cp\u003eWe\u0027ve seen organizations successfully move from very infrequent releases to a higher cadence by using the \u003cstrong\u003erelease train\u003c/strong\u003e concept. The release train is a technique for coordinating releases across multiple teams or components that have runtime dependencies. All releases happen on a fixed and reliable schedule regardless of whether all expected features are ready (the train doesn\u0027t wait for you — if you miss it you wait for the next one). Although we wholeheartedly endorse discipline around regularly releasing and demoing working software, we\u0027ve experienced serious drawbacks with the approach over the medium to long term as it reinforces temporal coupling around sequencing of changes and can degrade quality as teams rush to complete features. We prefer to focus on the architectural and organizational approaches necessary to support independent releases. Although the train can be a useful forcing function for speeding up slower teams, we\u0027ve also seen it as imposing an upper limit on how quickly faster-moving teams can move. We believe that it is a technique that should be approached with a good degree of caution, if at all.\u003c/p\u003e","theta":"126","volume":"2019-04"},{"name":"Templating in YAML","id":"201904059","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"19","display_name":"Templating in YAML","radius":"375","description":"\u003cp\u003eAs infrastructures grow in complexity, so do the configuration files that define them. Tools such as \u003ca href\u003d\"https://aws.amazon.com/cloudformation/\"\u003eAWS CloudFormation\u003c/a\u003e, \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/helm\"\u003eHelm\u003c/a\u003e expect configuration files in JSON or YAML syntax, presumably in an attempt to make them easy to write and process. However, in most cases, teams quickly reach the point where they have some parts that are similar but not quite the same, for example, when the same service must be deployed in different regions with a slightly different setup. For such cases tools offer \u003cstrong\u003etemplating in YAML\u003c/strong\u003e (or JSON), which has caused a huge amount of \u003ca href\u003d\"https://leebriggs.co.uk/blog/2019/02/07/why-are-we-templating-yaml.html\"\u003efrustration with practitioners\u003c/a\u003e. The problem is that the syntax of JSON and YAML requires all sorts of awkward compromises to graft templating features such as conditionals and loops into the files. We recommend using an API from a programming language instead or, when this is not an option, a templating system in a programming language, either a general-purpose language such as Python or something specialized such as \u003ca href\u003d\"https://jsonnet.org/\"\u003eJsonnet\u003c/a\u003e.\u003c/p\u003e","theta":"108","volume":"2019-04"},{"name":"Contentful","id":"1254","quadrant":"Platforms","ring":"Adopt","movement":"t","radarId":"20","display_name":"Contentful","radius":"125","description":"\u003cp\u003eHeadless content management systems (CMSes) are becoming a common component of digital platforms. \u003ca href\u003d\"http://www.contentful.com/\"\u003e\u003cstrong\u003eContentful\u003c/strong\u003e\u003c/a\u003e is a modern headless CMS that our teams have successfully integrated into their development workflows. We particularly like its API-first approach and implementation of \u003ca href\u003d\"http://www.contentful.com/r/knowledgebase/cms-as-code/\"\u003eCMS as code\u003c/a\u003e. It supports powerful content modeling primitives as code and content model evolution scripts, which allow it to be treated like other data store schemas and enable \u003ca href\u003d\"http://martinfowler.com/articles/evodb.html\"\u003eevolutionary database design\u003c/a\u003e practices to be applied to CMS development. Its robustness and a stream of new features, including a sandbox environment, have impressed our teams further and made Contentful our default choice in this space.\u003c/p\u003e","theta":"225","volume":"2019-04"},{"name":"AWS Fargate","id":"1255","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"21","display_name":"AWS Fargate","radius":"200","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://aws.amazon.com/fargate/\"\u003eAWS Fargate\u003c/a\u003e\u003c/strong\u003e, the docker-as-a-service option on \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e, is now widely available across regions. It\u0027s a great solution for situations in which teams want to run Docker containers, because \u003ca href\u003d\"/radar/platforms/aws-lambda\"\u003eAWS Lambda\u003c/a\u003e functions aren\u0027t powerful enough, without having to manage EC2 instances or Kubernetes clusters. Our teams report generally positive experiences with Fargate; however, the convenience of this managed service can come at a cost, in financial terms.\u003c/p\u003e","theta":"192","volume":"2019-04"},{"name":"EVM beyond Ethereum","id":"201904053","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"22","display_name":"EVM beyond Ethereum","radius":"250","description":"\u003cp\u003e\u003ca href\u003d\"https://github.com/ethereum/wiki/wiki/Ethereum-Virtual-Machine-(EVM)-Awesome-List\"\u003eEthereum Virtual Machine (EVM)\u003c/a\u003e was originally designed for the \u003ca href\u003d\"/radar/platforms/ethereum\"\u003eEthereum\u003c/a\u003e main network. Nowadays, however, most teams no longer want to reinvent blockchain from scratch; instead, they\u0027d like to take \u003cstrong\u003eEVM beyond Ethereum\u003c/strong\u003e. We\u0027ve seen a lot of blockchain teams choose to fork Ethereum (e.g., \u003ca href\u003d\"/radar/platforms/quorum\"\u003eQuorum\u003c/a\u003e) or implement the EVM spec (e.g., \u003ca href\u003d\"https://github.com/hyperledger/burrow\"\u003eBurrow\u003c/a\u003e, \u003ca href\u003d\"https://github.com/PegaSysEng/pantheon\"\u003ePantheon\u003c/a\u003e), adding their own designs. The intention is to not only reuse the Ethereum design but also leverage its ecosystem and developer community. To many developers, the concept of \"smart contract\" is almost equivalent to a smart contract written in \u003ca href\u003d\"/radar/languages-and-frameworks/solidity\"\u003eSolidity\u003c/a\u003e. Although Ethereum itself has some constraints, the technology around the EVM ecosystem is booming.\u003c/p\u003e","theta":"205","volume":"2019-04"},{"name":"InfluxDB","id":"201904054","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"23","display_name":"InfluxDB","radius":"170","description":"\u003cp\u003e\u003ca href\u003d\"/radar/platforms/time-series-databases\"\u003eTime series databases\u003c/a\u003e (TSDBs) have been around for some time now. But increasingly they\u0027re becoming more mainstream as more use cases naturally fit the time series model. \u003ca href\u003d\"https://github.com/influxdata/influxdb\"\u003e\u003cstrong\u003eInfluxDB\u003c/strong\u003e\u003c/a\u003e continues to remain a good choice for TSDBs with monitoring being one of its key use cases. \u003ca href\u003d\"/radar/platforms/tick-stack\"\u003eTICK Stack\u003c/a\u003e is an example of a monitoring solution that has InfluxDB at its heart. Influx 2.0 alpha recently introduced Flux — a scripting language for querying and processing time series data. It\u0027s still early days for Flux and the jury\u0027s out on its \u003ca href\u003d\"https://medium.com/timescale/sql-vs-flux-influxdb-query-language-time-series-database-290977a01a8a\"\u003ebroader adoption beyond InfluxDB\u003c/a\u003e, but it promises to be more powerful and expressive than InfluxQL and enables pushing time series analytic workloads to the database. However, clustering support for InfluxDB is only available with the enterprise version which has limited its adoption on some of our projects.\u003c/p\u003e","theta":"218","volume":"2019-04"},{"name":"Istio","id":"1199","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"24","display_name":"Istio","radius":"225","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://istio.io/\"\u003eIstio\u003c/a\u003e\u003c/strong\u003e is becoming the de facto infrastructure to operationalize a \u003ca href\u003d\"https://martinfowler.com/articles/microservices.html\"\u003emicroservices\u003c/a\u003e ecosystem. Its out-of-the-box implementation of cross-cutting concerns — such as service discovery, service-to-service and origin-to-service security, observability (including telemetry and distributed tracing), rolling releases and resiliency — has been bootstrapping our microservices implementations very quickly. It\u0027s the main implementation of the \u003ca href\u003d\"/radar/techniques/service-mesh\"\u003eservice mesh\u003c/a\u003e technique we\u0027ve been using. We\u0027ve been enjoying its monthly releases and its continuous improvements with seamless upgrades. We use Istio to bootstrap our projects, starting with observability (tracing and telemetry) and service-to-service security. We\u0027re closely watching its improvements to service-to-service authentication everywhere in and outside of the mesh. We\u0027d also like to see Istio establish best practices for configuration files to strike a balance between giving autonomy to service developers and control to the service mesh operators.\u003c/p\u003e","theta":"231","volume":"2019-04"},{"name":"Kafka Streams","id":"1058","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"25","display_name":"Kafka Streams","radius":"200","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://kafka.apache.org/documentation/streams/\"\u003eKafka Streams\u003c/a\u003e\u003c/strong\u003e is a lightweight library to build streaming applications. It supports basic streaming APIs such as join, filter, map and aggregate as well as local storage for common use cases such as windowing and sessions. Unlike other stream-processing platforms such as \u003ca href\u003d\"/radar/platforms/apache-spark\"\u003eApache Spark\u003c/a\u003e and \u003ca href\u003d\"https://doc.akka.io/docs/akka-stream-kafka/current/home.html\"\u003eAlpakka Kafka\u003c/a\u003e, Kafka Streams has been a good fit for scenarios that don\u0027t require large-scale distribution and parallel processing; hence we could get away without yet another piece of infrastructure such as cluster schedulers. Naturally, Kafka Streams has been a good choice when operating in the Kafka ecosystem. Kafka Streams is particularly useful when we have to process data strictly in order and exactly once. One particular use case of Kafka Streams is to build a \u003ca href\u003d\"https://en.wikipedia.org/wiki/Change_data_capture#Event_Programming\"\u003echange data capture (CDC)\u003c/a\u003e platform.\u003c/p\u003e","theta":"244","volume":"2019-04"},{"name":"Nomad","id":"983","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"26","display_name":"Nomad","radius":"200","description":"\u003cp\u003eHashiCorp continues to release interesting software. We\u0027ve featured \u003ca href\u003d\"/radar/tools/hashicorp-vault\"\u003eHashiCorp Vault\u003c/a\u003e in March 2017, and tools related to Terraform are all over this edition of the Radar. We\u0027ve moved \u003cstrong\u003e\u003ca href\u003d\"https://www.nomadproject.io/\"\u003eNomad\u003c/a\u003e\u003c/strong\u003e to Trial because we\u0027ve had positive experiences using it. While \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e continues to gain traction, we like Nomad\u0027s general applicability. It\u0027s not just limited to running containerized workloads but can be used to schedule just about anything. Java and Golang are supported natively as well as batch and distributed cron jobs. We like its focus on multi- and hybrid-cloud operations, something likely to become more important to avoid sticky clouds and the fact that it does scheduling well.\u003c/p\u003e","theta":"257","volume":"2019-04"},{"name":"CloudEvents","id":"201904049","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"27","display_name":"CloudEvents","radius":"300","description":"\u003cp\u003eOutside the function code itself, applications written as serverless functions are tightly coupled to the cloud platform on which they\u0027re hosted. Although events are a common FaaS-triggering mechanism, and every cloud provider supports them in some form, the current proprietary specifications prevent interoperability across clouds. The \u003cstrong\u003e\u003ca href\u003d\"https://cloudevents.io/\"\u003eCloudEvents\u003c/a\u003e\u003c/strong\u003e specification is a burgeoning standard that has been accepted into the \u003ca href\u003d\"https://www.cncf.io/sandbox-projects/\"\u003eCNCF Sandbox\u003c/a\u003e. The standard is still in active development but several language bindings exist and Microsoft has announced first-class support in \u003ca href\u003d\"/radar/platforms/azure\"\u003eAzure\u003c/a\u003e. We\u0027re hoping other cloud providers will follow suit.\u003c/p\u003e","theta":"187","volume":"2019-04"},{"name":"Cloudflare Workers","id":"201904051","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"28","display_name":"Cloudflare Workers","radius":"330","description":"\u003cp\u003eMost modern server-side or serverless code execution platforms are centered around containers or VMs. \u003cstrong\u003e\u003ca href\u003d\"https://www.cloudflare.com/products/cloudflare-workers/\"\u003eCloudflare Workers\u003c/a\u003e\u003c/strong\u003e, however, takes a different approach to hosting a serverless computing offering. It uses \u003ca href\u003d\"https://v8docs.nodesource.com/node-0.8/d5/dda/classv8_1_1_isolate.html\"\u003eV8 Isolates\u003c/a\u003e, the open source JavaScript engine developed for Chrome, to run functions as a service (FaaS) on their extensive CDN network. Code can be written in JavaScript or anything that compiles to \u003ca href\u003d\"/radar/languages-and-frameworks/webassembly\"\u003eWebAssembly\u003c/a\u003e and data can be accessed from Cloudflare\u0027s cache or key-value store. The major benefit for developers is performance: by being on the edge network, close to end users, cold-starts take only five milliseconds. For the provider the benefits include both the ability to densely pack isolates because of their lower memory overhead and faster performance through reduced process context switching. This is definitely an intriguing approach to monitor and assess.\u003c/p\u003e","theta":"195","volume":"2019-04"},{"name":"Deno","id":"201904052","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"29","display_name":"Deno","radius":"315","description":"\u003cp\u003eAs a group we have mixed feelings about programming in JavaScript on the server side, especially when the rationale for doing so is simply to avoid \u003ca href\u003d\"/radar/techniques/polyglot-programming\"\u003epolyglot programming\u003c/a\u003e. That said, if you decide to use JavaScript or TypeScript on the server, have a look at \u003cstrong\u003e\u003ca href\u003d\"https://deno.land/\"\u003eDeno\u003c/a\u003e\u003c/strong\u003e. Written by Ryan Dahl, the inventor of Node.js, Deno aims to avoid what Ryan considers mistakes that were made in Node.js. It brings a strict sandbox system and built-in dependency and package management, and it supports \u003ca href\u003d\"/radar/languages-and-frameworks/typescript\"\u003eTypeScript\u003c/a\u003e out of the box. Deno is built using \u003ca href\u003d\"/radar/languages-and-frameworks/rust\"\u003eRust\u003c/a\u003e and V8.\u003c/p\u003e","theta":"202","volume":"2019-04"},{"name":"Hot Chocolate","id":"201904047","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"30","display_name":"Hot Chocolate","radius":"330","description":"\u003cp\u003eThe \u003ca href\u003d\"/radar/languages-and-frameworks/graphql\"\u003eGraphQL\u003c/a\u003e ecosystem and community keep growing. \u003cstrong\u003e\u003ca href\u003d\"https://hotchocolate.io/\"\u003eHot Chocolate\u003c/a\u003e\u003c/strong\u003e is a GraphQL server for .NET (core and classic). It lets you build and host schemas and then serve queries against them. The team behind Hot Chocolate has recently added schema stitching which allows for a single entry point to query across multiple schemas aggregated from different locations. Although there are plenty of ways to misuse this approach, it\u0027s worth assessing whether to add it to your toolkit.\u003c/p\u003e","theta":"210","volume":"2019-04"},{"name":"Knative","id":"1337","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"31","display_name":"Knative","radius":"285","description":"\u003cp\u003eThe \u003ca href\u003d\"/radar/techniques/serverless-architecture\"\u003eserverless architecture\u003c/a\u003e has popularized a FaaS style of programming among developers; it helps developers focus on solving core business problems with independently built and deployed functions that react to an event, run a business process, produce other events in the process and scale down to zero. Historically, proprietary serverless platforms such as \u003ca href\u003d\"/radar/platforms/aws-lambda\"\u003eAWS Lambda\u003c/a\u003e or Microsoft \u003ca href\u003d\"https://azure.microsoft.com/en-us/services/functions/\"\u003eAzure Functions\u003c/a\u003e have enabled this programming paradigm. \u003cstrong\u003e\u003ca href\u003d\"https://www.knative.dev/\"\u003eKnative\u003c/a\u003e\u003c/strong\u003e is an open-source Kubernetes-based platform to run FaaS workloads. There are few things that stand out about Knative: it\u0027s open source and provider agnostic; it implements the serverless workflow as described in the CNCF Serverless Working Group \u003ca href\u003d\"https://github.com/cncf/wg-serverless/tree/master/whitepapers/serverless-overview\"\u003ewhitepaper\u003c/a\u003e; it ensures cross-service interoperability by implementing its eventing interface consistent with \u003ca href\u003d\"https://github.com/cloudevents/spec/blob/master/spec.md#design-goals\"\u003eCNCF CloudEvents\u003c/a\u003e specification; and, most importantly, it addresses a common challenge of operating a harmonized and yet hybrid FaaS and long-running container-based architecture. It easily integrates with both \u003ca href\u003d\"/radar/platforms/istio\"\u003eIstio\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e. For example, developers can take advantage of roll-out strategies that Istio implements by traffic splitting between different revisions of the functions. Developers can take benefit of Istio-provided observability not only for long-running container services but also for FaaS programs in the same Kubernetes environment. We anticipate that Knative open-source eventing interface will continue to enable new underlying source and destination event integrations.\u003c/p\u003e","theta":"217","volume":"2019-04"},{"name":"MinIO","id":"201904048","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"32","display_name":"MinIO","radius":"300","description":"\u003cp\u003eObject storage is a popular choice for storing unstructured data and in a few cases structured data in the cloud. We do discourage the use of \u003ca href\u003d\"/radar/techniques/generic-cloud-usage\"\u003egeneric cloud\u003c/a\u003e but if you want to minimize the risk of cloud stickiness for object storage, we\u0027ve found \u003cstrong\u003e\u003ca href\u003d\"https://min.io/\"\u003eMinIO\u003c/a\u003e\u003c/strong\u003e quite helpful. With an S3-compatible API layer, MinIO abstracts object storage across cloud providers, including \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e, \u003ca href\u003d\"/radar/platforms/azure\"\u003eAzure\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/google-cloud-platform\"\u003eGoogle Cloud Platform\u003c/a\u003e (GCP), and we\u0027ve used it successfully in products with flexible target infrastructures from data centers to cloud providers.\u003c/p\u003e","theta":"225","volume":"2019-04"},{"name":"Prophet","id":"201904067","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"33","display_name":"Prophet","radius":"330","description":"\u003cp\u003eEven in the era of deep learning, statistical models still play a role in business decision support. Time series models are widely used to forecast inventories, demand, customer traffic, and so on. Hand-crafting these models so that they\u0027re robust and flexible has typically been the role of either specialized statisticians or large commercial software vendors. \u003cstrong\u003e\u003ca href\u003d\"https://facebook.github.io/prophet/\"\u003eProphet\u003c/a\u003e\u003c/strong\u003e is an open-source alternative to commercial forecasting packages that can be programmed in R or Python. Facebook claims to use Prophet internally for business forecasting at scale and has made it available as an open-source package for anyone to use. We like that Prophet removes some of the tedium of model construction, maintenance and data manipulation so that human analysts and subject matter experts can focus on doing what they do best.\u003c/p\u003e","theta":"232","volume":"2019-04"},{"name":"Quorum","id":"1297","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"34","display_name":"Quorum","radius":"285","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.jpmorgan.com/global/Quorum\"\u003eQuorum\u003c/a\u003e\u003c/strong\u003e is \"an enterprise-focused version of Ethereum\" that aims to provide network permissioning and transaction privacy as well as higher performance. One of our teams has worked deeply with Quorum; however, their experience so far hasn\u0027t been great. Some challenges result from \u003ca href\u003d\"/radar/techniques/smart-contracts\"\u003ecomplex smart contract programming\u003c/a\u003e and some come from Quorum itself. For example, it doesn\u0027t work well with load balancers and only has partial database support, which will lead to significant deployment burden. We faced some stability and compatibility issues especially on private transactions. Quorum recently attracted a lot of attention because of \u003ca href\u003d\"https://www.jpmorgan.com/global/news/digital-coin-payments\"\u003eJPM Coin\u003c/a\u003e. However, from a tech perspective, we recommend being cautious when implementing Quorum while keeping an eye on its development.\u003c/p\u003e","theta":"240","volume":"2019-04"},{"name":"SPIFFE","id":"1331","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"35","display_name":"SPIFFE","radius":"285","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://spiffe.io/\"\u003eSPIFFE\u003c/a\u003e\u003c/strong\u003e standardization of service identity has been an important step in enabling turnkey solutions for end-to-end encryption and mutual authentication between services. The SPIFFE standards are backed by the OSS \u003ca href\u003d\"https://github.com/spiffe/spire\"\u003eSPIFFE Runtime Environment (SPIRE)\u003c/a\u003e, which automatically delivers cryptographically provable identities to services. \u003ca href\u003d\"/radar/platforms/istio\"\u003eIstio\u003c/a\u003e also uses SPIFFE by default. SPIFFE enables many use cases, including identity translation, OAuth client authentication, mTLS \"encryption everywhere\" and workload observability. ThoughtWorks is actively working with the Istio and SPIFFE communities to bridge the gap between legacy service identity providers and SPIFFE-based identities so that mTLS can be used everywhere between services, inside a service mesh and outside.\u003c/p\u003e","theta":"247","volume":"2019-04"},{"name":"Tendermint","id":"201904012","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"36","display_name":"Tendermint","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"https://en.wikipedia.org/wiki/Byzantine_fault\"\u003eByzantine fault tolerance (BFT)\u003c/a\u003e is one of the fundamental problems in cryptocurrency and blockchain systems. It requires overall system agreement on a single data value in the presence of a number of arbitrary faulty processes, which includes malicious fraud. \u003cstrong\u003e\u003ca href\u003d\"https://www.tendermint.com/\"\u003eTendermint\u003c/a\u003e\u003c/strong\u003e is a BFT state machine replication engine that lets you implement your own blockchain systems. The consensus engine, Tendermint Core, takes over the peer-to-peer communication and consensus part, you just need to implement the rest of the application (e.g., construct transaction and verify cryptographic signature) and communicate with Tendermint Core through \u003ca href\u003d\"https://github.com/tendermint/tendermint/tree/master/abci\"\u003eABCI\u003c/a\u003e. Some blockchain \u003ca href\u003d\"https://tendermint.com/ecosystem\"\u003eimplementations\u003c/a\u003e have already chosen Tendermint as their consensus engine.\u003c/p\u003e","theta":"255","volume":"2019-04"},{"name":"TimescaleDB","id":"201904050","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"37","display_name":"TimescaleDB","radius":"300","description":"\u003cp\u003eIn previous Radars we\u0027ve discussed \u003ca href\u003d\"/radar/platforms/postgresql-for-nosql\"\u003ePostgreSQL for NoSQL\u003c/a\u003e. PostgreSQL\u0027s maturity and extensibility have led to a steady stream of innovative persistence stores built on the Postgres engine. One that caught our attention is \u003cstrong\u003e\u003ca href\u003d\"https://www.timescale.com/\"\u003eTimescaleDB\u003c/a\u003e\u003c/strong\u003e, a database that allows fast writes and optimized queries over time-series data. Albeit not (yet) as full-featured as \u003ca href\u003d\"/radar/platforms/influxdb\"\u003eInfluxDB\u003c/a\u003e, TimescaleDB offers an alternative data model and querying capability. You should evaluate TimescaleDB if you have modest scalability needs, prefer to use SQL and appreciate the stability and familiar administrative interface that PostgreSQL offers.\u003c/p\u003e","theta":"262","volume":"2019-04"},{"name":"Cypress","id":"1149","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"38","display_name":"Cypress","radius":"80","description":"\u003cp\u003eWe keep receiving positive feedback on \"post-Selenium\" web UI testing tools such as \u003cstrong\u003e\u003ca href\u003d\"http://www.cypress.io/\"\u003eCypress\u003c/a\u003e\u003c/strong\u003e, \u003ca href\u003d\"/radar/tools/testcafe\"\u003eTestCafe\u003c/a\u003e and \u003ca href\u003d\"/radar/languages-and-frameworks/puppeteer\"\u003ePuppeteer\u003c/a\u003e. Running end-to-end tests can present challenges, such as the long duration of the running process, the flakiness of some tests and the challenges of fixing failures in CI when running tests in headless mode. Our teams have had very good experiences with Cypress by solving common issues such as lack of performance and long wait time for responses and resources to load. Cypress has become the tool of choice for end-to-end testing within our teams.\u003c/p\u003e","theta":"74","volume":"2019-04"},{"name":"Jupyter","id":"1154","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"39","display_name":"Jupyter","radius":"75","description":"\u003cp\u003eOver the past couple of years, we\u0027ve noticed a steady rise in the popularity of analytics notebooks. These are Mathematica-inspired applications that combine text, visualization and code in a living, computational document. \u003cstrong\u003e\u003ca href\u003d\"http://jupyter.org/\"\u003eJupyter\u003c/a\u003e\u003c/strong\u003e Notebooks are widely used by our teams for prototyping and exploration in analytics and machine learning. We\u0027ve moved Jupyter to Adopt for this issue of the Radar to reflect that it has emerged as the current default for Python notebooks. However, we caution to use \u003ca href\u003d\"/radar/techniques/productionizing-jupyter-notebooks\"\u003eJupyter Notebooks in production\u003c/a\u003e.\u003c/p\u003e","theta":"60","volume":"2019-04"},{"name":"LocalStack","id":"1271","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"40","display_name":"LocalStack","radius":"85","description":"\u003cp\u003eOne of the challenges of using cloud services is being able to develop and test locally. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/localstack/localstack\"\u003eLocalStack\u003c/a\u003e\u003c/strong\u003e solves this problem for \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e by providing local \u003ca href\u003d\"https://martinfowler.com/bliki/TestDouble.html\"\u003etest double\u003c/a\u003e implementations of a wide range of AWS services, including S3, Kinesis, DynamoDB and Lambda. It builds on top of best-of-breed tools such as \u003ca href\u003d\"https://github.com/mhart/kinesalite\"\u003eKinesalite\u003c/a\u003e, \u003ca href\u003d\"https://github.com/mhart/dynalite\"\u003edynalite\u003c/a\u003e and \u003ca href\u003d\"https://github.com/spulec/moto\"\u003eMoto\u003c/a\u003e and adds isolated processes and error injection functionality. LocalStack is very easy to use, ships with a simple JUnit runner and a JUnit 5 extension and can also run inside a docker container. For many teams, it has become the default for testing services that are deployed on AWS.\u003c/p\u003e","theta":"45","volume":"2019-04"},{"name":"Terraform","id":"815","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"41","display_name":"Terraform","radius":"65","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.terraform.io/\"\u003eTerraform\u003c/a\u003e\u003c/strong\u003e, is rapidly becoming a de facto choice for creating and managing cloud infrastructures by writing declarative definitions. The configuration of the servers instantiated by Terraform is usually left to Puppet, Chef or Ansible. We like Terraform because the syntax of its files is quite readable and because it supports a number of cloud providers while making no attempt to provide an artificial abstraction across those providers. The active community will add support for the latest features from most cloud providers. Following our first, more cautious, mention of Terraform almost two years ago, it has seen continued development and has evolved into a stable product with a good ecosystem that has proven its value in our projects. The issue with state file management can now be sidestepped by using what Terraform calls a \"remote state backend.\" We\u0027ve successfully used \u003ca href\u003d\"https://aws.amazon.com/s3/\"\u003eAWS S3\u003c/a\u003e for that purpose.\u003c/p\u003e","theta":"30","volume":"2019-04"},{"name":"UI dev environments","id":"1272","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"42","display_name":"UI dev environments","radius":"95","description":"\u003cp\u003eAs more and more teams embrace \u003ca href\u003d\"/radar/techniques/designops\"\u003eDesignOps\u003c/a\u003e, practices and tooling in this space mature. \u003cstrong\u003eUI dev environments\u003c/strong\u003e provide a comprehensive environment for quickly iterating on UI components, focusing on collaboration between user experience designers and developers. We now have a few options in this space: \u003ca href\u003d\"https://storybook.js.org/\"\u003eStorybook\u003c/a\u003e, \u003ca href\u003d\"https://react-styleguidist.js.org/\"\u003eReact Styleguidist\u003c/a\u003e, \u003ca href\u003d\"https://github.com/c8r\"\u003eCompositor\u003c/a\u003e and \u003ca href\u003d\"https://mdxjs.com/\"\u003eMDX\u003c/a\u003e. You can use these tools standalone in component library or design system development as well as embedded in a web application project. Many teams were able to decrease their UI feedback cycles and improve timing of UI work in preparation for development work, which has made using UI dev environments a reasonable default for us.\u003c/p\u003e","theta":"15","volume":"2019-04"},{"name":"AnyStatus","id":"201904006","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"43","display_name":"AnyStatus","radius":"200","description":"\u003cp\u003eAs developers used to pushing many small commits daily, we rely on monitors to notify us when builds go green. \u003cstrong\u003e\u003ca href\u003d\"https://www.anystat.us/\"\u003eAnyStatus\u003c/a\u003e\u003c/strong\u003e is a lightweight Windows desktop app that rolls up metrics and events from various sources into one place. Examples include build results and releases, health checks for different services and OS metrics. Think of it as CCTray on steroids. It\u0027s also available as a Visual Studio plugin.\u003c/p\u003e","theta":"82","volume":"2019-04"},{"name":"AVA","id":"201904036","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"44","display_name":"AVA","radius":"200","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/avajs/ava\"\u003eAVA\u003c/a\u003e\u003c/strong\u003e is a test runner for Node.js. Even though JavaScript is single-threaded, IO in Node.js can happen in parallel because of its asynchronous nature. AVA takes advantage of this and runs your tests concurrently, which is especially beneficial for IO-heavy tests. In addition, test files are run in parallel as separate processes, giving you even better performance and an isolated environment for each test file. AVA is a lightweight option, when compared to full-featured frameworks such as \u003ca href\u003d\"/radar/languages-and-frameworks/jest\"\u003eJest\u003c/a\u003e. It is opinionated and forces you to write atomic test cases.\u003c/p\u003e","theta":"74","volume":"2019-04"},{"name":"batect","id":"201904061","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"45","display_name":"batect","radius":"200","description":"\u003cp\u003eSo much energy and effort continue to be wasted on configuring local development environments and troubleshooting the \"works on my machine\" problem. For many years our teams have adopted the \u003ca href\u003d\"https://www.thoughtworks.com/insights/blog/praise-go-script-part-i\"\u003e\"check out and go\"\u003c/a\u003e approach where we use a scripted approach to ensure the local development environment is configured consistently. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/charleskorn/batect/\"\u003ebatect\u003c/a\u003e\u003c/strong\u003e is an open source tool developed by a ThoughtWorker that makes it easy to set up and share a build environment based on \u003ca href\u003d\"/radar/techniques/docker-for-builds\"\u003eDocker\u003c/a\u003e. batect becomes the entry point script for your build system, launching containers to perform build tasks that don\u0027t rely at all on local setup. Changes to build configuration and dependencies are simply shared through source control without requiring any changes or installations on local machines or CI agents. While we like \u003ca href\u003d\"/radar/tools/cage\"\u003eCage\u003c/a\u003e, among other tools, in this space, we see batect quickly growing in favor with our teams.\u003c/p\u003e","theta":"66","volume":"2019-04"},{"name":"Elasticsearch LTR","id":"201904018","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"46","display_name":"Elasticsearch LTR","radius":"200","description":"\u003cp\u003eOne of the challenges of search is ensuring the most relevant results for the user appear at the top of the list. This is where learning to rank (LTR) can help. LTR is the process of applying machine learning to rank documents retrieved by a search engine. If you\u0027re using \u003ca href\u003d\"/radar/platforms/elastic-search\"\u003eElasticsearch\u003c/a\u003e, you can achieve search-relevant ranking with the \u003ca href\u003d\"https://github.com/o19s/elasticsearch-learning-to-rank\"\u003e\u003cstrong\u003eElasticsearch LTR\u003c/strong\u003e\u003c/a\u003e plugin. The plugin uses \u003ca href\u003d\"https://sourceforge.net/p/lemur/wiki/RankLib/\"\u003eRankLib\u003c/a\u003e for generating the models during the training phase. Then, when querying Elasticsearch, you can use this plugin to \"rescore\" the top results. We\u0027ve used it in a few projects and have been happy with the results. There\u0027s also an equivalent \u003ca href\u003d\"http://lucene.apache.org/solr/guide/7_7/learning-to-rank.html\"\u003eLTR solution\u003c/a\u003e for Solr users.\u003c/p\u003e","theta":"58","volume":"2019-04"},{"name":"Helm","id":"1222","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"47","display_name":"Helm","radius":"265","description":"\u003cp\u003e\u003ca href\u003d\"http://helm.sh\"\u003e\u003cstrong\u003eHelm\u003c/strong\u003e\u003c/a\u003e is a package manager for \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e. It comes with a repository of curated Kubernetes applications that are maintained in the official \u003ca href\u003d\"https://github.com/helm/charts\"\u003eCharts repository\u003c/a\u003e. Helm has two components: a command line utility called Helm and a cluster component called Tiller. Securing a Kubernetes cluster is a wide and nuanced topic, but we highly recommend setting up Tiller in a role-based access control (RBAC) environment. We\u0027ve used Helm in a number of client projects and its dependency management, templating and hook mechanism has greatly simplified the application lifecycle management in Kubernetes. However, we recommend proceeding with caution — Helm\u0027s \u003ca href\u003d\"/radar/techniques/templating-in-yaml\"\u003eYAML templating\u003c/a\u003e can be difficult to understand, and Tiller still has some rough edges. Helm 3 is expected to address these issues.\u003c/p\u003e","theta":"50","volume":"2019-04"},{"name":"InSpec","id":"1113","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"48","display_name":"InSpec","radius":"190","description":"\u003cp\u003eHow does an organization give autonomy to delivery teams while still making sure their deployed solutions are safe and compliant? How do you ensure that servers, once deployed, maintain a consistent configuration without drift? \u003cstrong\u003e\u003ca href\u003d\"https://www.chef.io/inspec/\"\u003eInSpec\u003c/a\u003e\u003c/strong\u003e is positioned as a solution for continuous compliance and security, but you can also use it for general infrastructure testing. InSpec allows the creation of declarative infrastructure tests, which can then be continuously run against provisioned environments including production. Our teams particularly praise its extensible design with resources and matchers for multiple platforms. We recommend trialling InSpec as a solution to the problem of assuring compliance and security.\u003c/p\u003e","theta":"41","volume":"2019-04"},{"name":"Lottie","id":"201904024","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"49","display_name":"Lottie","radius":"200","description":"\u003cp\u003eGood UI animation could greatly improve user experience. However, to reproduce a designer\u0027s delicate animation on an app is usually a challenging task for developers. \u003cstrong\u003e\u003ca href\u003d\"http://airbnb.io/lottie/#/\"\u003eLottie\u003c/a\u003e\u003c/strong\u003e is a library for Android, iOS, web, and Windows that parses Adobe After Effects animations exported as JSON with Bodymovin and renders them natively on mobile and on the web. Both designers and developers can continue to use their familiar tools and have a fluent collaboration.\u003c/p\u003e","theta":"33","volume":"2019-04"},{"name":"Stolon","id":"201904023","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"50","display_name":"Stolon","radius":"180","description":"\u003cp\u003eSetting up highly available PostgreSQL instances can be tricky, which is why we like \u003ca href\u003d\"/radar/tools/patroni\"\u003ePatroni\u003c/a\u003e — it helps us speed up the setup of PostgreSQL clusters. \u003ca href\u003d\"https://github.com/sorintlab/stolon\"\u003e\u003cstrong\u003eStolon\u003c/strong\u003e\u003c/a\u003e is another tool that we\u0027ve used successfully to run high-availability (HA) clusters of PostgreSQL instances in production using Kubernetes. Although PostgreSQL supports streaming replication out of the box, the challenge in an HA setup is to assure that the clients always connect to the current master. We like that Stolon enforces the connection to the right PostgreSQL master by actively closing connections to unelected masters and routing requests to the active one.\u003c/p\u003e","theta":"25","volume":"2019-04"},{"name":"TestCafe","id":"1278","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"51","display_name":"TestCafe","radius":"200","description":"\u003cp\u003eWe have good experience using \"post-Selenium\" web UI testing tools such as \u003ca href\u003d\"/radar/tools/cypress\"\u003eCypress\u003c/a\u003e, \u003cstrong\u003e\u003ca href\u003d\"https://github.com/DevExpress/testcafe\"\u003eTestCafe\u003c/a\u003e\u003c/strong\u003e and \u003ca href\u003d\"/radar/languages-and-frameworks/puppeteer\"\u003ePuppeteer\u003c/a\u003e. TestCafe lets you write tests in JavaScript or \u003ca href\u003d\"/radar/languages-and-frameworks/typescript\"\u003eTypeScript\u003c/a\u003e and runs in-browser tests. TestCafe has several useful features that include out-of-the-box parallel execution and HTTP request mocking. TestCafe uses an asynchronous execution model with no explicit wait times, which results in much more stable test suites. Its selector API makes it easier to implement \u003ca href\u003d\"https://martinfowler.com/bliki/PageObject.html\"\u003ePageObject\u003c/a\u003e patterns. TestCafe recently released version 1.0.\u003cem\u003ex\u003c/em\u003e, which improved stability and functionality.\u003c/p\u003e","theta":"17","volume":"2019-04"},{"name":"Traefik","id":"1153","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"52","display_name":"Traefik","radius":"190","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://traefik.io/\"\u003eTraefik\u003c/a\u003e\u003c/strong\u003e is an open-source reverse proxy and load balancer. If you\u0027re looking for an edge proxy that provides simple routing without all the features of \u003ca href\u003d\"https://nginx.org\"\u003eNGINX\u003c/a\u003e and \u003ca href\u003d\"https://haproxy.org\"\u003eHAProxy\u003c/a\u003e, Traefik is a good choice. The router provides a reload-less reconfiguration, metrics, monitoring and circuit breakers that are essential when running microservices. It also integrates nicely with \u003ca href\u003d\"/radar/tools/let-s-encrypt\"\u003eLet\u0027s Encrypt\u003c/a\u003e to provide SSL termination as well as infrastructure components such as Kubernetes, Docker Swarm or Amazon ECS to automatically pick up new services or instances to include in its load balancing.\u003c/p\u003e","theta":"9","volume":"2019-04"},{"name":"Anka","id":"201904010","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"53","display_name":"Anka","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://ankadoc.bitbucket.io/\"\u003eAnka\u003c/a\u003e\u003c/strong\u003e is a set of tools to create, manage and distribute build and test macOS reproducible virtual environments for iOS and macOS development. It brings Docker-like experience to macOS environments: instant start, CLI to manage virtual machines and registry to version and tag virtual machines for distribution. We discovered Anka when we proposed a macOS private cloud solution to a client. This tool is worth considering when applying DevOps workflow to iOS and macOS environments.\u003c/p\u003e","theta":"84","volume":"2019-04"},{"name":"Cage","id":"201904022","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"54","display_name":"Cage","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://cage.faraday.io/\"\u003eCage\u003c/a\u003e\u003c/strong\u003e is an open-source wrapper around \u003ca href\u003d\"https://docs.docker.com/compose/\"\u003eDocker Compose\u003c/a\u003e that lets you configure and run multiple dependent components as a larger application. It lets you orchestrate the execution of components such as Docker images, service source code from repo, scripts to load datastores and pods, which are containers that run together as a unit. Cage uses the Docker Compose v2 configuration file format. It addresses some of the Docker Compose gaps such as supporting multiple environments, including the dev environment for running a distributed application on the local developer machine and the test environment for running integration tests and production.\u003c/p\u003e","theta":"78","volume":"2019-04"},{"name":"Cilium","id":"201904009","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"55","display_name":"Cilium","radius":"310","description":"\u003cp\u003eTraditional Linux network security approaches, such as iptables, filter on IP address and TCP/UDP ports. However, these IP addresses frequently churn in dynamic microservices environments. By leveraging Linux \u003ca href\u003d\"http://www.brendangregg.com/ebpf.html\"\u003eeBPF\u003c/a\u003e, \u003cstrong\u003e\u003ca href\u003d\"https://cilium.io/\"\u003eCilium\u003c/a\u003e\u003c/strong\u003e provides API-aware networking and security by transparently inserting security in a way that is based on service, pod or container identity in contrast to IP address identification. By decoupling security from addressing, Cilium could play a significant role as a new network protection layer and we recommend you to check it out.\u003c/p\u003e","theta":"72","volume":"2019-04"},{"name":"Detekt","id":"201904007","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"56","display_name":"Detekt","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/arturbosch/detekt\"\u003eDetekt\u003c/a\u003e\u003c/strong\u003e is a static code analysis tool for \u003ca href\u003d\"/radar/languages-and-frameworks/kotlin\"\u003eKotlin\u003c/a\u003e. It finds code smells and code complexity. You can run it from the command line or use its plugins for integration with popular developer tools such as \u003ca href\u003d\"/radar/tools/gradle\"\u003eGradle\u003c/a\u003e (to perform code analysis via builds) or \u003ca href\u003d\"https://www.sonarqube.org/\"\u003eSonarQube\u003c/a\u003e (to perform code coverage in addition to static code analysis), and IntelliJ. Detekt is a great addition to build pipelines of Kotlin applications.\u003c/p\u003e","theta":"66","volume":"2019-04"},{"name":"Flagr","id":"201904013","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"57","display_name":"Flagr","radius":"300","description":"\u003cp\u003e\u003ca href\u003d\"https://martinfowler.com/articles/feature-toggles.html\"\u003eFeature toggles\u003c/a\u003e are an important technique in continuous deployment scenarios. We\u0027ve come across a number of good home-grown solutions, but we do like the approach \u003cstrong\u003e\u003ca href\u003d\"https://github.com/checkr/flagr\"\u003eFlagr\u003c/a\u003e\u003c/strong\u003e takes: a complete feature toggle as a service, distributed as a Docker container. It comes with SDKs for all major languages, has a simple and well-documented REST API and provides a convenient frontend.\u003c/p\u003e","theta":"60","volume":"2019-04"},{"name":"Gremlin","id":"201904008","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"58","display_name":"Gremlin","radius":"290","description":"\u003cp\u003e\u003ca href\u003d\"https://www.gremlin.com/\"\u003e\u003cstrong\u003eGremlin\u003c/strong\u003e\u003c/a\u003e is a SaaS solution for organizations to conduct \u003ca href\u003d\"/radar/techniques/chaos-katas\"\u003echaos experiments\u003c/a\u003e and help test the resilience of their systems. It comes with a series of failure attacks — including resource, network and state failures — that can be run ad hoc or on schedule and require minimal setup (especially for \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e users, who can run \u003ca href\u003d\"/radar/tools/helm\"\u003eHelm\u003c/a\u003e to install Gremlin). The Gremlin client also has a nice web-based user interface, which makes it easy to execute and manage chaos experiments.\u003c/p\u003e","theta":"54","volume":"2019-04"},{"name":"Honeycomb","id":"201904021","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"59","display_name":"Honeycomb","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.honeycomb.io/\"\u003eHoneycomb\u003c/a\u003e\u003c/strong\u003e is an observability tool that ingests rich data from production systems and makes it manageable through dynamic sampling. Developers can log large amounts of rich events and decide later how to slice and correlate them. This interactive approach is useful when working with today\u0027s large distributed systems because we\u0027ve passed the point where we can reasonably anticipate which questions we might want to ask of production systems.\u003c/p\u003e","theta":"48","volume":"2019-04"},{"name":"Humio","id":"201904014","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"60","display_name":"Humio","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://humio.com/\"\u003eHumio\u003c/a\u003e\u003c/strong\u003e is a fairly new player in the log management space. It\u0027s been built from the ground up to be super fast at both log ingestion and query using its built-in query language on top of a custom-designed time series database. It integrates with just about everything out there from an ingestion, visualization and alerting perspective. The log management space has been dominated by Splunk and the ELK Stack, so having alternatives is a good thing. We\u0027ll be watching Humio\u0027s development with interest.\u003c/p\u003e","theta":"42","volume":"2019-04"},{"name":"Kubernetes Operators","id":"201904016","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"61","display_name":"Kubernetes Operators","radius":"285","description":"\u003cp\u003eWe\u0027re excited about the impact \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e has had on our industry but also concerned about the operational complexity that comes with it. Keeping a Kubernetes cluster up and running and then managing packages deployed on it requires special skills and time. Operational processes such as upgrades, migrations, backups, among others, can be a full-time job. We think that \u003cstrong\u003e\u003ca href\u003d\"https://coreos.com/operators/\"\u003eKubernetes Operators\u003c/a\u003e\u003c/strong\u003e will play a key role in reducing this complexity. The framework provides a standard mechanism to describe automated operational processes for packages running in a Kubernetes cluster. Although Operators were spearheaded and promoted by RedHat, several community-developed Operators for common open-source packages such as \u003ca href\u003d\"/radar/tools/jaeger\"\u003eJaeger\u003c/a\u003e, \u003ca href\u003d\"/radar/platforms/mongodb\"\u003eMongoDB\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/redis\"\u003eRedis\u003c/a\u003e have begun to emerge.\u003c/p\u003e","theta":"36","volume":"2019-04"},{"name":"OpenAPM","id":"201904017","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"62","display_name":"OpenAPM","radius":"300","description":"\u003cp\u003eOne of the challenges in adopting an open-source alternative to popular commercial packages is sorting through the complicated landscape of projects to understand which components you need, which ones play nicely together and exactly which part of a total solution each component covers. This is particularly difficult in the world of observability, where the standard practice is to purchase one comprehensive but pricey package to do it all. \u003cstrong\u003e\u003ca href\u003d\"https://openapm.io\"\u003eOpenAPM\u003c/a\u003e\u003c/strong\u003e makes the open-source selection process for observability tools easier. It displays the current crop of open-source packages classified by component roles, so you can interactively select compatible components. As long as you keep the tool up to date, it should help you navigate through the confusing array of possible tools.\u003c/p\u003e","theta":"30","volume":"2019-04"},{"name":"Systems","id":"201904019","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"63","display_name":"Systems","radius":"300","description":"\u003cp\u003eIt\u0027s easy to think of many of the processes we work within as linear chains of cause and effect. Most of the time we are working within more complex systems where positive and negative feedback loops influence outcomes. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/lethain/systems\"\u003eSystems\u003c/a\u003e\u003c/strong\u003e is a set of tools for describing, executing and visualizing systems diagrams. Using a compact DSL and running either standalone or within a Jupyter Notebook, it\u0027s super easy to describe fairly complex processes and the flow of information through them. It\u0027s pretty much a niche tool; but an interesting and fun one.\u003c/p\u003e","theta":"24","volume":"2019-04"},{"name":"Taurus","id":"201904020","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"64","display_name":"Taurus","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://gettaurus.org/\"\u003eTaurus\u003c/a\u003e\u003c/strong\u003e is a handy application and service performance testing tool written in Python. It wraps many performance testing executors, including \u003ca href\u003d\"/radar/tools/gatling\"\u003eGatling\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/locust\"\u003eLocust\u003c/a\u003e. You can run it from the command line and easily integrate it with continuous delivery pipelines to run performance tests at different stages of the pipeline. Taurus also has great reporting either as console text-based output or integrated with an interactive web UI. Our teams have found that configuring Taurus YAML files is easy because you can use multiple files to describe each test scenario and refer to underlying executer\u0027s scenario definitions.\u003c/p\u003e","theta":"18","volume":"2019-04"},{"name":"Terraform provider GoCD","id":"201904015","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"65","display_name":"Terraform provider GoCD","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/beamly/terraform-provider-gocd\"\u003eTerraform provider GoCD\u003c/a\u003e\u003c/strong\u003e lets you build pipelines using \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e, a mature and widely used tool in the \u003ca href\u003d\"/radar/tools/infrastructure-as-code\"\u003einfrastructure as code\u003c/a\u003e space. With this provider, you can write pipelines in the \u003ca href\u003d\"https://github.com/hashicorp/hcl\"\u003eHashiCorp Configuration Language (HCL)\u003c/a\u003e that use all of the functionality Terraform provides, including workspaces, modules and remote state. This approach is an excellent alternative to \u003ca href\u003d\"https://github.com/gocd-contrib/gomatic\"\u003eGomatic\u003c/a\u003e, which we highlighted in the \u003ca href\u003d\"/radar/techniques/pipelines-as-code\"\u003ePipelines as code\u003c/a\u003e blip before. The Golang SDK used in this provider has automatic regression tests for the GoCD API which should minimize issues while upgrading.\u003c/p\u003e","theta":"12","volume":"2019-04"},{"name":"Terratest","id":"201904011","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"66","display_name":"Terratest","radius":"300","description":"\u003cp\u003eWe widely use \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e as code to configure a cloud infrastructure. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/gruntwork-io/terratest\"\u003eTerratest\u003c/a\u003e\u003c/strong\u003e is a Golang library that makes it easier to write automated tests for infrastructure code. A test run creates real infrastructure components (such as servers, firewalls or load balancers), deploys applications on them and validates the expected behavior using Terratest. At the end of the test, Terratest can undeploy the apps and clean up resources. This makes it largely useful for end-to-end tests of your infrastructure in a real environment.\u003c/p\u003e","theta":"6","volume":"2019-04"},{"name":"Handwritten CloudFormation","id":"201904003","quadrant":"Tools","ring":"Hold","movement":"t","radarId":"67","display_name":"Handwritten CloudFormation","radius":"375","description":"\u003cp\u003e\u003ca href\u003d\"https://aws.amazon.com/cloudformation/\"\u003eAWS CloudFormation\u003c/a\u003e is a proprietary declarative language to provision AWS infrastructure as code. Handwriting CloudFormation files is often a default approach to bootstrap AWS infrastructure automation. Although this might be a sensible way to start a small project, our teams, and the industry at large, have found that \u003cstrong\u003ehandwritten CloudFormation\u003c/strong\u003e simply does not scale as the infrastructure grows. Noticeable pitfalls of handwritten CloudFormation files for large projects include poor readability, lack of imperative constructs, limited parameter definition and usage, and lack of type checking. Addressing these shortfalls has led to a rich ecosystem of both open-source and custom tooling. We find \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e a sensible default that not only addresses shortfalls of CloudFormation but also has an active community to add the latest AWS features and fix bugs. In addition to Terraform, you can choose from many other tools and languages, including \u003ca href\u003d\"/radar/languages-and-frameworks/troposphere\"\u003etroposphere\u003c/a\u003e, \u003ca href\u003d\"https://github.com/cloudreach/sceptre\"\u003esceptre\u003c/a\u003e, \u003ca href\u003d\"https://github.com/capitalone/stack-deployment-tool\"\u003eStack Deployment Tool\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/pulumi\"\u003ePulumi\u003c/a\u003e.\u003c/p\u003e","theta":"45","volume":"2019-04"},{"name":"Apollo","id":"1239","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"68","display_name":"Apollo","radius":"100","description":"\u003cp\u003eOur teams report that \u003cstrong\u003e\u003ca href\u003d\"http://www.apollographql.com/client\"\u003eApollo\u003c/a\u003e\u003c/strong\u003e has become the library of choice when building a \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e application that uses GraphQL to access data from a \u003ca href\u003d\"/radar/techniques/bff-backend-for-frontends\"\u003eback-end\u003c/a\u003e service. Although the Apollo project also provides a server framework and a GraphQL gateway, the Apollo client gets our attention because it simplifies the problem of binding UI components to data served by any GraphQL backend. Put simply, this means less code needs to be written than using REST backends and redux.\u003c/p\u003e","theta":"292","volume":"2019-04"},{"name":"MockK","id":"1315","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"69","display_name":"MockK","radius":"130","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://mockk.io\"\u003eMockK\u003c/a\u003e\u003c/strong\u003e is our go-to tool for mocks when writing tests for \u003ca href\u003d\"/radar/languages-and-frameworks/kotlin\"\u003eKotlin\u003c/a\u003e applications. We like to use this library because of its first-class support for Kotlin language features such as \u003ca href\u003d\"https://kotlinlang.org/docs/reference/coroutines-overview.html\"\u003ecoroutines\u003c/a\u003e or lambda blocks. As a native library, it helps our teams to write clean and concise code on testing Kotlin applications instead of using the inconvenient wrappers of Mockito or PowerMock.\u003c/p\u003e","theta":"315","volume":"2019-04"},{"name":"TypeScript","id":"681","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"70","display_name":"TypeScript","radius":"130","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.typescriptlang.org/\"\u003eTypeScript\u003c/a\u003e\u003c/strong\u003e, a statically typed language and superset of JavaScript, has become our sensible default. Large-scale projects benefit most from the type safety. Our developers favor its minimal configuration management, well-integrated IDE support and its ability to refactor code safely and gradually adopt types. With its \u003ca href\u003d\"https://definitelytyped.org/\"\u003egood repository\u003c/a\u003e of TypeScript-type definitions at hand, we benefit from all the rich JavaScript libraries while gaining type safety.\u003c/p\u003e","theta":"337","volume":"2019-04"},{"name":"Apache Beam","id":"1320","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"71","display_name":"Apache Beam","radius":"170","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://beam.apache.org/\"\u003eApache Beam\u003c/a\u003e\u003c/strong\u003e is an open-source unified programming model for defining and executing both batch and streaming data parallel processing pipelines. The Beam model is based on the \u003ca href\u003d\"http://www.vldb.org/pvldb/vol8/p1792-Akidau.pdf\"\u003eDataflow model\u003c/a\u003e which allows us to express logic in an elegant way so that we can easily switch between batch, windowed batch or streaming. The big data-processing ecosystem has been evolving quite a lot which can make it difficult to choose the right data-processing engine. One of the key reasons to choose Beam is that it allows us to switch between different runners — a few months ago \u003ca href\u003d\"http://samza.apache.org/\"\u003eApache Samza\u003c/a\u003e was added to the other runners it already supports, which include \u003ca href\u003d\"https://spark.apache.org/\"\u003eApache Spark\u003c/a\u003e, \u003ca href\u003d\"https://flink.apache.org/\"\u003eApache Flink\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/google-cloud-dataflow\"\u003eGoogle Cloud Dataflow\u003c/a\u003e. Different runners have different capabilities and providing a portable API is a difficult task. Beam tries to strike a delicate balance by actively pulling innovations from these runners into the Beam model and also working with the community to influence the roadmap of these runners. Beam has SDKs in multiple languages including Java, Python and Golang. We\u0027ve also had success using \u003ca href\u003d\"https://github.com/spotify/scio\"\u003eScio\u003c/a\u003e which provides a Scala wrapper around Beam.\u003c/p\u003e","theta":"278","volume":"2019-04"},{"name":"Formik","id":"201904043","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"72","display_name":"Formik","radius":"260","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://jaredpalmer.com/formik/\"\u003eFormik\u003c/a\u003e\u003c/strong\u003e is a useful higher-order component for making the surprisingly verbose and complex job of handling forms in \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e much easier. It localizes state management, assists with submission and optionally uses \u003ca href\u003d\"https://www.npmjs.com/package/yup\"\u003eYup\u003c/a\u003e to simplify data validation.\u003c/p\u003e","theta":"283","volume":"2019-04"},{"name":"HiveRunner","id":"201904044","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"73","display_name":"HiveRunner","radius":"210","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/klarna/HiveRunner\"\u003eHiveRunner\u003c/a\u003e\u003c/strong\u003e is an open-source unit test framework for Apache Hadoop \u003ca href\u003d\"/radar/languages-and-frameworks/hive\"\u003eHive\u003c/a\u003e queries based on JUnit4. When writing nontrivial analytics or data pipelines in Hive SQL, we found HiveRunner to be a good enabler for writing tests and even TDDing out some moderately complicated SQL. HiveRunner enables you to write Hive SQL as releasable tested artifacts.\u003c/p\u003e","theta":"290","volume":"2019-04"},{"name":"joi","id":"201904042","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"74","display_name":"joi","radius":"260","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/hapijs/joi\"\u003ejoi\u003c/a\u003e\u003c/strong\u003e is a schema description language and validator for JavaScript objects. We like that joi is independent of any web application framework, so our teams can use the same schemas across different stacks. You can also use companion libraries to generate Swagger documentation for APIs that validate requests with joi schemas.\u003c/p\u003e","theta":"297","volume":"2019-04"},{"name":"Ktor","id":"1295","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"75","display_name":"Ktor","radius":"190","description":"\u003cp\u003e\u003ca href\u003d\"/radar/languages-and-frameworks/kotlin\"\u003eKotlin\u003c/a\u003e has demonstrated its value beyond mobile app development. When building microservices and shipping software to production, our teams have had good experiences with Ktor. \u003cstrong\u003e\u003ca href\u003d\"https://ktor.io\"\u003eKtor\u003c/a\u003e\u003c/strong\u003e is a framework that, unlike other web frameworks that support Kotlin, is written in Kotlin, using language features such as \u003ca href\u003d\"https://kotlinlang.org/docs/reference/coroutines-overview.html\"\u003ecoroutines\u003c/a\u003e which allow for an asynchronous nonblocking implementation. The flexibility to incorporate different tools for logging, DI or a template engine — in addition to its lightweight architecture — makes Ktor an interesting option for creating RESTful services.\u003c/p\u003e","theta":"304","volume":"2019-04"},{"name":"Laconia","id":"201904100","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"76","display_name":"Laconia","radius":"265","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://laconiajs.io/\"\u003eLaconia\u003c/a\u003e\u003c/strong\u003e is a framework for developing \u003ca href\u003d\"/radar/platforms/aws-lambda\"\u003eAWS Lambda\u003c/a\u003e functions in JavaScript. As interest and use of serverless tech has grown so has the complexity of the applications being built. Laconia is a small, lightweight framework that takes away some of the rough edges we often encounter. It uses dependency injection to isolate your application code from lower-level AWS APIs and provides adaptors for the different events that your application can respond too. It also plays nicely with the \u003ca href\u003d\"/radar/tools/serverless-framework\"\u003eServerless Framework\u003c/a\u003e at deploy time. We like small and simple frameworks and Laconia is just that.\u003c/p\u003e","theta":"311","volume":"2019-04"},{"name":"Puppeteer","id":"1324","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"77","display_name":"Puppeteer","radius":"170","description":"\u003cp\u003eMuch like \u003ca href\u003d\"/radar/tools/cypress\"\u003eCypress\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/testcafe\"\u003eTestCafe\u003c/a\u003e, \u003cstrong\u003e\u003ca href\u003d\"https://pptr.dev/\"\u003ePuppeteer\u003c/a\u003e\u003c/strong\u003e is one of the web UI testing tools garnering praise from our teams. Puppeteer can have fine-grained control over headless browsers, obtain time-trace for performance diagnostics and more. Our teams have found Puppeteer to be stable as well as faster and more flexible than alternatives based on WebDriver.\u003c/p\u003e","theta":"318","volume":"2019-04"},{"name":"Reactor","id":"1243","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"78","display_name":"Reactor","radius":"190","description":"\u003cp\u003eWe\u0027ve talked about \u003cstrong\u003e\u003ca href\u003d\"http://projectreactor.io\"\u003eReactor\u003c/a\u003e\u003c/strong\u003e in the previous Radars. It has continued to gain traction in many of our projects. With the Spring ecosystem embracing Reactor, it has become the dominant implementation of \u003ca href\u003d\"http://www.reactive-streams.org/\"\u003eReactive Streams\u003c/a\u003e. Reactive systems come with improved scalability and resilience but with increased cost of debugging and a steeper learning curve. For those projects where this tradeoff is acceptable, Reactor has proven to be a good choice. Some of our projects have observed significant improvements in scalability once they moved to Reactor and the rest of the Reactive stack. With \u003ca href\u003d\"http://r2dbc.io/\"\u003eR2DBC\u003c/a\u003e we are starting to get reactive support for RDBMS drivers which addresses one of the weaknesses of reactive services.\u003c/p\u003e","theta":"325","volume":"2019-04"},{"name":"Resilience4j","id":"201904031","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"79","display_name":"Resilience4j","radius":"250","description":"\u003cp\u003e\u003ca href\u003d\"https://github.com/resilience4j/resilience4j\"\u003e\u003cstrong\u003eResilience4j\u003c/strong\u003e\u003c/a\u003e is a lightweight fault tolerance library inspired by Netflix \u003ca href\u003d\"/radar/tools/hystrix\"\u003eHystrix\u003c/a\u003e. We like its lightweight and modular structure where we pull in specific modules for specific capabilities such as circuit-breaking, rate-limiting, retry, and bulkhead. While \u003ca href\u003d\"/radar/techniques/service-mesh\"\u003eservice meshes\u003c/a\u003e are taking on some of the fault tolerance capabilities, fault tolerance libraries continue to remain a key component of our systems for more nuanced domain-specific fault tolerance behavior and for non-containerized services. With Hystrix going into \u003ca href\u003d\"https://github.com/Netflix/Hystrix/commit/a7df971cbaddd8c5e976b3cc5f14013fe6ad00e6#diff-04c6e90faac2675aa89e2176d2eec7d8\"\u003emaintenance mode\u003c/a\u003e, Resilience4j becomes a default choice in the Java ecosystem. It can work with synchronous APIs as well as reactive ones. It also surfaces metrics to \u003ca href\u003d\"https://metrics.dropwizard.io/4.0.0/\"\u003edropwizard metrics\u003c/a\u003e, \u003ca href\u003d\"/radar/tools/prometheus\"\u003ePrometheus\u003c/a\u003e and others using additional modules.\u003c/p\u003e","theta":"332","volume":"2019-04"},{"name":"Room","id":"201904045","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"80","display_name":"Room","radius":"210","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://developer.android.com/topic/libraries/architecture/room\"\u003eRoom\u003c/a\u003e\u003c/strong\u003e is a persistence library to access SQLite on Android. It makes database access code much simpler, with minimal boilerplate code, and more robust, with compile-time verification of SQL queries. Our developers like its complete integration with observable queries, using \u003ca href\u003d\"https://developer.android.com/topic/libraries/architecture/livedata\"\u003eLiveData\u003c/a\u003e. Room is one of the Android \u003ca href\u003d\"https://developer.android.com/jetpack\"\u003eJetpack\u003c/a\u003e components that were created to make application development on Android easier.\u003c/p\u003e","theta":"339","volume":"2019-04"},{"name":"Rust","id":"771","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"81","display_name":"Rust","radius":"160","description":"\u003cp\u003eSince we last featured it on the Radar in January 2015, we\u0027ve seen steadily increasing interest in \u003cstrong\u003e\u003ca href\u003d\"http://www.rust-lang.org/\"\u003eRust\u003c/a\u003e\u003c/strong\u003e. Some of our clients are now using Rust, mostly in the context of infrastructure tooling but also in high-powered embedded devices. Interest was fuelled by a growing ecosystem as well as improvements to the language itself. The latter included straightforward performance improvements but also changes that make Rust more intuitive, for example the change to non-lexical scoping. Most of the significant changes are included in the Rust 2018 standard released last December.\u003c/p\u003e","theta":"346","volume":"2019-04"},{"name":"WebFlux","id":"1321","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"82","display_name":"WebFlux","radius":"220","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html\"\u003eWebFlux\u003c/a\u003e\u003c/strong\u003e is the Spring Framework implementation of \u003ca href\u003d\"https://www.reactive-streams.org/\"\u003eReactive Streams\u003c/a\u003e. We see a rise in reactive programming models across our teams in general and the use of WebFlux in teams who are working in the Spring ecosystem. It\u0027s best used in large microservices ecosystems where the high performance of the requests is a major concern. It allows overlapping request processing asynchronously without the complications of using multiple threads. WebFlux uses \u003ca href\u003d\"https://github.com/reactor/reactor\"\u003eReactor\u003c/a\u003e as its reactive library but it is interoperable with other reactive libraries via Reactive Streams. It uses \u003ca href\u003d\"https://netty.io/\"\u003eNetty\u003c/a\u003e as its underlying high-performance communications engine. Although we encourage using Reactive Streams, adopting this programming model requires a significant shift in thinking.\u003c/p\u003e","theta":"353","volume":"2019-04"},{"name":"Aeron","id":"201904029","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"83","display_name":"Aeron","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/real-logic/aeron\"\u003eAeron\u003c/a\u003e\u003c/strong\u003e is an efficient and reliable peer-to-peer message transport. It provides a replicated persistent log of messages via a number of media drivers, including HTTP, UDP and TCP. It also supports persistent storage of message streams for later replay. For many applications, Aeron may be overkill because it operates at a pretty low level (OSI Layer 4 conceptually), but it\u0027s peer-to-peer design and low (and predictable) latency are useful in a number of use cases. Indeed, we\u0027ve found it to be useful in certain machine learning applications as well as playing a part in event-driven architectures. We think it\u0027s worth pointing out that alternative messaging protocols exist that don\u0027t require additional services such as \u003ca href\u003d\"/radar/tools/apache-kafka\"\u003eApache Kafka\u003c/a\u003e to be run.\u003c/p\u003e","theta":"275","volume":"2019-04"},{"name":"Arrow","id":"201904040","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"84","display_name":"Arrow","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://arrow-kt.io/\"\u003eArrow\u003c/a\u003e\u003c/strong\u003e is a functional programming library for \u003ca href\u003d\"/radar/languages-and-frameworks/kotlin\"\u003eKotlin\u003c/a\u003e, created by merging two existing popular libraries (\u003ca href\u003d\"https://github.com/JcMinarro/kategory\"\u003ekategory\u003c/a\u003e and \u003ca href\u003d\"https://github.com/MarioAriasC/funKTionale\"\u003efunKTionale\u003c/a\u003e). While Kotlin provides building blocks for functional programming, Arrow delivers a package of ready-to-use higher-level abstractions for application developers. It provides data types, type classes, effects, optics and other functional programming patterns as well as integrations with popular libraries. With Arrow, existing libraries are unified, which should go a long way to avoid fractured communities in this space.\u003c/p\u003e","theta":"280","volume":"2019-04"},{"name":"Chaos Toolkit","id":"201904028","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"85","display_name":"Chaos Toolkit","radius":"290","description":"\u003cp\u003eThe \u003cstrong\u003e\u003ca href\u003d\"https://chaostoolkit.org/\"\u003eChaos Toolkit\u003c/a\u003e\u003c/strong\u003e is one of a number of \u003ca href\u003d\"/radar/techniques/chaos-engineering\"\u003eChaos Engineering\u003c/a\u003e tools that made this edition of the Radar. You use the toolkit to describe and then run repeatable experiments on your infrastructure to understand its resilience in the event of failure. Many of our teams have been using homegrown tools to do this, so it\u0027s great to see an open-source project dedicated to the practice. The toolkit already has drivers for \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e, \u003ca href\u003d\"/radar/platforms/azure-service-fabric\"\u003eAzure Service Fabric\u003c/a\u003e and GCE (among others) and plays nicely with build tools which lets you experiment with automation. The usual caveats apply though, Chaos Engineering is a very powerful technique that is best used on resilience-aware systems, that is, systems that have been built to cope with failure. For that reason, we recommend starting using Chaos Toolkit in your nonproduction environments first.\u003c/p\u003e","theta":"285","volume":"2019-04"},{"name":"Dask","id":"201904026","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"86","display_name":"Dask","radius":"330","description":"\u003cp\u003eData scientists and engineers often use libraries such as \u003ca href\u003d\"https://pandas.pydata.org/\"\u003epandas\u003c/a\u003e to perform ad hoc data analysis. Although expressive and powerful, these libraries have one critical limitation: they only work on a single CPU and don\u0027t provide horizontal scalability for large data sets. \u003ca href\u003d\"https://dask.org/\"\u003e\u003cstrong\u003eDask\u003c/strong\u003e\u003c/a\u003e, however, includes a lightweight, high-performance scheduler that can scale from a laptop to a cluster of machines. And because it works with \u003ca href\u003d\"http://www.numpy.org/\"\u003eNumPy\u003c/a\u003e, pandas and \u003ca href\u003d\"/radar/tools/scikit-learn\"\u003eScikit-learn\u003c/a\u003e, Dask looks promising for further assessment.\u003c/p\u003e","theta":"291","volume":"2019-04"},{"name":"Embark","id":"201904004","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"87","display_name":"Embark","radius":"300","description":"\u003cp\u003eWe\u0027ve recommended \u003ca href\u003d\"/radar/languages-and-frameworks/truffle\"\u003eTruffle\u003c/a\u003e for \u003ca href\u003d\"/radar/techniques/ethereum-for-decentralized-applications\"\u003edecentralized application\u003c/a\u003e (dapp) development in the past. \u003cstrong\u003e\u003ca href\u003d\"https://embark.status.im/\"\u003eEmbark\u003c/a\u003e\u003c/strong\u003e too can make your work easier. Embark provides features such as scaffolding, building, testing and debugging and integrates with decentralized storages such as \u003ca href\u003d\"/radar/platforms/ipfs\"\u003eIPFS\u003c/a\u003e. Through its declarative configuration, you can manage \u003ca href\u003d\"/radar/techniques/smart-contracts\"\u003esmart contract\u003c/a\u003e configuration, dependencies, artifact and deployment quite easily. Embark\u0027s interactive CLI dashboard is also impressive. We keep seeing people use \u003ca href\u003d\"https://remix.ethereum.org\"\u003eRemix\u003c/a\u003e to write smart contracts and manually deploy their apps without automated testing, source control management or artifact management. We\u0027d like to draw people\u0027s attention to dapp engineering practice by promoting tools such as Truffle and Embark.\u003c/p\u003e","theta":"296","volume":"2019-04"},{"name":"fastai","id":"201904041","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"88","display_name":"fastai","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://docs.fast.ai/\"\u003efastai\u003c/a\u003e\u003c/strong\u003e is an open-source Python library that simplifies training fast and accurate neural nets. It is built on top of \u003ca href\u003d\"/radar/languages-and-frameworks/pytorch\"\u003ePyTorch\u003c/a\u003e and has become a popular tool for our data scientists. fastai simplifies painful aspects of model training such as preprocessing and loading data down to a few lines of code. It\u0027s built on deep learning best practices and has out-of-the-box support for computer vision, natural language processing (NLP) and more. The founders\u0027 motivation has been to create an easy-to-use library for deep learning and an improved successor to \u003ca href\u003d\"/radar/languages-and-frameworks/keras\"\u003eKeras\u003c/a\u003e. \u003ca href\u003d\"/radar/platforms/google-cloud-platform\"\u003eGCP\u003c/a\u003e, \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/azure\"\u003eAzure\u003c/a\u003e all have already included fastai in their machine images. The creators of fastai, acknowledging the speed and safety limitations of Python, have announced \u003ca href\u003d\"https://www.fast.ai/2019/03/06/fastai-swift/\"\u003eembracing Swift\u003c/a\u003e as an alternative language for deep learning. We\u0027ll be closely watching this space.\u003c/p\u003e","theta":"301","volume":"2019-04"},{"name":"http4k","id":"201904033","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"89","display_name":"http4k","radius":"295","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.http4k.org/\"\u003ehttp4k\u003c/a\u003e\u003c/strong\u003e is an HTTP toolkit written in pure \u003ca href\u003d\"/radar/languages-and-frameworks/kotlin\"\u003eKotlin\u003c/a\u003e for serving and consuming HTTP services. One of the key ideas behind http4k is that HTTP apps are modelled by composing two simple functions — HttpHandler and Filter. They derive inspiration from Twitter\u0027s \u003ca href\u003d\"https://monkey.org/%7Emarius/funsrv.pdf\"\u003e\"Your Server as a Function\"\u003c/a\u003e paper. It\u0027s very lightweight with the core module having no dependencies apart from Kotlin StdLib. Apart from its elegance and simplicity, we also like its emphasis on testability — given that the entities in the libraries are immutable and the routes in the app, as well as the app itself, are just functions, they\u0027re super easy to test. One of the things to be aware of, though, is that we don\u0027t have nonblocking or coroutines support in http4k yet.\u003c/p\u003e","theta":"307","volume":"2019-04"},{"name":"Immer","id":"201904034","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"90","display_name":"Immer","radius":"320","description":"\u003cp\u003eWith the increasing complexity of single-page JavaScript applications, managing state predictably is becoming more and more important. Immutability can help to ensure our applications behave consistently, but unfortunately JavaScript doesn\u0027t natively support the ability to create immutable objects. Libraries such as \u003ca href\u003d\"/radar/languages-and-frameworks/immutable-js\"\u003eImmutable.js\u003c/a\u003e filled that gap but introduced new problems because now two kinds of objects and arrays existed in the application, the library\u0027s version and the native JavaScript ones. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/mweststrate/immer\"\u003eImmer\u003c/a\u003e\u003c/strong\u003e — German for \u003cem\u003ealways\u003c/em\u003e — is a tiny package that lets you work with immutable state in a more convenient way. It\u0027s based on the copy-on-write mechanism, has a minimal API and operates on normal JavaScript objects and arrays. This means that data access is seamless and no large refactoring efforts are needed when introducing immutability to an existing codebase.\u003c/p\u003e","theta":"312","volume":"2019-04"},{"name":"Karate","id":"201904027","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"91","display_name":"Karate","radius":"295","description":"\u003cp\u003eGiven our experience that tests are the only API specifications that really matter, we\u0027re always on the lookout for new tools that might help. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/karatelabs/karate\"\u003eKarate\u003c/a\u003e\u003c/strong\u003e is an API testing framework whose unique feature is that tests are written directly in Gherkin without relying on a general-purpose programming language to implement test behavior. Karate is really a domain-specific language for describing HTTP-based API tests. Although this approach is interesting and makes for some very readable specifications for simple tests, the special-purpose language for matching and validating payloads can become quite syntax-heavy and difficult to understand. It remains to be seen if more complex tests written in this style will be readable and maintainable over the long haul.\u003c/p\u003e","theta":"317","volume":"2019-04"},{"name":"Micronaut","id":"201904032","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"92","display_name":"Micronaut","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://micronaut.io/\"\u003eMicronaut\u003c/a\u003e\u003c/strong\u003e is a new JVM framework for building microservices using Java, \u003ca href\u003d\"/radar/languages-and-frameworks/kotlin\"\u003eKotlin\u003c/a\u003e or Groovy. It distinguishes itself through a small memory footprint and short startup time. It achieves these improvements by avoiding runtime reflection for DI and proxy generation, a common shortcoming of traditional frameworks, and instead uses a \u003ca href\u003d\"https://martinfowler.com/articles/injection.html\"\u003eDI\u003c/a\u003e/\u003ca href\u003d\"https://en.wikipedia.org/wiki/Aspect-oriented_programming\"\u003eAOP\u003c/a\u003e container which performs dependency injection at compile time. This makes it attractive not just for standard server-side microservices but also in the context of, for example, the Internet of Things, Android applications and serverless functions. Micronaut uses Netty and has first-class support for reactive programming. It also includes many features that make it cloud-native friendly such as service discovery and circuit breaking. Micronaut is a very promising entrant to the full stack framework for the JVM space and we\u0027re keenly watching it.\u003c/p\u003e","theta":"322","volume":"2019-04"},{"name":"Next.js","id":"201904030","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"93","display_name":"Next.js","radius":"300","description":"\u003cp\u003e\u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e has revolutionized the way most people write single-page JavaScript applications. Generally, we recommend you use Create React App throughout the application lifecycle so you don\u0027t have to configure your setup, builds and packages manually. But some developers will prefer a tool whose initial defaults reflect a sound set of opinions. \u003cstrong\u003e\u003ca href\u003d\"https://nextjs.org/\"\u003eNext.js\u003c/a\u003e\u003c/strong\u003e is just such an opinionated framework and it is garnering quite a bit of interest among our front-end enthusiasts. Next.js simplifies routing, renders on the server side by default and streamlines dependencies and builds. We\u0027re keen to see if it lives up to expectations on our own projects.\u003c/p\u003e","theta":"328","volume":"2019-04"},{"name":"Pose","id":"201904005","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"94","display_name":"Pose","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://popmotion.io/pose/\"\u003ePose\u003c/a\u003e\u003c/strong\u003e is a simple CSS-like animation library for \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e, \u003ca href\u003d\"/radar/languages-and-frameworks/react-native\"\u003eReact Native\u003c/a\u003e and \u003ca href\u003d\"/radar/languages-and-frameworks/vue-js\"\u003eVue.js\u003c/a\u003e frameworks. It is a declarative motion system that combines the simplicity of CSS syntax with the power and flexibility of JavaScript animations and interactions.\u003c/p\u003e","theta":"333","volume":"2019-04"},{"name":"react-testing-library","id":"201904035","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"95","display_name":"react-testing-library","radius":"285","description":"\u003cp\u003eAs the pace of change in JavaScript frameworks has slowed, our teams have more time to work with specific frameworks and are gaining deeper insights as a result. With \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e and the dominant testing framework, \u003ca href\u003d\"/radar/languages-and-frameworks/enzyme\"\u003eEnzyme\u003c/a\u003e, we\u0027ve observed a worrying trend of unit tests becoming tightly coupled to implementation details without providing — because the focus is on shallow details — much confidence that features work as expected. These unit tests make evolving the design difficult and they shift too much responsibility up the test pyramid to functional testing. This has made us revisit the idea of \u003ca href\u003d\"https://www.martinfowler.com/bliki/SubcutaneousTest.html\"\u003esubcutaneous testing\u003c/a\u003e. Additionally, because of its design, \u003ca href\u003d\"https://github.com/airbnb/enzyme/issues/1917\"\u003eEnzyme has issues\u003c/a\u003e trying to keep up with React\u0027s development. All this has pushed us toward assessing \u003cstrong\u003e\u003ca href\u003d\"https://github.com/kentcdodds/react-testing-library\"\u003ereact-testing-library\u003c/a\u003e\u003c/strong\u003e as a new framework for testing React applications.\u003c/p\u003e","theta":"338","volume":"2019-04"},{"name":"ReasonML","id":"201904038","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"96","display_name":"ReasonML","radius":"335","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://reasonml.github.io/\"\u003eReasonML\u003c/a\u003e\u003c/strong\u003e is an interesting new language based on OCaml with a sprinkling of C-like syntax and uses JavaScript as the default compilation target. Created by Facebook, it allows embedded JavaScript snippets and JSX templating with good \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e integration. It aims to be approachable for JavaScript developers and leverages that ecosystem, while providing type safety in a functional language.\u003c/p\u003e","theta":"344","volume":"2019-04"},{"name":"Taiko","id":"201904025","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"97","display_name":"Taiko","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/getgauge/taiko\"\u003eTaiko\u003c/a\u003e\u003c/strong\u003e is a node.js library with a clear and concise API to assist with chrome or chromium browser automation. You can leverage Taiko\u0027s smart selectors and write reliable tests as the structure of the web application evolves. There\u0027s no need for ID, CSS or XPath selectors or adding explicit waits (for XHR requests) in test scripts. The interactive REPL recorder comes in handy when you want to develop the tests side by side as you explore the functionality. Although you could use Taiko independently, we\u0027ve had good success using it with \u003ca href\u003d\"/radar/tools/gauge\"\u003eGauge\u003c/a\u003e.\u003c/p\u003e","theta":"349","volume":"2019-04"},{"name":"Vapor","id":"201904039","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"98","display_name":"Vapor","radius":"335","description":"\u003cp\u003eWe\u0027re strong proponents of \u003ca href\u003d\"/radar/techniques/polyglot-programming\"\u003epolyglot programming\u003c/a\u003e but recognize that in some cases it can make sense to focus on a single programming language. If you\u0027re heavily invested in Swift, most likely because of iOS development, and you find yourself looking for a technology to write server-side services, have a look at \u003cstrong\u003e\u003ca href\u003d\"https://vapor.codes/\"\u003eVapor\u003c/a\u003e\u003c/strong\u003e, a modern web framework for Swift that has gained a fair amount of popularity.\u003c/p\u003e","theta":"354","volume":"2019-04"}],"date":"2019-04"},{"blips":[{"name":"Container security scanning","id":"1041","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"1","display_name":"Container security scanning","radius":"75","description":"\u003cp\u003eThe continued adoption of containers for deployments, especially \u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e, has made \u003cstrong\u003econtainer security scanning\u003c/strong\u003e a must-have technique and we\u0027ve moved this technique into Adopt to reflect that. Specifically, containers introduced a new path for security issues; it\u0027s vital that you use tools to scan and check containers during deployment. We prefer using automated scanning tools that run as part of the deployment pipeline.\u003c/p\u003e","theta":"164","volume":"2019-11"},{"name":"Data integrity at the origin","id":"201911043","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"2","display_name":"Data integrity at the origin","radius":"90","description":"\u003cp\u003eToday, many organizations\u0027 answer to unlocking data for analytical usage is to build a labyrinth of data pipelines. Pipelines retrieve data from one or multiple sources, cleanse it and then transform and move it to another location for consumption. This approach to data management often leaves the consuming pipelines with the difficult task of verifying the inbound data\u0027s integrity and building complex logic to cleanse the data to meet its required level of quality. The fundamental problem is that the source of the data has no incentive and accountability for providing quality data to its consumers. For this reason, we strongly advocate for \u003cstrong\u003edata integrity at the origin\u003c/strong\u003e, by which we mean, any source that provides consumable data must describe its measures of data quality explicitly and guarantee those measures. The main reason behind this is that the originating systems and teams are most intimately familiar with their data and best positioned to fix it at the source. \u003ca href\u003d\"/radar/techniques/data-mesh\"\u003eData mesh\u003c/a\u003e architecture takes this one step further, comparing consumable data to a \u003cem\u003eproduct\u003c/em\u003e, where data quality and its objectives are integral attributes of every shared data set.\u003c/p\u003e","theta":"153","volume":"2019-11"},{"name":"Micro frontends","id":"1035","quadrant":"Techniques","ring":"Adopt","movement":"c","radarId":"3","display_name":"Micro frontends","radius":"75","description":"\u003cp\u003eWe\u0027ve seen significant benefits from introducing \u003ca href\u003d\"https://martinfowler.com/articles/microservices.html\"\u003emicroservices\u003c/a\u003e, which have allowed teams to scale the delivery of independently deployed and maintained services. Unfortunately, we\u0027ve also seen many teams create a front-end monolith — a large, entangled browser application that sits on top of the back-end services — largely neutralizing the benefits of microservices. \u003cstrong\u003eMicro frontends\u003c/strong\u003e have continued to gain in popularity since they were first introduced. We\u0027ve seen many teams adopt some form of this architecture as a way to manage the complexity of multiple developers and teams contributing to the same user experience. In June of this year, one of the originators of this technique published an \u003ca href\u003d\"https://martinfowler.com/articles/micro-frontends.html\"\u003eintroductory article\u003c/a\u003e that serves as a reference for micro frontends. It shows how this style can be implemented using various web programming mechanisms and builds out an example application using \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e. We\u0027re confident this style will grow in popularity as larger organizations try to decompose UI development across multiple teams.\u003c/p\u003e","theta":"133","volume":"2019-11"},{"name":"Pipelines for infrastructure as code","id":"1131","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"4","display_name":"Pipelines for infrastructure as code","radius":"100","description":"\u003cp\u003eThe use of continuous delivery pipelines to orchestrate the release process for software has become a mainstream concept. CI/CD tools can be used to test server configuration (e.g., Chef cookbooks, Puppet modules, Ansible playbooks), server image building (e.g., \u003ca href\u003d\"/radar/tools/packer\"\u003ePacker\u003c/a\u003e), environment provisioning (e.g., \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e, CloudFormation) and the integration of environments. The use of \u003cstrong\u003epipelines for infrastructure as code\u003c/strong\u003e lets you find errors before changes are applied to operational environments — including environments used for development and testing. They also offer a way to ensure that infrastructure tooling is run consistently, using CI/CD agents rather than individual workstations. Our teams have had good results adopting this technique on their projects.\u003c/p\u003e","theta":"129","volume":"2019-11"},{"name":"Run cost as architecture fitness function","id":"1338","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"5","display_name":"Run cost as architecture fitness function","radius":"112","description":"\u003cp\u003eAutomating the estimation, tracking and projection of cloud infrastructure\u0027s run cost is necessary for today\u0027s organizations. The cloud providers\u0027 savvy pricing models, combined with proliferation of pricing parameters and the dynamic nature of today\u0027s architecture, can lead to surprisingly expensive run cost. For example, the price of \u003ca href\u003d\"/radar/techniques/serverless-architecture\"\u003eserverless\u003c/a\u003e based on API calls, event streaming solutions based on traffic or data processing clusters based on running jobs, all have a dynamic nature that changes over time as the architecture evolves. When our teams manage infrastructure on the cloud, implementing \u003cstrong\u003erun cost as architecture fitness function\u003c/strong\u003e is one of their early activities. This means that our teams can observe the cost of running services against the value delivered; when they see deviations from what was expected or acceptable, they\u0027ll discuss whether it\u0027s time to evolve the architecture. The observation and calculation of the run cost is implemented as an automated function.\u003c/p\u003e","theta":"116","volume":"2019-11"},{"name":"Testing using real device","id":"201911031","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"6","display_name":"Testing using real device","radius":"125","description":"\u003cp\u003eWhen adopting continuous delivery (CD) successfully, teams strive to make the various test environments look as close to production as possible. This allows them to avoid bugs that would otherwise only show themselves in the production environment. This remains just as valid for embedded and Internet of Things software; if we don\u0027t run our tests in realistic environments we can expect to find some bugs for the first time in production. \u003cstrong\u003eTesting using real devices\u003c/strong\u003e helps avoid this issue by making sure the right devices are available in the CD pipeline.\u003c/p\u003e","theta":"101","volume":"2019-11"},{"name":"Automated machine learning (AutoML)","id":"201911037","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"7","display_name":"Automated machine learning (AutoML)","radius":"220","description":"\u003cp\u003eThe power and promise of machine learning has created a demand for expertise that outstrips the supply of data scientists who specialize in this area. In response to this skills gap, we\u0027ve seen the emergence of \u003cstrong\u003eAutomated machine learning (AutoML)\u003c/strong\u003e tools that purport to make it easy for nonexperts to automate the end-to-end process of model selection and training. Examples include \u003ca href\u003d\"https://cloud.google.com/automl/\"\u003eGoogle\u0027s AutoML\u003c/a\u003e, \u003ca href\u003d\"https://www.datarobot.com\"\u003eDataRobot\u003c/a\u003e and \u003ca href\u003d\"http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html\"\u003ethe H2O AutoML interface\u003c/a\u003e. Although we\u0027ve seen promising results from these tools, we\u0027d caution businesses against viewing them as the sum total of their machine-learning journey. As stated on the \u003ca href\u003d\"http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html\"\u003eH2O website\u003c/a\u003e, \"there is still a fair bit of knowledge and background in data science that is required to produce high-performing machine learning models.\" Blind trust in automated techniques also increases the risk of introducing ethical bias or making decisions that disadvantage minorities. While businesses may use these tools as a starting point to generate useful, trained models, we encourage them to seek out experienced data scientists to validate and refine the results.\u003c/p\u003e","theta":"173","volume":"2019-11"},{"name":"Binary attestation","id":"201911045","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"8","display_name":"Binary attestation","radius":"210","description":"\u003cp\u003eAs the usage of containers, deployment of large fleet of services by autonomous teams and increased speed of continuous delivery become common practice for many organizations, the need for automated deploy-time software security controls arise. \u003cstrong\u003eBinary attestation\u003c/strong\u003e is a technique to implement deploy-time security control; to cryptographically verify that a binary image is authorized for deployment. Using this technique, an attestor, an automated build process or a security team signs off the binaries that have passed the required quality checks and tests and are authorized to be deployed. Services such as \u003ca href\u003d\"https://cloud.google.com/binary-authorization/\"\u003eGCP Binary Authorization\u003c/a\u003e enabled by \u003ca href\u003d\"/radar/tools/grafeas\"\u003eGrafeas\u003c/a\u003e, and tools such as \u003ca href\u003d\"/radar/tools/in-toto\"\u003ein-toto\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/docker-notary\"\u003eDocker Notary\u003c/a\u003e support creating attestations and validating the image signatures before deployment.\u003c/p\u003e","theta":"165","volume":"2019-11"},{"name":"Continuous delivery for machine learning (CD4ML)","id":"201904066","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"9","display_name":"Continuous delivery for machine learning (CD4ML)","radius":"170","description":"\u003cp\u003eWith an increased popularity of ML-based applications, and the technical complexity involved in building them, our teams rely heavily on \u003cstrong\u003e\u003ca href\u003d\"https://martinfowler.com/articles/cd4ml.html\"\u003econtinuous delivery for machine learning (CD4ML)\u003c/a\u003e\u003c/strong\u003e to deliver such applications safely, quickly and in a sustainable manner. CD4ML is the discipline of bringing CD principles and practices to ML applications. It removes long cycle times between training models and deploying them to production. CD4ML removes manual handoffs between different teams, data engineers, data scientists and ML engineers in the end-to-end process of build and deployment of a model served by an application. Using CD4ML, our teams have successfully implemented the automated versioning, testing and deployment of all components of ML-based applications: data, model and code.\u003c/p\u003e","theta":"158","volume":"2019-11"},{"name":"Data discoverability","id":"201911035","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"10","display_name":"Data discoverability","radius":"200","description":"\u003cp\u003eOne of the main points of friction for data scientists and analysts, in their workflow, is to locate the data they need, make sense of it and evaluate whether it\u0027s trustworthy to use it. This remains a challenge due to the missing metadata about the available data sources and lack of adequate functionality needed to search and locate data. We encourage teams who are providing analytical data sets or building data platforms to make \u003cstrong\u003edata discoverability\u003c/strong\u003e a first-class function of their environments; to provide the ability to easily locate available data, detect its quality, understand its structure and lineage and get access to it. Traditionally this function has been provided by bloated data cataloguing solutions. In recent years, we\u0027ve seen the growth of open-source projects that are improving developer experiences for both data providers and data consumers to do one thing really well: to make data discoverable. \u003ca href\u003d\"https://github.com/lyft/amundsen\"\u003eAmundsen\u003c/a\u003e by Lyft and \u003ca href\u003d\"https://github.com/linkedin/WhereHows\"\u003eWhereHows\u003c/a\u003e by LinkedIn are among these tools. What we like to see is a change in providers\u0027 behavior to intentionally share the metadata that help discoverability in favor of discoverability tools that infer partial metadata information from silos of application databases.\u003c/p\u003e","theta":"150","volume":"2019-11"},{"name":"Dependency drift fitness function","id":"201911044","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"11","display_name":"Dependency drift fitness function","radius":"210","description":"\u003cp\u003eMany teams and organizations have no formal or consistent way of tracking technical dependencies in their software. This issue often shows itself when that software needs to be changed, at which point the use of an outdated version of a library, API or component will cause problems or delay. \u003cstrong\u003eDependency drift fitness function\u003c/strong\u003e is a technique to introduce a specific \u003ca href\u003d\"/radar/techniques/evolutionary-architecture\"\u003eevolutionary architecture\u003c/a\u003e fitness function to track these dependencies over time, thus giving an indication of the possible work needed and whether a potential issue is getting better or worse.\u003c/p\u003e","theta":"143","volume":"2019-11"},{"name":"Design systems","id":"201911040","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"12","display_name":"Design systems","radius":"200","description":"\u003cp\u003eAs application development becomes increasingly dynamic and complex, it\u0027s a challenge to achieve the effective delivery of accessible and usable products that are consistent in style. \u003cstrong\u003eDesign systems\u003c/strong\u003e define a collection of design patterns, component libraries and good design and engineering practices that ensure consistency in the development of digital products. We\u0027ve found design systems a useful addition to our toolbox when working across teams and disciplines in product development, because they allow teams to focus on more strategic challenges around the product itself without the need to reinvent the wheel every time they need to add a visual component. The types of components and tools you use to create design systems can vary greatly.\u003c/p\u003e","theta":"135","volume":"2019-11"},{"name":"Experiment tracking tools for machine learning","id":"201911042","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"13","display_name":"Experiment tracking tools for machine learning","radius":"180","description":"\u003cp\u003eThe day-to-day work of machine learning often boils down to a series of experiments in selecting a modeling approach, the network topology, training data and various optimizations or tweaks to the model. Because many of these models are still difficult to interpret or explain, data scientists must use experience and intuition to hypothesize changes and then measure the impact those changes have on the overall performance of the model. As these models have become increasingly common in business systems, several different \u003cstrong\u003eexperiment tracking tools for machine learning\u003c/strong\u003e have emerged to help investigators keep track of these experiments and work through them methodically. Although no clear winner has emerged, tools such as \u003ca href\u003d\"https://mlflow.org/\"\u003eMLflow\u003c/a\u003e or \u003ca href\u003d\"https://www.wandb.com/\"\u003eWeights \u0026 Biases\u003c/a\u003e and platforms such as \u003ca href\u003d\"https://comet.ml\"\u003eComet\u003c/a\u003e or \u003ca href\u003d\"https://neptune.ml\"\u003eNeptune\u003c/a\u003e have introduced rigor and repeatability into the entire machine learning workflow. They also facilitate collaboration and help turn data science from a solitary endeavor into a team sport.\u003c/p\u003e","theta":"128","volume":"2019-11"},{"name":"Explainability as a first-class model selection criterion","id":"201911039","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"14","display_name":"Explainability as a first-class model selection criterion","radius":"170","description":"\u003cp\u003eDeep neural networks have demonstrated remarkable recall and accuracy across a wide range of problems. Given sufficient training data and an appropriately chosen topology, these models meet and exceed human capabilities in certain select problem spaces. However, they\u0027re inherently opaque. Although parts of models can be reused through \u003ca href\u003d\"/radar/techniques/transfer-learning-for-nlp\"\u003etransfer learning\u003c/a\u003e, we\u0027re seldom able to ascribe any human-understandable meaning to these elements. In contrast, an explainable model is one that allows us to say how a decision was made. For example, a decision tree yields a chain of inference that describes the classification process. Explainability becomes critical in certain regulated industries or when we\u0027re concerned about the ethical impact of a decision. As these models are incorporated more widely into critical business systems, it\u0027s important to consider \u003cstrong\u003eexplainability as a first-class model selection criterion\u003c/strong\u003e. Despite their power, neural networks might not be an appropriate choice when explainability requirements are strict.\u003c/p\u003e","theta":"120","volume":"2019-11"},{"name":"Security policy as code","id":"201911034","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"15","display_name":"Security policy as code","radius":"200","description":"\u003cp\u003eSecurity policies are rules and procedures that protect our systems from threats and disruption. For example, access control policies define and enforce who can access which services and resources under what circumstances; or network security policies can dynamically limit the traffic rate to a particular service. The complexity of the technology landscape today demands treating \u003cstrong\u003esecurity policy as code\u003c/strong\u003e: define and keep policies under version control, automatically validate them, automatically deploy them and monitor their performance. Tools such as \u003ca href\u003d\"/radar/tools/open-policy-agent-opa\"\u003eOpen Policy Agent\u003c/a\u003e, or platforms such as \u003ca href\u003d\"/radar/platforms/istio\"\u003eIstio\u003c/a\u003e provide flexible policy definition and enforcement mechanisms that support the practice of security policy as code.\u003c/p\u003e","theta":"113","volume":"2019-11"},{"name":"Sidecars for endpoint security","id":"1136","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"16","display_name":"Sidecars for endpoint security","radius":"180","description":"\u003cp\u003eMany of the technical solutions we build today run in increasingly complex \u003ca href\u003d\"/radar/techniques/polycloud\"\u003epolycloud\u003c/a\u003e or hybrid-cloud environments with multiple distributed components and services. Under such circumstances, we apply two security principles early in implementation: \u003cem\u003ezero trust network\u003c/em\u003e, never trust the network and always verify; and the principle of \u003cem\u003eleast privilege\u003c/em\u003e, granting the minimum permissions necessary for performing a particular job. \u003cstrong\u003eSidecars for endpoint security\u003c/strong\u003e is a common technique we use to implement these principles to enforce security controls at every component\u0027s endpoint, e.g., APIs of services, data stores or \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e control interface. We do this using an out-of-process sidecar — a process or a container that is deployed and scheduled with each service sharing the same execution context, host and identity. \u003ca href\u003d\"/radar/tools/open-policy-agent-opa\"\u003eOpen Policy Agent\u003c/a\u003e and \u003ca href\u003d\"http://github.com/envoyproxy/envoy\"\u003eEnvoy\u003c/a\u003e are tools that implement this technique. Sidecars for endpoint security minimize the trusted footprint to a local endpoint rather than the network perimeter. We like to see the responsibility of sidecar’s security policy configuration left with the team that is responsible for the endpoint and not a separate centralized team.\u003c/p\u003e","theta":"105","volume":"2019-11"},{"name":"Zhong Tai","id":"201911038","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"17","display_name":"Zhong Tai","radius":"180","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.thoughtworks.com/insights/blog/zhong-tai-radical-approach-enterprise-it\"\u003eZhong Tai\u003c/a\u003e\u003c/strong\u003e has been a buzzword in the Chinese IT industry for years, but it has yet to catch on in the West. At its core, Zhong Tai is an approach to delivering encapsulated business models. It\u0027s designed to help a new breed of small businesses deliver first-rate services without the costs of traditional enterprise infrastructure and enabling existing organizations to bring innovative services to market at breakneck speeds. The Zhong Tai strategy was originally proposed by Alibaba and soon followed by many Chinese Internet companies, because their business model is digital native, making it suitable to replicate for new markets and sectors. Nowadays, more Chinese firms are using Zhong Tai as a lever for digital transformation.\u003c/p\u003e","theta":"98","volume":"2019-11"},{"name":"BERT","id":"201911049","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"18","display_name":"BERT","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://arxiv.org/abs/1810.04805\"\u003eBERT\u003c/a\u003e\u003c/strong\u003e stands for Bidirectional Encoder Representations from Transformers; it\u0027s a new method of pretraining language representations which was published by researchers at Google in October 2018. BERT has significantly altered the natural language processing (NLP) landscape by obtaining state-of-the-art results on a wide array of NLP tasks. Based on Transformer architecture, it learns from both the left and right side of a token\u0027s context during training. Google has also released pretrained general-purpose BERT models that have been trained on a large corpus of unlabelled text including Wikipedia. Developers can use and fine-tune these pre-trained models on their task-specific data and achieve great results. We talked about \u003ca href\u003d\"/radar/techniques/transfer-learning-for-nlp\"\u003etransfer learning for NLP\u003c/a\u003e in our April 2019 edition of the Radar; BERT and its successors continue to make transfer learning for NLP a very exciting field with significant reduction in effort for users dealing with text classification.\u003c/p\u003e","theta":"169","volume":"2019-11"},{"name":"Data mesh","id":"201911051","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"19","display_name":"Data mesh","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://martinfowler.com/articles/data-monolith-to-mesh.html\"\u003eData mesh\u003c/a\u003e\u003c/strong\u003e is an architectural paradigm that unlocks analytical data at scale; rapidly unlocking access to an ever-growing number of distributed domain data sets, for a proliferation of consumption scenarios such as machine learning, analytics or data intensive applications across the organization. Data mesh addresses the common failure modes of the traditional centralized \u003ca href\u003d\"https://martinfowler.com/bliki/DataLake.html\"\u003edata lake\u003c/a\u003e or data platform architecture, with a shift from the centralized paradigm of a lake, or its predecessor, the data warehouse. Data mesh shifts to a paradigm that draws from modern distributed architecture: considering domains as the first-class concern, applying platform thinking to create a self-serve data infrastructure, treating data as a product and implementing open standardization to enable an ecosystem of interoperable distributed data products.\u003c/p\u003e","theta":"158","volume":"2019-11"},{"name":"Ethical bias testing","id":"201911054","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"20","display_name":"Ethical bias testing","radius":"290","description":"\u003cp\u003eOver the past year, we\u0027ve seen a shift in interest around machine learning and deep neural networks in particular. Until now, tool and technique development has been driven by excitement over the remarkable capabilities of these models. Currently though, there is rising concern that these models could cause unintentional harm. For example, a model could be trained to make profitable credit decisions by simply excluding disadvantaged applicants. Fortunately, we\u0027re seeing a growing interest in \u003cstrong\u003eethical bias testing\u003c/strong\u003e that will help to uncover potentially harmful decisions. Tools such as \u003ca href\u003d\"https://github.com/marcotcr/lime\"\u003elime\u003c/a\u003e, \u003ca href\u003d\"https://aif360.mybluemix.net/\"\u003eAI Fairness 360\u003c/a\u003e or \u003ca href\u003d\"/radar/tools/what-if-tool\"\u003eWhat-If\u003c/a\u003e can help uncover inaccuracies that result from underrepresented groups in training data and visualization tools such as \u003ca href\u003d\"https://ai.googleblog.com/2017/07/facets-open-source-visualization-tool.html\"\u003eGoogle Facets\u003c/a\u003e or \u003ca href\u003d\"https://pair-code.github.io/facets/\"\u003eFacets Dive\u003c/a\u003e can be used to discover subgroups within a corpus of training data. However, this is a developing field and we expect standards and practices specific to ethical bias testing to emerge over time.\u003c/p\u003e","theta":"147","volume":"2019-11"},{"name":"Federated learning","id":"201911053","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"21","display_name":"Federated learning","radius":"300","description":"\u003cp\u003eModel training generally requires collecting data from its source and transporting it to a centralized location where the model training algorithm runs. This becomes particularly problematic when the training data consists of personally identifiable information. We\u0027re encouraged by the emergence of \u003cstrong\u003efederated learning\u003c/strong\u003e as a privacy-preserving method for training on a large diverse set of data relating to individuals. Federated learning techniques allow the data to remain on the users\u0027 device, under their control, yet contribute to an aggregate corpus of training data. In one such technique, each user device updates a model independently; then the model parameters, rather than the data itself, are combined into a centralized view. Network bandwidth and device computational limitations present some significant technical challenges, but we like the way federated learning leaves users in control of their own personal information.\u003c/p\u003e","theta":"135","volume":"2019-11"},{"name":"JAMstack","id":"201911110","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"22","display_name":"JAMstack","radius":"320","description":"\u003cp\u003eThe trend that started as \u003ca href\u003d\"/radar/platforms/backend-as-a-service\"\u003ebackend as a service\u003c/a\u003e for native mobile apps many years ago is now becoming popular with web applications. We\u0027re seeing frameworks such as \u003ca href\u003d\"/radar/languages-and-frameworks/gatsby-js\"\u003eGatsby.js\u003c/a\u003e that combine static site generation and client-side rendering with third-party APIs. Referred to as \u003cstrong\u003e\u003ca href\u003d\"https://jamstack.org/\"\u003eJAMstack\u003c/a\u003e\u003c/strong\u003e (the JAM stands for \u003cstrong\u003eJ\u003c/strong\u003eavaScript, \u003cstrong\u003eA\u003c/strong\u003ePI, and \u003cstrong\u003eM\u003c/strong\u003earkup), this approach can provide rich user experiences to web applications that rely mostly on APIs and SaaS offerings. Because the HTML is rendered either in the web browser or at build time, the deployment model is the same as fully statically generated sites, with all its benefits: the attack surface on the server is small and great performance can be achieved with low resource usage. Such deployments are also ideal for a content delivery network. In fact, we toyed with the idea of labelling this technique as \u003cem\u003eCDN first\u003c/em\u003e applications.\u003c/p\u003e","theta":"124","volume":"2019-11"},{"name":"Privacy-preserving record linkage (PPRL) using Bloom filter","id":"201911048","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"23","display_name":"Privacy-preserving record linkage (PPRL) using Bloom filter","radius":"310","description":"\u003cp\u003eLinking records from different data providers in the presence of a shared key is trivial. However, you may not always have a shared key; even if you do, it may not be a good idea to expose it due to privacy concerns. \u003cstrong\u003ePrivacy-preserving record linkage (PPRL) using Bloom filter\u003c/strong\u003e (a space-efficient probabilistic data structure) is an established technique that allows probabilistic linkage of records from different data providers without exposing privately identifiable personal data. For example, when linking data from two data providers, each provider encrypts its personally identifiable data using \u003ca href\u003d\"https://en.wikipedia.org/wiki/Bloom_filter\"\u003eBloom filter\u003c/a\u003e to get cryptographic linkage keys and then sends them to you via a secure channel. Once data is received, the records can be linked by computing similarity scores between sets of cryptographic linkage keys from each provider. Among other techniques, we found PPRL using Bloom filters to be scalable for large data sets.\u003c/p\u003e","theta":"113","volume":"2019-11"},{"name":"Semi-supervised learning loops","id":"201911052","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"24","display_name":"Semi-supervised learning loops","radius":"300","description":"\u003cp\u003e\u003cstrong\u003eSemi-supervised learning loops\u003c/strong\u003e are a class of iterative machine-learning workflows that take advantage of the relationships to be found in unlabeled data. These techniques may improve models by combining labeled and unlabeled data sets in various ways. In other cases they compare models trained on different subsets of the data. Unlike either unsupervised learning where a machine infers classes in unlabeled data or supervised techniques where the training set is entirely labeled, semi-supervised techniques take advantage of a small set of labeled data and a much larger set of unlabeled data. Semi-supervised learning is also closely related to active learning techniques where a human is directed to selectively label ambiguous data points. Since expert humans that can accurately label data are a scarce resource and labeling is often the most time-consuming activity in the machine-learning workflow, semi-supervised techniques lower the cost of training and make machine learning feasible for a new class of users.\u003c/p\u003e","theta":"102","volume":"2019-11"},{"name":"10x engineers","id":"201911057","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"25","display_name":"10x engineers","radius":"375","description":"\u003cp\u003eThe old term \u003cstrong\u003e10x engineer\u003c/strong\u003e has come under scrutiny these past few months. A widely shared Twitter thread essentially suggests companies should excuse antisocial and damaging behaviors in order to retain engineers who are perceived as having immense individual output. Thankfully, many people on social media made fun of the concept, but the stereotype of the \"rockstar developer\" is still pervasive. In our experience, great engineers are driven not by individual output but by working in amazing teams. It\u0027s more effective to build teams of talented individuals with mixed experiences and diverse backgrounds and provide the right ingredients for teamwork, learning and continuous improvement. These 10x teams can move faster, scale more quickly and are much more resilient — without needing to pander to bad behaviors.\u003c/p\u003e","theta":"162","volume":"2019-11"},{"name":"Front-end integration via artifact","id":"201911056","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"26","display_name":"Front-end integration via artifact","radius":"375","description":"\u003cp\u003eWhen teams embrace the concept of \u003ca href\u003d\"/radar/techniques/micro-frontends\"\u003emicro frontends\u003c/a\u003e they have a number of patterns at their disposal to integrate the individual micro frontends into one application. As always there are antipatterns, too. A common one in this case is \u003cstrong\u003efront-end integration via artifact\u003c/strong\u003e. For each micro frontend an artifact is built, usually an NPM package, which is pushed into a registry. A later step, sometimes in a different build pipeline, then combines the individual packages into a final package that contains all micro frontends. From a purely technical perspective this integration at build time results in a working application. However, integrating via artifact implies that for each change the full artifact needs to be rebuilt, which is time consuming and will likely have a negative impact on developer experience. Worse, this style of integrating frontends also introduces direct dependencies between the micro frontends at build time and therefore causes considerable coordination overhead.\u003c/p\u003e","theta":"144","volume":"2019-11"},{"name":"Lambda pinball","id":"201911055","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"27","display_name":"Lambda pinball","radius":"375","description":"\u003cp\u003eWe\u0027ve been building \u003ca href\u003d\"/radar/techniques/serverless-architecture\"\u003eserverless\u003c/a\u003e architectures on our projects for a couple of years now, and we\u0027ve noticed that it\u0027s quite easy to fall into the trap of building a distributed monolith. \u003cstrong\u003e\u003ca href\u003d\"https://twitter.com/ctford/status/1128774411832762369\"\u003eLambda pinball\u003c/a\u003e\u003c/strong\u003e architectures characteristically lose sight of important domain logic in the tangled web of lambdas, buckets and queues as requests bounce around increasingly complex graphs of cloud services. Typically they\u0027re hard to test as units, and the application needs must be tested as an integrated whole. One pattern we can use to avoid these pinball architectures is to draw a distinction between \u003ca href\u003d\"https://martinfowler.com/ieeeSoftware/published.pdf\"\u003epublic and published interfaces\u003c/a\u003e and apply good old domain boundaries with published interfaces between them.\u003c/p\u003e","theta":"126","volume":"2019-11"},{"name":"Legacy migration feature parity","id":"201911046","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"28","display_name":"Legacy migration feature parity","radius":"375","description":"\u003cp\u003eWe find that more and more organizations need to replace aging legacy systems to keep up with the demands of their customers (both internal and external). One antipattern we keep seeing is \u003cstrong\u003elegacy migration feature parity\u003c/strong\u003e, the desire to retain feature parity with the old. We see this as a huge missed opportunity. Often the old systems have bloated over time, with many features unused by users (50% according to a \u003ca href\u003d\"https://www.standishgroup.com/sample_research_files/Exceeding%20Value_Layout.pdf\"\u003e2014 Standish Group report\u003c/a\u003e) and business processes that have evolved over time. Replacing these features is a waste. Our advice: Convince your customers to take a step back and understand what their users currently \u003cem\u003eneed\u003c/em\u003e and prioritize these needs against business outcomes and metrics — which often is easier said than done. This means conducting user research and applying modern product development practices rather than simply replacing the existing ones.\u003c/p\u003e","theta":"108","volume":"2019-11"},{"name":"Apache Flink","id":"972","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"29","display_name":"Apache Flink","radius":"190","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://flink.apache.org/\"\u003eApache Flink\u003c/a\u003e\u003c/strong\u003e has seen increasing adoption since our initial assessment on 2016. Flink is recognized as the leading stream-processing engine and also gradually matured in the fields of batch processing and machine learning. One of Flink\u0027s key differentiator from other stream-processing engines is its use of consistent checkpoints of an application\u0027s state. In the event of failure, the application is restarted and its state is loaded from the latest checkpoint — so that the application can continue processing as if the failure had never happened. This helps us to reduce complexity of building and operating external systems for fault tolerance. We see more and more companies using Flink to build their data-processing platform.\u003c/p\u003e","theta":"195","volume":"2019-11"},{"name":"Apollo Auto","id":"201911016","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"30","display_name":"Apollo Auto","radius":"260","description":"\u003cp\u003eOnce exclusive to tech giants, self-driving technology isn\u0027t rocket science anymore, as demonstrated by \u003cstrong\u003e\u003ca href\u003d\"http://apollo.auto/\"\u003eApollo Auto\u003c/a\u003e\u003c/strong\u003e. The goal of the Baidu-owned Apollo program is to become the Android of the autonomous driving industry. The Apollo platform has components such as perception, simulation, planning and intelligent control that enable car companies to integrate their own autonomous driving systems into their vehicles\u0027 hardware. The developer community is still new but with a lot of vendors joining to contribute more ports. One of our projects helped our client to complete self-driving license exams with the Apollo-based autopilot system. Apollo also provides an evolutionary architecture approach to adopt advanced features gradually, which enables us to integrate more sensors and functions in an agile, iterative way.\u003c/p\u003e","theta":"210","volume":"2019-11"},{"name":"GCP Pub/Sub","id":"201911015","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"31","display_name":"GCP Pub/Sub","radius":"210","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://cloud.google.com/pubsub/\"\u003eGCP Pub/Sub\u003c/a\u003e\u003c/strong\u003e is Google Cloud\u0027s event streaming platform. It\u0027s a popular piece of infrastructure for many of our architectures running \u003ca href\u003d\"/radar/platforms/google-cloud-platform\"\u003eGoogle Cloud Platform\u003c/a\u003e, including mass event ingestion, communication of serverless workloads and streaming data-processing workflows. One of its unique features is support of pull and push subscriptions: subscribing to receive all published messages available at the time of subscription or pushing messages to a particular endpoint. Our teams have enjoyed its reliability and scale and that it just works as advertised.\u003c/p\u003e","theta":"225","volume":"2019-11"},{"name":"Mongoose OS","id":"1256","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"32","display_name":"Mongoose OS","radius":"180","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://mongoose-os.com/\"\u003eMongoose OS\u003c/a\u003e\u003c/strong\u003e remains one of our preferred open-source microcontroller operating systems and embedded firmware development frameworks. It\u0027s worth noting that Mongoose OS fills a noticeable gap for embedded software developers: the gap between Arduino firmware suitable for prototyping and bare-metal microcontrollers\u0027 native SDKs. Our teams have successfully used \u003ca href\u003d\"https://mongoose-os.com/about.html\"\u003eCesanta\u0027s\u003c/a\u003e new end-to-end device management platform, \u003ca href\u003d\"https://mdash.net/home/\"\u003emDash\u003c/a\u003e, for small-scale greenfield hardware projects. Major Internet of Things (IoT) cloud platform providers today support the Mongoose OS development framework for their device management, connectivity, and over-the-air (OTA) firmware upgrades. Since we last reported on Mongoose OS, the number of supported boards and microcontrollers has grown to include STM, Texas Instruments and Espressif. We continue to enjoy its seamless support for OTA updates and its built-in security at the individual device level.\u003c/p\u003e","theta":"240","volume":"2019-11"},{"name":"ROS","id":"201911017","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"33","display_name":"ROS","radius":"250","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.ros.org/\"\u003eROS\u003c/a\u003e\u003c/strong\u003e (Robot Operating System) is a set of libraries and tools to help software developers create robot applications. It\u0027s a development framework that provides hardware abstraction, device drivers, libraries, visualizers, message-passing, package management and more. \u003ca href\u003d\"/radar/platforms/apollo-auto\"\u003eApollo Auto\u003c/a\u003e is based on ROS. In our other \u003ca href\u003d\"https://en.wikipedia.org/wiki/Advanced_driver-assistance_systems\"\u003eADAS\u003c/a\u003e simulation project, we\u0027ve also used ROS\u0027s messaging system (\u003ca href\u003d\"http://wiki.ros.org/Bags\"\u003ebag\u003c/a\u003e). The technology isn\u0027t new, but it has regained developers’ attention with the development of ADAS.\u003c/p\u003e","theta":"255","volume":"2019-11"},{"name":"AWS Cloud Development Kit","id":"201911007","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"34","display_name":"AWS Cloud Development Kit","radius":"310","description":"\u003cp\u003eFor many of our teams \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e has become the default choice for defining cloud infrastructure. However, some of our teams have been experimenting with \u003cstrong\u003e\u003ca href\u003d\"https://docs.aws.amazon.com/cdk/latest/guide/home.html\"\u003eAWS Cloud Development Kit\u003c/a\u003e\u003c/strong\u003e (AWS CDK) and they like what they\u0027ve seen so far. In particular, they like the use of first-class programming languages instead of configuration files which allows them to use existing tools, test approaches and skills. Like similar tools, care is still needed to ensure deployments remain easy to understand and maintain. Given that support for C# and Java is coming soon and ignoring for now some gaps in functionality, we think AWS CDK is worth watching as an alternative to other configuration file–based approaches.\u003c/p\u003e","theta":"185","volume":"2019-11"},{"name":"Azure DevOps","id":"1329","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"35","display_name":"Azure DevOps","radius":"315","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://azure.microsoft.com/en-us/services/devops/\"\u003eAzure DevOps\u003c/a\u003e\u003c/strong\u003e services include a set of managed services such as hosted Git repos, CI/CD pipelines, automated testing tooling, backlog management tooling and artifact repository. Azure DevOps Pipelines have been maturing over time. We particularly like its ability to define \u003ca href\u003d\"/radar/techniques/pipelines-as-code\"\u003ePipelines as code\u003c/a\u003e and its ecosystem of extensions on the Azure DevOps \u003ca href\u003d\"https://marketplace.visualstudio.com/azuredevops\"\u003emarketplace\u003c/a\u003e. At the time of writing, our teams are still running into a few immature features, including lack of an effective UI for pipeline visualization and navigation and the inability to trigger a pipeline from artifacts or other pipelines.\u003c/p\u003e","theta":"190","volume":"2019-11"},{"name":"Azure Pipelines","id":"201911011","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"36","display_name":"Azure Pipelines","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://azure.microsoft.com/en-us/services/devops/pipelines/\"\u003eAzure Pipelines\u003c/a\u003e\u003c/strong\u003e is a product of \u003ca href\u003d\"/radar/platforms/azure-devops\"\u003eAzure DevOps\u003c/a\u003e that offers cloud-based solutions to implement pipelines as code for projects hosted in Azure DevOps Git server or other Git solution such as GitHub or Bitbucket. The interesting part of this solution is the ability to run your scripts in Linux, MacOS and Windows agents without the overhead of managing a virtual machine on your own. This represents a big step forward, especially for teams that work on Windows environments with .NET Framework solutions; we\u0027re also assessing this service for continuous delivery in iOS.\u003c/p\u003e","theta":"195","volume":"2019-11"},{"name":"Crowdin","id":"201911003","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"37","display_name":"Crowdin","radius":"320","description":"\u003cp\u003eMost of the projects with multilingual support start with development teams building features in one language and managing the rest through offline translation via emails and spreadsheets. Although this simple setup works, things can quickly get out of hand. You may have to keep answering the same questions for different language translators, sucking the energy out of the collaboration between translators, proofreaders and the development team. \u003cstrong\u003e\u003ca href\u003d\"https://crowdin.com\"\u003eCrowdin\u003c/a\u003e\u003c/strong\u003e is one of a handful of platforms that help in streamlining the localization workflow of your project. With Crowdin the development team can continue building features and the platform streamlines the text that needs translation into an online workflow. We like that Crowdin nudges the teams to continuously and incrementally incorporate translation rather than managing them in large batches toward the end.\u003c/p\u003e","theta":"200","volume":"2019-11"},{"name":"Crux","id":"201911009","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"38","display_name":"Crux","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.juxt.pro/crux/index.html\"\u003eCrux\u003c/a\u003e\u003c/strong\u003e is an open-source document database with bitemporal graph queries. Most database systems are temporal, meaning they help us model facts along with the time at which they occurred. Bitemporal database systems let you model not just the \u003cem\u003evalid\u003c/em\u003e time the fact occurred but also the \u003cem\u003etransaction\u003c/em\u003e time when it was received. If you need a document store with graph capabilities for querying the content, then give Crux a try. It\u0027s currently in alpha and lacks SQL support, but you can use a \u003ca href\u003d\"https://en.wikipedia.org/wiki/Datalog\"\u003eDatalog\u003c/a\u003e query interface for reading and traversing relationships.\u003c/p\u003e","theta":"205","volume":"2019-11"},{"name":"Delta Lake","id":"201911008","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"39","display_name":"Delta Lake","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://docs.databricks.com/delta/index.html\"\u003eDelta Lake\u003c/a\u003e\u003c/strong\u003e is an open-source storage layer by Databricks that attempts to bring transactions to big data processing. One of the problems we often encounter when using \u003ca href\u003d\"/radar/platforms/apache-spark\"\u003eApache Spark\u003c/a\u003e is the lack of ACID transactions. Delta Lake integrates with the Spark API and addresses this problem by its use of a transaction log and versioned \u003ca href\u003d\"https://parquet.apache.org/\"\u003eParquet\u003c/a\u003e files. With its serializable isolation, it allows concurrent readers and writers to operate on Parquet files. Other welcome features include schema enforcement on write and versioning, which allows us to query and revert to older versions of data if necessary. We\u0027ve started to use it in some of our projects and quite like it.\u003c/p\u003e","theta":"210","volume":"2019-11"},{"name":"Fission","id":"201911002","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"40","display_name":"Fission","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e\u0027s serverless ecosystem is growing. We talked about \u003ca href\u003d\"/radar/platforms/knative\"\u003eKnative\u003c/a\u003e in a previous Radar; now we\u0027re seeing \u003cstrong\u003e\u003ca href\u003d\"https://fission.io/\"\u003eFission\u003c/a\u003e\u003c/strong\u003e gaining traction. Fission lets developers focus on writing short-lived functions and map them to HTTP requests while the framework handles the rest of the plumbing and automation of Kubernetes resources behind the scenes. Fission also lets you \u003ca href\u003d\"https://fission.io/workflows/\"\u003ecompose functions\u003c/a\u003e, integrate with third-party providers via web hooks and automate the management of the Kubernetes infrastructure.\u003c/p\u003e","theta":"215","volume":"2019-11"},{"name":"FoundationDB","id":"201911111","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"41","display_name":"FoundationDB","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.foundationdb.org\"\u003eFoundationDB\u003c/a\u003e\u003c/strong\u003e is an open-source multimodel database, acquired by Apple in 2015 and then open sourced in April 2018. The core of FoundationDB is a distributed key-value store, which provides strict serializability transactions. One of the interesting aspects of FoundationDB is its concept of layers to offer additional models. These layers are essentially stateless components built on top of the core key-value store, such as the \u003ca href\u003d\"https://www.foundationdb.org/blog/announcing-record-layer/\"\u003eRecord layer\u003c/a\u003e and the \u003ca href\u003d\"https://www.foundationdb.org/blog/announcing-document-layer/\"\u003eDocument layer\u003c/a\u003e. FoundationDB sets a high standard with its \u003ca href\u003d\"https://apple.github.io/foundationdb/testing.html\"\u003eSimulation testing\u003c/a\u003e where they run daily tests simulating various system failures. With its performance, rigorous testing and easy operability, FoundationDB is not just a database but can also be used by those looking to build distributed systems where they can use FoundationDB as a core primitive on which to build their system.\u003c/p\u003e","theta":"220","volume":"2019-11"},{"name":"GraalVM","id":"201911010","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"42","display_name":"GraalVM","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.graalvm.org/\"\u003eGraalVM\u003c/a\u003e\u003c/strong\u003e is a universal virtual machine by Oracle for running applications written in JVM languages, JavaScript, Python, Ruby and R, as well as C/C++ and other LLVM-based languages. At its simplest, GraalVM can be used as a more performant VM for JVM and other supported non-JVM languages. But it also allows us to write polyglot applications with very little performance impact; and its \u003ca href\u003d\"https://www.graalvm.org/22.0/reference-manual/native-image/\"\u003eNative Image\u003c/a\u003e utility (currently only available as an \u003ca href\u003d\"https://docs.oracle.com/en/graalvm/enterprise/19/guide/overview/license/licensing-information.html\"\u003eEarly Adopter Technology\u003c/a\u003e) lets us compile Java code ahead of time to stand-alone executables for faster startup and less memory use. GraalVM has generated a lot of excitement in the Java community, and a host of Java frameworks (including \u003ca href\u003d\"/radar/languages-and-frameworks/micronaut\"\u003eMicronaut\u003c/a\u003e, \u003ca href\u003d\"https://quarkus.io/\"\u003eQuarkus\u003c/a\u003e, and \u003ca href\u003d\"https://helidon.io/#/\"\u003eHelidon\u003c/a\u003e) are already taking advantage of it.\u003c/p\u003e","theta":"225","volume":"2019-11"},{"name":"Hydra","id":"201911014","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"43","display_name":"Hydra","radius":"290","description":"\u003cp\u003eNot everyone needs a self-hosted OAuth2 solution, but if you do, we found \u003cstrong\u003e\u003ca href\u003d\"https://www.ory.sh/hydra/\"\u003eHydra\u003c/a\u003e\u003c/strong\u003e — a fully compliant open-source OAuth2 server and OpenID connect provider — quite useful. We really like that Hydra doesn\u0027t provide any identity management solutions out of the box; so no matter what flavor of identity management you have, it\u0027s possible to integrate it with Hydra through a clean API. This clear separation of identity from the rest of the OAuth2 framework makes it easier to integrate Hydra with an existing authentication ecosystem.\u003c/p\u003e","theta":"230","volume":"2019-11"},{"name":"Kuma","id":"201911006","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"44","display_name":"Kuma","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://kuma.io\"\u003eKuma\u003c/a\u003e\u003c/strong\u003e is a platform-agnostic \u003ca href\u003d\"/radar/techniques/service-mesh\"\u003eservice mesh\u003c/a\u003e for \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e, VMs and bare metal environments. Kuma is implemented as a control plane on top of \u003ca href\u003d\"https://www.envoyproxy.io/\"\u003eEnvoy\u003c/a\u003e and as such can instrument any Layer 4/Layer 7 traffic to secure, observe, route and enhance connectivity between services. Most of the service mesh implementations are targeted natively at the Kubernetes ecosystem which in itself is not bad but hinders the adoption of service mesh for existing non-Kubernetes applications. Rather than waiting for large platform transformation efforts to be complete, you can now use Kuma and modernize the network infrastructure.\u003c/p\u003e","theta":"235","volume":"2019-11"},{"name":"MicroK8s","id":"201911012","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"45","display_name":"MicroK8s","radius":"290","description":"\u003cp\u003eWe talked about \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e in the past and it continues to be the default choice for deploying and managing containers in production clusters. However, it\u0027s getting increasingly difficult to provide a similar experience offline for developers. Among other options, we\u0027ve found \u003cstrong\u003e\u003ca href\u003d\"https://microk8s.io/\"\u003eMicroK8s\u003c/a\u003e\u003c/strong\u003e to be quite useful. To install the \u003ca href\u003d\"https://snapcraft.io/microk8s\"\u003eMicroK8s snap\u003c/a\u003e, pick a release channel (stable, candidate, beta or edge), and you can get Kubernetes running with a few commands. You can also keep track of mainstream releases and choose to upgrade your setup automatically.\u003c/p\u003e","theta":"240","volume":"2019-11"},{"name":"Oculus Quest","id":"201911001","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"46","display_name":"Oculus Quest","radius":"320","description":"\u003cp\u003eWe\u0027ve long tracked AR/VR (Augmented/Virtual Reality) in our Radar, but its appeal has been limited to specific platforms and tethering options. The \u003cstrong\u003eOculus Quest\u003c/strong\u003e changes the game, becoming one of the first consumer mass-market standalone VR headsets that requires no tethering or support outside a smartphone. This device opens the door for a huge jump in potential exposure to VR applications, whose demand will in turn drive the market toward more aggressive innovation. We applaud the democratization of VR this device helps usher in and can\u0027t wait to see what\u0027s on the horizon.\u003c/p\u003e","theta":"245","volume":"2019-11"},{"name":"ONNX","id":"201911047","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"47","display_name":"ONNX","radius":"290","description":"\u003cp\u003eThe tools and frameworks ecosystem around neural networks have been evolving rapidly. The interoperability between them, however, has been a challenge. It\u0027s not uncommon in the ML industry to quickly prototype and train the model in one tool and then deploy it in a different tool for inference. Because the internal format of these tools aren\u0027t compatible, we need to implement and maintain messy convertors to make the models compatible. The Open Neural Network Exchange format \u003cstrong\u003e\u003ca href\u003d\"https://onnx.ai/\"\u003eONNX\u003c/a\u003e\u003c/strong\u003e  addresses this problem. In ONNX, the neural networks are represented as graphs using standard operator specifications, and together with a serialization format for trained weights, neural network models can be \u003ca href\u003d\"https://onnx.ai/supported-tools\"\u003etransferred from one tool to another\u003c/a\u003e. This opens up lots of possibilities, including \u003ca href\u003d\"https://github.com/onnx/models\"\u003eModel Zoo\u003c/a\u003e, a collection of pretrained models in ONNX format.\u003c/p\u003e","theta":"250","volume":"2019-11"},{"name":"Rootless containers","id":"201911013","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"48","display_name":"Rootless containers","radius":"310","description":"\u003cp\u003eIdeally, containers should be managed and run by the respective container runtime without root privileges. This is not trivial but when achieved, it reduces the attack surface and avoids whole classes of security problems, notably privilege escalation out of the container. The community has discussed this as \u003cstrong\u003erootless containers\u003c/strong\u003e for quite a while, and it is part of the open container runtime specification and its standard implementation \u003ca href\u003d\"https://github.com/opencontainers/runc#rootless-containers\"\u003erunc\u003c/a\u003e, which underpins \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e. Now, Docker 19.03 introduces rootless containers as an experimental feature. Although fully functional, the feature doesn\u0027t yet work with several other features such as cgroups resource controls and \u003ca href\u003d\"https://wiki.ubuntu.com/AppArmor\"\u003eAppArmor\u003c/a\u003e security profiles.\u003c/p\u003e","theta":"255","volume":"2019-11"},{"name":"Snowflake","id":"201911005","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"49","display_name":"Snowflake","radius":"320","description":"\u003cp\u003eWe often relate data warehousing to a central infrastructure that is hard to scale and manage with the growing demands around data. \u003cstrong\u003e\u003ca href\u003d\"https://www.snowflake.com\"\u003eSnowflake\u003c/a\u003e\u003c/strong\u003e, however, is a new SQL Data Warehouse as a Service solution built from the ground up for the cloud. With a bunch of neatly crafted features such as database-level atomicity, structured and semi-structured data support, in-database analytics functions and above all with a clear separation of storage, compute and services layer, Snowflake addresses most of the challenges faced in data warehousing.\u003c/p\u003e","theta":"260","volume":"2019-11"},{"name":"Teleport","id":"201911004","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"50","display_name":"Teleport","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://gravitational.com/teleport/\"\u003eTeleport\u003c/a\u003e\u003c/strong\u003e is a security gateway for remotely accessing cloud native infrastructures. One of Teleport\u0027s interesting \u003ca href\u003d\"https://gravitational.com/teleport/features/\"\u003efeatures\u003c/a\u003e is its ability to double as a Certificate Authority (CA) for your infrastructure. You can issue short-lived certificates and build richer role-based access control (RBAC) for your \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e infrastructure (or for just SSH). With increased focus on infrastructure security it\u0027s important to keep track of changes. However, not all events require the same level of auditing. With Teleport you can stick with logging for most of the events but go the extra mile by recording the user screen for more privileged root sessions.\u003c/p\u003e","theta":"265","volume":"2019-11"},{"name":"Commitizen","id":"201911081","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"51","display_name":"Commitizen","radius":"95","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://commitizen.github.io/cz-cli/\"\u003eCommitizen\u003c/a\u003e\u003c/strong\u003e is a simple tool to help streamline the commit process when using Git. It prompts you to provide any required fields and also formats your commit message appropriately. It supports different conventions for describing the required check-in formats, and you can add your own via an adapter. This simple tool saves time and avoids later rejections from a commit hook.\u003c/p\u003e","theta":"68","volume":"2019-11"},{"name":"ESLint","id":"201911079","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"52","display_name":"ESLint","radius":"65","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://eslint.org/\"\u003eESLint\u003c/a\u003e\u003c/strong\u003e is being used as a standard in many of our projects. As a linting tool for JavaScript it has multiple rule sets, recommended rules and plugins in order to extend to frameworks or JavaScript flavors. We\u0027ve seen it leveraged heavily to help teams create and enforce norms in their code by allowing for real-time analysis of code during development. It can be used to standardize coding practices by enforcing best practices and code styling, and identify vulnerabilities in your code. It does so by integrating well with most IDEs and giving live feedback while coding. It\u0027s styling rules in particular will automatically fix the linting errors, making the process seamless and effective without incurring additional development cost. Developers can quickly get up to speed with the rules thanks to the community documentation, which does a good job of explaining coding patterns.  As ESLint becomes more common and powerful, it has gained traction in the industry, and this is illustrated by the \u003ca href\u003d\"/radar/languages-and-frameworks/typescript\"\u003eTypeScript\u003c/a\u003e team\u0027s move to support and work with ESLint rather than investing in TSLint.\u003c/p\u003e","theta":"45","volume":"2019-11"},{"name":"React Styleguidist","id":"201911080","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"53","display_name":"React Styleguidist","radius":"95","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/styleguidist/react-styleguidist\"\u003eReact Styleguidist\u003c/a\u003e\u003c/strong\u003e is a development environment for React components. It includes a dev server with hot reloading capabilities and generates an HTML style guide for sharing with teams. The style guide shows a live version of all components in one place with documentation and a list of their props. We\u0027ve mentioned React Styleguidist as a \u003ca href\u003d\"/radar/tools/ui-dev-environments\"\u003eUI dev environment\u003c/a\u003e before, and over time it has become our default choice among similar tools in this space.\u003c/p\u003e","theta":"23","volume":"2019-11"},{"name":"Bitrise","id":"1287","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"54","display_name":"Bitrise","radius":"220","description":"\u003cp\u003eBuilding, testing and deploying mobile applications entails complex steps, especially when we consider a pipeline from source code repository to app stores. All of these steps can be automated with scripts and build pipelines in generic CI/CD tools. However, our teams have found \u003cstrong\u003e\u003ca href\u003d\"https://www.bitrise.io\"\u003eBitrise\u003c/a\u003e\u003c/strong\u003e, a domain-specific CD tool for mobile applications, useful for mobile applications when there was no need to integrate with build pipelines for back-end systems. Bitrise is easy to set up and provides a comprehensive set of prebuilt steps for most mobile development needs.\u003c/p\u003e","theta":"81","volume":"2019-11"},{"name":"Dependabot","id":"1224","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"55","display_name":"Dependabot","radius":"180","description":"\u003cp\u003eKeeping dependencies up to date is a chore, but for security reasons it\u0027s important to respond to updates in a timely manner. You can use tools to make this process as painless and automated as possible. In practical use our teams have had good experiences with \u003cstrong\u003e\u003ca href\u003d\"http://dependabot.com/\"\u003eDependabot\u003c/a\u003e\u003c/strong\u003e. It integrates with GitHub repositories and automatically checks dependencies for new versions. When required, Dependabot will open a pull request with upgraded dependencies.\u003c/p\u003e","theta":"72","volume":"2019-11"},{"name":"Detekt","id":"201904007","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"56","display_name":"Detekt","radius":"200","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/arturbosch/detekt\"\u003eDetekt\u003c/a\u003e\u003c/strong\u003e is a static code analysis tool for \u003ca href\u003d\"/radar/languages-and-frameworks/kotlin\"\u003eKotlin\u003c/a\u003e. It provides code smell analysis and complexity reports based on highly configurable rule sets. It can be run from the command line and, using plugins, via \u003ca href\u003d\"/radar/tools/gradle\"\u003eGradle\u003c/a\u003e, \u003ca href\u003d\"https://www.sonarqube.org/\"\u003eSonarQube\u003c/a\u003e and IntelliJ. Our teams have found great value in using Detekt to maintain high code quality. When analysis and report generation are integrated into a build pipeline, it\u0027s obviously important that the reports are checked on a regular basis and the team sets aside time to act on the findings.\u003c/p\u003e","theta":"63","volume":"2019-11"},{"name":"Figma","id":"201911070","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"57","display_name":"Figma","radius":"220","description":"\u003cp\u003eOne of the great pain points in interaction and visual design is the lack of tools built for collaboration. This is where \u003cstrong\u003e\u003ca href\u003d\"https://www.figma.com/\"\u003eFigma\u003c/a\u003e\u003c/strong\u003e comes in. It has the same functionalities of design programs such as Sketch and Invision, but by being able to collaborate with another person at the same time, it helps you discover new ideas together with real-time collaboration capabilities. Our teams find Figma very useful, especially in remote and distributed design work enablement and facilitation. In addition to its collaboration capabilities, Figma also offers an API that helps to improve the \u003ca href\u003d\"/radar/techniques/designops\"\u003eDesignOps\u003c/a\u003e process.\u003c/p\u003e","theta":"54","volume":"2019-11"},{"name":"Jib","id":"201911072","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"58","display_name":"Jib","radius":"180","description":"\u003cp\u003eBuilding containerized applications can require complex configurations in development environments and on build agents. If you\u0027re building a Java application and use Docker, you might consider using Google\u0027s \u003cstrong\u003e\u003ca href\u003d\"https://github.com/GoogleContainerTools/jib\"\u003eJib\u003c/a\u003e\u003c/strong\u003e. Jib is an open-source plugin supporting both Maven and Gradle. The Jib plugin uses information from your build config to build your application directly as a Docker image without requiring a Dockerfile or Docker daemon. Jib optimizes around image layering, promising to speed up subsequent builds.\u003c/p\u003e","theta":"45","volume":"2019-11"},{"name":"Loki","id":"201911073","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"59","display_name":"Loki","radius":"200","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://loki.js.org\"\u003eLoki\u003c/a\u003e\u003c/strong\u003e is a visual regression tool that works with \u003ca href\u003d\"https://storybook.js.org/\"\u003eStorybook\u003c/a\u003e, which we mentioned previously in the context of \u003ca href\u003d\"/radar/tools/ui-dev-environments\"\u003eUI dev environments\u003c/a\u003e. With a few lines of configuration, Loki can be used to test all UI components. The preferred mode of operation is using Chrome in a Docker container as this avoids one-pixel differences when tests are run in nonidentical environments. Our experience has been that the tests are very stable, but updates to Storybook tend to cause tests to fail with minor differences. It also seems impossible to test components which use \u003ccode\u003eposition: fixed\u003c/code\u003e but you can work around that by wrapping the component with a \u003ccode\u003efixed\u003c/code\u003e.\u003c/p\u003e","theta":"36","volume":"2019-11"},{"name":"Trivy","id":"201911077","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"60","display_name":"Trivy","radius":"190","description":"\u003cp\u003eBuild pipelines that create and deploy containers should include \u003ca href\u003d\"/radar/techniques/container-security-scanning\"\u003econtainer security scanning\u003c/a\u003e. Our teams particularly like \u003cstrong\u003e\u003ca href\u003d\"https://github.com/aquasecurity/trivy\"\u003eTrivy\u003c/a\u003e\u003c/strong\u003e, a vulnerability scanner for containers, because it\u0027s easier to set up than other tools,  thanks to it shipping as a stand-alone binary. Other benefits of Trivy are that it\u0027s open-source software and that it supports \u003ca href\u003d\"/radar/techniques/distroless-docker-images\"\u003edistroless containers\u003c/a\u003e.\u003c/p\u003e","theta":"27","volume":"2019-11"},{"name":"Twistlock","id":"201911075","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"61","display_name":"Twistlock","radius":"200","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.paloaltonetworks.com/prisma/cloud\"\u003eTwistlock\u003c/a\u003e\u003c/strong\u003e is a commercial product with build-time and run-time security vulnerability detection and prevention capabilities. These capabilities span protecting VMs, container schedulers and containers to various registries and repositories that applications rely on. Twistlock has helped our teams accelerate development of regulated applications, where application infrastructure and architecture require compliance with, for example, Payment Card Industry (PCI) standards and the Health Insurance Portability and Accountability Act (HIPAA). Our teams have enjoyed the developer experience that Twistlock provides: the ability to run provisioning as code, the easy integration with other common observability platforms, and the out-of-the-box benchmarks to measure the infrastructure against industry-consensus best practices. We run Twistlock with regular runtime scans over our cloud-native applications, particularly when regulatory compliance is required.\u003c/p\u003e","theta":"18","volume":"2019-11"},{"name":"Yocto Project","id":"201911074","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"62","display_name":"Yocto Project","radius":"220","description":"\u003cp\u003eIncreasingly we\u0027re seeing powerful Internet of Things devices that run Linux rather than a special embedded OS. In order to reduce resource usage and decrease the attack surface, it makes sense to build a custom Linux distribution that only contains the tools and dependencies needed to run the software on the device. In this context the \u003cstrong\u003e\u003ca href\u003d\"https://www.yoctoproject.org/\"\u003eYocto Project\u003c/a\u003e\u003c/strong\u003e has renewed relevance as a tool to create a Linux distribution tailored to the needs of a specific case. The learning curve is steep and due to its flexibility, it can be easy to do the wrong thing. However, over the many years of its existence, the Yocto Project has attracted an active community that can help. Compared to similar tools, it\u0027s easier to integrate into a CD workflow and, unlike Android Things or Ubuntu core for example, it\u0027s not tied to a specific ecosystem.\u003c/p\u003e","theta":"9","volume":"2019-11"},{"name":"Aplas","id":"201911066","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"63","display_name":"Aplas","radius":"290","description":"\u003cp\u003eIt\u0027s often very difficult to get a handle on our software estates as they grow ever more complex. \u003cstrong\u003e\u003ca href\u003d\"https://aplas.com/public\"\u003eAplas\u003c/a\u003e\u003c/strong\u003e is a new software mapping tool that can be used to create visualizations of our software landscapes in the form of maps. The tool works by ingesting metadata about your existing systems and then displaying a map over which various views can be projected. Ingestion is either a manual process or one that can be automated via APIs. We\u0027re pretty excited to see this product evolve and to see what\u0027s possible with the automated collection of metadata. It should be possible, for example, to expose \u003ca href\u003d\"/radar/techniques/architectural-fitness-function\"\u003earchitectural fitness functions\u003c/a\u003e such as \u003ca href\u003d\"/radar/techniques/run-cost-as-architecture-fitness-function\"\u003erun cost\u003c/a\u003e to create visualizations of how much is being spent on cloud infrastructure. Understanding which systems talk to other systems via which technology is another problem we often face and Aplas can visualize it for us.\u003c/p\u003e","theta":"84","volume":"2019-11"},{"name":"asdf-vm","id":"201911067","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"64","display_name":"asdf-vm","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://asdf-vm.com\"\u003easdf-vm\u003c/a\u003e\u003c/strong\u003e is a command-line tool to manage runtime versions of multiple languages, per project. It\u0027s similar to other command-line version management tools, such as \u003ca href\u003d\"https://rvm.io/\"\u003eRVM\u003c/a\u003e for Ruby and \u003ca href\u003d\"https://github.com/nvm-sh/nvm\"\u003envm\u003c/a\u003e for Node.js, with the advantage of an extensible plugin architecture to handle multiple languages. Its list of current \u003ca href\u003d\"https://asdf-vm.com/#/plugins-all\"\u003eplugins\u003c/a\u003e include many languages as well as tools such as \u003ca href\u003d\"https://github.com/rajatvig/asdf-bazel\"\u003eBazel\u003c/a\u003e or \u003ca href\u003d\"https://github.com/RykHawthorn/asdf-tflint\"\u003etflint\u003c/a\u003e, whose runtime version you may need to manage per project.\u003c/p\u003e","theta":"78","volume":"2019-11"},{"name":"AWSume","id":"201911062","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"65","display_name":"AWSume","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/trek10inc/awsume\"\u003eAWSume\u003c/a\u003e\u003c/strong\u003e is a convenient script to manage AWS session tokens and assume role credentials from the command line. We find AWSume quite handy when we deal with multiple AWS accounts at the same time. Instead of specifying profiles individually in every command, the script reads from the CLI cache and exports them to environment variables. As a result, both the commands and AWS SDKs pick up the right credentials.\u003c/p\u003e","theta":"72","volume":"2019-11"},{"name":"dbt","id":"201911076","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"66","display_name":"dbt","radius":"310","description":"\u003cp\u003eData transformation is an essential part of data-processing workflows: filtering, grouping or joining multiple sources into a format that is suitable for analyzing data or feeding machine-learning models. \u003cstrong\u003e\u003ca href\u003d\"https://www.getdbt.com\"\u003edbt\u003c/a\u003e\u003c/strong\u003e is an open-source tool and a commercial SaaS product that provides simple and effective transformation capabilities for data analysts. The current frameworks and tooling for data transformation fall either into the group of \u003cem\u003epowerful and flexible\u003c/em\u003e — requiring intimate understanding of the programming model and languages of the framework such as \u003ca href\u003d\"/radar/platforms/apache-spark\"\u003eApache Spark\u003c/a\u003e — or in the group of dumb drag-and-drop UI tools that don\u0027t lend themselves to reliable engineering practices such as automated testing and deployment. dbt fills a niche: it uses SQL — an interface widely understood — to model simple batch transformations, while it provides command-line tooling that encourages good engineering practices such as versioning, automated testing and deployment; essentially it implements SQL-based transformation modeling as code. dbt currently supports multiple \u003ca href\u003d\"https://docs.getdbt.com/docs/supported-databases\"\u003edata sources\u003c/a\u003e, including \u003ca href\u003d\"/radar/platforms/snowflake\"\u003eSnowflake\u003c/a\u003e and Postgres, and provides various \u003ca href\u003d\"https://docs.getdbt.com/docs/running-dbt-in-production\"\u003eexecution options\u003c/a\u003e, such as \u003ca href\u003d\"/radar/tools/airflow\"\u003eAirflow\u003c/a\u003e and Apache\u0027s own cloud offering. Its transformation capability is limited to what SQL offers, and it doesn\u0027t support real-time streaming transformations at the time of writing.\u003c/p\u003e","theta":"66","volume":"2019-11"},{"name":"Docker Notary","id":"201911068","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"67","display_name":"Docker Notary","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/notaryproject/notary\"\u003eDocker Notary\u003c/a\u003e\u003c/strong\u003e is an OSS tool that enables signing of assets such as images, files and containers. This means that the provenance of assets can be asserted which is superuseful in regulated environments and better practice everywhere. As an example, when a container is created, it\u0027s signed by a private key and a hash, tied to the publisher\u0027s identity, stored as metadata. Once published, the provenance of the container (or other asset) can be checked using the image hash and the publisher\u0027s public key. There are publicly available, trusted registries such as the \u003ca href\u003d\"https://docs.docker.com/ee/dtr/\"\u003eDocker Trusted Registry\u003c/a\u003e, but it\u0027s also possible to run your own. Our teams have reported some spiky edges running local Notary servers and suggest using a registry that includes Notary where possible.\u003c/p\u003e","theta":"60","volume":"2019-11"},{"name":"Facets","id":"201911101","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"68","display_name":"Facets","radius":"300","description":"\u003cp\u003eGiven the growing amount of weighty decisions that are derived from large data sets, either directly or as training input for machine learning models, it\u0027s important to understand the gaps, flaws and potential biases in your data. Google\u0027s \u003cstrong\u003e\u003ca href\u003d\"https://pair-code.github.io/facets/\"\u003eFacets\u003c/a\u003e\u003c/strong\u003e project provides two helpful tools in this space: Facets Overview and Facets Dive. Facets Overview visualizes the distribution of values for features in a data set, can show training and validation set skew and can be used to compare multiple data sets; Facets Dive is for drilling down and visualizing individual data points in large data sets, using different visual dimensions to explore the relationships between attributes. They\u0027re both useful tools in carrying out \u003ca href\u003d\"/radar/techniques/ethical-bias-testing\"\u003eethical bias testing\u003c/a\u003e.\u003c/p\u003e","theta":"54","volume":"2019-11"},{"name":"Falco","id":"201911063","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"69","display_name":"Falco","radius":"310","description":"\u003cp\u003eWith increased adoption of \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e as container orchestrator, the security toolset around containers and Kubernetes is evolving rapidly. \u003cstrong\u003e\u003ca href\u003d\"https://falco.org/\"\u003eFalco\u003c/a\u003e\u003c/strong\u003e is one such container-native tool aimed at addressing runtime security. Falco leverages \u003ca href\u003d\"https://sysdig.com/blog/fascinating-world-linux-system-calls/\"\u003eSysdig\u0027s Linux kernel instrumentation\u003c/a\u003e and system call profiling and lets us gain deep insights into system behavior and helps us detect abnormal activities in applications, containers, underlying host or Kubernetes orchestrator itself. We like Falco\u0027s capability to detect threats without injecting third-party code or sidecar containers.\u003c/p\u003e","theta":"48","volume":"2019-11"},{"name":"in-toto","id":"201911065","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"70","display_name":"in-toto","radius":"300","description":"\u003cp\u003eWe\u0027re seeing increased use of \u003ca href\u003d\"/radar/techniques/binary-attestation\"\u003eBinary attestation\u003c/a\u003e for securing the software supply chain, particularly within regulated industries. The currently favored approaches seem to involve either building a custom system for implementing the binary verification or relying on a cloud vendor\u0027s service. We\u0027re encouraged to see the open-source \u003cstrong\u003e\u003ca href\u003d\"https://github.com/in-toto/in-toto\"\u003ein-toto\u003c/a\u003e\u003c/strong\u003e enter this space. in-toto is a framework for cryptographically verifying every component and step along the path to production for a software artifact. The project includes a number of integrations into many widely used build, container auditing and deployment tools. A software supply chain tool can be a critical piece of an organization\u0027s security apparatus, so we like that as an open-source project, in-toto\u0027s behavior is transparent, and its own integrity and supply chain can be verified by the community. We\u0027ll have to wait and see if it\u0027ll gain a critical mass of users and contributors to compete in this space.\u003c/p\u003e","theta":"42","volume":"2019-11"},{"name":"Kubeflow","id":"201911060","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"71","display_name":"Kubeflow","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.kubeflow.org/\"\u003eKubeflow\u003c/a\u003e\u003c/strong\u003e is interesting for two reasons. First, it is an innovative use of \u003ca href\u003d\"/radar/tools/kubernetes-operators\"\u003eKubernetes Operators\u003c/a\u003e which we\u0027ve spotlighted in our April 2019 edition of the Radar. Second, it provides a way to encode and version machine-learning workflows so that they can be more easily ported from one execution environment to another. Kubeflow consists of several components, including Jupyter notebooks, data pipelines, and control tools. Several of these components are packaged as Kubernetes operators to draw on Kubernetes\u0027s ability to react to events generated by pods implementing various stages of the workflow. By packaging the individual programs and data as containers, entire workflows can be ported from one environment to another. This can be useful when moving a useful but computationally challenging workflow developed in the cloud to a custom supercomputer or tensor processing unit cluster.\u003c/p\u003e","theta":"36","volume":"2019-11"},{"name":"MemGuard","id":"201911061","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"72","display_name":"MemGuard","radius":"290","description":"\u003cp\u003eIf your application handles sensitive information (such as cryptographic keys) as plain text in memory, there\u0027s a high probability that someone could potentially exploit it as an attack vector and compromise the information. Most of the cloud-based solutions often use \u003ca href\u003d\"https://en.wikipedia.org/wiki/Hardware_security_module\"\u003ehardware security modules (HSM)\u003c/a\u003e to avoid such attacks. However, if you\u0027re in a situation where you need to do this in a self-hosted manner without access to HSMs, then we\u0027ve found \u003cstrong\u003e\u003ca href\u003d\"https://github.com/awnumar/memguard\"\u003eMemGuard\u003c/a\u003e\u003c/strong\u003e to be quite useful. MemGuard acts as a secured software enclave for storage of sensitive information in memory. Although MemGuard is not a replacement for HSMs, it does deploy a number of security tactics such as protection against cold boot attacks, avoiding interference with garbage collection and fortifying with guard pages to reduce the likelihood of sensitive data being exposed.\u003c/p\u003e","theta":"30","volume":"2019-11"},{"name":"Open Policy Agent (OPA)","id":"201911069","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"73","display_name":"Open Policy Agent (OPA)","radius":"310","description":"\u003cp\u003eDefining and enforcing security policies uniformly across a diverse technology landscape is a challenge. Even for simple applications, you have to control access to their components — such as container orchestrators, services and data stores to keep the services\u0027 state — using their components\u0027 built-in security policy configuration and enforcement mechanisms.\u003c/p\u003e\n\n\u003cp\u003eWe\u0027re excited about \u003cstrong\u003e\u003ca href\u003d\"https://www.openpolicyagent.org/\"\u003eOpen Policy Agent (OPA)\u003c/a\u003e\u003c/strong\u003e, an open-source technology that attempts to solve this problem. OPA lets you define fine-grained access control and flexible policies as code, using the \u003ca href\u003d\"https://www.openpolicyagent.org/docs/latest/policy-language/\"\u003eRego\u003c/a\u003e policy definition language. Rego enforces the policies in a distributed and unobtrusive manner outside of the application code. At the time of this writing, OPA implements uniform and flexible policy definition and enforcement to secure access to Kubernetes APIs, microservices APIs through \u003ca href\u003d\"https://www.envoyproxy.io/\"\u003eEnvoy\u003c/a\u003e sidecar and \u003ca href\u003d\"/radar/tools/apache-kafka\"\u003eKafka\u003c/a\u003e. It can also be used as a sidecar to any service to verify access policies or filter response data. \u003ca href\u003d\"https://www.styra.com/\"\u003eStyra\u003c/a\u003e, the company behind OPA, provides commercial solutions for centralized visibility to distributed policies. We like to see OPA mature through the \u003ca href\u003d\"https://www.cncf.io/blog/2019/04/02/toc-votes-to-move-opa-into-cncf-incubator/\"\u003eCNCF incubation program\u003c/a\u003e and continue to build support for more challenging policy enforcement scenarios such as diverse data stores.\u003c/p\u003e","theta":"24","volume":"2019-11"},{"name":"Pumba","id":"201911071","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"74","display_name":"Pumba","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/alexei-led/pumba\"\u003ePumba\u003c/a\u003e\u003c/strong\u003e is a chaos testing and network emulation tool for Docker. Pumba can kill, stop, remove or pause Docker containers. Pumba can also emulate networks and simulate different network failures such as delays, packet loss and bandwidth rate limits. Pumba uses the \u003ca href\u003d\"https://en.wikipedia.org/wiki/Tc_(Linux)\"\u003etc\u003c/a\u003e tool for network emulation which means it needs to be available in our containers or we need to run Pumba in a sidecar container with tc. Pumba is particularly useful when we want to run some automated chaos tests against a distributed system running on a bunch of containers locally or in the build pipeline.\u003c/p\u003e","theta":"18","volume":"2019-11"},{"name":"Skaffold","id":"201911059","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"75","display_name":"Skaffold","radius":"290","description":"\u003cp\u003eGoogle brings us \u003cstrong\u003e\u003ca href\u003d\"https://skaffold.dev/\"\u003eSkaffold\u003c/a\u003e\u003c/strong\u003e, an open-source tool to automate local development workflows, including deployment on \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e. Skaffold detects changes in source code and triggers workflows to build, tag and deploy into a K8s cluster including capturing application logs back to the command line. The workflows are pluggable with different build and deployment tools, but this comes with an opinionated default configuration to make it easier to get started.\u003c/p\u003e","theta":"12","volume":"2019-11"},{"name":"What-If Tool","id":"201911064","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"76","display_name":"What-If Tool","radius":"300","description":"\u003cp\u003eThe machine learning world has shifted emphasis slightly from exploring what models are capable of understanding to how they do it. Concerns about introducing bias or overgeneralizing a model\u0027s applicability have resulted in interesting new tools such as \u003cstrong\u003e\u003ca href\u003d\"https://pair-code.github.io/what-if-tool/\"\u003eWhat-If Tool\u003c/a\u003e\u003c/strong\u003e (WIT). This tool helps data scientists to dig into a model\u0027s behavior and to visualize the impact various features and data sets have on the output. Introduced by Google and available either through \u003ca href\u003d\"https://www.tensorflow.org/tensorboard\"\u003eTensorboard\u003c/a\u003e or \u003ca href\u003d\"/radar/tools/jupyter\"\u003eJupyter\u003c/a\u003e notebooks, WIT simplifies the tasks of comparing models, slicing data sets, visualizing facets and editing individual data points. Although WIT makes it easier to perform these analyses, they still require a deep understanding of the mathematics and theory behind the models. It is a tool for data scientists to gain deeper insights into model behavior. Naive users shouldn\u0027t expect any tool to remove the risk or minimize the damage done by a misapplied or poorly trained algorithm.\u003c/p\u003e","theta":"6","volume":"2019-11"},{"name":"Azure Data Factory for orchestration","id":"201911058","quadrant":"Tools","ring":"Hold","movement":"t","radarId":"77","display_name":"Azure Data Factory for orchestration","radius":"375","description":"\u003cp\u003e\u003ca href\u003d\"https://azure.microsoft.com/en-us/services/data-factory/\"\u003eAzure Data Factory\u003c/a\u003e (ADF) is currently Azure\u0027s default product for orchestrating data-processing pipelines. It supports data ingestion, copying data from and to different storage types on prem or on Azure and executing transformation logic. While we\u0027ve had a reasonable experience with ADF for simple migrations of data stores from on prem to cloud, we discourage the use of \u003cstrong\u003eAzure Data Factory for orchestration\u003c/strong\u003e of complex data-processing pipelines. Our experience has been challenging due to several factors, including limited coverage of capabilities that can be implemented through coding first, as it appears that ADF is prioritizing enabling \u003ca href\u003d\"/radar/platforms/low-code-platforms\"\u003elow-code platform\u003c/a\u003e capabilities first; poor debuggability and error reporting; limited observability as ADF logging capabilities don\u0027t integrate with other products such as Azure Data Lake Storage or Databricks, making it difficult to get an end-to-end observability in place; and availability of data source-triggering mechanisms only to certain regions. At this time, we encourage using other open-source orchestration tools (e.g., \u003ca href\u003d\"/radar/tools/airflow\"\u003eAirflow\u003c/a\u003e) for complex data pipelines and limit ADF for data copying or snapshotting. We\u0027re hoping that ADF will address these concerns to support for more complex data-processing workflows and prioritize access to capabilities through code first.\u003c/p\u003e","theta":"45","volume":"2019-11"},{"name":"Arrow","id":"201904040","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"78","display_name":"Arrow","radius":"170","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://arrow-kt.io/\"\u003eArrow\u003c/a\u003e\u003c/strong\u003e is a functional programming library for \u003ca href\u003d\"/radar/languages-and-frameworks/kotlin\"\u003eKotlin\u003c/a\u003e, created by merging two existing popular libraries (\u003ca href\u003d\"https://github.com/JcMinarro/kategory\"\u003ekategory\u003c/a\u003e and \u003ca href\u003d\"https://github.com/MarioAriasC/funKTionale\"\u003efunKTionale\u003c/a\u003e). While Kotlin provides building blocks for functional programming, Arrow delivers a package of ready-to-use higher-level abstractions for application developers. It provides data types, type classes, effects, optics and other functional programming patterns as well as integrations with popular libraries. Our initial positive impressions of Arrow were confirmed when using it to build applications that are now in production.\u003c/p\u003e","theta":"278","volume":"2019-11"},{"name":"Flutter","id":"1246","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"79","display_name":"Flutter","radius":"170","description":"\u003cp\u003eSeveral of our teams use \u003cstrong\u003e\u003ca href\u003d\"http://flutter.io/\"\u003eFlutter\u003c/a\u003e\u003c/strong\u003e and really like it. It\u0027s a cross-platform framework that enables you to write native mobile apps in \u003ca href\u003d\"/radar/languages-and-frameworks/google-dart\"\u003eDart\u003c/a\u003e. It benefits from Dart and can be compiled into native code and communicates with the target platform without bridge and context switching. Flutter\u0027s hot-reload feature is still impressive and provides superfast visual feedback when editing code. We\u0027re confident in recommending that you try Flutter on one of your projects.\u003c/p\u003e","theta":"292","volume":"2019-11"},{"name":"jest-when","id":"201911030","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"80","display_name":"jest-when","radius":"220","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.npmjs.com/package/jest-when\"\u003ejest-when\u003c/a\u003e\u003c/strong\u003e is a lightweight JavaScript library that complements \u003ca href\u003d\"/radar/languages-and-frameworks/jest\"\u003eJest\u003c/a\u003e by matching mock function call arguments. Jest is a great tool for testing the stack; jest-when allows you to expect specific arguments for mock functions and thus lets you write more robust unit tests of modules with many dependencies.\u003c/p\u003e","theta":"300","volume":"2019-11"},{"name":"Micronaut","id":"201904032","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"81","display_name":"Micronaut","radius":"190","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://micronaut.io/\"\u003eMicronaut\u003c/a\u003e\u003c/strong\u003e is a JVM framework for building services using Java, \u003ca href\u003d\"/radar/languages-and-frameworks/kotlin\"\u003eKotlin\u003c/a\u003e or Groovy. It distinguishes itself through a small memory footprint and short startup time; it achieves these improvements by avoiding runtime reflection for \u003ca href\u003d\"https://martinfowler.com/articles/injection.html\"\u003edependency injection (DI)\u003c/a\u003e and proxy generation, a common shortcoming of traditional frameworks, and instead uses a DI/\u003ca href\u003d\"https://en.wikipedia.org/wiki/Aspect-oriented_programming\"\u003eAOP\u003c/a\u003e container which performs dependency injection at compile time. This makes it attractive not just for standard server-side microservices but also in the context of, for example, the Internet of Things, Android applications and serverless functions. Micronaut uses Netty and has first-class support for reactive programming. It also includes features such as service discovery and circuit breaking that make it cloud-native friendly. Micronaut is a very promising entrant to the full-stack framework for the JVM space, and we\u0027re seeing it in more and more projects in production, prompting us to move it to Trial.\u003c/p\u003e","theta":"310","volume":"2019-11"},{"name":"React Hooks","id":"201911020","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"82","display_name":"React Hooks","radius":"245","description":"\u003cp\u003eEarlier this year, \u003cstrong\u003e\u003ca href\u003d\"https://reactjs.org/docs/hooks-intro.html\"\u003eReact Hooks\u003c/a\u003e\u003c/strong\u003e were introduced to the popular JavaScript framework. They make it possible to use state and other React features without writing a class, offering a cleaner approach than higher-order components or render-props for use cases. Libraries such as \u003ca href\u003d\"/radar/languages-and-frameworks/material-ui\"\u003eMaterial UI\u003c/a\u003e and \u003ca href\u003d\"/radar/languages-and-frameworks/apollo\"\u003eApollo\u003c/a\u003e have already switched to using Hooks. There are some issues with testing Hooks, especially with Enzyme, which contributed to our reassessment of \u003ca href\u003d\"/radar/languages-and-frameworks/enzyme\"\u003eEnzyme\u003c/a\u003e as the tool of choice.\u003c/p\u003e","theta":"320","volume":"2019-11"},{"name":"React Testing Library","id":"201904035","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"83","display_name":"React Testing Library","radius":"160","description":"\u003cp\u003eThe JavaScript world moves pretty fast, and as we gain more experience using a framework our recommendations change. The \u003cstrong\u003e\u003ca href\u003d\"https://testing-library.com/\"\u003eReact Testing Library\u003c/a\u003e\u003c/strong\u003e is a good example of a framework that with deeper usage has eclipsed the alternatives to become the sensible default when testing React-based frontends. Our teams like the fact that tests written with this framework are less brittle than with alternative frameworks such as \u003ca href\u003d\"/radar/languages-and-frameworks/enzyme\"\u003eEnzyme\u003c/a\u003e because you\u0027re encouraged to test component relationships individually as opposed to testing all implementation details.\u003c/p\u003e","theta":"330","volume":"2019-11"},{"name":"Styled components","id":"201911078","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"84","display_name":"Styled components","radius":"220","description":"\u003cp\u003eUsing tagged template literals \u003cstrong\u003e\u003ca href\u003d\"https://www.styled-components.com/\"\u003estyled components\u003c/a\u003e\u003c/strong\u003e make it possible to put the CSS needed to style a React component directly into the JavaScript code that creates the component. This greatly reduces the pain with managing CSS and obviates the need for naming conventions or other means of avoiding naming conflicts in CSS. Developers can see the styling when looking at the component definition, and they don\u0027t have to memorize several megabytes worth of CSS. Of course, placing the CSS into the JavaScript code can make it harder to get a consistent view across the styling of different components, which is why we recommend understanding the trade-offs with this approach.\u003c/p\u003e","theta":"340","volume":"2019-11"},{"name":"TensorFlow","id":"982","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"85","display_name":"TensorFlow","radius":"174","description":"\u003cp\u003eWith its 2.0 release, \u003cstrong\u003e\u003ca href\u003d\"https://www.tensorflow.org/\"\u003eTensorFlow\u003c/a\u003e\u003c/strong\u003e retains its prominence as the industry’s leading machine learning framework. TensorFlow began as a numerical processing package that gradually expanded to include libraries supporting a variety of ML approaches and execution environments, ranging from mobile CPU to large GPU clusters. Along the way, a slew of frameworks became available to simplify the tasks of network creation and training. At the same time, other frameworks, notably \u003ca href\u003d\"/radar/languages-and-frameworks/pytorch\"\u003ePyTorch\u003c/a\u003e, offered an imperative programming model that made debugging and execution simpler and easier. TensorFlow 2.0 now defaults to imperative flow (eager execution) and adopts \u003ca href\u003d\"/radar/languages-and-frameworks/keras\"\u003eKeras\u003c/a\u003e as the single high-level API. While these changes modernize TensorFlow\u0027s usability and make it more competitive with PyTorch, it is a significant rewrite that often breaks backward compatibility — many tools and serving frameworks in the TensorFlow ecosystem won\u0027t immediately work with the new version. For the time being, consider whether you want to design and experiment in TensorFlow 2.0 but revert to version 1 to serve and run your models in production.\u003c/p\u003e","theta":"350","volume":"2019-11"},{"name":"Fairseq","id":"201911028","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"86","display_name":"Fairseq","radius":"330","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/pytorch/fairseq\"\u003eFairseq\u003c/a\u003e\u003c/strong\u003e is a sequence-to-sequence modelling toolkit by Facebook AI Research that allows researchers and developers to train custom models for translation, summarization, language modeling and other NLP tasks. For users of \u003ca href\u003d\"/radar/languages-and-frameworks/pytorch\"\u003ePyTorch\u003c/a\u003e, this is a good choice. It provides reference implementations of various sequence-to-sequence models; supports distributed training across multiple GPUs and machines; is very extensible; and has a bunch of pretrained models, including \u003ca href\u003d\"https://github.com/pytorch/fairseq/blob/master/examples/roberta/README.md\"\u003eRoBERTa\u003c/a\u003e which is an optimization on top of \u003ca href\u003d\"/radar/techniques/bert\"\u003eBERT\u003c/a\u003e.\u003c/p\u003e","theta":"278","volume":"2019-11"},{"name":"Flair","id":"201911029","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"87","display_name":"Flair","radius":"330","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/zalandoresearch/flair\"\u003eFlair\u003c/a\u003e\u003c/strong\u003e is a simple Python-based framework for NLP processing. It allows users to do standard NLP tasks such as \u003ca href\u003d\"https://en.wikipedia.org/wiki/Named-entity_recognition\"\u003enamed entity recognition (NER)\u003c/a\u003e, \u003ca href\u003d\"https://en.wikipedia.org/wiki/Part-of-speech_tagging\"\u003epart-of-speech tagging (PoS)\u003c/a\u003e, \u003ca href\u003d\"https://en.wikipedia.org/wiki/Word-sense_disambiguation\"\u003eword-sense disambiguation\u003c/a\u003e and classification and performs well on a range of NLP tasks. Flair presents a simple and unified interface for a variety of word and document embeddings, including \u003ca href\u003d\"/radar/techniques/bert\"\u003eBERT\u003c/a\u003e, Elmo and its own Flair embeddings. It also has multilingual support. The framework itself is built on top of \u003ca href\u003d\"/radar/languages-and-frameworks/pytorch\"\u003ePyTorch\u003c/a\u003e. We\u0027re using it in some of our projects and like its ease of use and powerful abstractions.\u003c/p\u003e","theta":"286","volume":"2019-11"},{"name":"Gatsby.js","id":"201911025","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"88","display_name":"Gatsby.js","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.gatsbyjs.org/\"\u003eGatsby.js\u003c/a\u003e\u003c/strong\u003e is a framework to write web applications in an architectural style known as \u003ca href\u003d\"/radar/techniques/jamstack\"\u003eJAMstack\u003c/a\u003e. Part of the application is generated at build time and deployed as a static site, while the remainder of the functionality is implemented as a \u003ca href\u003d\"https://en.wikipedia.org/wiki/Progressive_web_applications\"\u003eprogressive web application (PWA)\u003c/a\u003e running in the browser. Such applications work without code running on the server side. Usually, though, the PWA makes calls to third-party APIs and SaaS solutions for content management, for example. In the case of Gatsby.js, all client and build time code is written using React. The framework includes some optimizations to make the web application feel fast. It provides code and data splitting out of the box to minimize load times and speeds up performance when navigating the application by prefetching resources. APIs are called via \u003ca href\u003d\"/radar/languages-and-frameworks/graphql\"\u003eGraphQL\u003c/a\u003e and several plugins simplify integration with existing services.\u003c/p\u003e","theta":"294","volume":"2019-11"},{"name":"GraphQL","id":"986","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"89","display_name":"GraphQL","radius":"300","description":"\u003cp\u003eWe\u0027ve seen many successful \u003cstrong\u003e\u003ca href\u003d\"https://github.com/facebook/graphql\"\u003eGraphQL\u003c/a\u003e\u003c/strong\u003e implementations on our projects. We\u0027ve seen some interesting patterns of use too, including \u003ca href\u003d\"/radar/techniques/graphql-for-server-side-resource-aggregation\"\u003eGraphQL for server-side resource aggregation\u003c/a\u003e. That said, we\u0027ve concerns about misuse of this framework and some of the problems that can occur. Examples include performance gotchas around N+1 queries and lots of boilerplate code needed when adding new models, leading to complexity. There are workarounds to these gotchas such as query caching. Even though it\u0027s not a silver bullet, we still think it\u0027s worth assessing as part of your architecture.\u003c/p\u003e","theta":"302","volume":"2019-11"},{"name":"KotlinTest","id":"201911021","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"90","display_name":"KotlinTest","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/kotlintest/kotlintest\"\u003eKotlinTest\u003c/a\u003e\u003c/strong\u003e is a stand-alone testing tool for the \u003ca href\u003d\"/radar/languages-and-frameworks/kotlin\"\u003eKotlin\u003c/a\u003e ecosystem that our teams have come to like. It allows \u003ca href\u003d\"/radar/techniques/property-based-unit-testing\"\u003eproperty-based testing\u003c/a\u003e, a technique we\u0027ve highlighted in the Radar before. Key advantages are that it offers a variety of testing styles in order to structure the test suites and that it comes with a comprehensive set of matchers, which allow for expressive tests in an elegant internal DSL.\u003c/p\u003e","theta":"310","volume":"2019-11"},{"name":"NestJS","id":"201911023","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"91","display_name":"NestJS","radius":"330","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://nestjs.com/\"\u003eNestJS\u003c/a\u003e\u003c/strong\u003e is a server-side Node.js framework written in \u003ca href\u003d\"/radar/languages-and-frameworks/typescript\"\u003eTypeScript\u003c/a\u003e. By integrating the rich ecology of the Node.js community, NestJS provides an out-of-the-box application architecture. The mental model to develop NestJS is similar to the server-side version of Angular or the TypeScript version of Spring Boot, so the learning curve for developers is low. NestJS supports protocols such as \u003ca href\u003d\"/radar/languages-and-frameworks/graphql\"\u003eGraphQL\u003c/a\u003e, Websocket and ORM libraries.\u003c/p\u003e","theta":"319","volume":"2019-11"},{"name":"Paged.js","id":"201911024","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"92","display_name":"Paged.js","radius":"340","description":"\u003cp\u003eWhen using HTML and related technologies to produce books and other print output, the question of pagination must be considered. This includes page counters, repeated elements in headers and footers, as well as mechanisms to avoid awkward page breaks. \u003cstrong\u003e\u003ca href\u003d\"https://www.pagedmedia.org/paged-js/\"\u003ePaged.js\u003c/a\u003e\u003c/strong\u003e is an open-source library that implements a series of polyfills for the \u003ca href\u003d\"https://www.w3.org/TR/css-page-3/\"\u003ePaged Media\u003c/a\u003e and \u003ca href\u003d\"https://www.w3.org/TR/css-gcpm-3/\"\u003eGenerated Content for Paged Media\u003c/a\u003e CSS modules. It is still experimental but fills an important gap in the \"write once, publish everywhere\" story for HTML.\u003c/p\u003e","theta":"327","volume":"2019-11"},{"name":"Quarkus","id":"201911026","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"93","display_name":"Quarkus","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://quarkus.io/\"\u003eQuarkus\u003c/a\u003e\u003c/strong\u003e is a cloud-native, container-first framework by Red Hat for writing Java applications. It has a very fast startup time (tens of milliseconds) and has low memory utilization which makes it a good candidate for FaaS or frequent scaling up and down in a container orchestrator. Like \u003ca href\u003d\"/radar/languages-and-frameworks/micronaut\"\u003eMicronaut\u003c/a\u003e, Quarkus achieves this by using ahead-of-time compilation techniques to do dependency injection at compile time and avoid the runtime costs of reflection. It also works well with \u003ca href\u003d\"/radar/platforms/graalvm\"\u003eGraalVM\u003c/a\u003e\u0027s Native Image which further reduces startup time. Quarkus supports both imperative and reactive models. Along with Micronaut and \u003ca href\u003d\"https://helidon.io/#/\"\u003eHelidon\u003c/a\u003e, Quarkus is leading the charge on the new generation of Java frameworks which attempt to address startup performance and memory without sacrificing developer effectiveness. It\u0027s gained a lot of community attention and is worth keeping an eye on.\u003c/p\u003e","theta":"335","volume":"2019-11"},{"name":"SwiftUI","id":"201911018","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"94","display_name":"SwiftUI","radius":"290","description":"\u003cp\u003eApple has taken a big step forward with their new \u003cstrong\u003e\u003ca href\u003d\"https://developer.apple.com/xcode/swiftui/\"\u003eSwiftUI\u003c/a\u003e\u003c/strong\u003e framework for implementing user interfaces on macOS and iOS platforms. We like that SwiftUI moves beyond the somewhat kludgy relationship between Interface Builder and XCode and adopts a coherent, declarative and code-centric approach. You can now view your code and the resulting visual interface side by side in XCode 11, making for a much better developer experience. The SwiftUI framework also draws inspiration from the \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e world that has dominated web development in recent years. Immutable values in view models and an asynchronous update mechanism make for a unified reactive programming model. This gives developers an entirely native alternative to similar reactive frameworks such as \u003ca href\u003d\"/radar/languages-and-frameworks/react-native\"\u003eReact Native\u003c/a\u003e or \u003ca href\u003d\"/radar/languages-and-frameworks/flutter\"\u003eFlutter\u003c/a\u003e. Although SwiftUI definitely represents the future of Apple UI development, it is quite new and it will take time to smooth out the rough edges. We look forward to improved documentation and a community of developers who can establish a set of practices for testing and other engineering concerns.\u003c/p\u003e","theta":"343","volume":"2019-11"},{"name":"Testcontainers","id":"201911027","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"95","display_name":"Testcontainers","radius":"290","description":"\u003cp\u003eCreating reliable environments for running automated tests is a perennial problem, particularly as the number of components that modern systems depend on keeps increasing. \u003cstrong\u003e\u003ca href\u003d\"https://www.testcontainers.org/\"\u003eTestcontainers\u003c/a\u003e\u003c/strong\u003e is a Java library that helps mitigate this challenge by managing dockerized dependencies for your tests. This is particularly useful for spinning up repeatable database instances or similar infrastructure, but it can also be used in web browsers for UI testing. Our teams have found this library to be helpful for making integration tests more reliable with these programmable, lightweight and disposable containers.\u003c/p\u003e","theta":"351","volume":"2019-11"},{"name":"Enzyme","id":"1047","quadrant":"languages-and-frameworks","ring":"Hold","movement":"t","radarId":"96","display_name":"Enzyme","radius":"365","description":"\u003cp\u003eWe don\u0027t always move deprecated tools to Hold in the Radar, but our teams feel strongly that \u003cstrong\u003e\u003ca href\u003d\"http://airbnb.io/enzyme/\"\u003eEnzyme\u003c/a\u003e\u003c/strong\u003e has been replaced for unit testing \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e UI components by \u003ca href\u003d\"https://testing-library.com/docs/intro\"\u003eReact Testing Library\u003c/a\u003e. Teams using Enzyme have found that its focus on testing component internals leads to brittle, unmaintainable tests.\u003c/p\u003e","theta":"315","volume":"2019-11"}],"date":"2019-11"},{"blips":[{"name":"Applying product management to internal platforms","id":"1133","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"1","display_name":"Applying product management to internal platforms","radius":"90","description":"\u003cp\u003eMore and more companies are building internal platforms to roll out new digital solutions quickly and efficiently. Companies that succeed with this strategy are \u003cstrong\u003eapplying product management to internal platforms\u003c/strong\u003e. This means establishing empathy with internal consumers (the development teams) and collaborating with them on the design. Platform product managers create roadmaps and ensure the platform delivers value to the business and enhances the developer experience. Unfortunately, we\u0027re also seeing less successful approaches, where teams create a platform in the void, based on unverified assumptions and without internal customers. These platforms, often despite aggressive internal tactics, end up being underutilized and a drain on the organization\u0027s delivery capability. As usual, good product management is all about building products that consumers love.\u003c/p\u003e","blip_status":"move_in","theta":"168","volume":"2020-05"},{"name":"Infrastructure as code","id":"9142","quadrant":"Techniques","ring":"Adopt","movement":"c","radarId":"2","display_name":"Infrastructure as code","radius":"60","description":"\u003cp\u003eAlthough \u003cstrong\u003einfrastructure as code\u003c/strong\u003e is a relatively old technique (we’ve featured it in the Radar in 2011), it has become vitally important in the modern cloud era where the act of setting up infrastructure has become the passing of configuration instructions to a cloud platform. When we say \"as code\" we mean that all the good practices we\u0027ve learned in the software world should be applied to infrastructure. Using source control, adhering to the \u003ca href\u003d\"https://en.wikipedia.org/wiki/Don%27t_repeat_yourself\"\u003eDRY principle\u003c/a\u003e, modularization, maintainability, and using automated testing and deployment are all critical practices. Those of us with a deep software and infrastructure background need to empathize with and support colleagues who do not. Saying \"treat infrastructure like code\" isn\u0027t enough; we need to ensure the hard-won learnings from the software world are also applied consistently throughout the infrastructure realm.\u003c/p\u003e","blip_status":"c","theta":"155","volume":"2020-05"},{"name":"Micro frontends","id":"1035","quadrant":"Techniques","ring":"Adopt","movement":"c","radarId":"3","display_name":"Micro frontends","radius":"80","description":"\u003cp\u003eWe\u0027ve seen significant benefits from introducing \u003ca href\u003d\"https://martinfowler.com/articles/microservices.html\"\u003emicroservices\u003c/a\u003e, which have allowed teams to scale the delivery of independently deployed and maintained services. Unfortunately, we\u0027ve also seen many teams create a front-end monolith — a large, entangled browser application that sits on top of the back-end services — largely neutralizing the benefits of microservices. \u003cstrong\u003eMicro frontends\u003c/strong\u003e have continued to gain in popularity since they were first introduced. We\u0027ve seen many teams adopt some form of this architecture as a way to manage the complexity of multiple developers and teams contributing to the same user experience. In June of last year, one of the originators of this technique published an \u003ca href\u003d\"https://martinfowler.com/articles/micro-frontends.html\"\u003eintroductory article\u003c/a\u003e that serves as a reference for micro frontends. It shows how this style can be implemented using various web programming mechanisms and builds out an example application using \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e. We\u0027re confident this style will grow in popularity as larger organizations try to decompose UI development across multiple teams.\u003c/p\u003e","blip_status":"c","theta":"142","volume":"2020-05"},{"name":"Pipelines as code","id":"1037","quadrant":"Techniques","ring":"Adopt","movement":"c","radarId":"4","display_name":"Pipelines as code","radius":"60","description":"\u003cp\u003eThe \u003cstrong\u003epipelines as code\u003c/strong\u003e technique emphasizes that the configuration of delivery pipelines that build, test and deploy our applications or infrastructure should be treated as code; they should be placed under source control and modularized in reusable components with automated testing and deployment. As organizations move to decentralized autonomous teams building \u003ca href\u003d\"https://martinfowler.com/articles/microservices.html\"\u003emicroservices\u003c/a\u003e or \u003ca href\u003d\"/radar/techniques/micro-frontends\"\u003emicro frontends\u003c/a\u003e, the need for engineering practices in managing pipelines as code increases to keep building and deploying software consistent within the organization. This need has given rise to delivery pipeline templates and tooling that enable a standardized way to build and deploy services and applications. Such tools use the \u003cem\u003edeclarative delivery pipelines\u003c/em\u003e of applications, adopting a pipeline blueprint to execute the underlying tasks for various stages of a delivery lifecycle such as build, test and deployment; and they abstract away implementation details. The ability to build, test and deploy pipelines as code should be one of the evaluation criteria for choosing a CI/CD tool.\u003c/p\u003e","blip_status":"c","theta":"129","volume":"2020-05"},{"name":"Pragmatic remote pairing","id":"202005001","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"5","display_name":"Pragmatic remote pairing","radius":"115","description":"\u003cp\u003eWe firmly believe that \u003ca href\u003d\"https://martinfowler.com/articles/on-pair-programming.html\"\u003epair programming\u003c/a\u003e improves the quality of code, spreads knowledge throughout a team and allows overall faster delivery of software. In a post COVID-19 world, however, many software teams will be distributed or fully remote, and in this situation we recommend \u003cstrong\u003epragmatic remote pairing\u003c/strong\u003e: adjusting pairing practices to what\u0027s possible given the tools at hand. Consider tools such as \u003ca href\u003d\"/radar/tools/visual-studio-live-share\"\u003eVisual Studio Live Share\u003c/a\u003e for efficient, low-latency collaboration. Only resort to pixel-sharing if both participants reside in relative geographic proximity and have high-bandwidth internet connections. Pair developers who are in similar time zones rather than expecting pairing to work between participants regardless of their location. If pairing isn\u0027t working for logistical reasons, fall back to practices such as individual programming augmented via code reviews, pull-request collaboration (but beware \u003ca href\u003d\"/radar/techniques/long-lived-branches-with-gitflow\"\u003elong-lived branches with Gitflow\u003c/a\u003e) or shorter pairing sessions for critical parts of the code. We\u0027ve engaged in remote pairing for years, and we\u0027ve found it to be effective if done with a dose of pragmatism.\u003c/p\u003e","blip_status":"t","theta":"121","volume":"2020-05"},{"name":"Simplest possible feature toggle","id":"202005002","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"6","display_name":"Simplest possible feature toggle","radius":"115","description":"\u003cp\u003eUnfortunately, \u003ca href\u003d\"https://martinfowler.com/articles/feature-toggles.html\"\u003efeature toggles\u003c/a\u003e are less common than we\u0027d like, and quite often we see people mixing up its types and use cases. It\u0027s quite common to come across teams that use heavyweight platforms such as \u003ca href\u003d\"https://launchdarkly.com/\"\u003eLaunchDarkly\u003c/a\u003e to implement feature toggles, including release toggles, to benefit from \u003ca href\u003d\"https://martinfowler.com/articles/continuousIntegration.html\"\u003eContinuous Integration\u003c/a\u003e, when all you need are if/else conditionals. Therefore, unless you need A/B testing or \u003ca href\u003d\"https://martinfowler.com/bliki/CanaryRelease.html\"\u003ecanary release\u003c/a\u003e or hand over feature release responsibility to business folks, we encourage you to use the \u003cstrong\u003esimplest possible feature toggle\u003c/strong\u003e instead of unnecessarily complex feature toggle frameworks.\u003c/p\u003e","blip_status":"t","theta":"103","volume":"2020-05"},{"name":"Continuous delivery for machine learning (CD4ML)","id":"201904066","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"7","display_name":"Continuous delivery for machine learning (CD4ML)","radius":"190","description":"\u003cp\u003eApplying machine learning to make the business applications and services intelligent is more than just training models and serving them. It requires implementing end-to-end and continuously repeatable cycles of training, testing, deploying, monitoring and operating the models. \u003cstrong\u003e\u003ca href\u003d\"https://martinfowler.com/articles/cd4ml.html\"\u003eContinuous delivery for machine learning (CD4ML)\u003c/a\u003e\u003c/strong\u003e is a technique that enables reliable end-to-end cycles of development, deploying and monitoring machine learning models. The underpinning technology stack to enable CD4ML includes tooling for accessing and discovering data, version control of artefacts (such as data, model and code), continuous delivery pipelines, automated environment provisioning for various deployments and experiments, model performance assessment and tracking, and model operational observability. Companies can choose their own tool set depending on their existing tech stack. CD4ML emphasizes automation and removing manual handoffs. CD4ML is our de facto approach for developing ML models.\u003c/p\u003e","blip_status":"c","theta":"172","volume":"2020-05"},{"name":"Ethical bias testing","id":"201911054","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"8","display_name":"Ethical bias testing","radius":"190","description":"\u003cp\u003eOver the past year, we\u0027ve seen a shift in interest around machine learning and deep neural networks in particular. Until now, tool and technique development has been driven by excitement over the remarkable capabilities of these models. Currently, though, there is rising concern that these models could cause unintentional harm. For example, a model could be trained inadvertently to make profitable credit decisions by simply excluding disadvantaged applicants. Fortunately, we\u0027re seeing a growing interest in \u003cstrong\u003eethical bias testing\u003c/strong\u003e that will help to uncover potentially harmful decisions. Tools such as \u003ca href\u003d\"https://github.com/marcotcr/lime\"\u003elime\u003c/a\u003e, \u003ca href\u003d\"https://aif360.mybluemix.net/\"\u003eAI Fairness 360\u003c/a\u003e or \u003ca href\u003d\"/radar/tools/what-if-tool\"\u003eWhat-If Tool\u003c/a\u003e can help uncover inaccuracies that result from underrepresented groups in training data and visualization tools such as \u003ca href\u003d\"https://ai.googleblog.com/2017/07/facets-open-source-visualization-tool.html\"\u003eGoogle Facets\u003c/a\u003e or \u003ca href\u003d\"https://pair-code.github.io/facets/\"\u003eFacets Dive\u003c/a\u003e can be used to discover subgroups within a corpus of training data. We\u0027ve used lime (local interpretable model-agnostic explanations) in addition to this technique in order to understand the predictions of any machine-learning classifier and what classifiers (or models) are doing.\u003c/p\u003e","blip_status":"move_in","theta":"164","volume":"2020-05"},{"name":"GraphQL for server-side resource aggregation","id":"1213","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"9","display_name":"GraphQL for server-side resource aggregation","radius":"200","description":"\u003cp\u003eWe see more and more tools such as \u003ca href\u003d\"https://www.apollographql.com/docs/apollo-server/federation/introduction/\"\u003eApollo Federation\u003c/a\u003e that can aggregate multiple GraphQL endpoints into a single graph. However, we caution against misusing \u003ca href\u003d\"/radar/languages-and-frameworks/graphql\"\u003eGraphQL\u003c/a\u003e, especially when turning it into a server-to-server protocol. Our practice is to use \u003cstrong\u003e\u003ca href\u003d\"/radar/techniques/graphql-for-server-side-resource-aggregation\"\u003eGraphQL for server-side resource aggregation\u003c/a\u003e\u003c/strong\u003e only. When using this pattern, the microservices continue to expose well-defined RESTful APIs, while under-the-hood aggregate services or \u003ca href\u003d\"/radar/techniques/bff-backend-for-frontends\"\u003eBFF (Backend for Frontends)\u003c/a\u003e patterns use GraphQL resolvers as the implementation for stitching resources from other services. The shape of the graph is driven by domain-modeling exercises to ensure ubiquitous language is limited to subgraphs where needed (in the case of one-microservice-per-bounded-context). This technique simplifies the internal implementation of aggregate services or BFFs, while encouraging good modeling of services to avoid \u003ca href\u003d\"/radar/techniques/anemic-rest\"\u003eanemic REST\u003c/a\u003e.\u003c/p\u003e","blip_status":"move_in","theta":"156","volume":"2020-05"},{"name":"Micro frontends for mobile","id":"202005013","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"10","display_name":"Micro frontends for mobile","radius":"210","description":"\u003cp\u003eSince introducing it in the Radar in 2016, we\u0027ve seen widespread adoption of \u003ca href\u003d\"/radar/techniques/micro-frontends\"\u003emicro frontends\u003c/a\u003e for web UIs. Recently, however, we\u0027ve seen projects extend this architectural style to include \u003cstrong\u003emicro frontends for mobile\u003c/strong\u003e applications as well. When the application becomes sufficiently large and complex, it becomes necessary to distribute the development over multiple teams. This presents the challenge of maintaining team autonomy while integrating their work into a single app. Although we\u0027ve seen teams writing their own frameworks to enable this development style, existing modularization frameworks such as \u003ca href\u003d\"/radar/languages-and-frameworks/atlas-and-beehive\"\u003eAtlas and Beehive\u003c/a\u003e can also simplify the problem of integrating multiteam app development.\u003c/p\u003e","blip_status":"t","theta":"148","volume":"2020-05"},{"name":"Platform engineering product teams","id":"1101","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"11","display_name":"Platform engineering product teams","radius":"180","description":"\u003cp\u003eThe adoption of cloud and DevOps — while increasing the productivity of teams who can now move more quickly with reduced dependency on centralized operations teams and infrastructure — also has constrained teams that lack the skills to self-manage a full application and operations stack. Some organizations have tackled this challenge by creating \u003cstrong\u003eplatform engineering product teams\u003c/strong\u003e. These teams maintain an internal platform that enables delivery teams to deploy and operate systems with reduced lead time and stack complexity. The emphasis here is on API-driven self-service and supporting tools, with delivery teams still responsible for supporting what they deploy onto the platform. Organizations that consider establishing such a platform team should be very cautious not to accidentally create a \u003ca href\u003d\"/radar/techniques/separate-devops-team\"\u003eseparate DevOps team\u003c/a\u003e, nor should they simply relabel their \u003ca href\u003d\"/radar/platforms/superficial-private-cloud\"\u003eexisting hosting and operations structure\u003c/a\u003e as a platform. If you\u0027re wondering how to best set up platform teams, we\u0027ve been using the concepts from \u003ca href\u003d\"https://teamtopologies.com/\"\u003eTeam Topologies\u003c/a\u003e to split platform teams in our projects into Enabling Teams, core \"platform within a platform\" teams and Stream-aligned Teams.\u003c/p\u003e","blip_status":"move_in","theta":"137","volume":"2020-05"},{"name":"Security policy as code","id":"201911034","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"12","display_name":"Security policy as code","radius":"220","description":"\u003cp\u003eSecurity policies are rules and procedures that protect our systems from threats and disruption. For example, access control policies define and enforce who can access which services and resources under what circumstances; or network security policies can dynamically limit the traffic rate to a particular service. The complexity of the technology landscape today demands treating \u003cstrong\u003esecurity policy as code\u003c/strong\u003e: define and keep policies under version control, automatically validate them, automatically deploy them and monitor their performance. Tools such as \u003ca href\u003d\"/radar/tools/open-policy-agent-opa\"\u003eOpen Policy Agent\u003c/a\u003e or platforms such as \u003ca href\u003d\"/radar/platforms/istio\"\u003eIstio\u003c/a\u003e provide flexible policy definition and enforcement mechanisms that support the practice of security policy as code.\u003c/p\u003e","blip_status":"c","theta":"131","volume":"2020-05"},{"name":"Semi-supervised learning loops","id":"201911052","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"13","display_name":"Semi-supervised learning loops","radius":"220","description":"\u003cp\u003e\u003cstrong\u003eSemi-supervised learning loops\u003c/strong\u003e are a class of iterative machine-learning workflows that take advantage of the relationships to be found in unlabeled data. These techniques may improve models by combining labeled and unlabeled data sets in various ways. In other cases they compare models trained on different subsets of the data. Unlike either unsupervised learning where a machine infers classes in unlabeled data or supervised techniques where the training set is entirely labeled, semi-supervised techniques take advantage of a small set of labeled data and a much larger set of unlabeled data. Semi-supervised learning is also closely related to active learning techniques where a human is directed to selectively label ambiguous data points. Since expert humans that can accurately label data are a scarce resource and labeling is often the most time-consuming activity in the machine-learning workflow, semi-supervised techniques lower the cost of training and make machine learning feasible for a new class of users. We\u0027re also seeing the application of weakly supervised techniques where machine-labeled data is used but is trusted less than the data labeled by humans.\u003c/p\u003e","blip_status":"move_in","theta":"123","volume":"2020-05"},{"name":"Transfer learning for NLP","id":"201904062","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"14","display_name":"Transfer learning for NLP","radius":"200","description":"\u003cp\u003eWe had this technique in Assess previously. The innovations in the NLP landscape continue at a great pace, and we\u0027re able to leverage these innovations in our projects thanks to the ubiquitous \u003cstrong\u003etransfer learning for NLP\u003c/strong\u003e. The GLUE benchmark (a suite of language understanding tasks) scores have seen dramatic progress over the past couple of years with average scores moving from 70.0 at launch to some of the leaders crossing 90.0 as of April 2020. A lot of our projects in the NLP domain are able to make significant progress by starting from pretrained models from ELMo, \u003ca href\u003d\"/radar/techniques/bert\"\u003eBERT\u003c/a\u003e, and \u003ca href\u003d\"/radar/languages-and-frameworks/ernie\"\u003eERNIE\u003c/a\u003e, among others, and then fine-tuning them based on the project needs.\u003c/p\u003e","blip_status":"move_in","theta":"115","volume":"2020-05"},{"name":"Use \"remote native\" processes and approaches","id":"202005004","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"15","display_name":"Use \"remote native\" processes and approaches","radius":"220","description":"\u003cp\u003e\u003ca href\u003d\"https://www.martinfowler.com/articles/remote-or-co-located.html\"\u003eDistributed teams come in many shapes and setups\u003c/a\u003e; delivery teams in a 100% single-site co-located setup, however, have become the exception for us. Most of our teams are either multisite teams or have at least some team members working off-site. Therefore, \u003cstrong\u003eusing \"remote native\" processes and approaches\u003c/strong\u003e by default can help significantly with the overall team flow and effectiveness. This starts with making sure that everybody has access to the necessary remote systems. Moreover, using tools such as \u003ca href\u003d\"/radar/tools/visual-studio-live-share\"\u003eVisual Studio Live Share\u003c/a\u003e, \u003ca href\u003d\"/radar/tools/mural\"\u003eMURAL\u003c/a\u003e or \u003ca href\u003d\"https://gsuite.google.com/products/jamboard/\"\u003eJamboard\u003c/a\u003e turn online workshops and remote pairing into routines instead of ineffective exceptions. But \"remote native\" goes beyond a lift-and-shift of co-location practices to the digital world: Embracing more asynchronous communication, even more discipline around decision documentation, and \"everybody always remote\" meetings are other approaches our teams practice by default to optimize for location fluidity.\u003c/p\u003e","blip_status":"t","theta":"107","volume":"2020-05"},{"name":"Zero trust architecture (ZTA)","id":"202005092","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"16","display_name":"Zero trust architecture (ZTA)","radius":"200","description":"\u003cp\u003eThe technology landscape of organizations today is increasingly more complex with assets — data, functions, infrastructure and users — spread across security boundaries, such as local hosts, multiple cloud providers and a variety of SaaS vendors. This demands a paradigm shift in enterprise security planning and systems architecture, moving from static and slow-changing security policy management, based on trust zones and network configurations, to dynamic, fine-grained security policy enforcement based on temporal access privileges.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003eZero trust architecture (ZTA)\u003c/strong\u003e is an organization\u0027s strategy and journey to implement zero-trust security principles for all of their assets — such as devices, infrastructure, services, data and users — and includes implementing practices such as securing all access and communications regardless of the network location, enforcing policies as code based on the least privilege and as granular as possible, and continuous monitoring and automated mitigation of threats. Our Radar reflects many of the enabling techniques such as \u003ca href\u003d\"/radar/techniques/security-policy-as-code\"\u003esecurity policy as code\u003c/a\u003e, \u003ca href\u003d\"/radar/techniques/sidecars-for-endpoint-security\"\u003esidecars for endpoint security\u003c/a\u003e and \u003ca href\u003d\"/radar/techniques/beyondcorp\"\u003eBeyondCorp\u003c/a\u003e. If you\u0027re on your journey toward ZTA, refer to the \u003ca href\u003d\"https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-207-draft2.pdf\"\u003eNIST ZTA publication\u003c/a\u003e to learn more about principles, enabling technology components and migration patterns as well as Google\u0027s publication on \u003ca href\u003d\"https://cloud.google.com/security/beyondprod\"\u003eBeyondProd\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"99","volume":"2020-05"},{"name":"Data mesh","id":"201911051","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"17","display_name":"Data mesh","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://martinfowler.com/articles/data-monolith-to-mesh.html\"\u003eData mesh\u003c/a\u003e\u003c/strong\u003e is an architectural and organizational paradigm that challenges the age-old assumption that we must centralize big analytical data to use it, have data all in one place or be managed by a centralized data team to deliver value. Data mesh claims that for big data to fuel innovation, its ownership must be federated among domain data owners who are accountable for providing their data as products (with the support of a self-serve data platform to abstract the technical complexity involved in serving data products);  it must also adopt a new form of federated governance through automation to enable interoperability of domain-oriented data products. Decentralization, along with interoperability and focus on the experience of data consumers, are key to the democratization of innovation using data.\u003c/p\u003e\n\n\u003cp\u003eIf your organization has a large number of domains with numerous systems and teams generating data or a diverse set of data-driven use cases and access patterns, we suggest you assess data mesh. Implementation of data mesh requires investment in building a self-serve data platform and embracing an organizational change for domains to take on the long-term ownership of their data products, as well as an incentive structure that rewards domains serving and utilizing data as a product.\u003c/p\u003e","blip_status":"c","theta":"168","volume":"2020-05"},{"name":"Decentralized identity","id":"202005083","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"18","display_name":"Decentralized identity","radius":"310","description":"\u003cp\u003eSince the birth of the internet, the technology landscape has experienced an accelerated evolution toward decentralization. While protocols such as HTTP and architectural patterns such as \u003ca href\u003d\"https://martinfowler.com/articles/microservices.html\"\u003emicroservices\u003c/a\u003e or \u003ca href\u003d\"/radar/techniques/data-mesh\"\u003edata mesh\u003c/a\u003e enable decentralized implementations, identity management remains centralized. The emergence of distributed ledger technology (DLT), however, provides the opportunity to enable the concept of \u003cstrong\u003edecentralized identity\u003c/strong\u003e. In a decentralized identity system, entities — that is, discrete identifiable units such as people, organizations and things — are free to use any shared root of trust. In contrast, conventional identity management systems are based on centralized authorities and registries such as corporate directory services, certificate authorities or domain name registries.\u003c/p\u003e\n\n\u003cp\u003eThe development of \u003ca href\u003d\"https://www.w3.org/TR/did-core/\"\u003edecentralized identifiers\u003c/a\u003e — globally unique, persistent and \u003cem\u003eself-sovereign identifiers\u003c/em\u003e that are cryptographically verifiable — is a major enabling standard. Although scaled implementations of decentralized identifiers in the wild are still rare, we\u0027re excited by the premise of this movement and have started using the concept in our architecture. For the latest experiments and industry collaborations, check out \u003ca href\u003d\"https://identity.foundation/\"\u003eDecentralized Identity Foundation\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"155","volume":"2020-05"},{"name":"Declarative data pipeline definition","id":"202005084","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"19","display_name":"Declarative data pipeline definition","radius":"300","description":"\u003cp\u003eMany data pipelines are defined in a large, more or less imperative script written in Python or Scala. The script contains the logic of the individual steps as well as the code chaining the steps together. When faced with a similar situation in Selenium tests, developers discovered the Page Object pattern, and later many behavior-driven development (BDD) frameworks implemented a split between step definitions and their composition. Some teams are now experimenting with bringing the same thinking to data engineering. A separate \u003cstrong\u003edeclarative data pipeline definition\u003c/strong\u003e, maybe written in YAML, contains only the declaration and sequence of steps. It states input and output data sets but refers to scripts if and when more complex logic is needed. With \u003ca href\u003d\"https://github.com/binaryaffairs/a-la-mode\"\u003eA La Mode\u003c/a\u003e, we\u0027re seeing the first open source tool appear in this space.\u003c/p\u003e","blip_status":"t","theta":"142","volume":"2020-05"},{"name":"DeepWalk","id":"202005085","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"20","display_name":"DeepWalk","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/phanein/deepwalk\"\u003eDeepWalk\u003c/a\u003e\u003c/strong\u003e is an algorithm that helps apply machine learning on graphs. When working on data sets that are represented as graphs, one of the key problems is to extract features from the graph. This is where DeepWalk can help. It uses SkipGram to construct node embeddings by viewing the graph as a language where each node is a unique word in the language and random walks of finite length on the graph constitutes a sentence. These embeddings can then be used by various ML models. DeepWalk is one of the techniques we\u0027re trialling on some of our projects where we\u0027ve needed to apply machine learning on graphs.\u003c/p\u003e","blip_status":"t","theta":"129","volume":"2020-05"},{"name":"Managing stateful systems via container orchestration","id":"202005009","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"21","display_name":"Managing stateful systems via container orchestration","radius":"310","description":"\u003cp\u003eWe recommend caution in \u003cstrong\u003emanaging stateful systems via container orchestration\u003c/strong\u003e platforms such as Kubernetes. Some databases are not built with native support for orchestration — they don\u0027t expect a scheduler to kill and relocate them to a different host. Building a highly available service on top of such databases is not trivial, and we still recommend running them on bare metal hosts or a virtual machine (VM) rather than to force-fit them into a container orchestration platform.\u003c/p\u003e","blip_status":"t","theta":"116","volume":"2020-05"},{"name":"Preflight builds","id":"202005006","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"22","display_name":"Preflight builds","radius":"310","description":"\u003cp\u003eEven though we strongly advocate in favor of CI rather than \u003ca href\u003d\"/radar/techniques/gitflow\"\u003eGitflow\u003c/a\u003e, we know that \u003ca href\u003d\"https://trunkbaseddevelopment.com/committing-straight-to-the-trunk/\"\u003ecommitting straight to the trunk\u003c/a\u003e and running the CI on a master branch can be ineffective if the team is too big, the builds are slow or flaky, or the team lacks the discipline to run the full test suite locally. In this situation a red build can block multiple devs or pairs of devs. Instead of fixing the underlying root cause — slow builds, the inability to run tests locally or monolithic architectures that necessitate many people working in the same area — teams usually rely on feature branches to bypass these issues. We discourage feature branches, given they may require significant effort to resolve merge conflicts, and they introduce longer feedback loops and potential bugs during conflict resolution. Instead, we propose using \u003cstrong\u003epreflight builds\u003c/strong\u003e as an alternative: these are pull request–based builds for “micro branches” that live only for the duration of the pipeline run, with the branch opened for every commit. To help automate this workflow, we\u0027ve come across bots such as \u003ca href\u003d\"https://bors.tech/\"\u003eBors\u003c/a\u003e, which automates merging to master and branch deletion in case the mini branch build succeeds. We\u0027re assessing this flow, and you should too; but don\u0027t use this to solve the wrong problem, as it can lead to misuse of branches and may cause more harm than benefit.\u003c/p\u003e","blip_status":"t","theta":"103","volume":"2020-05"},{"name":"Cloud lift and shift","id":"702","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"23","display_name":"Cloud lift and shift","radius":"375","description":"\u003cp\u003eIt is rather curious, that after over a decade of industry experience with cloud migration, we still feel it\u0027s necessary to call out \u003cstrong\u003ecloud lift and shift\u003c/strong\u003e; a practice that views cloud simply as a hosting solution, resulting in the replication of an existing architecture, security practices and IT operational models in the cloud. This fails to realize the cloud\u0027s promises of agility and digital innovation. A cloud migration requires intentional change across multiple axes toward a cloud-native state, and depending on the unique migration circumstances, each organization might end up somewhere on the spectrum from cloud lift and shift to cloud native. Systems architecture, for example, is one of the pillars of delivery agility and often requires change. The temptation to simply \u003ca href\u003d\"https://cloud.google.com/migrate/anthos/docs/anthos-migrate-benefits\"\u003elift and shift existing systems as containers\u003c/a\u003e to the cloud can be strong. While this tactic can speed up cloud migration, it falls short when it comes to creating agility and delivering features and value. Enterprise security in the cloud is fundamentally different from traditional perimeter-based security through firewalls and zoning, and it demands a journey toward \u003ca href\u003d\"/radar/techniques/zero-trust-architecture-zta\"\u003ezero trust architecture\u003c/a\u003e. The IT operating model too has to be reformed to safely provide cloud services through self-serve automated platforms and empower teams to take more of the operational responsibility and gain autonomy. Last but not least, organizations must build a foundation to enable continuous change, such as creating pipelines with continuous testing of applications and infrastructure as a part of the migration. These will help the migration process, result in a more robust and well-factored system and give organizations a way to continue to evolve and improve their systems.\u003c/p\u003e","blip_status":"c","theta":"165","volume":"2020-05"},{"name":"Legacy migration feature parity","id":"201911046","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"24","display_name":"Legacy migration feature parity","radius":"375","description":"\u003cp\u003eWe find that more and more organizations need to replace aging legacy systems to keep up with the demands of their customers (both internal and external). One antipattern we keep seeing is \u003cstrong\u003elegacy migration feature parity\u003c/strong\u003e , the desire to retain feature parity with the old. We see this as a huge missed opportunity. Often the old systems have bloated over time, with many features unused by users (50% according to a \u003ca href\u003d\"https://www.standishgroup.com/sample_research_files/Exceeding%20Value_Layout.pdf\"\u003e2014 Standish Group report\u003c/a\u003e) and business processes that have evolved over time. Replacing these features is a waste. Our advice: Convince your customers to take a step back and understand what their users currently \u003cem\u003eneed\u003c/em\u003e and prioritize these needs against business outcomes and metrics — which often is easier said than done. This means conducting user research and applying modern product development practices rather than simply replacing the existing ones.\u003c/p\u003e","blip_status":"c","theta":"150","volume":"2020-05"},{"name":"Log aggregation for business analytics","id":"202005090","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"25","display_name":"Log aggregation for business analytics","radius":"375","description":"\u003cp\u003eSeveral years ago, a new generation of log aggregation platforms emerged that were capable of storing and searching over vast amounts of log data to uncover trends and insights in operational data. \u003ca href\u003d\"/radar/tools/splunk\"\u003eSplunk\u003c/a\u003e was the most prominent but by no means the only example of these tools. Because these platforms provide broad operational and security visibility across the entire estate of applications, administrators and developers have grown increasingly dependent on them. This enthusiasm spread as stakeholders discovered that they could use \u003cstrong\u003elog aggregation for business analytics\u003c/strong\u003e. However, business needs can quickly outstrip the flexibility and usability of these tools. Logs intended for technical observability are often inadequate to infer deep customer understanding. We prefer either to use tools and metrics designed for customer analytics or to take a more event-driven approach to observability where both business and operational events are collected and stored in a way they can be replayed and processed by more purpose-built tools.\u003c/p\u003e","blip_status":"t","theta":"135","volume":"2020-05"},{"name":"Long-lived branches with Gitflow","id":"790","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"26","display_name":"Long-lived branches with Gitflow","radius":"385","description":"\u003cp\u003eFive years ago we highlighted the problems with \u003cstrong\u003elong-lived branches with Gitflow\u003c/strong\u003e. Essentially, long-lived branches are the opposite of continuously integrating all changes to the source code, and in our experience continuous integration is the better approach for most kinds of software development. Later we extended our caution to \u003ca href\u003d\"/radar/techniques/gitflow\"\u003eGitflow\u003c/a\u003e itself, because we saw teams using it almost exclusively with long-lived branches. Today, we still see teams in settings where continuous delivery of web-based systems is the stated goal being drawn to long-lived branches. So we were delighted that the author of Gitflow has now added a note to his \u003ca href\u003d\"https://nvie.com/posts/a-successful-git-branching-model/\"\u003eoriginal article\u003c/a\u003e, explaining that Gitflow was not intended for such use cases.\u003c/p\u003e","blip_status":"c","theta":"120","volume":"2020-05"},{"name":"Snapshot testing only","id":"202005089","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"27","display_name":"Snapshot testing only","radius":"385","description":"\u003cp\u003eThe value of snapshot testing is undeniable when working with legacy systems by ensuring that the system continues to work and the legacy code doesn\u0027t break. However, we\u0027re seeing the common, rather harmful practice of using \u003cstrong\u003esnapshot testing only\u003c/strong\u003e as the primary test mechanism. Snapshot tests validate the exact result generated in the DOM by a component, not the component\u0027s behavior; therefore, it can be weak and unreliable, fostering the \"only delete the snapshot and regenerate it\" bad practice. Instead, you should test the logic and behavior of the components emulating what users would do. This mindset is encouraged by tools in the \u003ca href\u003d\"https://testing-library.com/docs/guiding-principles\"\u003eTesting Library\u003c/a\u003e family.\u003c/p\u003e","blip_status":"t","theta":"105","volume":"2020-05"},{"name":".NET Core","id":"866","quadrant":"Platforms","ring":"Adopt","movement":"c","radarId":"28","display_name":".NET Core","radius":"60","description":"\u003cp\u003eWe previously had \u003cstrong\u003e.NET Core\u003c/strong\u003e in Adopt, indicating that it had become our default for .NET projects. But we felt it\u0027s worth again calling attention to .NET Core. With the release of .NET Core 3.\u003cem\u003ex\u003c/em\u003e last year, the bulk of the features from .NET Framework have now been ported into .NET Core. With the announcement that \u003ca href\u003d\"https://devblogs.microsoft.com/dotnet/introducing-net-5\"\u003e.NET Framework is on its last release\u003c/a\u003e, Microsoft have reinforced the view that \u003ca href\u003d\"https://devblogs.microsoft.com/dotnet/net-core-is-the-future-of-net/\"\u003e.NET Core is the future of .NET\u003c/a\u003e. Microsoft has done a lot of work to make .NET Core \u003ca href\u003d\"https://devblogs.microsoft.com/dotnet/using-net-and-docker-together-dockercon-2019-update/\"\u003econtainer friendly\u003c/a\u003e. Most of our .NET Core–based projects target Linux and are often deployed as containers. The upcoming \u003ca href\u003d\"https://devblogs.microsoft.com/dotnet/introducing-net-5/\"\u003e.NET 5\u003c/a\u003e release looks promising, and we\u0027re looking forward to it.\u003c/p\u003e","blip_status":"c","theta":"210","volume":"2020-05"},{"name":"Istio","id":"1199","quadrant":"Platforms","ring":"Adopt","movement":"t","radarId":"29","display_name":"Istio","radius":"140","description":"\u003cp\u003eIf you\u0027re building and operating a scaled \u003ca href\u003d\"https://martinfowler.com/articles/microservices.html\"\u003emicroservices\u003c/a\u003e architecture and have embraced \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e, adopting \u003ca href\u003d\"/radar/techniques/service-mesh\"\u003eservice mesh\u003c/a\u003e to manage all cross-cutting aspects of running the architecture is a default position. Among various implementations of service mesh, \u003cstrong\u003e\u003ca href\u003d\"https://istio.io\"\u003eIstio\u003c/a\u003e\u003c/strong\u003e has gained majority adoption. It has a rich feature set, including service discovery, traffic management, service-to-service and origin-to-service security, observability (including telemetry and distributed tracing), rolling releases and resiliency. Its user experience has been improved in its latest releases, because of its ease of installation and control panel architecture. Istio has lowered the bar for implementing large-scale microservices with operational quality for many of our clients, while admitting that operating your own Istio and Kubernetes instances requires adequate knowledge and internal resources which is not for the fainthearted.\u003c/p\u003e","blip_status":"move_in","theta":"240","volume":"2020-05"},{"name":"Anka","id":"201904010","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"30","display_name":"Anka","radius":"225","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://ankadoc.bitbucket.io/\"\u003eAnka\u003c/a\u003e\u003c/strong\u003e is a set of tools to create, manage, distribute, build and test macOS reproducible virtual environments for iOS and macOS. It brings Docker-like experience to macOS environments: instant start, CLI to manage virtual machines and registry to version and tag virtual machines for distribution. We\u0027ve used Anka to build a macOS private cloud for a client. This tool is worth considering when virtualizing iOS and macOS environments.\u003c/p\u003e","blip_status":"move_in","theta":"189","volume":"2020-05"},{"name":"Argo CD","id":"202005041","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"31","display_name":"Argo CD","radius":"255","description":"\u003cp\u003eWithout making a judgment of the GitOps technique, we\u0027d like to talk about \u003cstrong\u003e\u003ca href\u003d\"https://argoproj.github.io/argo-cd/\"\u003eArgo CD\u003c/a\u003e\u003c/strong\u003e within the scope of deploying and monitoring applications in \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e environments. Based on its ability to automate the deployment of the desired application state in the specified target environments in Kubernetes and our good experience with troubleshooting failed deployments, verifying logs and monitoring deployment status, we recommend you give Argo CD a try. You can even see graphically what is going on in the cluster, how a change is propagated and how pods are created and destroyed in real time.\u003c/p\u003e","blip_status":"t","theta":"198","volume":"2020-05"},{"name":"Crowdin","id":"201911003","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"32","display_name":"Crowdin","radius":"230","description":"\u003cp\u003eMost of the projects with multilingual support start with development teams building features in one language and managing the rest through offline translation via emails and spreadsheets. Although this simple setup works, things can quickly get out of hand. You may have to keep answering the same questions for different language translators, sucking the energy out of the collaboration between translators, proofreaders and the development team. \u003cstrong\u003e\u003ca href\u003d\"https://crowdin.com\"\u003eCrowdin\u003c/a\u003e\u003c/strong\u003e is one of a handful of platforms that help in streamlining the localization workflow of your project. With Crowdin the development team can continue building features, while the platform streamlines the text that needs translation into an online workflow. We like that Crowdin nudges the teams to continuously and incrementally incorporate translations rather than managing them in large batches toward the end.\u003c/p\u003e","blip_status":"move_in","theta":"207","volume":"2020-05"},{"name":"eBPF","id":"202005111","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"33","display_name":"eBPF","radius":"220","description":"\u003cp\u003eFor several years now, the Linux kernel has included the extended Berkeley Packet Filter (\u003cstrong\u003eeBPF\u003c/strong\u003e) virtual machine and provided the ability to attach eBPF filters to particular sockets. But \u003cem\u003eextended\u003c/em\u003e BPF goes far beyond packet filtering and allows custom scripts to be triggered at various points within the kernel with very little overhead. Although this technology isn\u0027t new, it\u0027s now coming into its own with the increasing use of microservices deployed as orchestrated containers. Service-to-service communications can be complex in these systems, making it difficult to correlate latency or performance issues back to an API call. We\u0027re now seeing tools released with prewritten eBPF scripts for collecting and visualizing packet traffic or reporting on CPU utilization. With the rise of \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e, we’re seeing a new generation of security enforcement and instrumentation based on eBPF scripts that help tame the complexity of a large microservices deployment.\u003c/p\u003e","blip_status":"t","theta":"216","volume":"2020-05"},{"name":"Firebase","id":"202005015","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"34","display_name":"Firebase","radius":"200","description":"\u003cp\u003eGoogle\u0027s \u003cstrong\u003e\u003ca href\u003d\"https://firebase.google.com/\"\u003eFirebase\u003c/a\u003e\u003c/strong\u003e has undergone significant evolution since we mentioned it as part of a \u003ca href\u003d\"/radar/techniques/serverless-architecture\"\u003eserverless architecture\u003c/a\u003e in 2016. Firebase is a comprehensive platform for building mobile and web apps in a way that\u0027s supported by Google\u0027s underlying scalable infrastructure. We particularly like Firebase App Distribution, which makes it easy to publish test versions of an app via a CD pipeline, and Firebase Remote Config, which allows configuration changes to be dynamically pushed to apps without needing to republish them.\u003c/p\u003e","blip_status":"t","theta":"225","volume":"2020-05"},{"name":"Hot Chocolate","id":"201904047","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"35","display_name":"Hot Chocolate","radius":"230","description":"\u003cp\u003eThe \u003ca href\u003d\"/radar/languages-and-frameworks/graphql\"\u003eGraphQL\u003c/a\u003e ecosystem and community keep growing. \u003cstrong\u003e\u003ca href\u003d\"https://hotchocolate.io/\"\u003eHot Chocolate\u003c/a\u003e\u003c/strong\u003e is a GraphQL server for .NET (Core and Classic). It lets you build and host schemas and then serve queries against them using the same base components of GraphQL — data loader, resolver, schema, operations and types. The team behind Hot Chocolate has recently added schema stitching, which allows for a single entry point to query across multiple schemas aggregated from different locations. Despite the potential to misuse this approach, our teams are happy with Hot Chocolate — it’s well documented, and we\u0027re able to deliver value quickly to our clients.\u003c/p\u003e","blip_status":"move_in","theta":"234","volume":"2020-05"},{"name":"Hydra","id":"201911014","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"36","display_name":"Hydra","radius":"240","description":"\u003cp\u003eNot everyone needs a self-hosted OAuth2 solution, but if you do, have a look at \u003cstrong\u003e\u003ca href\u003d\"https://www.ory.sh/hydra/\"\u003eHydra\u003c/a\u003e\u003c/strong\u003e — a fully compliant open source OAuth2 server and OpenID connect provider. Hydra has in-memory storage support for development and a relational database (PostgreSQL) for production use cases. Hydra as such is stateless and easy to scale horizontally in platforms such as \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e. Depending on your performance requirement, you may have to tune the number of database instances while scaling Hydra instances. And because Hydra doesn\u0027t provide any identity management solutions out of the box, you can integrate whatever flavor of identity management you have with Hydra through a clean API. This clear separation of identity from the rest of the OAuth2 framework makes it easier to integrate Hydra with an existing authentication ecosystem.\u003c/p\u003e","blip_status":"move_in","theta":"243","volume":"2020-05"},{"name":"OpenTelemetry","id":"1095","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"37","display_name":"OpenTelemetry","radius":"210","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://opentelemetry.io/\"\u003eOpenTelemetry\u003c/a\u003e\u003c/strong\u003e is an open source observability project that merges \u003ca href\u003d\"https://opentracing.io/\"\u003eOpenTracing\u003c/a\u003e and \u003ca href\u003d\"https://github.com/census-instrumentation\"\u003eOpenCensus\u003c/a\u003e. The OpenTelemetry project includes \u003ca href\u003d\"https://github.com/open-telemetry/opentelemetry-specification\"\u003especification\u003c/a\u003e, libraries, agents, and other components needed to capture telemetry from services to better observe, manage and debug them. It covers the three pillars of observability — distributed tracing, metrics and logging (currently in beta) — and its specification connects these three pieces through \u003ca href\u003d\"https://github.com/open-telemetry/opentelemetry-specification/blob/master/specification/correlationcontext/api.md\"\u003ecorrelations\u003c/a\u003e; thus you can use \u003cem\u003emetrics\u003c/em\u003e to pinpoint a problem, locate the corresponding \u003cem\u003etraces\u003c/em\u003e to discover where the problem occured, and ultimately study the corresponding \u003cem\u003elogs\u003c/em\u003e to find the exact root cause. OpenTelemetry components can be connected to back-end observability systems such as \u003ca href\u003d\"/radar/tools/prometheus\"\u003ePrometheus\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/jaeger\"\u003eJaeger\u003c/a\u003e among \u003ca href\u003d\"https://opentelemetry.io/registry/?s\u003dexporter\"\u003eothers\u003c/a\u003e. Formation of OpenTracing is a positive step toward the convergence of standardization and the simplification of tooling.\u003c/p\u003e","blip_status":"c","theta":"252","volume":"2020-05"},{"name":"Snowflake","id":"201911005","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"38","display_name":"Snowflake","radius":"220","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.snowflake.com\"\u003eSnowflake\u003c/a\u003e\u003c/strong\u003e has proven to be a robust SaaS big data storage, warehouse or lake solution for many of our clients. It has a superior architecture to scale storage, compute, and services to load, unload and use data. It\u0027s also very flexible: it supports storage of structured, semi-structured and unstructured data; provides a growing list of \u003ca href\u003d\"https://docs.snowflake.com/en/user-guide/conns-drivers.html\"\u003econnectors\u003c/a\u003e for different access patterns such as Spark for data science and SQL for analytics; and runs on multiple cloud providers. Our advice to many of our clients is to use managed services for their utility technology such as big data storage; however, if the risk and regulations prohibit the use of managed services, then Snowflake is a good candidate for companies with large volumes of data and heavy processing workloads. Although we\u0027ve been successful using Snowflake in our medium-sized engagements, we\u0027ve yet to experience Snowflake in large ecosystems where data need to be owned across segments of the organization.\u003c/p\u003e","blip_status":"move_in","theta":"261","volume":"2020-05"},{"name":"Anthos","id":"202005031","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"39","display_name":"Anthos","radius":"290","description":"\u003cp\u003eWe see a shift from accidental hybrid or whole-of-estate cloud migration plans to intentional and sophisticated hybrid, poly or portable cloud strategies, where organizations apply multidimensional principles to establish and execute their cloud strategy: where to host their various data and functional assets based on risk, ability to control and performance profiles; how to utilize their on-premise infrastructure investments while reducing the cost of operations; and how to take advantage of multiple cloud providers and their unique differentiated services without creating complexity and friction for users building and operating applications.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://cloud.google.com/anthos\"\u003eAnthos\u003c/a\u003e\u003c/strong\u003e is Google\u0027s answer to enable hybrid and multicloud strategies by providing a high-level management and control plane on top of a set of open source technologies such as \u003ca href\u003d\"https://cloud.google.com/anthos/gke\"\u003eGKE\u003c/a\u003e, \u003ca href\u003d\"https://cloud.google.com/anthos/service-mesh\"\u003eService Mesh\u003c/a\u003e and a Git-based \u003ca href\u003d\"https://cloud.google.com/anthos/config-management\"\u003eConfiguration Management\u003c/a\u003e. It enables running portable workloads and other assets on different hosting environments, including Google Cloud and on-premises hardware. Although other cloud providers have comparative offerings, Anthos intends to go beyond a hybrid cloud to a portable cloud enabler using open source components, but that is yet to be seen. We\u0027re seeing a rising interest in Anthos. While Google\u0027s approach in managed hybrid cloud environments seems promising, it’s not a magic bullet and requires changes in both existing cloud and on-premise assets. Our advice for clients considering Anthos is to make measured tradeoffs between selecting services from the Google Cloud ecosystem and other options, to maintain their right level of neutrality and control.\u003c/p\u003e","blip_status":"t","theta":"188","volume":"2020-05"},{"name":"Apache Pulsar","id":"202005032","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"40","display_name":"Apache Pulsar","radius":"335","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://pulsar.apache.org/en/\"\u003eApache Pulsar\u003c/a\u003e\u003c/strong\u003e is an open source pub-sub messaging/streaming platform, competing in a similar space with \u003ca href\u003d\"/radar/tools/apache-kafka\"\u003eApache Kafka\u003c/a\u003e. It provides expected functionality — such as low-latency async and sync message delivery and scalable persistent storage of messages — as well as various client libraries. What has excited us to evaluate Pulsar is its ease of scalability, particularly in large organizations with multiple segments of users. Pulsar natively supports multitenancy, georeplication, role-based access control and segregation of billing. We\u0027re also looking to Pulsar to solve the problem of a never-ending log of messages for our large-scale data systems where events are expected to persist indefinitely and subscribers are able to start consuming messages retrospectively. This is supported through a \u003ca href\u003d\"https://pulsar.apache.org/docs/en/concepts-tiered-storage/\"\u003etiered storage\u003c/a\u003e model. Although Pulsar is a promising platform for large organizations, there is room for improvement. Its current installation requires administering \u003ca href\u003d\"https://pulsar.apache.org/docs/en/administration-zk-bk/\"\u003eZooKeeper and BookKeeper\u003c/a\u003e among other pieces of technology. We hope that with its growing adoption, users can soon count on wider community support.\u003c/p\u003e","blip_status":"t","theta":"196","volume":"2020-05"},{"name":"Cosmos","id":"202005033","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"41","display_name":"Cosmos","radius":"310","description":"\u003cp\u003eThe performance of blockchain technology has been greatly improved since we \u003ca href\u003d\"/radar/techniques/blockchain-beyond-bitcoin\"\u003einitially assessed\u003c/a\u003e this area in the Radar. However, there\u0027s still no single blockchain that could achieve \"internet-level\" throughput. As various blockchain platforms develop, we\u0027re seeing new data and value silos. That\u0027s why cross-chain tech has always been a key topic in the blockchain community: the future of blockchain may be a network of independent parallel blockchains. This is also the vision of \u003cstrong\u003e\u003ca href\u003d\"https://cosmos.network/\"\u003eCosmos\u003c/a\u003e\u003c/strong\u003e. Cosmos releases \u003ca href\u003d\"/radar/platforms/tendermint\"\u003eTendermint\u003c/a\u003e and CosmosSDK to let developers customize independent blockchains. These parallel blockchains could exchange value through the Inter-Blockchain Communication (IBC) protocol and Peg-Zones. Our teams have had great experiences with CosmosSDK, and the IBC protocol is maturing. This architecture could solve blockchain interoperability and scalability issues.\u003c/p\u003e","blip_status":"t","theta":"204","volume":"2020-05"},{"name":"Google BigQuery ML","id":"202005040","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"42","display_name":"Google BigQuery ML","radius":"335","description":"\u003cp\u003eOften training and predicting outcomes from machine learning models require code to take the data to the model. \u003cstrong\u003e\u003ca href\u003d\"https://cloud.google.com/bigquery-ml/docs\"\u003eGoogle BigQuery ML\u003c/a\u003e\u003c/strong\u003e inverts this by bringing the model to the data. \u003ca href\u003d\"https://cloud.google.com/bigquery\"\u003eGoogle BigQuery\u003c/a\u003e is a data warehouse designed to serve large-scale queries using SQL, for analytical use cases. Google BigQuery ML extends this function and its SQL interface to create, train and evaluate machine learning models using its data sets; and eventually run model predictions to create new BigQuery data sets. It supports a limited set of models out of the box, such as linear regression for forecasting or binary and multiclass regression for classification. It also supports, with limited functionality, importing previously trained \u003ca href\u003d\"/radar/languages-and-frameworks/tensorflow\"\u003eTensorFlow\u003c/a\u003e models. Although BigQuery ML and its SQL-based approach lower the bar for using machine learning to make predictions and recommendations, particularly for quick explorations, this comes with a difficult trade-off: compromising on other aspects of model training such as \u003ca href\u003d\"/radar/techniques/ethical-bias-testing\"\u003eethical bias testing\u003c/a\u003e, \u003ca href\u003d\"/radar/techniques/explainability-as-a-first-class-model-selection-criterion\"\u003eexplainability\u003c/a\u003e and \u003ca href\u003d\"/radar/techniques/continuous-delivery-for-machine-learning-cd4ml\"\u003econtinuous delivery for machine learning\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"212","volume":"2020-05"},{"name":"JupyterLab","id":"202005034","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"43","display_name":"JupyterLab","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html\"\u003eJupyterLab\u003c/a\u003e\u003c/strong\u003e is the next-generation web-based user interface for Project \u003ca href\u003d\"/radar/tools/jupyter\"\u003eJupyter\u003c/a\u003e. If you\u0027ve been using Jupyter Notebooks, JupyterLab is worth a try; it gives you an interactive environment for Jupyter notebooks, code and data. We see it as an evolution of Jupyter Notebook: it provides a better experience by extending its original capabilities of allowing code, visualization and documentation to exist in one place.\u003c/p\u003e","blip_status":"t","theta":"220","volume":"2020-05"},{"name":"Marquez","id":"202005075","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"44","display_name":"Marquez","radius":"330","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://marquezproject.github.io/marquez/\"\u003eMarquez\u003c/a\u003e\u003c/strong\u003e is a relatively young open source project for collecting and serving metadata information about a data ecosystem. It represents a simple data model to capture metadata such as lineage, upstream and downstream data processing jobs and their status, and a flexible set of tags to capture the attributes of data sets. It provides a simple \u003ca href\u003d\"https://marquezproject.github.io/marquez/openapi.html#\"\u003eRESTful API\u003c/a\u003e to manage the metadata which eases the integration of Marquez to other tool sets within the data ecosystem.\u003c/p\u003e\n\n\u003cp\u003eWe\u0027ve used Marquez as a starting point and easily extended it to fit our needs such as enforcing security policies as well as changes to its domain language. If you\u0027re looking for a small and simple tool to bootstrap storage and visualization of your data-processing jobs and data sets, Marquez is a good place to start.\u003c/p\u003e","blip_status":"t","theta":"229","volume":"2020-05"},{"name":"Matomo","id":"202005076","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"45","display_name":"Matomo","radius":"340","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://matomo.org\"\u003eMatomo\u003c/a\u003e\u003c/strong\u003e (formerly Piwik) is an open source web analytics platform that provides you with full control over your data. You can self-host Matomo and secure your web analytics data from third parties. Matomo also makes it easy to integrate web analytics data with your in-house data platform and lets you build usage models that are tailored to your needs.\u003c/p\u003e","blip_status":"t","theta":"237","volume":"2020-05"},{"name":"MeiliSearch","id":"202005035","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"46","display_name":"MeiliSearch","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/meilisearch/MeiliSearch\"\u003eMeiliSearch\u003c/a\u003e\u003c/strong\u003e is a fast, easy-to-use and easy-to-deploy text search engine. Over the years Elasticsearch has become the popular choice for scalable text searches. However, if you don\u0027t have the volume of data that warrants a distributed solution but still want to provide a fast typo-tolerant search engine, then we recommend assessing MeiliSearch.\u003c/p\u003e","blip_status":"t","theta":"245","volume":"2020-05"},{"name":"Stratos","id":"202005037","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"47","display_name":"Stratos","radius":"300","description":"\u003cp\u003eUltraleap (previously Leap Motion) has been a leader in the XR space for some time, creating remarkable hand-tracking hardware that allows a user\u0027s hands to make the leap into virtual reality. \u003cstrong\u003e\u003ca href\u003d\"https://www.ultraleap.com/haptics/\"\u003eStratos\u003c/a\u003e\u003c/strong\u003e is Ultraleap\u0027s underlying haptics, sensors and software platform, and it can use targeted ultrasound to create haptic feedback in mid-air. A use case is responding to a driver\u0027s hand gesture to change the air conditioning in the car and providing haptic feedback as part of the interface. We\u0027re excited to see this technology and what creative technologists might do to incorporate it into their use cases.\u003c/p\u003e","blip_status":"t","theta":"253","volume":"2020-05"},{"name":"Trillian","id":"202005038","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"48","display_name":"Trillian","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/google/trillian\"\u003eTrillian\u003c/a\u003e\u003c/strong\u003e is a cryptographically verifiable, centralized data store. For trustless, decentralized environments, you can use blockchain-based distributed ledgers. For enterprise environments, however, where the cost of CPU-heavy consensus protocols is unwarranted, we recommend you give Trillian a try.\u003c/p\u003e","blip_status":"t","theta":"261","volume":"2020-05"},{"name":"Node overload","id":"202005026","quadrant":"Platforms","ring":"Hold","movement":"t","radarId":"49","display_name":"Node overload","radius":"370","description":"\u003cp\u003eTechnologies, especially wildly popular ones, have a tendency to be overused. What we\u0027re seeing at the moment is \u003cstrong\u003eNode overload\u003c/strong\u003e, a tendency to use Node.js indiscriminately or for the wrong reasons. Among these, two stand out in our opinion. Firstly, we frequently hear that Node should be used so that all programming can be done in one programming language. Our view remains that \u003ca href\u003d\"/radar/techniques/polyglot-programming\"\u003epolyglot programming\u003c/a\u003e is a better approach, and this still goes \u003ca href\u003d\"/radar/languages-and-frameworks/javascript-as-a-first-class-language\"\u003eboth ways\u003c/a\u003e. Secondly, we often hear teams cite performance as a reason to choose Node.js. Although there are myriads of more or less sensible benchmarks, this perception is rooted in history. When Node.js became popular, it was the first major framework to embrace a nonblocking programming model which made it very efficient for IO-heavy tasks. (We mentioned this in our write-up of Node.js in 2012.) Due to its single-threaded nature, Node.js was never a good choice for compute-heavy workloads, though, and now that capable nonblocking frameworks also exist on other platforms — some with elegant, modern APIs — performance is no longer a reason to choose Node.js.\u003c/p\u003e","blip_status":"t","theta":"225","volume":"2020-05"},{"name":"Cypress","id":"1149","quadrant":"Tools","ring":"Adopt","movement":"c","radarId":"50","display_name":"Cypress","radius":"75","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://www.cypress.io/\"\u003eCypress\u003c/a\u003e\u003c/strong\u003e is still a favorite among our teams where developers manage end-to-end tests themselves, as part of a healthy \u003ca href\u003d\"https://martinfowler.com/articles/practical-test-pyramid.html#End-to-endTests\"\u003etest pyramid\u003c/a\u003e, of course. We decided to call it out again in this Radar because recent versions of Cypress have added \u003ca href\u003d\"https://cypress.io/blog/2020/02/06/introducing-firefox-and-edge-support-in-cypress-4-0/\"\u003esupport for Firefox\u003c/a\u003e, and we strongly suggest testing on multiple browsers. The dominance of Chrome and Chromium-based browsers has led to a worrying trend of teams seemingly only testing with Chrome which can lead to \u003ca href\u003d\"https://twitter.com/mike_conley/status/1245797292453609478\"\u003enasty surprises\u003c/a\u003e.\u003c/p\u003e","blip_status":"c","theta":"60","volume":"2020-05"},{"name":"Figma","id":"201911070","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"51","display_name":"Figma","radius":"100","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.figma.com/\"\u003eFigma\u003c/a\u003e\u003c/strong\u003e has demonstrated to be the go-to tool for collaborative design, not only for designers but for multidisciplinary teams too; it allows developers and other roles to view and comment on designs through the browser without the desktop version. Compared to its competitors (e.g., Invision or Sketch) which have you use more than one tool for versioning, collaborating and design sharing, Figma puts together all of these features in one tool that makes it easier for our teams to discover new ideas together. Our teams find Figma very useful, especially in remote and distributed design work enablement and facilitation. In addition to its real-time design and collaboration capabilities, Figma also offers an API that helps to improve the \u003ca href\u003d\"/radar/techniques/designops\"\u003eDesignOps\u003c/a\u003e process.\u003c/p\u003e","blip_status":"move_in","theta":"30","volume":"2020-05"},{"name":"Dojo","id":"202005108","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"52","display_name":"Dojo","radius":"230","description":"\u003cp\u003eA few years ago, Docker — and containers in general — radically changed how we think about packaging, deploying and running our applications. But despite this improvement in production, developers still spend a lot of time setting up development environments and regularly run into \"but it works on my machine\" style problems. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/kudulab/dojo\"\u003eDojo\u003c/a\u003e\u003c/strong\u003e aims to fix this by creating standard development environments, versioned and released as Docker images. Several of our teams use Dojo to streamline developing, testing and building code from local development through production pipelines.\u003c/p\u003e","blip_status":"t","theta":"84","volume":"2020-05"},{"name":"DVC","id":"202005061","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"53","display_name":"DVC","radius":"210","description":"\u003cp\u003eIn 2018 we mentioned \u003cstrong\u003e\u003ca href\u003d\"https://dvc.org/\"\u003eDVC\u003c/a\u003e\u003c/strong\u003e in conjunction with the \u003ca href\u003d\"/radar/techniques/versioning-data-for-reproducible-analytics\"\u003eversioning data for reproducible analytics\u003c/a\u003e. Since then it has become a favorite tool for managing experiments in machine learning (ML) projects. Since it\u0027s based on Git, DVC is a familiar environment for software developers to bring their engineering practices to ML practice. Because it versions the code that processes data along with the data itself and tracks stages in a pipeline, it helps bring order to the modeling activities without interrupting the analysts’ flow.\u003c/p\u003e","blip_status":"t","theta":"79","volume":"2020-05"},{"name":"Experiment tracking tools for machine learning","id":"201911042","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"54","display_name":"Experiment tracking tools for machine learning","radius":"230","description":"\u003cp\u003eThe day-to-day work of machine learning often boils down to a series of experiments in selecting a modeling approach and the network topology, training data and optimizing or tweaking the model. Data scientists must use experience and intuition to hypothesize changes and then measure the impact those changes have on the overall performance of the model. As this practice has matured, our teams have found an increasing need for \u003cstrong\u003eexperiment tracking tools for machine learning\u003c/strong\u003e. These tools help investigators keep track of the experiments and work through them methodically. Although no clear winner has emerged, tools such as \u003ca href\u003d\"https://mlflow.org/\"\u003eMLflow\u003c/a\u003e and platforms such as \u003ca href\u003d\"https://comet.ml\"\u003eComet\u003c/a\u003e or \u003ca href\u003d\"https://neptune.ml\"\u003eNeptune\u003c/a\u003e have introduced rigor and repeatability into the entire machine learning workflow.\u003c/p\u003e","blip_status":"c","theta":"74","volume":"2020-05"},{"name":"Goss","id":"202005109","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"55","display_name":"Goss","radius":"220","description":"\u003cp\u003eWe mentioned \u003cstrong\u003e\u003ca href\u003d\"https://github.com/aelsabbahy/goss\"\u003eGoss\u003c/a\u003e\u003c/strong\u003e, a tool for \u003ca href\u003d\"/radar/techniques/provisioning-testing\"\u003eprovisioning testing\u003c/a\u003e, in passing in previous Radars, for example, when describing the technique of \u003ca href\u003d\"/radar/techniques/tdd-ing-containers\"\u003eTDD\u0027ing containers\u003c/a\u003e. Although Goss isn\u0027t always an alternative to \u003ca href\u003d\"/radar/tools/serverspec\"\u003eServerspec\u003c/a\u003e, simply because it doesn\u0027t offer the same amount of features, you may want to consider it when its features meet your needs, especially since it comes as a small, self-contained binary (rather than requiring a Ruby environment). A common anti-pattern with using tools such as Goss is double-entry bookkeeping, where each change in the actual infrastructure as code files requires a corresponding change in the test assertions. Such tests are maintenance heavy and because of the close correspondence between code and test, failures mostly occur when an engineer updates one side and forgets the other. And these tests rarely catch genuine problems.\u003c/p\u003e","blip_status":"t","theta":"68","volume":"2020-05"},{"name":"Jaeger","id":"1285","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"56","display_name":"Jaeger","radius":"180","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/jaegertracing/jaeger\"\u003eJaeger\u003c/a\u003e\u003c/strong\u003e is an open source distributed tracing system. Similar to \u003ca href\u003d\"/radar/tools/zipkin\"\u003eZipkin\u003c/a\u003e, it\u0027s been inspired by the Google \u003ca href\u003d\"https://ai.google/research/pubs/pub36356\"\u003eDapper\u003c/a\u003e paper and complies with \u003ca href\u003d\"/radar/platforms/opentelemetry\"\u003eOpenTelemetry\u003c/a\u003e. We\u0027ve used Jaeger successfully with \u003ca href\u003d\"/radar/platforms/istio\"\u003eIstio\u003c/a\u003e and \u003ca href\u003d\"https://www.envoyproxy.io/\"\u003eEnvoy\u003c/a\u003e on Kubernetes and like its \u003ca href\u003d\"https://github.com/jaegertracing/jaeger-ui\"\u003eUI\u003c/a\u003e. Jaeger exposes tracing metrics in the \u003ca href\u003d\"/radar/tools/prometheus\"\u003ePrometheus\u003c/a\u003e format so they can be made available to other tools. However, a new generation of tools such as \u003ca href\u003d\"/radar/tools/honeycomb\"\u003eHoneycomb\u003c/a\u003e integrates traces and metrics into a single observability stream for simpler aggregate analysis. Jaeger joined \u003ca href\u003d\"https://www.cncf.io/blog/2017/09/13/cncf-hosts-jaeger/\"\u003eCNCF\u003c/a\u003e in 2017 and has recently been elevated to CNCF\u0027s highest level of maturity, indicating its widespread deployment into production systems.\u003c/p\u003e","blip_status":"move_in","theta":"62","volume":"2020-05"},{"name":"k9s","id":"202005058","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"57","display_name":"k9s","radius":"200","description":"\u003cp\u003eWe continue to be ardent supporters of \u003ca href\u003d\"/radar/techniques/infrastructure-as-code\"\u003einfrastructure as code\u003c/a\u003e, and we continue to believe that a robust monitoring solution is a prerequisite for operating distributed applications. Sometimes an interactive tool such as the AWS web console can be a useful addition. It allows us to explore all kinds of resources in an ad-hoc fashion without having to remember every single obscure command. Using an interactive tool to make manual modifications on the fly is still a questionable practice, though. For \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e we now have \u003cstrong\u003e\u003ca href\u003d\"https://k9scli.io/\"\u003ek9s\u003c/a\u003e\u003c/strong\u003e, which provides an interactive interface for basically everything that kubectl can do. And to boot, it\u0027s not a web application but runs inside a terminal window, evoking fond memories of \u003ca href\u003d\"https://en.wikipedia.org/wiki/Midnight_Commander\"\u003eMidnight Commander\u003c/a\u003e for some of us.\u003c/p\u003e","blip_status":"t","theta":"57","volume":"2020-05"},{"name":"kind","id":"202005020","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"58","display_name":"kind","radius":"230","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/kubernetes-sigs/kind\"\u003ekind\u003c/a\u003e\u003c/strong\u003e is a tool for running local \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e clusters using Docker container nodes. With \u003ca href\u003d\"https://github.com/kubernetes/test-infra/tree/master/kubetest\"\u003ekubetest\u003c/a\u003e integration, kind makes it easy to do end-to-end testing on Kubernetes. We\u0027ve used kind to create ephemeral Kubernetes clusters to test Kubernetes resources such as Operators and Custom Resource Definitions (CRDs) in our CI pipelines.\u003c/p\u003e","blip_status":"t","theta":"51","volume":"2020-05"},{"name":"mkcert","id":"202005059","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"59","display_name":"mkcert","radius":"210","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/FiloSottile/mkcert\"\u003emkcert\u003c/a\u003e\u003c/strong\u003e is a convenient tool for creating locally trusted development certificates. Using certificates from real certificate authorities (CAs) for local development can be challenging if not impossible (for hosts such as example.test, localhost or 127.0.0.1). In such situations self-signed certificates may be your only option. mkcert lets you generate self-signed certificates and installs the local CA in the system root store. For anything other than local development and testing, we strongly recommend using certificates from real CAs to avoid trust issues.\u003c/p\u003e","blip_status":"t","theta":"45","volume":"2020-05"},{"name":"MURAL","id":"202005030","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"60","display_name":"MURAL","radius":"175","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.mural.co/\"\u003eMURAL\u003c/a\u003e\u003c/strong\u003e describes itself as a \"digital workspace for visual collaboration\" and allows teams to interact with a shared workspace based on a whiteboard/sticky notes metaphor. Its features include voting, commenting, notes and \"follow the presenter.\" We particularly like the template feature that allows a facilitator to design and then reuse guided sessions with a team. Each of the major collaboration suites have a tool in this space (for example, \u003ca href\u003d\"https://jamboard.google.com/\"\u003eGoogle Jamboard\u003c/a\u003e and \u003ca href\u003d\"https://www.microsoft.com/en-ca/microsoft-365/microsoft-whiteboard/digital-whiteboard-app\"\u003eMicrosoft Whiteboard\u003c/a\u003e) and these are worth investigating, but we\u0027ve found MURAL to be slick, effective and flexible.\u003c/p\u003e","blip_status":"t","theta":"40","volume":"2020-05"},{"name":"Open Policy Agent (OPA)","id":"201911069","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"61","display_name":"Open Policy Agent (OPA)","radius":"190","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.openpolicyagent.org/\"\u003eOpen Policy Agent (OPA)\u003c/a\u003e\u003c/strong\u003e has rapidly become a favorable component of many distributed cloud-native solutions that we build for our clients. OPA provides a uniform framework and \u003ca href\u003d\"https://www.openpolicyagent.org/docs/latest/#rego\"\u003elanguage\u003c/a\u003e for declaring, enforcing and controlling policies for various components of a cloud-native solution. It\u0027s a great example of a tool that implements \u003ca href\u003d\"/radar/techniques/security-policy-as-code\"\u003esecurity policy as code\u003c/a\u003e. We\u0027ve had a smooth experience using OPA in multiple scenarios, including deploying resources to K8s clusters, enforcing access control across services in a \u003ca href\u003d\"/radar/techniques/service-mesh\"\u003eservice mesh\u003c/a\u003e and fine-grained security controls as code for accessing application resources. A recent commercial offering, \u003ca href\u003d\"https://www.styra.com/\"\u003eStyra\u0027s Declarative Authorization Service (DAS)\u003c/a\u003e, eases the adoption of OPA for enterprises by adding a management tool, or control plane, to OPA for K8s with a prebuilt policy library, impact analysis of the policies and logging capabilities. We look forward to maturity and extension of OPA beyond operational services to (big) data-centric solutions.\u003c/p\u003e","blip_status":"move_in","theta":"34","volume":"2020-05"},{"name":"Optimal Workshop","id":"1282","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"62","display_name":"Optimal Workshop","radius":"230","description":"\u003cp\u003eUX research demands data collection and analysis to make better decisions about the products we need to build. Our teams find \u003cstrong\u003e\u003ca href\u003d\"https://www.optimalworkshop.com\"\u003eOptimal Workshop\u003c/a\u003e\u003c/strong\u003e useful because it makes it easy to validate prototypes and configure tests for data collection and thus make better decisions. Features such as first-click, card sorting, or a heatmap of user interaction help to both validate prototypes and improve website navigation and information display. It\u0027s an ideal tool for distributed teams since it allows them to conduct remote research.\u003c/p\u003e","blip_status":"move_in","theta":"29","volume":"2020-05"},{"name":"Phrase","id":"202005044","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"63","display_name":"Phrase","radius":"230","description":"\u003cp\u003eAs mentioned in our description of \u003ca href\u003d\"/radar/platforms/crowdin\"\u003eCrowdin\u003c/a\u003e, you now have a choice of platforms to manage the translation of a product into multiple languages instead of emailing large spreadsheets. Our teams report positive experiences with \u003cstrong\u003e\u003ca href\u003d\"https://phrase.com/\"\u003ePhrase\u003c/a\u003e\u003c/strong\u003e, emphasizing that it\u0027s easy to use for all key user groups. Translators use a convenient browser-based UI. Managers can add new fields and synchronize translations with other teams in the same UI. Developers can access Phrase locally and from a build pipeline. A feature that deserves a specific mention is the ability to apply versioning to translations through tags, which makes it possible to compare the look of different translations inside the actual product.\u003c/p\u003e","blip_status":"t","theta":"23","volume":"2020-05"},{"name":"ScoutSuite","id":"1223","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"64","display_name":"ScoutSuite","radius":"180","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/nccgroup/ScoutSuite\"\u003eScoutSuite\u003c/a\u003e\u003c/strong\u003e is an expanded and updated tool based on Scout2 (featured in the Radar in 2018) that provides security posture assessment across \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e, \u003ca href\u003d\"/radar/platforms/azure\"\u003eAzure\u003c/a\u003e, \u003ca href\u003d\"/radar/platforms/google-cloud-platform\"\u003eGCP\u003c/a\u003e and other cloud providers. It works by automatically aggregating configuration data for an environment and applying rules to audit the environment. We\u0027ve found this very useful across projects for doing point-in-time security assessments.\u003c/p\u003e","blip_status":"move_in","theta":"17","volume":"2020-05"},{"name":"Visual regression testing tools","id":"717","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"65","display_name":"Visual regression testing tools","radius":"220","description":"\u003cp\u003eSince we first mentioned \u003cstrong\u003evisual regression testing tools\u003c/strong\u003e in 2014, the use of the technique has spread and the tools landscape has evolved. \u003ca href\u003d\"/radar/tools/backstopjs\"\u003eBackstopJS\u003c/a\u003e remains an excellent choice with new features being added regularly, including support for running inside Docker containers. \u003ca href\u003d\"/radar/tools/loki\"\u003eLoki\u003c/a\u003e was featured in our previous Radar. \u003ca href\u003d\"https://applitools.com/\"\u003eApplitools\u003c/a\u003e, \u003ca href\u003d\"https://crossbrowsertesting.com/\"\u003eCrossBrowserTesting\u003c/a\u003e and \u003ca href\u003d\"https://percy.io/\"\u003ePercy\u003c/a\u003e are SaaS solutions. Another notable mention is \u003ca href\u003d\"https://github.com/rsmbl\"\u003eResemble.js\u003c/a\u003e, an image diffing library. Although most teams use it indirectly as part of BackstopJS, some of our teams have been using it to analyze and compare images of web pages directly. In general, our experience shows that visual regression tools are less useful in the early stages when the interface goes through significant changes, but they certainly prove their worth as the product matures and the interface stabilizes.\u003c/p\u003e","blip_status":"c","theta":"12","volume":"2020-05"},{"name":"Visual Studio Live Share","id":"1265","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"66","display_name":"Visual Studio Live Share","radius":"180","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://marketplace.visualstudio.com/items?itemName\u003dMS-vsliveshare.vsliveshare-pack\"\u003eVisual Studio Live Share\u003c/a\u003e\u003c/strong\u003e is a suite of extensions for \u003ca href\u003d\"/radar/tools/visual-studio-code\"\u003eVisual Studio Code\u003c/a\u003e and Visual Studio. At a time when teams are searching for good remote collaboration options, we want to call attention to the excellent tooling here. Live Share provides a good, low-latency remote-pairing experience, and requires significantly less bandwidth than the brute-force approach of sharing your entire desktop. Importantly, developers can work with their preferred configuration, extensions and key mappings during a pairing session. In addition to real-time collaboration for editing and debugging code, Live Share allows voice calls and sharing terminals and servers.\u003c/p\u003e","blip_status":"c","theta":"7","volume":"2020-05"},{"name":"Apache Superset","id":"202005098","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"67","display_name":"Apache Superset","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://superset.apache.org/\"\u003eApache Superset\u003c/a\u003e\u003c/strong\u003e is a great business intelligence (BI) tool for data exploration and visualization to work with large data lake and data warehouse setups. It works, for example, with \u003ca href\u003d\"/radar/platforms/presto\"\u003ePresto\u003c/a\u003e, \u003ca href\u003d\"https://aws.amazon.com/athena/\"\u003eAmazon Athena\u003c/a\u003e and \u003ca href\u003d\"https://aws.amazon.com/redshift/\"\u003eAmazon Redshift\u003c/a\u003e and can be nicely integrated with enterprise authentication. Moreover, you don\u0027t have to be a data engineer to use it; it’s meant to benefit all engineers exploring data in their everyday work. It\u0027s worth pointing out that Apache Superset is currently undergoing incubation at the Apache Software Foundation (ASF), meaning it\u0027s not yet fully endorsed by ASF.\u003c/p\u003e","blip_status":"t","theta":"82","volume":"2020-05"},{"name":"AsyncAPI","id":"202005046","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"68","display_name":"AsyncAPI","radius":"330","description":"\u003cp\u003eOpen standards are one of the foundational pillars of building distributed systems. For example, the \u003ca href\u003d\"https://github.com/OAI\"\u003eOpenAPI (formerly Swagger)\u003c/a\u003e specification, as an industry standard to define RESTful APIs, has been instrumental to the success of distributed architectures such as \u003ca href\u003d\"https://martinfowler.com/articles/microservices.html\"\u003emicroservices\u003c/a\u003e. It has enabled a proliferation of tooling to support building, testing and monitoring RESTful APIs. However, such standardizations have been largely missing in distributed systems for \u003ca href\u003d\"https://martinfowler.com/articles/201701-event-driven.html\"\u003eevent-driven APIs\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.asyncapi.com/\"\u003eAsyncAPI\u003c/a\u003e\u003c/strong\u003e is an open source initiative to create a much needed event-driven and asynchronous API standardization and development tooling. The \u003ca href\u003d\"https://www.asyncapi.com/docs/specifications/2.0.0/\"\u003eAsyncAPI specification\u003c/a\u003e, inspired by the OpenAPI specification, describes and documents event-driven APIs in a machine-readable format. It\u0027s protocol agnostic, so it can be used for APIs that work over many protocols, including MQTT, WebSockets, and Kafka. We\u0027re eager to see the ongoing improvements of AsyncAPI and further maturity of its tooling ecosystem.\u003c/p\u003e","blip_status":"t","theta":"74","volume":"2020-05"},{"name":"ConfigCat","id":"202005106","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"69","display_name":"ConfigCat","radius":"310","description":"\u003cp\u003eIf you\u0027re looking for a service to support dynamic feature toggles (and bear in mind that simple feature toggles work well too), check out \u003cstrong\u003e\u003ca href\u003d\"https://configcat.com/\"\u003eConfigCat\u003c/a\u003e\u003c/strong\u003e. We\u0027d describe it as \"like LaunchDarkly but cheaper and a bit less fancy\" and find that it does most of what we need. ConfigCat supports simple feature toggles, user segmentation, and A/B testing and has a generous free tier for low-volume use cases or those just starting out.\u003c/p\u003e","blip_status":"t","theta":"66","volume":"2020-05"},{"name":"Gitpod","id":"202005048","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"70","display_name":"Gitpod","radius":"330","description":"\u003cp\u003eYou can build most software following a simple two-step process: check out a repository, and then run a single build script. The process of setting up a full coding environment can still be cumbersome, though. \u003cstrong\u003e\u003ca href\u003d\"https://www.gitpod.io/\"\u003eGitpod\u003c/a\u003e\u003c/strong\u003e addresses this by providing cloud-based, \"ready-to-code\" environments for Github or GitLab repositories. It offers an IDE based on Visual Studio Code that runs inside the web browser. By default, these environments are launched on the Google Cloud Platform, although you can also deploy on-premise solutions. We see the immediate appeal, especially for open source software where this approach can lower the bar for casual contributors. However, it remains to be seen how viable this approach will be in corporate environments.\u003c/p\u003e","blip_status":"t","theta":"58","volume":"2020-05"},{"name":"Gloo","id":"202005049","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"71","display_name":"Gloo","radius":"300","description":"\u003cp\u003eWith the increasing adoption of \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e and \u003ca href\u003d\"/radar/techniques/service-mesh\"\u003eservice mesh\u003c/a\u003e, API gateways have been experiencing an existential crisis in cloud-native distributed systems. After all, many of their capabilities (such as traffic control, security, routing and observability) are now provided by the cluster’s ingress controller and mesh gateway. \u003cstrong\u003e\u003ca href\u003d\"https://www.solo.io/products/gloo/\"\u003eGloo\u003c/a\u003e\u003c/strong\u003e is a lightweight API gateway that embraces this change; it uses \u003ca href\u003d\"https://www.envoyproxy.io/\"\u003eEnvoy\u003c/a\u003e as its gateway technology, while providing added value such as a cohesive view of the APIs to the external users and applications. It also provides an administrative interface for controlling Envoy gateways and runs and integrates with multiple service mesh implementations such as \u003ca href\u003d\"https://linkerd.io/\"\u003eLinkerd\u003c/a\u003e, \u003ca href\u003d\"/radar/platforms/istio\"\u003eIstio\u003c/a\u003e and \u003ca href\u003d\"https://aws.amazon.com/app-mesh/\"\u003eAWS App Mesh\u003c/a\u003e. While its open source implementation provides the basic capabilities expected from an API gateway, its enterprise edition has a more mature set of security controls such as API key management or integration with \u003ca href\u003d\"/radar/tools/open-policy-agent-opa\"\u003eOPA\u003c/a\u003e. Gloo is a promising lightweight API gateway that plays well with the ecosystem of cloud-native technology and architecture, while avoiding the API gateway trap of enabling business logic to glue APIs for the end user.\u003c/p\u003e","blip_status":"t","theta":"50","volume":"2020-05"},{"name":"Lens","id":"202005050","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"72","display_name":"Lens","radius":"310","description":"\u003cp\u003eOne of the strengths of \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e is its flexibility and range of configuration possibilities along with the API-driven, programmable configuration mechanisms and command-line visibility and control using manifest files. However, that strength can also be a weakness: when deployments are complex or when managing multiple clusters, it can be difficult to get a clear picture of the overall status through command-line arguments and manifests alone. \u003cstrong\u003e\u003ca href\u003d\"https://k8slens.dev/\"\u003eLens\u003c/a\u003e\u003c/strong\u003e attempts to solve this problem with an integrated environment for viewing the current state of the cluster and its workloads, visualizing cluster metrics and changing configurations through an embedded text editor. Rather than a simple point-and-click interface, Lens brings together the tools an administrator would run from the command line into a single, navigable interface. This tool is one of several approaches that are trying to tame the complexity of Kubernetes management. We\u0027ve yet to see a clear winner in this space, but Lens strikes an interesting balance between a graphical UI and command-line–only tools.\u003c/p\u003e","blip_status":"t","theta":"41","volume":"2020-05"},{"name":"Manifold","id":"202005100","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"73","display_name":"Manifold","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/uber/manifold\"\u003eManifold\u003c/a\u003e\u003c/strong\u003e is a model-agnostic visual debugger for machine learning (ML). Model developers spend a significant amount of time on iterating and improving an existing model rather than creating a new one. By shifting the focus from model space to data space, Manifold supplements the existing performance metrics with a visual characteristics of the data set that influences the model performance. We think Manifold will be a useful tool to assess in the ML ecosystem.\u003c/p\u003e","blip_status":"t","theta":"33","volume":"2020-05"},{"name":"Sizzy","id":"202005103","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"74","display_name":"Sizzy","radius":"310","description":"\u003cp\u003eBuilding web applications that look just as intended on a large number of devices and screen sizes can be cumbersome. \u003cstrong\u003e\u003ca href\u003d\"https://sizzy.co/\"\u003eSizzy\u003c/a\u003e\u003c/strong\u003e is a SaaS solution that shows many viewports in a single browser window. The application is rendered in all viewports simultaneously and interactions with the application are also synched across the viewports. In our experience interacting with an application in this way can make it easier to spot potential issues earlier, before a \u003ca href\u003d\"/radar/tools/visual-regression-testing-tools\"\u003evisual regression testing tool\u003c/a\u003e flags the issue in the build pipeline. We should mention, though, that some of our developers who tried Sizzy for a while did, on balance, prefer to work with the tooling provided by Chrome.\u003c/p\u003e","blip_status":"t","theta":"25","volume":"2020-05"},{"name":"Snowpack","id":"202005051","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"75","display_name":"Snowpack","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.snowpack.dev/\"\u003eSnowpack\u003c/a\u003e\u003c/strong\u003e is an interesting new entrant in the field of JavaScript build tools. The key improvement over other solutions is that Snowpack makes it possible to build applications with modern frameworks such as \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e, \u003ca href\u003d\"/radar/languages-and-frameworks/vue-js\"\u003eVue.js\u003c/a\u003e, and \u003ca href\u003d\"/radar/languages-and-frameworks/angular\"\u003eAngular\u003c/a\u003e without the need for a bundler. Cutting out the bundling step dramatically improves the feedback cycle during development because changes become available in the browser almost immediately. For this magic to work, Snowpack transforms the dependencies in \u003ccode\u003enode_modules\u003c/code\u003e into single JavaScript files in a new \u003ccode\u003eweb_modules\u003c/code\u003e directory, from where they can be imported as an ECMAScript module (ESM). For IE11 and other browsers that don\u0027t support ESM, a workaround is available. Unfortunately, because no browser today can import CSS from JavaScript, using CSS modules is \u003ca href\u003d\"https://www.snowpack.dev/#importing-css\"\u003enot straightforward\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"17","volume":"2020-05"},{"name":"tfsec","id":"202005105","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"76","display_name":"tfsec","radius":"320","description":"\u003cp\u003eSecurity is everyone\u0027s concern and capturing risks early is always better than facing problems later on. In the \u003ca href\u003d\"/radar/techniques/infrastructure-as-code\"\u003einfrastructure as code\u003c/a\u003e space, where \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e is an obvious choice to manage cloud environments, we now also have \u003cstrong\u003e\u003ca href\u003d\"https://github.com/liamg/tfsec\"\u003etfsec\u003c/a\u003e\u003c/strong\u003e, which is a static analysis tool that helps to scan Terraform templates and find any potential security issues. It comes with preset rules for different cloud providers including \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/azure\"\u003eAzure\u003c/a\u003e. We always like tools that help to mitigate security risks, and tfsec not only excels in identifying security risks, it\u0027s also easy to install and use.\u003c/p\u003e","blip_status":"t","theta":"9","volume":"2020-05"},{"name":"React Hooks","id":"201911020","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"77","display_name":"React Hooks","radius":"110","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://reactjs.org/docs/hooks-intro.html\"\u003eReact Hooks\u003c/a\u003e\u003c/strong\u003e have introduced a new approach to managing stateful logic; given React components have always been closer to functions than classes, Hooks have embraced this and brought state to the functions, instead of taking function as methods to the state with classes. Based on our experience, Hooks improve reuse of functionality among components and code readability. Given Hooks’ testability improvements, using \u003ca href\u003d\"https://reactjs.org/docs/test-renderer.html\"\u003eReact Test Renderer\u003c/a\u003e and \u003ca href\u003d\"/radar/languages-and-frameworks/react-testing-library\"\u003eReact Testing Library\u003c/a\u003e, and their growing community support, we consider them our approach of choice.\u003c/p\u003e","blip_status":"move_in","theta":"292","volume":"2020-05"},{"name":"React Testing Library","id":"201904035","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"78","display_name":"React Testing Library","radius":"110","description":"\u003cp\u003eThe JavaScript world moves pretty fast, and as we gain more experience using a framework our recommendations change. The \u003cstrong\u003e\u003ca href\u003d\"https://testing-library.com/\"\u003eReact Testing Library\u003c/a\u003e\u003c/strong\u003e is a good example of a framework that with deeper usage has eclipsed the alternatives to become the sensible default when testing React-based frontends. Our teams like the fact that tests written with this framework are less brittle than with alternative frameworks such as \u003ca href\u003d\"/radar/languages-and-frameworks/enzyme\"\u003eEnzyme\u003c/a\u003e, because you\u0027re encouraged to test component relationships individually as opposed to testing all implementation details. This mindset is brought by \u003ca href\u003d\"https://testing-library.com/\"\u003eTesting Library\u003c/a\u003e which React Testing Library is part of and which provides a whole family of libraries for \u003ca href\u003d\"/radar/languages-and-frameworks/angular\"\u003eAngular\u003c/a\u003e and \u003ca href\u003d\"/radar/languages-and-frameworks/vue-js\"\u003eVue.js\u003c/a\u003e, for example.\u003c/p\u003e","blip_status":"move_in","theta":"315","volume":"2020-05"},{"name":"Vue.js","id":"1055","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"79","display_name":"Vue.js","radius":"60","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://vuejs.org/\"\u003eVue.js\u003c/a\u003e\u003c/strong\u003e has become one of the successfully applied, loved and trusted frontend JavaScript frameworks among our community. Although there are other, well-adopted alternatives, such as \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e, the simplicity of Vue.js in API design, its clear segregation of directives and components (one file per component idiom) and its simpler state management have made it a compelling option among others.\u003c/p\u003e","blip_status":"move_in","theta":"325","volume":"2020-05"},{"name":"CSS-in-JS","id":"1186","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"80","display_name":"CSS-in-JS","radius":"210","description":"\u003cp\u003eSince we first mentioned \u003cstrong\u003eCSS-in-JS\u003c/strong\u003e as an emerging technique in 2017, it has become much more popular, a trend we also see in our work. With some solid production experience under our belts, we can now recommend CSS-in-JS as a technique to trial. A good starting point is the \u003ca href\u003d\"/radar/languages-and-frameworks/styled-components\"\u003estyled components\u003c/a\u003e framework, which we mentioned in our previous Radar. Next to all the positives, though, there usually is a downside when using CSS-in-JS: the calculation of styles at runtime can cause a \u003ca href\u003d\"https://calendar.perfplanet.com/2019/the-unseen-performance-costs-of-css-in-js-in-react-apps/\"\u003enoticeable lag for end users\u003c/a\u003e. With \u003ca href\u003d\"https://linaria.now.sh/\"\u003eLinaria\u003c/a\u003e we\u0027re now seeing a new class of frameworks that were created with this issue in mind. Linaria employs a number of techniques to shift most of the performance overhead to build time. Alas, this does come with its own set of trade-offs, most notably a lack of dynamic style support in IE11.\u003c/p\u003e","blip_status":"move_in","theta":"278","volume":"2020-05"},{"name":"Exposed","id":"202005068","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"81","display_name":"Exposed","radius":"200","description":"\u003cp\u003eThrough their extended use of \u003ca href\u003d\"/radar/languages-and-frameworks/kotlin\"\u003eKotlin\u003c/a\u003e, our development teams have gained experience with more frameworks designed specifically for Kotlin rather than using Java frameworks with Kotlin. Although it\u0027s been around for a while, \u003cstrong\u003e\u003ca href\u003d\"https://github.com/JetBrains/Exposed\"\u003eExposed\u003c/a\u003e\u003c/strong\u003e has caught our attention as a lightweight object-relational mapper (ORM). Exposed has two flavors of database access: a typesafe internal DSL wrapping SQL and an implementation of the data access object (DAO) pattern. It supports features expected from a mature ORM such as handling of many-to-many references, eager loading, and support for joins across entities. We also like that the implementation works without proxies and doesn\u0027t rely on reflection, which is certainly beneficial to performance.\u003c/p\u003e","blip_status":"t","theta":"286","volume":"2020-05"},{"name":"GraphQL Inspector","id":"202005028","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"82","display_name":"GraphQL Inspector","radius":"232","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/kamilkisiela/graphql-inspector\"\u003eGraphQL Inspector\u003c/a\u003e\u003c/strong\u003e lets you compare changes between two GraphQL schemas. We\u0027ve \u003ca href\u003d\"/radar/languages-and-frameworks/graphql\"\u003ecautioned against the use of GraphQL\u003c/a\u003e in the past, and we\u0027re happy to see some improvements in tooling around GraphQL since. Most of our teams continue to use \u003ca href\u003d\"/radar/techniques/graphql-for-server-side-resource-aggregation\"\u003eGraphQL for server-side resource aggregation\u003c/a\u003e, and by integrating GraphQL Inspector in their CI pipelines, we\u0027ve been able to catch potential breaking changes in the GraphQL schema.\u003c/p\u003e","blip_status":"t","theta":"294","volume":"2020-05"},{"name":"Karate","id":"201904027","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"83","display_name":"Karate","radius":"190","description":"\u003cp\u003eGiven our experience that tests are the only API specifications that really matter, we\u0027re always on the lookout for new tools that might help with testing. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/karatelabs/karate\"\u003eKarate\u003c/a\u003e\u003c/strong\u003e is an API testing framework whose unique feature is that tests are written in Gherkin-based syntax without relying on a general-purpose programming language to implement test behavior. Karate uses a domain-specific language for describing HTTP-based API tests. Our teams like the readable specification that they get with this tool and recommend to keep tests with Karate in the upper levels of the \u003ca href\u003d\"https://martinfowler.com/articles/practical-test-pyramid.html\"\u003etesting pyramid\u003c/a\u003e and not overload its use by making very detailed assertions.\u003c/p\u003e","blip_status":"move_in","theta":"302","volume":"2020-05"},{"name":"Koin","id":"202005070","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"84","display_name":"Koin","radius":"220","description":"\u003cp\u003eAs \u003ca href\u003d\"/radar/languages-and-frameworks/kotlin\"\u003eKotlin\u003c/a\u003e is used increasingly for both mobile and server-side development, the associated ecosystem continues to evolve. \u003cstrong\u003e\u003ca href\u003d\"https://insert-koin.io/\"\u003eKoin\u003c/a\u003e\u003c/strong\u003e is a Kotlin framework that handles one of the routine problems in software development: dependency injection. Although you can choose from a variety of dependency injection frameworks for Kotlin, our teams have come to prefer the simplicity of Koin. Koin avoids using annotations and injects either through constructors or by mimicking Kotlin\u0027s lazy initialization so that objects are injected only when needed. This is in contrast to the statically compiled \u003ca href\u003d\"/radar/languages-and-frameworks/dagger\"\u003eDagger\u003c/a\u003e injection framework for Android. Our developers like the lightweight nature of this framework and its built-in testability.\u003c/p\u003e","blip_status":"t","theta":"310","volume":"2020-05"},{"name":"NestJS","id":"201911023","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"85","display_name":"NestJS","radius":"220","description":"\u003cp\u003eThe growth in popularity of Node.js and trends such as \u003ca href\u003d\"/radar/platforms/node-overload\"\u003eNode overload\u003c/a\u003e have led to the application of Node.js for developing business applications. We often see problems, such as scalability and maintainability, with large JavaScript-based applications. \u003cstrong\u003e\u003ca href\u003d\"https://nestjs.com/\"\u003eNestJS\u003c/a\u003e\u003c/strong\u003e is a \u003ca href\u003d\"/radar/languages-and-frameworks/typescript\"\u003eTypeScript-first\u003c/a\u003e framework that makes the development of Node.js applications safer and less error prone. NestJS is opinionated and comes with SOLID principles and an Angular-inspired architecture out of the box. When building Node.js microservices, NestJS is one of the frameworks that our teams commonly use to empower developers to create testable, scalable, loosely coupled and easily maintainable applications.\u003c/p\u003e","blip_status":"move_in","theta":"319","volume":"2020-05"},{"name":"PyTorch","id":"1172","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"86","display_name":"PyTorch","radius":"175","description":"\u003cp\u003eOur teams have continued to use and appreciate the \u003cstrong\u003e\u003ca href\u003d\"http://pytorch.org/\"\u003ePyTorch\u003c/a\u003e\u003c/strong\u003e machine learning framework, and several teams prefer PyTorch over \u003ca href\u003d\"/radar/languages-and-frameworks/tensorflow\"\u003eTensorFlow\u003c/a\u003e. PyTorch exposes the inner workings of ML that TensorFlow hides, making it easier to debug, and contains constructs that programmers are familiar with such as loops and actions. Recent releases have improved performance of PyTorch, and we\u0027ve been using it successfully in production projects.\u003c/p\u003e","blip_status":"move_in","theta":"317","volume":"2020-05"},{"name":"Rust","id":"771","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"87","display_name":"Rust","radius":"165","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://www.rust-lang.org/\"\u003eRust\u003c/a\u003e\u003c/strong\u003e is continuously gaining in popularity. We\u0027ve had heated discussions about which is better, Rust or C++/Go, without a clear winner. However, we\u0027re glad to see Rust has improved significantly, with more built-in APIs being added and stabilized, including \u003ca href\u003d\"https://blog.rust-lang.org/2019/11/07/Async-await-stable.html\"\u003eadvanced async support\u003c/a\u003e, since we mentioned it in our previous Radar. In addition, Rust has also inspired the design of new languages. For example, the \u003ca href\u003d\"https://developers.libra.org/docs/move-overview\"\u003eMove language\u003c/a\u003e on Libra borrows Rust\u0027s way of managing memory to manage resources, ensuring that digital assets can never be copied or implicitly discarded.\u003c/p\u003e","blip_status":"c","theta":"335","volume":"2020-05"},{"name":"Sarama","id":"202005110","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"88","display_name":"Sarama","radius":"200","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/Shopify/sarama\"\u003eSarama\u003c/a\u003e\u003c/strong\u003e is a Go client library for \u003ca href\u003d\"/radar/tools/apache-kafka\"\u003eApache Kafka\u003c/a\u003e. If you’re developing your APIs in Go, you\u0027ll find Sarama quite easy to set up and manage as it doesn\u0027t depend on any native libraries. Sarama has two types of APIs — a high-level API for easily producing and consuming messages and a low-level API for controlling bytes on the wire.\u003c/p\u003e","blip_status":"t","theta":"343","volume":"2020-05"},{"name":"SwiftUI","id":"201911018","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"89","display_name":"SwiftUI","radius":"185","description":"\u003cp\u003eApple has taken a big step forward with their new \u003cstrong\u003e\u003ca href\u003d\"https://developer.apple.com/xcode/swiftui/\"\u003eSwiftUI\u003c/a\u003e\u003c/strong\u003e framework for implementing user interfaces on the macOS and iOS platforms. We like that SwiftUI moves beyond the somewhat kludgy relationship between Interface Builder and Xcode and adopts a coherent, declarative and code-centric approach. You can now view your code and the resulting visual interface side by side in Xcode 11, making for a much better developer experience. The SwiftUI framework also draws inspiration from the \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e world that has dominated web development in recent years. Immutable values in view models and an asynchronous update mechanism make for a unified reactive programming model. This gives developers an entirely native alternative to similar reactive frameworks such as \u003ca href\u003d\"/radar/languages-and-frameworks/react-native\"\u003eReact Native\u003c/a\u003e or \u003ca href\u003d\"/radar/languages-and-frameworks/flutter\"\u003eFlutter\u003c/a\u003e. SwiftUI definitely represents the future of Apple UI development, and although new, it has shown its benefits. We\u0027ve been having great experience with it — and its shallow learning curve. It\u0027s worth noting that you should know your customer\u0027s use case before jumping into using SwiftUI, given that it doesn\u0027t support iOS 12 or below.\u003c/p\u003e","blip_status":"move_in","theta":"351","volume":"2020-05"},{"name":"Clinic.js Bubbleprof","id":"202005064","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"90","display_name":"Clinic.js Bubbleprof","radius":"320","description":"\u003cp\u003eWith the aim of improving performance in our code, profiling tools are very useful to identify bottlenecks or delays in code which are hard to identify, especially in asynchronous operations. \u003cstrong\u003e\u003ca href\u003d\"https://clinicjs.org/bubbleprof/\"\u003eClinic.js Bubbleprof\u003c/a\u003e\u003c/strong\u003e represents visually the async operations in Node.js processes, drawing a map of delays in the application\u0027s flow. We like this tool because it helps developers to easily identify and prioritize what to improve in the code.\u003c/p\u003e","blip_status":"t","theta":"280","volume":"2020-05"},{"name":"Deequ","id":"202005024","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"91","display_name":"Deequ","radius":"305","description":"\u003cp\u003eThere are still some tool gaps when applying good software engineering practices in data engineering. Attempting to automate data quality checks between different steps in a data pipeline, one of our teams was surprised when they found only a few tools in this space. They settled on \u003cstrong\u003e\u003ca href\u003d\"https://github.com/awslabs/deequ\"\u003eDeequ\u003c/a\u003e\u003c/strong\u003e, a library for writing tests that resemble unit tests for data sets. Deequ is built on top of \u003ca href\u003d\"/radar/platforms/apache-spark\"\u003eApache Spark\u003c/a\u003e, and even though it\u0027s published by AWS Labs it can be used in environments other than \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"290","volume":"2020-05"},{"name":"ERNIE","id":"202005099","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"92","display_name":"ERNIE","radius":"300","description":"\u003cp\u003eIn the previous edition of the Radar we had \u003ca href\u003d\"/radar/techniques/bert\"\u003eBERT\u003c/a\u003e — which is a key milestone in the NLP landscape. Last year, Baidu released \u003cstrong\u003e\u003ca href\u003d\"https://github.com/PaddlePaddle/ERNIE/\"\u003eERNIE\u003c/a\u003e\u003c/strong\u003e 2.0 (Enhanced Representation through kNowledge IntEgration) which outperformed BERT on seven GLUE language understanding tasks and on all nine of the Chinese NLP tasks. ERNIE, like BERT, provides unsupervised pretrained language models, which can be fine-tuned by adding output layers to create state-of-the-art models for a variety of NLP tasks. ERNIE differs from traditional pretraining methods in that it is a continual pretraining framework. Instead of training with a small number of pretraining objectives, it could constantly introduce a large variety of pretraining tasks to help the model efficiently learn language representations. We\u0027re pretty excited about the advancements in NLP and are looking forward to experimenting with ERNIE on our projects.\u003c/p\u003e","blip_status":"t","theta":"300","volume":"2020-05"},{"name":"MediaPipe","id":"202005065","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"93","display_name":"MediaPipe","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/google/mediapipe\"\u003eMediaPipe\u003c/a\u003e\u003c/strong\u003e is a framework for building MultiModal (such as video, audio, time series data, etc.), cross-platform (for example, Android, iOS, Web, and edge devices) and applied ML pipelines. It provides multiple capabilities, including face detection, hand tracking, gesture detection and object detection. Although MediaPipe is primarily deployed to mobile devices, it\u0027s started to show up in the browser thanks to WebAssembly and XNNPack ML Inference Library. We\u0027re exploring MediaPipe for some AR use cases and like what we see so far.\u003c/p\u003e","blip_status":"t","theta":"310","volume":"2020-05"},{"name":"Tailwind CSS","id":"202005054","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"94","display_name":"Tailwind CSS","radius":"300","description":"\u003cp\u003eCSS tools and frameworks offer predesigned components for fast results; after a while, however, they can complicate customization. \u003cstrong\u003e\u003ca href\u003d\"https://tailwindcss.com/\"\u003eTailwind CSS\u003c/a\u003e\u003c/strong\u003e proposes an interesting approach by providing lower-level utility CSS classes to create building blocks without opinionated styles and aiming for easy customization. The breadth of the low-level utilities allows you to avoid writing any classes or CSS on your own which leads to a more maintainable codebase in the long term. It seems that Tailwind CSS offers the right balance between reusability and customization to create visual components.\u003c/p\u003e","blip_status":"t","theta":"320","volume":"2020-05"},{"name":"Tamer","id":"202005066","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"95","display_name":"Tamer","radius":"315","description":"\u003cp\u003eIf you need to ingest data from relational databases into a Kafka topic, consider \u003cstrong\u003e\u003ca href\u003d\"https://github.com/laserdisc-io/tamer\"\u003eTamer\u003c/a\u003e\u003c/strong\u003e, which labels itself \"a domesticated JDBC source connector for Kafka.\" Despite being a relatively new framework, we\u0027ve found Tamer to be more efficient than the Kafka JDBC connector, especially when huge amounts of data are involved.\u003c/p\u003e","blip_status":"t","theta":"330","volume":"2020-05"},{"name":"Wire","id":"202005025","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"96","display_name":"Wire","radius":"300","description":"\u003cp\u003eThe Golang community has had its fair share of dependency injection skeptics, partly because they confused the \u003ca href\u003d\"https://martinfowler.com/articles/injection.html\"\u003epattern\u003c/a\u003e with specific frameworks, and developers with a system-programming background naturally dislike runtime overhead caused by reflection. Then along came \u003cstrong\u003e\u003ca href\u003d\"https://github.com/google/wire\"\u003eWire\u003c/a\u003e\u003c/strong\u003e, a compile-time dependency injection tool that can generate code and wire components together. Wire has no additional runtime overhead, and the static dependency graph is easier to reason about. Whether you handwrite your code or use frameworks, we recommend using dependency injection to encourage modular and testable designs.\u003c/p\u003e","blip_status":"t","theta":"340","volume":"2020-05"},{"name":"XState","id":"202005067","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"97","display_name":"XState","radius":"300","description":"\u003cp\u003eWe\u0027ve featured several state management libraries in the Radar before, but \u003cstrong\u003e\u003ca href\u003d\"https://xstate.js.org/docs/\"\u003eXState\u003c/a\u003e\u003c/strong\u003e takes a slightly different approach. It\u0027s a simple JavaScript and \u003ca href\u003d\"/radar/languages-and-frameworks/typescript\"\u003eTypeScript\u003c/a\u003e framework for creating finite state machines and visualizing them as state charts. It integrates with the more popular reactive JavaScript frameworks (\u003ca href\u003d\"/radar/languages-and-frameworks/vue-js\"\u003eVue.js\u003c/a\u003e, \u003ca href\u003d\"/radar/languages-and-frameworks/ember-js\"\u003eEmber.js\u003c/a\u003e, \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e and \u003ca href\u003d\"https://rxjs.dev/\"\u003eRxJS\u003c/a\u003e) and is based on the W3C standard for finite state machines. Another notable feature is the serialization of machine definitions. One thing that we\u0027ve found helpful when creating finite state machines in other contexts (particularly when writing game logic) is the ability to visualize states and their possible transitions; we like the fact that it\u0027s really easy to do this with XState\u0027s \u003ca href\u003d\"https://xstate.js.org/viz/\"\u003evisualizer\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"350","volume":"2020-05"},{"name":"Enzyme","id":"1047","quadrant":"languages-and-frameworks","ring":"Hold","movement":"c","radarId":"98","display_name":"Enzyme","radius":"385","description":"\u003cp\u003eWe don\u0027t always move deprecated tools to Hold in the Radar, but our teams feel strongly that \u003cstrong\u003e\u003ca href\u003d\"http://airbnb.io/enzyme/\"\u003eEnzyme\u003c/a\u003e\u003c/strong\u003e has been replaced for unit testing \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e UI components by \u003ca href\u003d\"https://testing-library.com/docs/intro\"\u003eReact Testing Library\u003c/a\u003e. Teams using Enzyme have found that its focus on testing component internals leads to brittle, unmaintainable tests.\u003c/p\u003e","blip_status":"c","theta":"315","volume":"2020-05"}],"date":"2020-05"},{"blips":[{"name":"Dependency drift fitness function","id":"201911044","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"1","display_name":"Dependency drift fitness function","radius":"110","description":"\u003cp\u003eFitness functions introduced by \u003ca href\u003d\"/radar/techniques/evolutionary-architecture\"\u003eevolutionary architecture\u003c/a\u003e, borrowed from \u003ca href\u003d\"https://en.wikipedia.org/wiki/Evolutionary_computation#:%7E:text\u003dIn%20computer%20science%2C%20evolutionary%20computation,soft%20computing%20studying%20these%20algorithms.\"\u003eevolutionary computing\u003c/a\u003e, are executable functions that inform us if our applications and architecture are objectively moving away from their desired characteristics. They\u0027re essentially tests that can be incorporated into our release pipelines. One of the major characteristics of an application is the freshness of its dependencies to other libraries, APIs or environmental components that a \u003cstrong\u003edependency drift fitness function\u003c/strong\u003e tracks to flag the out-of-date dependencies that require updating. With the growing and maturing number of tools that detect dependency drifts, such as \u003ca href\u003d\"/radar/tools/dependabot\"\u003eDependabot\u003c/a\u003e or \u003ca href\u003d\"/radar/tools/snyk\"\u003eSnyk\u003c/a\u003e, we can easily incorporate dependency drift fitness functions into our software release process to take timely action in keeping our application dependencies up to date.\u003c/p\u003e","blip_status":"move_in","theta":"162","volume":"2020-10"},{"name":"Run cost as architecture fitness function","id":"1338","quadrant":"Techniques","ring":"Adopt","movement":"c","radarId":"2","display_name":"Run cost as architecture fitness function","radius":"50","description":"\u003cp\u003eAutomating the estimation, tracking and projection of cloud infrastructure\u0027s run cost is necessary for today\u0027s organizations. The cloud providers\u0027 savvy pricing models, combined with the proliferation of pricing parameters and the dynamic nature of today\u0027s architecture, can lead to surprisingly expensive run costs. For example, the price of \u003ca href\u003d\"/radar/techniques/serverless-architecture\"\u003eserverless\u003c/a\u003e based on API calls, event streaming solutions based on traffic or data processing clusters based on running jobs, all have a dynamic nature that changes over time as the architecture evolves. When our teams manage infrastructure on the cloud, implementing \u003cstrong\u003erun cost as architecture fitness function\u003c/strong\u003e is one of their early activities. This means that our teams can observe the cost of running services against the value delivered; when they see deviations from what was expected or acceptable, they\u0027ll discuss whether it\u0027s time to evolve the architecture. The observation and calculation of the run cost is implemented as an automated function.\u003c/p\u003e","blip_status":"c","theta":"144","volume":"2020-10"},{"name":"Security policy as code","id":"201911034","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"3","display_name":"Security policy as code","radius":"110","description":"\u003cp\u003eAs the technology landscape is becoming more complex, concerns such as security need more automation and engineering practices. When building systems, we need to take into consideration security policies, which are rules and procedures to protect our systems from threats and disruption. For example, access control policies define and enforce who can access which services and resources under what circumstances; by contrast, network security policies can dynamically limit the traffic rate to a particular service.\u003c/p\u003e\n\n\u003cp\u003eSeveral of our teams have had a great experience treating \u003cstrong\u003esecurity policy as code\u003c/strong\u003e. When we say \u003cem\u003eas code\u003c/em\u003e, we not only mean to write these security policies in a file but also to apply practices such as keeping the code under version control, introducing automatic validation in the pipeline, automatically deploying them in the environments and observing and monitoring their performance. Based on our experience and the maturity of the existing tools — including \u003ca href\u003d\"/radar/tools/open-policy-agent-opa\"\u003eOpen Policy Agent\u003c/a\u003e and platforms such as \u003ca href\u003d\"/radar/platforms/istio\"\u003eIstio\u003c/a\u003e which provide flexible policy definition and enforcement mechanisms that support the practice of security policy as code — we highly recommend using this technique in your environment.\u003c/p\u003e","blip_status":"move_in","theta":"126","volume":"2020-10"},{"name":"Tailored service templates","id":"777","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"4","display_name":"Tailored service templates","radius":"70","description":"\u003cp\u003eSince we last mentioned \u003cstrong\u003etailored service templates\u003c/strong\u003e, we\u0027ve seen a broader adoption of the pattern to help pave the road for organizations moving to microservices. With constant advances in observability tooling, container orchestration and service mesh sidecars, a template provides sensible defaults to bootstrap a new service, removing a great deal of setup needed to make the service work well with the surrounding infrastructure. We\u0027ve had success \u003ca href\u003d\"/radar/techniques/applying-product-management-to-internal-platforms\"\u003eapplying product management\u003c/a\u003e principles to tailored service templates, treating internal developers as customers and making it easier for them to push code to production and operate it with appropriate observability. This has the added benefit of acting as a lightweight governance mechanism to centralize default technical decisions.\u003c/p\u003e","blip_status":"move_in","theta":"108","volume":"2020-10"},{"name":"Continuous delivery for machine learning (CD4ML)","id":"201904066","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"5","display_name":"Continuous delivery for machine learning (CD4ML)","radius":"220","description":"\u003cp\u003eAbout a decade ago we introduced \u003ca href\u003d\"/radar/techniques/continuous-delivery-cd\"\u003econtinuous delivery (CD)\u003c/a\u003e, our default way to deliver software solutions. Today\u0027s solutions increasingly include machine-learning models and we find them no exception in adopting continuous delivery practices. We call this \u003cstrong\u003e\u003ca href\u003d\"https://martinfowler.com/articles/cd4ml.html\"\u003econtinuous delivery for machine learning (CD4ML)\u003c/a\u003e\u003c/strong\u003e. Although the principles of CD remain the same, the practices and tools to implement the end-to-end process of training, testing, deploying and monitoring models require some modifications. For example: version control must not only include code but also the data, the models and its parameters; the testing pyramid extends to include model bias, fairness and data and feature validation; the deployment process must consider how to promote and evaluate the performance of new models against current champion models. While the industry is celebrating the new buzzword of MLOps, we feel CD4ML is our holistic approach to implement an end-to-end process to reliably release and continuously improve machine-learning models, from idea to production.\u003c/p\u003e","blip_status":"c","theta":"171","volume":"2020-10"},{"name":"Data mesh","id":"201911051","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"6","display_name":"Data mesh","radius":"180","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://martinfowler.com/articles/data-monolith-to-mesh.html\"\u003eData mesh\u003c/a\u003e\u003c/strong\u003e marks a welcome architectural and organizational paradigm shift in how we manage big analytical data. The paradigm is founded on four principles: (1) domain-oriented decentralization of data ownership and architecture; (2) domain-oriented data served as a product; (3) self-serve data infrastructure as a platform to enable autonomous, domain-oriented data teams; and (4) federated governance to enable ecosystems and interoperability. Although the principles are intuitive and attempt to address many of the known challenges of previous centralized analytical data management, they transcend the available analytical data technologies. After building data mesh for multiple clients on top of the existing tooling, we learned two things: (a) there is a large gap in open-source or commercial tooling to accelerate implementation of data mesh (for example, implementation of a universal access model to time-based polyglot data which we currently custom build for our clients) and (b) despite the gap, it\u0027s feasible to use the existing technologies as the basic building blocks.\u003c/p\u003e\n\n\u003cp\u003eNaturally, technology fit is a major component of implementing your organization\u0027s data strategy based on data mesh. Success, however, demands an organizational restructure to separate the data platform team, create the role of data product owner for each domain and introduce the incentive structures necessary for domains to own and share their analytical data as products.\u003c/p\u003e","blip_status":"move_in","theta":"162","volume":"2020-10"},{"name":"Declarative data pipeline definition","id":"202005084","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"7","display_name":"Declarative data pipeline definition","radius":"220","description":"\u003cp\u003eMany data pipelines are defined in a large, more or less imperative script written in Python or Scala. The script contains the logic of the individual steps as well as the code chaining the steps together. When faced with a similar situation in Selenium tests, developers discovered the Page Object pattern, and later many behavior-driven development (BDD) frameworks implemented a split between step definitions and their composition. Some teams are now experimenting with bringing the same thinking to data engineering. A separate \u003cstrong\u003edeclarative data pipeline definition\u003c/strong\u003e, maybe written in YAML, contains only the declaration and sequence of steps. It states input and output data sets but refers to scripts if and when more complex logic is needed. \u003ca href\u003d\"https://github.com/binaryaffairs/a-la-mode\"\u003eA La Mode\u003c/a\u003e is a relatively new tool that takes a DSL approach to defining pipelines, but \u003ca href\u003d\"https://github.com/rambler-digital-solutions/airflow-declarative\"\u003eairflow-declarative\u003c/a\u003e, a tool that turns directed acyclic graphs defined in YAML into \u003ca href\u003d\"/radar/tools/airflow\"\u003eAirflow\u003c/a\u003e task schedules, seems to have the most momentum in this space.\u003c/p\u003e","blip_status":"move_in","theta":"153","volume":"2020-10"},{"name":"Diagrams as code","id":"202010027","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"8","display_name":"Diagrams as code","radius":"250","description":"\u003cp\u003eWe\u0027re seeing more and more tools that enable you to create software architecture and other \u003cstrong\u003ediagrams as code\u003c/strong\u003e. There are benefits to using these tools over the heavier alternatives, including easy version control and the ability to generate the DSLs from many sources. Tools in this space that we like include \u003ca href\u003d\"https://diagrams.mingrammer.com/\"\u003eDiagrams\u003c/a\u003e, \u003ca href\u003d\"https://structurizr.com/dsl\"\u003eStructurizr DSL\u003c/a\u003e, \u003ca href\u003d\"https://asciidoctor.org/docs/asciidoctor-diagram/\"\u003eAsciiDoctor Diagram\u003c/a\u003e and stables such as \u003ca href\u003d\"https://www.websequencediagrams.com/\"\u003eWebSequenceDiagrams\u003c/a\u003e, \u003ca href\u003d\"/radar/tools/plantuml\"\u003ePlantUML\u003c/a\u003e and the venerable \u003ca href\u003d\"https://graphviz.org/\"\u003eGraphviz\u003c/a\u003e. It\u0027s also fairly simple to generate your own SVG these days, so don\u0027t rule out quickly writing your own tool either. One of our authors wrote a small \u003ca href\u003d\"/radar/languages-and-frameworks/ruby\"\u003eRuby\u003c/a\u003e script to quickly create SVGs, for example.\u003c/p\u003e","blip_status":"t","theta":"144","volume":"2020-10"},{"name":"Distroless Docker images","id":"1330","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"9","display_name":"Distroless Docker images","radius":"180","description":"\u003cp\u003eWhen building \u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e images for our applications, we\u0027re often concerned with two things: the security and the size of the image. Traditionally, we\u0027ve used \u003ca href\u003d\"/radar/techniques/container-security-scanning\"\u003econtainer security scanning\u003c/a\u003e tools to detect and patch \u003ca href\u003d\"https://cve.mitre.org/\"\u003ecommon vulnerabilities and exposures\u003c/a\u003e and small distributions such as \u003ca href\u003d\"https://alpinelinux.org/\"\u003eAlpine Linux\u003c/a\u003e to address the image size and distribution performance. We\u0027ve now gained more experience with \u003cstrong\u003edistroless Docker images\u003c/strong\u003e and are ready to recommend this approach as another important security precaution for containerized applications. Distroless Docker images reduce the footprint and dependencies by doing away with a full operating system distribution. This technique reduces security scan noise and the application attack surface. There are fewer vulnerabilities that need to be patched and as a bonus, these smaller images are more efficient. Google has published a set of \u003ca href\u003d\"https://github.com/GoogleContainerTools/distroless\"\u003edistroless container images\u003c/a\u003e for different languages. You can create distroless application images using the Google build tool \u003ca href\u003d\"https://bazel.build/\"\u003eBazel\u003c/a\u003e or simply use multistage Dockerfiles. Note that distroless containers by default don\u0027t have a shell for debugging. However, you can easily find debug versions of distroless containers online, including a \u003ca href\u003d\"https://busybox.net/downloads/BusyBox.html\"\u003eBusyBox shell\u003c/a\u003e. Distroless Docker images is a technique pioneered by Google and, in our experience, is still largely confined to Google-generated images. We\u0027re hoping that the technique catches on beyond this ecosystem.\u003c/p\u003e","blip_status":"move_in","theta":"135","volume":"2020-10"},{"name":"Event interception","id":"202010012","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"10","display_name":"Event interception","radius":"210","description":"\u003cp\u003eAs many more companies migrate away from their legacy systems, we feel it\u0027s worth highlighting an alternative to change data capture (CDC) as a mechanism for getting data from these systems. Martin Fowler described \u003cstrong\u003e\u003ca href\u003d\"https://www.martinfowler.com/bliki/EventInterception.html\"\u003eevent interception\u003c/a\u003e\u003c/strong\u003e back in 2004. In modern terms it involves forking requests on ingress to a system so that it\u0027s possible to gradually build a replacement. Often this is done by copying events or messages but forking HTTP requests is equally valid. Examples include forking events from point-of-sale systems before they\u0027re written to a mainframe and forking payment transactions before they\u0027re written to a core banking system. Both lead to the gradual replacement of parts of the legacy systems. We feel that as a technique, obtaining state changes from the source, rather than trying to recreate them postprocessing using CDC, has been overlooked which is why we\u0027re highlighting it in this issue of the Radar.\u003c/p\u003e","blip_status":"t","theta":"126","volume":"2020-10"},{"name":"Parallel run with reconciliation","id":"202010062","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"11","display_name":"Parallel run with reconciliation","radius":"240","description":"\u003cp\u003eReplacing legacy code at scale is always a difficult endeavor and one that often benefits from executing a \u003cstrong\u003eparallel run with reconciliation\u003c/strong\u003e. In practice, the technique relies on executing the same production flow through both the old and new code, returning the response from the legacy code but comparing the results to gain confidence in the new code. Despite being an old technique, we\u0027ve seen more robust implementations in recent years building on continuous delivery practices such as canary releases and feature toggles and extending them by adding an extra layer of experimentation and data analysis to compare live results. We\u0027ve even used the approach to compare cross-functional results such as response time. Although we\u0027ve used the technique multiple times with bespoke tooling, we certainly owe a nod to GitHub\u0027s \u003ca href\u003d\"https://github.com/github/scientist\"\u003eScientist\u003c/a\u003e tool, which they used to modernize a critical piece of their application and which has now been ported to multiple languages.\u003c/p\u003e","blip_status":"t","theta":"117","volume":"2020-10"},{"name":"Use \"remote native\" processes and approaches","id":"202005004","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"12","display_name":"Use \"remote native\" processes and approaches","radius":"210","description":"\u003cp\u003eAs the pandemic stretches on it seems that highly distributed teams will be the \"new normal,\" at least for the time being. Over the past six months we\u0027ve learnt a lot about effective remote working. On the positive side, good visual work-management and collaboration tools have made it easier than ever to collaborate remotely with colleagues. Developers, for example, can count on \u003ca href\u003d\"/radar/tools/visual-studio-live-share\"\u003eVisual Studio Live Share\u003c/a\u003e and \u003ca href\u003d\"https://visualstudio.microsoft.com/services/github-codespaces/\"\u003eGitHub Codespaces\u003c/a\u003e to facilitate teamwork and increase productivity. The biggest downside to remote work might be burnout: far too many people are scheduled for back-to-back video calls all day long, and this has begun to take its toll. While online visual tools make it easier to collaborate, it\u0027s also possible to build complex giant diagrams that end up being very hard to use, and the security aspects of tool proliferation also need to be carefully managed. Our advice is to remember to take a step back, talk to your teams, evaluate what\u0027s working and what\u0027s not and change processes and tools as needed.\u003c/p\u003e","blip_status":"c","theta":"108","volume":"2020-10"},{"name":"Zero trust architecture","id":"202005092","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"13","display_name":"Zero trust architecture","radius":"180","description":"\u003cp\u003eWhile the fabric of computing and data continues to shift in enterprises — from monolithic applications to \u003ca href\u003d\"/radar/techniques/microservices\"\u003emicroservices\u003c/a\u003e, from centralized data lakes to \u003ca href\u003d\"/radar/techniques/data-mesh\"\u003edata mesh\u003c/a\u003e, from on-prem hosting to polycloud, with an increasing proliferation of connected devices — the approach to securing enterprise assets for the most part remains unchanged, with heavy reliance and trust in the network perimeter: Organizations continue to make heavy investments to secure their assets by hardening the virtual walls of their enterprises, using private links and firewall configurations and replacing static and cumbersome security processes that no longer serve the reality of today. This continuing trend compelled us to highlight \u003cstrong\u003ezero trust architecture\u003c/strong\u003e (ZTA) again.\u003c/p\u003e\n\n\u003cp\u003eZTA is a paradigm shift in security architecture and strategy. It’s based on the assumption that a network perimeter is no longer representative of a secure boundary and no implicit trust should be granted to users or services based solely on their physical or network location. The number of resources, tools and platforms available to implement aspects of ZTA keeps growing and includes: enforcing \u003ca href\u003d\"/radar/techniques/security-policy-as-code\"\u003epolicies as code\u003c/a\u003e based on the least privilege and as granular as possible principles and continuous monitoring and automated mitigation of threats; using \u003ca href\u003d\"/radar/techniques/service-mesh\"\u003eservice mesh\u003c/a\u003e to enforce security control application-to-service and service-to-service; implementing \u003ca href\u003d\"/radar/techniques/binary-attestation\"\u003ebinary attestation\u003c/a\u003e to verify the origin of the binaries; and including \u003ca href\u003d\"/radar/techniques/secure-enclaves\"\u003esecure enclaves\u003c/a\u003e in addition to traditional encryption to enforce the three pillars of data security: in transit, at rest and in memory. For introductions to the topic, consult the \u003ca href\u003d\"https://csrc.nist.gov/publications/detail/sp/800-207/final\"\u003eNIST ZTA\u003c/a\u003e publication and Google\u0027s white paper on \u003ca href\u003d\"https://cloud.google.com/security/beyondprod\"\u003eBeyondProd\u003c/a\u003e.\u003c/p\u003e","blip_status":"c","theta":"99","volume":"2020-10"},{"name":"Bounded low-code platforms","id":"202010004","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"14","display_name":"Bounded low-code platforms","radius":"335","description":"\u003cp\u003eOne of the most nuanced decisions facing companies at the moment is the adoption of low-code or no-code platforms, that is, platforms that solve very specific problems in very limited domains. Many vendors are pushing aggressively into this space. The problems we see with these platforms typically relate to an inability to apply good engineering practices such as versioning. Testing too is typically really hard. However, we noticed some interesting new entrants to the market — including \u003ca href\u003d\"https://www.honeycode.aws/\"\u003eAmazon Honeycode\u003c/a\u003e, which makes it easy to create simple task or event management apps, and \u003ca href\u003d\"https://parabola.io/\"\u003eParabola\u003c/a\u003e for IFTTT-like cloud workflows — which is why we\u0027re including \u003cstrong\u003ebounded low-code platforms\u003c/strong\u003e in this volume. Nevertheless, we remain deeply skeptical about their wider applicability since these tools, like Japanese Knotweed, have a knack of escaping their bounds and tangling everything together. That\u0027s why we still strongly advise caution in their adoption.\u003c/p\u003e","blip_status":"t","theta":"170","volume":"2020-10"},{"name":"Browser-tailored polyfills","id":"202010008","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"15","display_name":"Browser-tailored polyfills","radius":"320","description":"\u003cp\u003ePolyfills are extremely useful to help the web evolve, providing substitute implementations of modern features for browsers that don\u0027t implement them (yet). Too often, though, web applications ship polyfills to browsers that don\u0027t need them, which causes unnecessary download and parsing overhead. The situation is becoming more pronounced now as only a few rendering engines remain and the bulk of the polyfills target only one of them: the Trident renderer in IE11. Further, market share of IE11 is dwindling with \u003ca href\u003d\"https://techcommunity.microsoft.com/t5/microsoft-365-blog/microsoft-365-apps-say-farewell-to-internet-explorer-11-and/ba-p/1591666\"\u003esupport ending\u003c/a\u003e in less than a year. We therefore suggest that you make use of \u003cstrong\u003ebrowser-tailored polyfills\u003c/strong\u003e, shipping only necessary polyfills to a given browser. This technique can even be implemented as a service with \u003ca href\u003d\"https://polyfill.io/v3/\"\u003ePolyfill.io\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"160","volume":"2020-10"},{"name":"Decentralized identity","id":"202005083","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"16","display_name":"Decentralized identity","radius":"300","description":"\u003cp\u003eIn 2016, Christopher Allen, a key contributor to \u003ca href\u003d\"https://en.wikipedia.org/wiki/Transport_Layer_Security\"\u003eSSL/TLS\u003c/a\u003e, inspired us with an introduction of 10 principles underpinning a new form of digital identity and a path to get there, \u003ca href\u003d\"http://www.lifewithalacrity.com/2016/04/the-path-to-self-soverereign-identity.html\"\u003ethe path to self-sovereign identity\u003c/a\u003e. Self-sovereign identity, also known as \u003cstrong\u003edecentralized identity\u003c/strong\u003e, is a “lifetime portable identity for any person, organization, or thing that does not depend on any centralized authority and can never be taken away,” according to the \u003ca href\u003d\"/radar/platforms/trust-over-ip-stack\"\u003eTrust over IP\u003c/a\u003e standard. Adopting and implementing decentralized identity is gaining momentum and becoming attainable. We see its adoption in privacy-respecting \u003ca href\u003d\"https://www.civic.com/healthkey/\"\u003ecustomer health applications\u003c/a\u003e, \u003ca href\u003d\"https://www.truu.id/\"\u003egovernment healthcare infrastructure\u003c/a\u003e and \u003ca href\u003d\"https://id-bulletin.com/2020/06/04/news-gleif-and-evernym-demo-organization-wallets-to-deliver-trust-and-transparency-in-digital-business/\"\u003ecorporate legal identity\u003c/a\u003e. If you want to rapidly get started with decentralized identity, you can assess \u003ca href\u003d\"https://sovrin.org/\"\u003eSovrin Network\u003c/a\u003e, \u003ca href\u003d\"https://github.com/hyperledger/aries\"\u003eHyperledger Aries\u003c/a\u003e and \u003ca href\u003d\"https://github.com/hyperledger/indy-node\"\u003eIndy\u003c/a\u003e OSS, as well as \u003ca href\u003d\"https://www.w3.org/TR/did-core/\"\u003edecentralized identifiers\u003c/a\u003e and \u003ca href\u003d\"/radar/techniques/verifiable-credentials\"\u003everifiable credentials\u003c/a\u003e standards. We\u0027re watching this space closely as we help our clients with their strategic positioning in the new era of digital trust.\u003c/p\u003e","blip_status":"c","theta":"150","volume":"2020-10"},{"name":"Kube-managed cloud services","id":"202010057","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"17","display_name":"Kube-managed cloud services","radius":"310","description":"\u003cp\u003eCloud providers have slowly started supporting \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e-style APIs, via custom resource definitions (CRDs), for managing their cloud services. In most cases these cloud services are a core part of the infrastructure, and we\u0027ve seen teams use tools such as \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e or \u003ca href\u003d\"/radar/platforms/pulumi\"\u003ePulumi\u003c/a\u003e to provision them. With these new CRDs (\u003ca href\u003d\"https://github.com/aws/aws-controllers-k8s\"\u003eACK\u003c/a\u003e for \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e, \u003ca href\u003d\"https://github.com/Azure/azure-service-operator\"\u003eAzure Service Operator\u003c/a\u003e for \u003ca href\u003d\"/radar/platforms/azure\"\u003eAzure\u003c/a\u003e and \u003ca href\u003d\"https://cloud.google.com/config-connector/docs/overview\"\u003eConfig Connectors\u003c/a\u003e for \u003ca href\u003d\"/radar/platforms/google-cloud-platform\"\u003eGCP\u003c/a\u003e) you can use Kubernetes to provision and manage these cloud services. One advantage of these \u003cstrong\u003eKube-managed cloud services\u003c/strong\u003e is that you can leverage the same Kubernetes control plane to enforce the declarative state of both your application and infrastructure. The downside is that it tightly couples your Kubernetes cluster with infrastructure, so we\u0027re carefully assessing it and you should too.\u003c/p\u003e","blip_status":"t","theta":"140","volume":"2020-10"},{"name":"Open Application Model (OAM)","id":"202010032","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"18","display_name":"Open Application Model (OAM)","radius":"330","description":"\u003cp\u003eWe\u0027ve talked a lot about the benefits of creating \u003ca href\u003d\"/radar/techniques/platform-engineering-product-teams\"\u003eplatform engineering product teams\u003c/a\u003e in support of your other product teams, but actually doing it is hard. It seems that the industry is still searching for the right abstraction in the world of \u003ca href\u003d\"/radar/techniques/infrastructure-as-code\"\u003einfrastructure as code\u003c/a\u003e. Although tools such as \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/helm\"\u003eHelm\u003c/a\u003e are steps in the right direction, the focus is still on managing infrastructure as opposed to application development. There are also shifts toward the concept of infrastructure as software with new tools such as \u003ca href\u003d\"/radar/platforms/pulumi\"\u003ePulumi\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/aws-cloud-development-kit\"\u003eCDK\u003c/a\u003e being released. The \u003cstrong\u003e\u003ca href\u003d\"https://oam.dev/\"\u003eOpen Application Model (OAM)\u003c/a\u003e\u003c/strong\u003e is an attempt to bring some standardization to this space. Using the abstractions of components, application configurations, scopes and traits, developers can describe their applications in a platform-agnostic way, while platform implementers define their platform in terms of workload, trait and scope. Whether the OAM will be widely adopted remains to be seen, but we recommend keeping an eye on this interesting and needed idea.\u003c/p\u003e","blip_status":"t","theta":"130","volume":"2020-10"},{"name":"Secure enclaves","id":"202010060","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"19","display_name":"Secure enclaves","radius":"300","description":"\u003cp\u003e\u003cstrong\u003eSecure enclaves\u003c/strong\u003e, also identified as \u003ca href\u003d\"https://en.wikipedia.org/wiki/Trusted_execution_environment\"\u003etrusted execution environments (TEE)\u003c/a\u003e, refer to a technique that isolates an environment — processor, memory and storage — with a higher level of security and only provides a limited exchange of information with its surrounding untrusted execution context. For example, a secure enclave at the hardware and OS levels can create and store private keys and perform operations with them such as encrypt data or verify signatures without the private keys leaving the secure enclave or being loaded in the untrusted application memory. Secure enclave provides a limited set of instructions to perform trusted operations, isolated from an untrusted application context.\u003c/p\u003e\n\n\u003cp\u003eThe technique has long been supported by many hardware and OS providers (including \u003ca href\u003d\"https://support.apple.com/guide/security/secure-enclave-overview-sec59b0b31ff/web\"\u003eApple\u003c/a\u003e), and developers have used it in IoT and edge applications. Only recently, however, has it gained attention in enterprise and cloud-based applications. Cloud providers have started to introduce \u003ca href\u003d\"https://confidentialcomputing.io/\"\u003econfidential computing\u003c/a\u003e features such as hardware-based secure enclaves: \u003ca href\u003d\"https://azure.microsoft.com/en-us/solutions/confidential-compute/\"\u003eAzure confidential computing infrastructure\u003c/a\u003e promises TEE-enabled VMs and access through the \u003ca href\u003d\"https://github.com/openenclave/openenclave\"\u003eOpen Enclave SDK\u003c/a\u003e open-source library to perform trusted operations. Similarly, \u003ca href\u003d\"https://cloud.google.com/compute/confidential-vm/docs/about-cvm\"\u003eGCP Confidential VMs and Compute Engine\u003c/a\u003e, still in beta, allow using VMs with data encryption in memory, and \u003ca href\u003d\"https://aws.amazon.com/ec2/nitro/nitro-enclaves/\"\u003eAWS Nitro Enclaves\u003c/a\u003e is following them with its upcoming preview release. With the introduction of cloud-based secure enclaves and confidential computing, we can add a third pillar to data protection: in rest, in transit and now in memory.\u003c/p\u003e\n\n\u003cp\u003eEven though we\u0027re still in the very early days of secure enclaves for enterprise, we encourage you to consider this technique, while staying informed about known \u003ca href\u003d\"https://en.wikipedia.org/wiki/Foreshadow\"\u003evulnerabilities\u003c/a\u003e that can compromise the secure enclaves of the underlying hardware providers.\u003c/p\u003e","blip_status":"t","theta":"120","volume":"2020-10"},{"name":"Switchback experimentation","id":"202010090","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"20","display_name":"Switchback experimentation","radius":"320","description":"\u003cp\u003eControlled experiments using A/B testing is a great way to inform decisions around product development. But it doesn\u0027t work well when we can\u0027t establish independence between the two groups involved in the A/B test — i.e., adding someone to the \"A\" group impacts the \"B\" group and vice versa. One technique to address this problem space is \u003cstrong\u003e\u003ca href\u003d\"https://medium.com/@DoorDash/switchback-tests-and-randomized-experimentation-under-network-effects-at-doordash-f1d938ab7c2a\"\u003eSwitchback experimentation\u003c/a\u003e\u003c/strong\u003e. The core concept here is we switch back and forth between the \"A\" and \"B\" modes of the experiment in a certain region at alternating time periods instead of both running during the same time period. We then compare the customer experience and other key metrics between the two time buckets. We\u0027ve tried this to good effect in some of our projects — it\u0027s a good tool to have in our experiments toolbelt.\u003c/p\u003e","blip_status":"t","theta":"110","volume":"2020-10"},{"name":"Verifiable credentials","id":"202010098","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"21","display_name":"Verifiable credentials","radius":"300","description":"\u003cp\u003eCredentials are everywhere in our lives and include passports, driver’s licenses and academic certificates. However, most digital credentials today are simple data records from information systems that are easy to modify and forge and often expose unnecessary information. In recent years, we\u0027ve seen the continuous maturity of \u003cstrong\u003eVerifiable Credentials\u003c/strong\u003e solve this issue. The \u003ca href\u003d\"https://www.w3.org/TR/vc-data-model/\"\u003eW3C standard\u003c/a\u003e defines it in a way that is cryptographically secure, privacy respecting and machine verifiable. The model puts credential holders at the center, which is similar to our experience when using physical credentials: users can put their verifiable credentials in their own digital wallets and show them to anyone at any time without the permission of the credentials’ issuer. This decentralized approach also enables users to better manage their own information and selectively disclose certain information and greatly improves data privacy protection. For example, powered by zero-knowledge proof technology, you can construct a verifiable credential to prove that you are an adult without revealing your birthday. The community has developed many \u003ca href\u003d\"https://www.w3.org/TR/vc-use-cases/\"\u003euse cases\u003c/a\u003e around verifiable credentials. We\u0027ve implemented our own COVID health certification with reference to the \u003ca href\u003d\"https://www.covidcreds.com/\"\u003eCOVID-19 Credentials Initiative (CCI)\u003c/a\u003e. Although verifiable credentials don\u0027t rely on blockchain technology or \u003ca href\u003d\"/radar/techniques/decentralized-identity\"\u003edecentralized identity\u003c/a\u003e, this technique often works with DID in practice and uses blockchain as a verifiable data registry. Many decentralized identity frameworks are also embedded with verifiable credentials.\u003c/p\u003e","blip_status":"t","theta":"100","volume":"2020-10"},{"name":"Apollo Federation","id":"202010003","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"22","display_name":"Apollo Federation","radius":"385","description":"\u003cp\u003eWhen we first covered \u003ca href\u003d\"/radar/languages-and-frameworks/graphql\"\u003eGraphQL\u003c/a\u003e in the Radar, we cautioned that its misuse can lead to antipatterns which, in the long run, has more disadvantages than benefits. Nevertheless, we’ve seen an increasing interest in GraphQL among our teams because of its ability to \u003ca href\u003d\"/radar/techniques/graphql-for-server-side-resource-aggregation\"\u003eaggregate information from different resources\u003c/a\u003e. This time we want to caution you about using \u003cstrong\u003e\u003ca href\u003d\"https://www.apollographql.com/docs/apollo-server/federation/introduction/\"\u003eApollo Federation\u003c/a\u003e\u003c/strong\u003e and its  strong support for a single unified data graph for your company. Even though at first glance the idea of having ubiquitous concepts across the organization is tempting, we have to take into account previous similar attempts in the industry — such as \u003ca href\u003d\"/radar/techniques/master-data-management\"\u003eMDM\u003c/a\u003e and canonical data model among others — that have exposed the pitfalls of this approach. The challenges can be significant, especially when the domain we find ourselves in is complex enough to create a unique unified model.\u003c/p\u003e","blip_status":"t","theta":"165","volume":"2020-10"},{"name":"ESBs in API Gateway\u0027s clothing","id":"202010074","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"23","display_name":"ESBs in API Gateway\u0027s clothing","radius":"385","description":"\u003cp\u003eWe\u0027ve long warned against \u003ca href\u003d\"/radar/tools/esb\"\u003ecentralized enterprise services buses\u003c/a\u003e and defined \u003ca href\u003d\"https://martinfowler.com/articles/microservices.html#SmartEndpointsAndDumbPipes\"\u003e\"smart endpoints, dumb pipes\"\u003c/a\u003e as one of the core characteristics of a microservices architecture. Unfortunately, we\u0027re observing a pattern of traditional ESBs rebranding themselves, creating \u003cstrong\u003eESBs in API gateway\u0027s clothing\u003c/strong\u003e that naturally encourage \u003ca href\u003d\"/radar/platforms/overambitious-api-gateways\"\u003eoverambitious API gateways\u003c/a\u003e. Don\u0027t let the marketing fool you: regardless of what you call it, putting business logic (including orchestration and transformation) in a centralized tool creates architectural coupling, decreases transparency, and increases vendor lock-in with no clear upside. API gateways can still act as a useful abstraction for crosscutting concerns, but we believe the smarts should live in the APIs themselves.\u003c/p\u003e","blip_status":"t","theta":"150","volume":"2020-10"},{"name":"Log aggregation for business analytics","id":"202005090","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"24","display_name":"Log aggregation for business analytics","radius":"370","description":"\u003cp\u003eSeveral years ago, a new generation of log aggregation platforms emerged that were capable of storing and searching over vast amounts of log data to uncover trends and insights in operational data. \u003ca href\u003d\"/radar/tools/splunk\"\u003eSplunk\u003c/a\u003e was the most prominent but by no means the only example of these tools. Because these platforms provide broad operational and security visibility across the entire estate of applications, administrators and developers have grown increasingly dependent on them. This enthusiasm spread as stakeholders discovered that they could use \u003cstrong\u003elog aggregation for business analytics\u003c/strong\u003e. However, business needs can quickly outstrip the flexibility and usability of these tools. Logs intended for technical observability are often inadequate to infer deep customer understanding. We prefer either to use tools and metrics designed for customer analytics or to take a more event-driven approach to observability where both business and operational events are collected and stored in a way they can be replayed and processed by more purpose-built tools.\u003c/p\u003e","blip_status":"c","theta":"135","volume":"2020-10"},{"name":"Micro frontend anarchy","id":"202010014","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"25","display_name":"Micro frontend anarchy","radius":"385","description":"\u003cp\u003eSince we originally introduced the term in 2016, \u003ca href\u003d\"/radar/techniques/micro-frontends\"\u003emicro frontends\u003c/a\u003e have grown in popularity and achieved mainstream acceptance. But like any new technique with an easy-to-remember name, it has occasionally been misused and abused. Particularly concerning is the tendency to use this architecture as an excuse to mix a range of competing technologies, tools or frameworks in a single page, leading to \u003cstrong\u003emicro frontend anarchy\u003c/strong\u003e. A particularly egregious form of this syndrome is using multiple frontend frameworks — for example, \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e and \u003ca href\u003d\"/radar/languages-and-frameworks/angular\"\u003eAngular\u003c/a\u003e — in the same \"single-page\" application. Although this might be technically possible, it is far from advisable when not part of a deliberate transition strategy. Other properties that should be consistent from team to team include the styling technique (e.g., \u003ca href\u003d\"/radar/languages-and-frameworks/css-in-js\"\u003eCSS-in-JS\u003c/a\u003e or \u003ca href\u003d\"/radar/languages-and-frameworks/css-modules\"\u003eCSS modules\u003c/a\u003e) and the means by which the individual components are integrated (e.g., iFrames or \u003ca href\u003d\"/radar/platforms/web-components-standard\"\u003eweb components\u003c/a\u003e). Furthermore, organizations should decide whether to standardize on consistent approaches or to leave it up to their teams to decide on state management, data fetching, build tooling, analytics and a host of other choices in a micro frontend application.\u003c/p\u003e","blip_status":"t","theta":"120","volume":"2020-10"},{"name":"Productionizing notebooks","id":"201904057","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"26","display_name":"Productionizing notebooks","radius":"375","description":"\u003cp\u003eOver the last few decades \u003ca href\u003d\"https://en.wikipedia.org/wiki/Notebook_interface\"\u003ecomputational notebooks\u003c/a\u003e, first introduced by \u003ca href\u003d\"https://en.wikipedia.org/wiki/Wolfram_Mathematica\"\u003eWolfram Mathematica\u003c/a\u003e, have evolved to support scientific research, exploration and educational workflows. Naturally, in support of data science workflows and with the likes of \u003ca href\u003d\"https://jupyter.org/\"\u003eJupyter notebooks\u003c/a\u003e and \u003ca href\u003d\"https://docs.databricks.com/notebooks/index.html\"\u003eDatabricks notebooks\u003c/a\u003e, they\u0027ve become a great companion by providing a simple and intuitive interactive computation environment for combining code to analyze data with rich text and visualization to tell a data story. Notebooks were designed to provide an ultimate medium for modern scientific communication and innovation. In recent years, however, we\u0027ve seen a trend for notebooks to be the medium for running the type of production-quality code typically used to drive enterprise operations. We see notebook \u003ca href\u003d\"https://databricks.com/blog/2017/10/30/continuous-integration-continuous-delivery-databricks.html\"\u003eplatform providers advertising\u003c/a\u003e the use of their exploratory notebooks in production. This is a case of good intentions — democratizing programming for data scientists — implemented poorly and at the cost of scalability, maintainability, resiliency and all the other qualities that a long-lived production code needs to support. We don\u0027t recommend \u003cstrong\u003eproductionizing notebooks\u003c/strong\u003e and instead encourage empowering data scientists to build production-ready code with the right programming frameworks, thus simplifying the \u003ca href\u003d\"/radar/techniques/continuous-delivery-for-machine-learning-cd4ml\"\u003econtinuous delivery\u003c/a\u003e tooling and abstracting complexity away through end-to-end ML platforms.\u003c/p\u003e","blip_status":"c","theta":"105","volume":"2020-10"},{"name":"Azure DevOps","id":"1329","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"27","display_name":"Azure DevOps","radius":"240","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://azure.microsoft.com/en-us/services/devops/\"\u003eAzure DevOps\u003c/a\u003e\u003c/strong\u003e services contain a set of managed services, including hosted Git repos, CI/CD pipelines, automated testing tooling, backlog management tooling and artifact repository. We\u0027ve seen our teams getting more experience in using this platform with good results, which means Azure DevOps is maturing. We particularly like its flexibility; it allows you to use the services you want even if they\u0027re from different providers. For instance, you could use an external Git repository while still using the Azure DevOps pipeline services. Our teams are especially excited about \u003ca href\u003d\"https://azure.microsoft.com/en-us/services/devops/pipelines/\"\u003eAzure DevOps Pipelines\u003c/a\u003e. Nevertheless, all the services offer a good developer experience that helps our teams deliver value.\u003c/p\u003e","blip_status":"move_in","theta":"198","volume":"2020-10"},{"name":"Debezium","id":"1288","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"28","display_name":"Debezium","radius":"200","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://debezium.io/\"\u003eDebezium\u003c/a\u003e\u003c/strong\u003e is a \u003ca href\u003d\"https://en.wikipedia.org/wiki/Change_data_capture\"\u003echange data capture (CDC)\u003c/a\u003e platform that can stream database changes onto \u003ca href\u003d\"/radar/tools/apache-kafka\"\u003eKafka\u003c/a\u003e topics. CDC is a popular technique with multiple use cases, including replicating data to other databases, feeding analytics systems, extracting microservices from monoliths and invalidating caches. Debezium reacts to changes in the database\u0027s log files and has CDC connectors for multiple databases, including Postgres, MySQL, Oracle and MongoDB. We\u0027re using Debezium in many projects, and it has worked very well for us.\u003c/p\u003e","blip_status":"move_in","theta":"216","volume":"2020-10"},{"name":"Honeycomb","id":"201904021","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"29","display_name":"Honeycomb","radius":"240","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.honeycomb.io/\"\u003eHoneycomb\u003c/a\u003e\u003c/strong\u003e is an observability service that ingests rich data from production systems and makes it manageable through dynamic sampling. Developers can log large amounts of rich events and later decide how to slice and correlate them. This interactive approach is useful when working with today\u0027s large distributed systems, because we\u0027ve passed the point where we can reasonably anticipate which questions we might want to ask of production systems. The Honeycomb team is actively developing for a number of languages and frameworks with plugins now available for \u003ca href\u003d\"/radar/languages-and-frameworks/go-language\"\u003eGo\u003c/a\u003e, \u003ca href\u003d\"/radar/platforms/node-js\"\u003eNode\u003c/a\u003e, Java and Rails among others; other new features are being added at a rapid pace. The pricing model has also been simplified to make it more attractive. Our teams love it.\u003c/p\u003e","blip_status":"move_in","theta":"234","volume":"2020-10"},{"name":"JupyterLab","id":"202005034","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"30","display_name":"JupyterLab","radius":"190","description":"\u003cp\u003eSince introducing \u003cstrong\u003e\u003ca href\u003d\"https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html\"\u003eJupyterLab\u003c/a\u003e\u003c/strong\u003e in the Assess ring in our last issue, it has become the preferred web-based user interface for Project \u003ca href\u003d\"/radar/tools/jupyter\"\u003eJupyter\u003c/a\u003e for many of our data practitioners. JupyterLab use is rapidly overtaking Jupyter Notebooks, which it will eventually replace. If you\u0027re still using Jupyter Notebooks, you should give JupyterLab a try. Its interactive environment is an evolution of Jupyter Notebook: it extends the original capabilities with drag-and-drop cells and tab autocompletion among other new features.\u003c/p\u003e","blip_status":"move_in","theta":"252","volume":"2020-10"},{"name":"Amundsen","id":"202010021","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"31","display_name":"Amundsen","radius":"325","description":"\u003cp\u003eData scientists spend a large part of their time on data discovery, which means tooling to help in this space is bound to generate some excitement. Although the \u003ca href\u003d\"/radar/platforms/apache-atlas\"\u003eApache Atlas\u003c/a\u003e project has become the de facto tool for metadata management, data discovery is still not easily accomplished. Enter \u003cstrong\u003e\u003ca href\u003d\"https://github.com/amundsen-io/amundsen\"\u003eAmundsen\u003c/a\u003e\u003c/strong\u003e, which can be deployed in concert with Apache Atlas to provide a much nicer search interface for data discovery.\u003c/p\u003e","blip_status":"t","theta":"188","volume":"2020-10"},{"name":"AWS Cloud Development Kit","id":"201911007","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"32","display_name":"AWS Cloud Development Kit","radius":"310","description":"\u003cp\u003eFor many of our teams, \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e has become the default choice for defining cloud infrastructure. However, some of our teams have been experimenting with \u003cstrong\u003e\u003ca href\u003d\"https://docs.aws.amazon.com/cdk/latest/guide/home.html\"\u003eAWS Cloud Development Kit\u003c/a\u003e\u003c/strong\u003e (AWS CDK), and they like what they\u0027ve seen so far. In particular, they like the use of first-class programming languages instead of configuration files which allows them to use existing tools, test approaches and skills. Like similar tools, care is still needed to ensure deployments remain easy to understand and maintain. It currently supports \u003ca href\u003d\"/radar/languages-and-frameworks/typescript\"\u003eTypeScript\u003c/a\u003e, JavaScript, Python, Java and C# and .NET. We\u0027ll continue to watch AWS CDK, especially since the AWS and HashiCorp teams recently launched a \u003ca href\u003d\"https://aws.amazon.com/blogs/developer/introducing-the-cloud-development-kit-for-terraform-preview/\"\u003epreview for Cloud Development Kit for Terraform\u003c/a\u003e to generate Terraform configurations and enable provisioning with the Terraform platform.\u003c/p\u003e","blip_status":"c","theta":"196","volume":"2020-10"},{"name":"Backstage","id":"202010066","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"33","display_name":"Backstage","radius":"315","description":"\u003cp\u003eOrganizations are looking to support and streamline development environments through developer portals or platforms. As the number of tools and technologies increases, some form of standardization is becoming increasingly important for consistency so that developers are able to focus on innovation and product development instead of getting bogged down with reinventing the wheel. A centralized developer portal can offer easy discoverability of services and best practices. \u003cstrong\u003e\u003ca href\u003d\"https://backstage.io/\"\u003eBackstage\u003c/a\u003e\u003c/strong\u003e is an open-source platform for creating developer portals by Spotify. It is based upon software templates, unifying infrastructure tooling and consistent and centralized technical documentation. Its plugin architecture allows for extensibility and adaptability into an organization’s infrastructure ecosystem.\u003c/p\u003e","blip_status":"t","theta":"204","volume":"2020-10"},{"name":"Dremio","id":"202010073","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"34","display_name":"Dremio","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.dremio.com/\"\u003eDremio\u003c/a\u003e\u003c/strong\u003e is a cloud data lake engine that powers interactive queries against cloud data lake storage. With Dremio, you don\u0027t have to manage data pipelines in order to extract and transform data into a separate data warehouse for predictive performance. Dremio creates virtual data sets from data ingested into a data lake and provides a uniform view to consumers. \u003ca href\u003d\"/radar/platforms/presto\"\u003ePresto\u003c/a\u003e popularized the technique of separating storage from the compute layer, and Dremio takes it further by improving performance and optimizing cost of operation.\u003c/p\u003e","blip_status":"t","theta":"212","volume":"2020-10"},{"name":"DuckDB","id":"202010028","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"35","display_name":"DuckDB","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://duckdb.org/\"\u003eDuckDB\u003c/a\u003e\u003c/strong\u003e is an embedded, columnar database for data science and analytical workloads. Analysts spend significant time cleaning and visualizing data locally before scaling it to servers. Although databases have been around for decades, most of them are designed for client-server use cases and therefore not suitable for local interactive queries. To work around this limitation analysts usually end up using in-memory data-processing tools such as \u003ca href\u003d\"https://pandas.pydata.org/\"\u003ePandas\u003c/a\u003e or \u003ca href\u003d\"https://github.com/Rdatatable/data.table\"\u003edata.table\u003c/a\u003e. Although these tools are effective, they do limit the scope of analysis to the volume of data that can fit in memory. We feel DuckDB neatly fills this gap in tooling with an embedded columnar engine that is optimized for analytics on local, larger-than-memory data sets.\u003c/p\u003e","blip_status":"t","theta":"220","volume":"2020-10"},{"name":"K3s","id":"202010039","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"36","display_name":"K3s","radius":"295","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://k3s.io/\"\u003eK3s\u003c/a\u003e\u003c/strong\u003e is a lightweight \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e distribution built for IoT and edge computing. It\u0027s packaged as a single binary and has minimal to no OS dependencies, making it really easy to operate and use. It uses \u003ca href\u003d\"https://docs.python.org/3/library/sqlite3.html\"\u003esqlite3\u003c/a\u003e as the default storage backend instead of \u003ca href\u003d\"https://etcd.io/\"\u003eetcd\u003c/a\u003e. It has a reduced memory footprint because it runs all relevant components in a single process. It also achieves a smaller binary by stripping out third-party storage drivers and cloud providers that are not relevant for the K3s use cases. For environments with constrained resources, K3s is a pretty good choice and worth considering.\u003c/p\u003e","blip_status":"t","theta":"229","volume":"2020-10"},{"name":"Materialize","id":"202010048","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"37","display_name":"Materialize","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://materialize.io/\"\u003eMaterialize\u003c/a\u003e\u003c/strong\u003e is a streaming database that enables you to do incremental computation without complicated data pipelines. Just describe your computations via standard SQL views and connect Materialize to the data stream. The underlying \u003ca href\u003d\"https://github.com/TimelyDataflow/differential-dataflow\"\u003edifferential data flow\u003c/a\u003e engine performs incremental computation to provide consistent and correct output with minimal latency. Unlike traditional databases, there are no restrictions in defining these materialized views and the computations are executed in real time.\u003c/p\u003e","blip_status":"t","theta":"237","volume":"2020-10"},{"name":"Pulumi","id":"1283","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"38","display_name":"Pulumi","radius":"295","description":"\u003cp\u003eWe\u0027ve seen interest in \u003cstrong\u003e\u003ca href\u003d\"https://pulumi.io/\"\u003ePulumi\u003c/a\u003e\u003c/strong\u003e slowly but steadily rising. Pulumi fills a gaping hole in the infrastructure coding world where \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e maintains a firm hold. While Terraform is a tried-and-true standby, its declarative nature suffers from inadequate abstraction facilities and limited testability. Terraform is adequate when the infrastructure is entirely static, but dynamic infrastructure definitions call for a real programming language. Pulumi distinguishes itself by allowing configurations to be written in \u003ca href\u003d\"/radar/languages-and-frameworks/typescript\"\u003eTypeScript\u003c/a\u003e/JavaScript, \u003ca href\u003d\"/radar/languages-and-frameworks/python-3\"\u003ePython\u003c/a\u003e and \u003ca href\u003d\"/radar/languages-and-frameworks/go-language\"\u003eGo\u003c/a\u003e — no markup language or templating required. Pulumi is tightly focused on cloud-native architectures — including containers, serverless functions and data services — and provides good support for \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e. Recently, \u003ca href\u003d\"/radar/platforms/aws-cloud-development-kit\"\u003eAWS CDK\u003c/a\u003e has mounted a challenge, but Pulumi remains the only cloud-neutral tool in this area. We\u0027re anticipating wider Pulumi adoption in the future and looking forward to a viable tool and knowledge ecosystem emerging to support it.\u003c/p\u003e","blip_status":"c","theta":"245","volume":"2020-10"},{"name":"Tekton","id":"202010094","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"39","display_name":"Tekton","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://tekton.dev/\"\u003eTekton\u003c/a\u003e\u003c/strong\u003e is a young \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e-native platform for managing continuous integration and delivery (CI/CD) pipelines. It not only installs and runs on Kubernetes but also defines its CI/CD pipelines as Kubernetes \u003ca href\u003d\"https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/\"\u003ecustom resources\u003c/a\u003e. This means the pipelines can now be controlled by native Kubernetes clients (CLI or APIs) and can take advantage of underlying resource management features such as rollbacks. The pipeline declaration format is flexible and allows defining workflows with conditions, parallel execution paths and handling final tasks to clean up among other features. As a result, Tekton can support complex and hybrid deployment workflows with rollbacks, canary release and more. Tekton is open source and also offered as a \u003ca href\u003d\"https://cloud.google.com/tekton\"\u003emanaged service by GCP\u003c/a\u003e. Although the documentation has room for improvement and the community is growing, we\u0027ve been using Tekton successfully for production workloads on \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"253","volume":"2020-10"},{"name":"Trust over IP stack","id":"202010097","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"40","display_name":"Trust over IP stack","radius":"320","description":"\u003cp\u003eContinuous challenges with how individuals and organizations establish trust digitally, over the internet, is giving rise to a new approach on how to prove identity, how to share and verify attributes needed to establish trust and how to securely transact. Our Radar features some of the foundational technologies such as \u003ca href\u003d\"/radar/techniques/decentralized-identity\"\u003edecentralized identity\u003c/a\u003e and \u003ca href\u003d\"/radar/techniques/verifiable-credentials\"\u003everifiable credentials\u003c/a\u003e that enable this new era of digital trust.\u003c/p\u003e\n\n\u003cp\u003eHowever, such a global scale change won\u0027t be possible without a standardization of a technical governance stack that enables interoperability. The new \u003ca href\u003d\"https://trustoverip.org/\"\u003eTrust over IP Foundation\u003c/a\u003e, part of the Linux Foundation, has set out to do just that. Taking its inspiration from how TCP/IP standardization as the narrow waist of the internet has enabled interoperability across billions of devices, the group is defining a four-layer technical and governance \u003cstrong\u003e\u003ca href\u003d\"https://github.com/hyperledger/aries-rfcs/blob/master/concepts/0289-toip-stack/README.md\"\u003eTrust over IP stack\u003c/a\u003e\u003c/strong\u003e. The stack includes public utilities such as decentralized identifiers, decentralized identity \u003cem\u003ecomms\u003c/em\u003e to standardized protocols for agents such as digital wallets to communicate, data exchange protocols such as flows to issue and verify verifiable credentials, as well as the application ecosystems such as education, finance, healthcare, etc. If you\u0027re revisiting your identity systems and how you establish trust with your ecosystem, we suggest looking into ToIP stack and its supporting tooling, \u003ca href\u003d\"https://www.hyperledger.org/projects/aries\"\u003eHyperledger Aries\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"261","volume":"2020-10"},{"name":"Node overload","id":"202005026","quadrant":"Platforms","ring":"Hold","movement":"c","radarId":"41","display_name":"Node overload","radius":"375","description":"\u003cp\u003eTechnologies, especially wildly popular ones, have a tendency to be overused. What we\u0027re seeing at the moment is \u003cstrong\u003eNode overload\u003c/strong\u003e, a tendency to use Node.js indiscriminately or for the wrong reasons. Among these, two stand out in our opinion. Firstly, we frequently hear that Node.js should be used so that all programming can be done in one programming language. Our view remains that \u003ca href\u003d\"/radar/techniques/polyglot-programming\"\u003epolyglot programming\u003c/a\u003e is a better approach, and this still goes \u003ca href\u003d\"/radar/languages-and-frameworks/javascript-as-a-first-class-language\"\u003eboth ways\u003c/a\u003e. Secondly, we often hear teams cite performance as a reason to choose Node.js. Although there are myriads of more or less sensible benchmarks, this perception is rooted in history. When Node.js became popular, it was the first major framework to embrace a nonblocking programming model which made it very efficient for IO-heavy tasks. (We mentioned this in our write-up of Node.js in 2012.) Due to its single-threaded nature, Node.js was never a good choice for compute-heavy workloads, though, and now that capable nonblocking frameworks also exist on other platforms — some with elegant, modern APIs — performance is no longer a reason to choose Node.js.\u003c/p\u003e","blip_status":"c","theta":"225","volume":"2020-10"},{"name":"Airflow","id":"1125","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"42","display_name":"Airflow","radius":"120","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://airflow.apache.org/\"\u003eAirflow\u003c/a\u003e\u003c/strong\u003e remains our most widely used and favorite open-source workflow management tool for data-processing pipelines as directed acyclic graphs (DAGs). This is a growing space with open-source tools such as \u003ca href\u003d\"https://github.com/spotify/luigi\"\u003eLuigi\u003c/a\u003e and \u003ca href\u003d\"https://github.com/argoproj/argo\"\u003eArgo\u003c/a\u003e and vendor-specific tools such as \u003ca href\u003d\"https://azure.microsoft.com/en-us/services/data-factory/\"\u003eAzure Data Factory\u003c/a\u003e or \u003ca href\u003d\"https://aws.amazon.com/datapipeline/\"\u003eAWS Data Pipeline\u003c/a\u003e. However, Airflow differentiates itself with its programmatic definition of workflows over limited low-code configuration files, support for automated testing, open-source and multiplatform installation, rich set of integration points to the data ecosystem and large community support. In decentralized data architectures such as \u003ca href\u003d\"/radar/techniques/data-mesh\"\u003edata mesh\u003c/a\u003e, however, Airflow currently falls short as a centralized workflow orchestration.\u003c/p\u003e","blip_status":"move_in","theta":"75","volume":"2020-10"},{"name":"Bitrise","id":"1287","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"43","display_name":"Bitrise","radius":"120","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.bitrise.io/\"\u003eBitrise\u003c/a\u003e\u003c/strong\u003e, a domain-specific CD tool for mobile applications, continues to be a useful part of the mobile workflow, and teams really should be using it. Bitrise can build, test and deploy mobile applications all the way from developer laptop to app store publishing. It\u0027s easy to set up and provides a comprehensive set of prebuilt steps for most mobile development needs.\u003c/p\u003e","blip_status":"move_in","theta":"60","volume":"2020-10"},{"name":"Dependabot","id":"1224","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"44","display_name":"Dependabot","radius":"65","description":"\u003cp\u003eAmong the available tools for keeping dependencies up to date, \u003cstrong\u003e\u003ca href\u003d\"http://dependabot.com/\"\u003eDependabot\u003c/a\u003e\u003c/strong\u003e is a solid default choice in our opinion. Dependabot\u0027s integration with \u003ca href\u003d\"/radar/tools/github\"\u003eGitHub\u003c/a\u003e is smooth and automatically sends you pull requests to update your dependencies to their latest versions. It can be enabled at the organization level, so it\u0027s very easy for teams to receive these pull requests. If you\u0027re not using GitHub, you can still use the Dependabot libraries within your build pipeline. If you\u0027re interested in an alternative tool, also consider \u003ca href\u003d\"https://github.com/renovatebot/renovate\"\u003eRenovate\u003c/a\u003e, which supports a wider range of services, including \u003ca href\u003d\"/radar/tools/gitlab\"\u003eGitLab\u003c/a\u003e, Bitbucket and \u003ca href\u003d\"/radar/platforms/azure-devops\"\u003eAzure DevOps\u003c/a\u003e.\u003c/p\u003e","blip_status":"move_in","theta":"50","volume":"2020-10"},{"name":"Helm","id":"1222","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"45","display_name":"Helm","radius":"90","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://helm.sh/\"\u003eHelm\u003c/a\u003e\u003c/strong\u003e is a package manager for \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e. It comes with a repository of curated Kubernetes applications that are maintained in the official \u003ca href\u003d\"https://github.com/helm/charts\"\u003eCharts repository\u003c/a\u003e. Since we last talked about Helm, Helm 3 has been released, and the most significant change is the removal of Tiller, the server-side component of Helm 2. The benefit of a design without Tiller is that you can only make changes to the Kubernetes cluster from the client side, that is, you can only modify the cluster according to the permissions you have as a user of the Helm command. We\u0027ve used Helm in a number of client projects and its dependency management, templating and hook mechanism has greatly simplified the application lifecycle management in Kubernetes.\u003c/p\u003e","blip_status":"move_in","theta":"35","volume":"2020-10"},{"name":"Trivy","id":"201911077","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"46","display_name":"Trivy","radius":"80","description":"\u003cp\u003eBuild pipelines that create and deploy containers should include \u003ca href\u003d\"/radar/techniques/container-security-scanning\"\u003econtainer security scanning\u003c/a\u003e. Our teams particularly like \u003cstrong\u003e\u003ca href\u003d\"https://github.com/aquasecurity/trivy\"\u003eTrivy\u003c/a\u003e\u003c/strong\u003e, a vulnerability scanner for containers. We\u0027ve tried \u003ca href\u003d\"https://github.com/quay/clair\"\u003eClair\u003c/a\u003e and \u003ca href\u003d\"https://github.com/anchore/anchore-engine\"\u003eAnchore Engine\u003c/a\u003e among other good tools in this field. Unlike Clair, Trivy doesn’t only check containers but also dependencies in the codebase. Also, because Trivy ships as a stand-alone binary, it\u0027s easier to set up and run the scan locally. Other benefits of Trivy are that it\u0027s open-source software and that it supports \u003ca href\u003d\"/radar/techniques/distroless-docker-images\"\u003edistroless containers\u003c/a\u003e.\u003c/p\u003e","blip_status":"move_in","theta":"20","volume":"2020-10"},{"name":"Bokeh","id":"843","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"47","display_name":"Bokeh","radius":"250","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://bokeh.org/\"\u003eBokeh\u003c/a\u003e\u003c/strong\u003e is one of the principal libraries in Python for creating scientific plots and data visualizations that render in the browser via JavaScript. Such tools, compared to desktop tools that create static images, make it easy to reuse code for exploratory work in web applications. Bokeh is particularly good for this. The library is mature and full-featured. What we like about Bokeh: it\u0027s great at keeping to its concern as a presentation layer tool and not trying to take on concerns such as data aggregation (see \u003ca href\u003d\"https://github.com/yhat/ggpy\"\u003eggplot\u003c/a\u003e) or web app development (such as \u003ca href\u003d\"https://shiny.rstudio.com/\"\u003eShiny\u003c/a\u003e or \u003ca href\u003d\"/radar/tools/dash\"\u003eDash\u003c/a\u003e). This makes it a joy to use when separation of concerns is important to you. Bokeh does provide web UI widgets and can run in server mode, but you can take or leave these features as you see fit. Bokeh is flexible, and it doesn\u0027t make too many assumptions about how you\u0027ll use it nor does it have many dependencies (such as \u003ca href\u003d\"https://pandas.pydata.org/\"\u003epandas\u003c/a\u003e or notebooks).\u003c/p\u003e","blip_status":"move_in","theta":"84","volume":"2020-10"},{"name":"Concourse","id":"928","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"48","display_name":"Concourse","radius":"180","description":"\u003cp\u003eImplementing sustainable continuous delivery pipelines that can build and deploy production software across multiple environments requires a tool that treats build pipelines and artifacts as first-class citizens. When we first started assessing \u003cstrong\u003e\u003ca href\u003d\"https://concourse-ci.org/\"\u003eConcourse\u003c/a\u003e\u003c/strong\u003e, we liked its simple and flexible model, the principle of container-based builds and the fact that it forces you to define \u003ca href\u003d\"/radar/techniques/pipelines-as-code\"\u003epipelines as code\u003c/a\u003e. Since then, the usability has improved, and the simple model has stood the test of time. Many of our teams and clients have successfully been using Concourse for large pipeline setups over longer periods of time. We also often leverage Concourse\u0027s flexibility to run workers anywhere, for example, when hardware integration tests require a local setup.\u003c/p\u003e","blip_status":"move_in","theta":"78","volume":"2020-10"},{"name":"Dash","id":"202010026","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"49","display_name":"Dash","radius":"240","description":"\u003cp\u003eThis edition of the Radar introduces several new tools for creating web applications that help end users visualize and interact with data. These are more than simple visualization libraries such as \u003ca href\u003d\"/radar/tools/d3\"\u003eD3\u003c/a\u003e. Instead, they reduce the effort necessary to build standalone analytic applications for manipulating existing data sets. \u003cstrong\u003e\u003ca href\u003d\"https://plotly.com/dash/\"\u003eDash\u003c/a\u003e\u003c/strong\u003e from Plotly is gaining popularity among data scientists for creating richly functional analytics applications in Python. Dash augments Python data libraries much like \u003ca href\u003d\"https://shiny.rstudio.com/\"\u003eShiny\u003c/a\u003e sits on top of R. These applications are sometimes referred to as dashboards, but the range of possible functionality is really much greater than the term implies. Dash is particularly suited to building scalable, production-ready applications, unlike \u003ca href\u003d\"/radar/languages-and-frameworks/streamlit\"\u003eStreamlit\u003c/a\u003e, another tool in this class. Consider using Dash when you need to present more sophisticated analyses to business users than a low- or no-code solution such as Tableau can provide.\u003c/p\u003e","blip_status":"t","theta":"71","volume":"2020-10"},{"name":"jscodeshift","id":"202010038","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"50","display_name":"jscodeshift","radius":"180","description":"\u003cp\u003eMaintaining large-scale JavaScript codebases is never easy, but it\u0027s especially challenging when migrating breaking changes. IDEs with refactoring capabilities may help in simple scenarios. However, when your codebase is a widely dependent library, every time you make a breaking change you have to go through a series of client codebases to make the appropriate updates — which requires human oversight and needs to be done manually. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/facebook/jscodeshift\"\u003ejscodeshift\u003c/a\u003e\u003c/strong\u003e, a toolkit to refactor JavaScript and \u003ca href\u003d\"/radar/languages-and-frameworks/typescript\"\u003eTypeScript\u003c/a\u003e, helps relieve this pain. It can parse your code to abstract syntax trees (AST) and provides an API to manipulate the tree with various transformations (e.g., adding, renaming and deleting properties from existing components) and then exports the tree as final source code. jscodeshift also comes with a simple unit testing utility, which can apply test-driven development for writing migration codemods. We\u0027ve found jscodeshift to be quite helpful when maintaining \u003ca href\u003d\"/radar/techniques/design-systems\"\u003edesign systems\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"65","volume":"2020-10"},{"name":"Kustomize","id":"202010043","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"51","display_name":"Kustomize","radius":"200","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://kustomize.io/\"\u003eKustomize\u003c/a\u003e\u003c/strong\u003e is a tool to manage and customize Kubernetes manifest files. It allows you to select and patch your base Kubernetes resources before applying them to different environments and is now natively supported by \u003ca href\u003d\"https://kubernetes.io/docs/reference/kubectl/overview/\"\u003ekubectl\u003c/a\u003e. We like it because it helps keep your code \u003ca href\u003d\"https://wiki.c2.com/?DontRepeatYourself\"\u003eDRY\u003c/a\u003e and in contrast to \u003ca href\u003d\"/radar/tools/helm\"\u003eHelm\u003c/a\u003e (which is trying to do many things — package management, version management and so on), we find Kustomize follows the Unix philosophy: do one thing well and expect the output of every program to be input to another.\u003c/p\u003e","blip_status":"t","theta":"58","volume":"2020-10"},{"name":"MLflow","id":"202010082","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"52","display_name":"MLflow","radius":"230","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://mlflow.org/\"\u003eMLflow\u003c/a\u003e\u003c/strong\u003e is an open-source tool for \u003ca href\u003d\"/radar/tools/experiment-tracking-tools-for-machine-learning\"\u003emachine-learning experiment tracking\u003c/a\u003e and lifecycle management. The workflow to develop and continuously evolve a machine-learning model includes a series of experiments (a collection of runs), tracking the performance of these experiments (a collection of metrics) and tracking and tweaking models (projects). MLflow facilitates this workflow nicely by supporting existing open standards and integrates well with many other tools in the ecosystem. \u003ca href\u003d\"https://databricks.com/product/managed-mlflow\"\u003eMLflow as a managed service by Databricks\u003c/a\u003e on the cloud, available in \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/azure\"\u003eAzure\u003c/a\u003e, is rapidly maturing and we\u0027ve used it successfully in our projects. We find MLflow a great tool for model management and tracking, supporting both UI-based and API-based interaction models. Our only growing concern is that MLflow is attempting to deliver too many conflating concerns as a single platform, such as model serving and scoring.\u003c/p\u003e","blip_status":"t","theta":"52","volume":"2020-10"},{"name":"Pitest","id":"970","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"53","display_name":"Pitest","radius":"230","description":"\u003cp\u003eTraditional testing approaches focus on evaluating if our production code is doing what it\u0027s supposed to do. However, we could make mistakes in the testing code introducing incomplete or useless assertions that create a false sense of confidence. This is where mutation testing comes in; it assesses the quality of the tests themselves, finding corner cases that are hard to realize. Our teams have used \u003cstrong\u003e\u003ca href\u003d\"http://pitest.org/\"\u003ePitest\u003c/a\u003e\u003c/strong\u003e for a while now, and we recommend its use in Java projects to measure the health of the test suite. In short, mutation testing introduces changes in the production code and executes the same tests a second time; if the tests are still green it means that the tests are not good and need to improve. When you’re using programming languages other than Java \u003ca href\u003d\"/radar/tools/stryker\"\u003eStryker\u003c/a\u003e is a good choice in this space.\u003c/p\u003e","blip_status":"move_in","theta":"45","volume":"2020-10"},{"name":"Sentry","id":"1232","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"54","display_name":"Sentry","radius":"200","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://sentry.io/\"\u003eSentry\u003c/a\u003e\u003c/strong\u003e is a cross-platform application monitoring tool with a focus on error reporting. Tools like Sentry distinguish themselves from traditional logging solutions such as the \u003ca href\u003d\"https://www.elastic.co/elk-stack\"\u003eELK Stack\u003c/a\u003e in their focus on discovering, investigating and fixing errors. Sentry has been around for a while and supports several languages and frameworks. We\u0027ve used Sentry in many projects, and it has been really useful in tracking errors, finding out if a commit actually fixed an issue and alerting us if an issue resurfaces due to a regression.\u003c/p\u003e","blip_status":"move_in","theta":"39","volume":"2020-10"},{"name":"ShellCheck","id":"202010086","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"55","display_name":"ShellCheck","radius":"220","description":"\u003cp\u003eEven though tooling has vastly improved in the infrastructure space, writing a shell script may make sense in some cases. Of course, the syntax of shell scripts can only be described as arcane, and as we\u0027ve less practice writing shell scripts these days, we\u0027ve come to like \u003cstrong\u003e\u003ca href\u003d\"https://www.shellcheck.net/\"\u003eShellCheck\u003c/a\u003e\u003c/strong\u003e, a linter for shell scripts. ShellCheck can be used from the command line, as part of a build or, even better, as an extension in many popular IDEs. The wiki contains a detailed description of several hundred issues that ShellCheck can detect, and most tools and IDEs provide a way to conveniently access the respective wiki page when an issue is found.\u003c/p\u003e","blip_status":"t","theta":"33","volume":"2020-10"},{"name":"Stryker","id":"202010017","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"56","display_name":"Stryker","radius":"230","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://stryker-mutator.io/\"\u003eStryker\u003c/a\u003e\u003c/strong\u003e is a relatively new entry in the mutation testing space. Similar to \u003ca href\u003d\"/radar/tools/pitest\"\u003ePitest\u003c/a\u003e, Stryker lets you evaluate the quality of your tests. We\u0027ve been using it quite successfully in JavaScript projects, but it also supports C# and Scala projects. Stryker is very user friendly and highly customizable, and we\u0027ve been able to increase code coverage as well as confidence in the applications we\u0027re delivering for our clients.\u003c/p\u003e","blip_status":"t","theta":"26","volume":"2020-10"},{"name":"Terragrunt","id":"1266","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"57","display_name":"Terragrunt","radius":"200","description":"\u003cp\u003eWe\u0027ve used \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e extensively to create and manage cloud infrastructure. In our experience with larger setups, where code is divided into modules that are included in different ways, teams eventually hit a wall of unavoidable repetition caused by a lack of flexibility. We\u0027ve addressed this by using \u003cstrong\u003e\u003ca href\u003d\"https://github.com/gruntwork-io/terragrunt\"\u003eTerragrunt\u003c/a\u003e\u003c/strong\u003e, a thin wrapper for Terraform that implements the practices advocated by Yevgeniy Brikman’s \u003cem\u003e\u003ca href\u003d\"https://www.oreilly.com/library/view/terraform-up-and/9781491977071/\"\u003eTerraform: Up and Running\u003c/a\u003e\u003c/em\u003e. We\u0027ve found Terragrunt helpful because it encourages versioned modules and reusability for different environments. Lifecycle hooks are another useful feature providing additional flexibility. In terms of packaging, Terragrunt has the same limitations as Terraform: there is no proper way to define packages or dependencies between packages. As a workaround, you can use modules and specify a version associated with a Git tag.\u003c/p\u003e","blip_status":"move_in","theta":"20","volume":"2020-10"},{"name":"tfsec","id":"202005105","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"58","display_name":"tfsec","radius":"220","description":"\u003cp\u003eSecurity is everyone\u0027s concern, and capturing risks early is always better than facing problems later on. In the \u003ca href\u003d\"/radar/techniques/infrastructure-as-code\"\u003einfrastructure as code\u003c/a\u003e space — where \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e has been an obvious choice to manage cloud environments — we now also have \u003cstrong\u003e\u003ca href\u003d\"https://github.com/liamg/tfsec\"\u003etfsec\u003c/a\u003e\u003c/strong\u003e, a static analysis tool that scans Terraform templates to find potential security issues. Our teams have been using tfsec quite successfully. The tool is easy to set up and use, which makes it a great choice for any development team determined to mitigate security risks to prevent breaches before they happen. Its preset rules for different cloud providers, including \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/azure\"\u003eAzure\u003c/a\u003e, compliment the benefits that tfsec brings to the teams that use Terraform.\u003c/p\u003e","blip_status":"move_in","theta":"13","volume":"2020-10"},{"name":"Yarn","id":"1112","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"59","display_name":"Yarn","radius":"180","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://yarnpkg.com/\"\u003eYarn\u003c/a\u003e\u003c/strong\u003e continues to be the package manager of choice for many teams. We\u0027re excited about Yarn 2, a major new release with a long list of changes and improvements. In addition to usability tweaks and improvements in the area of workspaces, Yarn 2 introduces the concept of \u003cem\u003ezero-installs\u003c/em\u003e, which allows developers to run a project directly after cloning it. However, Yarn 2 includes some breaking changes which makes the upgrade \u003ca href\u003d\"https://yarnpkg.com/advanced/migration\"\u003enontrivial\u003c/a\u003e. It also defaults to \u003ca href\u003d\"https://classic.yarnpkg.com/en/docs/pnp/\"\u003eplug\u0027n\u0027play\u003c/a\u003e (PnP) environments and at the same time doesn\u0027t support React Native in PnP environments. Teams can, of course, opt out of PnP or stay on Yarn 1. They should be aware, though, that Yarn 1 is now in maintenance mode.\u003c/p\u003e","blip_status":"c","theta":"7","volume":"2020-10"},{"name":"CML","id":"202010069","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"60","display_name":"CML","radius":"300","description":"\u003cp\u003eWe\u0027ve included \u003ca href\u003d\"/radar/techniques/continuous-delivery-for-machine-learning-cd4ml\"\u003econtinuous delivery for machine learning\u003c/a\u003e as a technique in previous Radars, and in this edition we want to highlight a promising new tool called \u003cstrong\u003e\u003ca href\u003d\"https://cml.dev/\"\u003eContinuous Machine Learning\u003c/a\u003e (or CML)\u003c/strong\u003e from the people who made \u003ca href\u003d\"/radar/tools/dvc\"\u003eDVC\u003c/a\u003e. CML aims to bring the best engineering practices of CI and CD to AI and ML teams and can help to organize your MLOps infrastructure on top of a traditional software engineering stack, instead of creating separate AI platforms. We like that they\u0027ve prioritized support for DVC and see this as a good sign for this burgeoning new tool.\u003c/p\u003e","blip_status":"t","theta":"85","volume":"2020-10"},{"name":"Eleventy","id":"202010011","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"61","display_name":"Eleventy","radius":"310","description":"\u003cp\u003eWe\u0027ve long liked the idea of using \u003ca href\u003d\"/radar/techniques/static-site-generators\"\u003estatic site generators\u003c/a\u003e to avoid complexity and improve performance, whenever the use case allows it. Although \u003cstrong\u003e\u003ca href\u003d\"https://www.11ty.dev/\"\u003eEleventy\u003c/a\u003e\u003c/strong\u003e has been around for a few years, it\u0027s recently caught our attention as it\u0027s matured and previous favorites such as \u003ca href\u003d\"/radar/languages-and-frameworks/gatsby-js\"\u003eGatsby.js\u003c/a\u003e displayed some scalability problems. Eleventy is quick to learn and easy to build sites with. We also like the ease with which you can create semantic (and therefore more accessible) markup with its templating and its simple and robust support for pagination.\u003c/p\u003e","blip_status":"t","theta":"80","volume":"2020-10"},{"name":"Flagger","id":"202010029","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"62","display_name":"Flagger","radius":"300","description":"\u003cp\u003e\u003ca href\u003d\"/radar/techniques/service-mesh\"\u003eService meshes\u003c/a\u003e and API gateways provide a convenient way to route traffic to a variety of microservices, all of which implement the same API interface. \u003cstrong\u003e\u003ca href\u003d\"https://flagger.app/\"\u003eFlagger\u003c/a\u003e\u003c/strong\u003e uses this feature to dynamically adjust the portion of traffic that is routed to a new version of a service. This is a common technique for \u003ca href\u003d\"/radar/techniques/1-canary\"\u003ecanary releases\u003c/a\u003e or blue/green deployment. Flagger works in conjunction with a variety of popular proxies (including Envoy and \u003ca href\u003d\"/radar/tools/kong-api-gateway\"\u003eKong\u003c/a\u003e) to progressively ramp up requests to a service and report metrics on the load in order to provide fast feedback on a new release. We like that Flagger simplifies this valuable practice so that it can be more widely adopted. Although Flagger is sponsored by Weaveworks, it stands on its own with no obligation to use it in conjunction with Weaveworks\u0027 other tooling.\u003c/p\u003e","blip_status":"t","theta":"75","volume":"2020-10"},{"name":"gossm","id":"202010030","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"63","display_name":"gossm","radius":"300","description":"\u003cp\u003eWhen connecting to server instances on \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e, it is recommended to go through a bastion host instead of a direct connection. However, provisioning a bastion host just for that purpose can be frustrating, which is why \u003ca href\u003d\"https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager.html\"\u003eAWS Systems Manager’s Session Manager\u003c/a\u003e provides tunneling to more comfortably connect to your servers. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/gjbae1212/gossm\"\u003egossm\u003c/a\u003e\u003c/strong\u003e is an open-source CLI tool that makes the use of the Session Manager even more convenient. gossm lets you leverage the security provided by Session Manager and IAM policies from your terminal using tools such as \u003ccode\u003essh\u003c/code\u003e and \u003ccode\u003escp\u003c/code\u003e. It also has some capabilities that the AWS CLI is missing, including server discovery and SSH integration.\u003c/p\u003e","blip_status":"t","theta":"69","volume":"2020-10"},{"name":"Great Expectations","id":"202010076","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"64","display_name":"Great Expectations","radius":"310","description":"\u003cp\u003eWith the rise of \u003ca href\u003d\"/radar/techniques/continuous-delivery-for-machine-learning-cd4ml\"\u003eCD4ML\u003c/a\u003e, operational aspects of data engineering and data science have received more attention. Automated data governance is one aspect of this development. \u003cstrong\u003e\u003ca href\u003d\"https://docs.greatexpectations.io/en/latest/\"\u003eGreat Expectations\u003c/a\u003e\u003c/strong\u003e is a framework that enables you to craft built-in controls that flag anomalies or quality issues in data pipelines. Just as unit tests run in a build pipeline, Great Expectations makes assertions during execution of a data pipeline. This is useful not only for implementing a sort of \u003ca href\u003d\"https://en.wikipedia.org/wiki/Andon_(manufacturing)\"\u003eAndon\u003c/a\u003e for data pipelines but also for ensuring that model-based algorithms remain within the operating range determined by their training data. Automated controls like these can help distribute and democratize data access and custodianship. Great Expectations also ships with a profiler tool to help understand the qualities of a particular data set and to set appropriate limits.\u003c/p\u003e","blip_status":"t","theta":"64","volume":"2020-10"},{"name":"k6","id":"202010078","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"65","display_name":"k6","radius":"300","description":"\u003cp\u003eWe\u0027re quite excited by \u003ca href\u003d\"https://k6.io/\"\u003e\u003cstrong\u003ek6\u003c/strong\u003e\u003c/a\u003e, a relatively new tool in the performance testing ecosystem with a heavy focus on developer experience. The k6 command line runner executes scripts written in JavaScript and allows you to configure the execution time and the number of virtual users. The CLI has several \u003ca href\u003d\"https://k6.io/blog/how-to-control-a-live-k6-test\"\u003eadvanced features\u003c/a\u003e that let you see the current statistics before the test has finished executing, scale the number of virtual users beyond what was originally defined and even pause and resume a running test. The command line output provides a set of customizable metrics with transformers that let you visualize the results in \u003ca href\u003d\"https://www.datadoghq.com/\"\u003eDatadog\u003c/a\u003e and other observability tools. Adding \u003ca href\u003d\"https://k6.io/docs/using-k6/checks\"\u003echecks\u003c/a\u003e to your scripts is an easy way to integrate performance testing into your CI/CD pipeline. For accelerated performance testing, check out the commercial version, \u003ca href\u003d\"https://k6.io/cloud\"\u003ek6 Cloud\u003c/a\u003e, which provides cloud scaling and additional visualizations.\u003c/p\u003e","blip_status":"t","theta":"59","volume":"2020-10"},{"name":"Katran","id":"202010079","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"66","display_name":"Katran","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/facebookincubator/katran\"\u003eKatran\u003c/a\u003e\u003c/strong\u003e is a high-performance layer 4 load balancer. It\u0027s not for everyone, but if you need redundancy for layer 7 load balancers (such as \u003ca href\u003d\"http://www.haproxy.org/\"\u003eHAProxy\u003c/a\u003e or \u003ca href\u003d\"https://www.nginx.com/\"\u003eNGINX\u003c/a\u003e) or need to scale load balancers to two or more servers, then we recommend assessing Katran. We see Katran as a flexible and efficient choice over techniques such as round-robin DNS over L7 load balancers or the IPVS Kernel model that network engineers usually adopt to solve similar challenges.\u003c/p\u003e","blip_status":"t","theta":"53","volume":"2020-10"},{"name":"Kiali","id":"202010080","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"67","display_name":"Kiali","radius":"315","description":"\u003cp\u003eGiven the increased use of \u003ca href\u003d\"/radar/techniques/service-mesh\"\u003eservice mesh\u003c/a\u003e to deploy collections of containerized microservices, we can expect to see tools emerge that automate and simplify the administrative tasks associated with this architectural style. \u003cstrong\u003e\u003ca href\u003d\"https://kiali.io/\"\u003eKiali\u003c/a\u003e\u003c/strong\u003e is one such tool. Kiali provides a graphical user interface to observe and control networks of services deployed with \u003ca href\u003d\"/radar/platforms/istio\"\u003eIstio\u003c/a\u003e. We\u0027ve found Kiali useful for visualizing the topology of services in a network and understanding the traffic routed between them. For example, when used in conjunction with \u003ca href\u003d\"/radar/tools/flagger\"\u003eFlagger\u003c/a\u003e, Kiali can display requests that have been routed to a canary service release. We particularly like Kiali\u0027s ability to artificially inject network faults into a service mesh to test resilience in the face of network interruptions. This practice is all too often ignored due to the complexity of configuring and running failure tests in a complex mesh of microservices.\u003c/p\u003e","blip_status":"t","theta":"48","volume":"2020-10"},{"name":"LGTM","id":"202010044","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"68","display_name":"LGTM","radius":"320","description":"\u003cp\u003eWriting secure code is as important as ever, but it\u0027s only one of the many things developers have to prioritize. \u003cstrong\u003e\u003ca href\u003d\"http://lgtm.com/\"\u003eLGTM\u003c/a\u003e\u003c/strong\u003e provides both a safety net and a means to benefit from a knowledge base of secure coding practices. It is a static code analysis tool with a focus on security that is backed by a (partially open-source) catalog of secure coding rules. The rules are implemented as queries over your codebase in the \u003ca href\u003d\"https://codeql.github.com/docs/ql-language-reference/about-the-ql-language/\"\u003eCodeQL\u003c/a\u003e query language. It can be used to integrate white-box security checks into your CD pipelines for Java, Go, JavaScript, Python, C# and C/C++. LGTM and CodeQL are part of the \u003ca href\u003d\"https://securitylab.github.com/\"\u003eGithub Security Lab\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"43","volume":"2020-10"},{"name":"Litmus","id":"202010081","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"69","display_name":"Litmus","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://litmuschaos.io/\"\u003eLitmus\u003c/a\u003e\u003c/strong\u003e is a chaos engineering tool with a low barrier to entry. It allows you to inject various error scenarios into your \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e cluster with minimal effort. We\u0027re particularly excited by the range of capabilities Litmus offers beyond your random pod kill, including simulating network, CPU, memory and I/O issues. Litmus also supports tailored experiments to simulate errors for \u003ca href\u003d\"/radar/tools/apache-kafka\"\u003eKafka\u003c/a\u003e and Cassandra among other common services.\u003c/p\u003e","blip_status":"t","theta":"38","volume":"2020-10"},{"name":"Opacus","id":"202010053","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"70","display_name":"Opacus","radius":"325","description":"\u003cp\u003eThe concept of \u003ca href\u003d\"/radar/techniques/differential-privacy\"\u003edifferential privacy\u003c/a\u003e first appeared in the Radar in 2016. Although the problem of breaking privacy through systematic model inference queries was recognized at the time, it was largely a theoretical issue since remedies were few. The industry has lacked tools to prevent this from happening. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/pytorch/opacus\"\u003eOpacus\u003c/a\u003e\u003c/strong\u003e is a new Python library that can be used in conjunction with \u003ca href\u003d\"/radar/languages-and-frameworks/pytorch\"\u003ePyTorch\u003c/a\u003e to help thwart one type of differential privacy attack. Although this is a promising development, finding the right model and data set to which it applies has been a challenge. The library is still quite new so we\u0027re looking forward to seeing how it\u0027ll be accepted going forward.\u003c/p\u003e","blip_status":"t","theta":"32","volume":"2020-10"},{"name":"OSS Index","id":"202010055","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"71","display_name":"OSS Index","radius":"310","description":"\u003cp\u003eIt\u0027s important for a development team to identify whether the dependencies of their application have known vulnerabilities. \u003cstrong\u003e\u003ca href\u003d\"https://ossindex.sonatype.org/\"\u003eOSS Index\u003c/a\u003e\u003c/strong\u003e could be used to achieve this goal. OSS Index is a free catalog of open-source components and scanning tools designed to help developers identify vulnerabilities, understand risk and keep their software safe. Our teams are already integrating this index into pipelines via different languages, including \u003ca href\u003d\"https://github.com/sonatype-nexus-community/auditjs\"\u003eAuditJS\u003c/a\u003e and \u003ca href\u003d\"https://github.com/sonatype-nexus-community/scan-gradle-plugin\"\u003eGradle plugin\u003c/a\u003e. The speed is fast, vulnerabilities are identified accurately and few false positives occur.\u003c/p\u003e","blip_status":"t","theta":"27","volume":"2020-10"},{"name":"Playwright","id":"202010056","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"72","display_name":"Playwright","radius":"300","description":"\u003cp\u003eWeb UI testing continues to be an active space. Some of the folks who built \u003ca href\u003d\"/radar/languages-and-frameworks/puppeteer\"\u003ePuppeteer\u003c/a\u003e have since moved on to Microsoft and are now applying their learnings to \u003cstrong\u003e\u003ca href\u003d\"https://playwright.dev/\"\u003ePlaywright\u003c/a\u003e\u003c/strong\u003e, which allows you to write tests for Chromium and Firefox as well as WebKit, all through the same API. Playwright has gained some attention for its support of all the major browser engines, which it currently achieves by including patched versions of Firefox and Webkit. It remains to be seen how quickly other tools can catch up, with more and more support for the \u003ca href\u003d\"https://chromedevtools.github.io/devtools-protocol/\"\u003eChrome DevTools Protocol\u003c/a\u003e as a common API for automating browsers.\u003c/p\u003e","blip_status":"t","theta":"22","volume":"2020-10"},{"name":"pnpm","id":"202010045","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"73","display_name":"pnpm","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://pnpm.js.org/\"\u003epnpm\u003c/a\u003e\u003c/strong\u003e is an up-and-coming package manager for \u003ca href\u003d\"/radar/platforms/node-js\"\u003eNode.js\u003c/a\u003e that we\u0027re looking at closely because of its higher speed and greater efficiency compared to other package managers. Dependencies are saved in a single place on the disk and are linked into the respective \u003ccode\u003enode_modules\u003c/code\u003e directories. pnpm also supports incremental optimization on file level, provides a solid API foundation to allow extension/customization and supports store server mode, which speeds up dependency download even more. If your organization has a large number of projects with the same dependencies, you may want to take a closer look at pnpm.\u003c/p\u003e","blip_status":"t","theta":"16","volume":"2020-10"},{"name":"Sensei","id":"202010034","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"74","display_name":"Sensei","radius":"330","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://securecodewarrior.com/sensei\"\u003eSensei\u003c/a\u003e\u003c/strong\u003e from Secure Code Warrior is a Java IDE plugin that makes it easy to create and distribute secure code quality guidelines. At ThoughtWorks we often advocate for \"tools over rules,\" that is, make it easy to do the right thing over applying checklist-like governance rules and procedures, and this tool fits this philosophy. Developers create recipes that can be easily shared with team members. These can be simple or complex and are implemented as queries targeting the Java AST. Examples include warnings for SQL injection, cryptographic weakness and many others. Another feature we like: Since it executes on code changes in the IDE, Sensei provides faster feedback than the more traditional static analysis tools.\u003c/p\u003e","blip_status":"t","theta":"11","volume":"2020-10"},{"name":"Zola","id":"202010099","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"75","display_name":"Zola","radius":"330","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.getzola.org/\"\u003eZola\u003c/a\u003e\u003c/strong\u003e is a static site generator written in \u003ca href\u003d\"/radar/languages-and-frameworks/rust\"\u003eRust\u003c/a\u003e. As such it comes as a single executable with no dependencies, is very fast and supports all the usual things you\u0027d expect such as Sass, content in markdown and hot reloading. We\u0027ve had success building static sites with Zola and appreciate how intuitive it is to use.\u003c/p\u003e","blip_status":"t","theta":"6","volume":"2020-10"},{"name":"Arrow","id":"201904040","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"76","display_name":"Arrow","radius":"110","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://arrow-kt.io/\"\u003eArrow\u003c/a\u003e\u003c/strong\u003e is promoted as the functional companion for \u003ca href\u003d\"/radar/languages-and-frameworks/kotlin\"\u003eKotlin\u0027s standard library\u003c/a\u003e. Indeed, the package of ready-to-use higher-level abstractions delivered by Arrow has proven so useful that our teams now consider Arrow a sensible default when working with Kotlin. Recently, in preparation for the 1.0 release, the Arrow team introduced several changes, including the addition of new modules but also some deprecations and removals.\u003c/p\u003e","blip_status":"move_in","theta":"300","volume":"2020-10"},{"name":"jest-when","id":"201911030","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"77","display_name":"jest-when","radius":"80","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.npmjs.com/package/jest-when\"\u003ejest-when\u003c/a\u003e\u003c/strong\u003e is a lightweight JavaScript library that complements \u003ca href\u003d\"/radar/languages-and-frameworks/jest\"\u003eJest\u003c/a\u003e by matching mock function call arguments. Jest is a great tool for testing the stack; jest-when allows you to expect specific arguments for mock functions which enables you to write more robust unit tests of modules with many dependencies. It\u0027s easy to use and provides great support for multiple matchers, which is why our teams have made jest-when their default choice for mocking in this space.\u003c/p\u003e","blip_status":"move_in","theta":"330","volume":"2020-10"},{"name":"Fastify","id":"202010002","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"78","display_name":"Fastify","radius":"210","description":"\u003cp\u003eIn the case where implementation in \u003ca href\u003d\"/radar/platforms/node-js\"\u003eNode.js\u003c/a\u003e is necessary, we see that \u003ca href\u003d\"https://www.fastify.io/\"\u003e\u003cstrong\u003eFastify\u003c/strong\u003e\u003c/a\u003e is an option that our teams are very happy with. This web framework offers ease in handling request-response validations, support for \u003ca href\u003d\"/radar/languages-and-frameworks/typescript\"\u003eTypeScript\u003c/a\u003e and a plugin ecosystem giving our teams an easier experience developing software. Although it\u0027s a good option in the Node.js ecosystem, we stand by our previous advice: don\u0027t fall into \u003ca href\u003d\"/radar/platforms/node-overload\"\u003eNode overload\u003c/a\u003e scenarios.\u003c/p\u003e","blip_status":"t","theta":"281","volume":"2020-10"},{"name":"Immer","id":"201904034","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"79","display_name":"Immer","radius":"183","description":"\u003cp\u003eWith the increasing complexity of single-page JavaScript applications, managing state predictably is becoming more and more important. Immutability can help to ensure our applications behave consistently but unfortunately JavaScript doesn\u0027t offer built-in deeply immutable data structures (see the \u003ca href\u003d\"https://github.com/tc39/proposal-record-tuple\"\u003eES Record and Tuple proposal\u003c/a\u003e). \u003cstrong\u003e\u003ca href\u003d\"https://github.com/mweststrate/immer\"\u003eImmer\u003c/a\u003e\u003c/strong\u003e — German for \u003cem\u003ealways\u003c/em\u003e — is a tiny package that lets you work with immutable state in a more convenient way. It\u0027s based on the copy-on-write mechanism, has a minimal API and operates on normal JavaScript objects and arrays. This means that data access is seamless and no large refactoring efforts are needed when introducing immutability to an existing codebase. Many of our teams now use it in their JavaScript codebases and prefer it to \u003ca href\u003d\"/radar/languages-and-frameworks/immutable-js\"\u003eImmutable.js\u003c/a\u003e, which is why we\u0027re moving it to Trial.\u003c/p\u003e","blip_status":"move_in","theta":"292","volume":"2020-10"},{"name":"Redux","id":"951","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"80","display_name":"Redux","radius":"180","description":"\u003cp\u003eWe\u0027ve decided to move \u003cstrong\u003e\u003ca href\u003d\"http://redux.js.org/\"\u003eRedux\u003c/a\u003e\u003c/strong\u003e back into the Trial ring to show that we no longer consider it the default approach for state management in \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e applications. Our experience shows that Redux is still a valuable framework in many cases but compared to other approaches, it also leads to more verbose and harder-to-follow code. Throwing \u003ca href\u003d\"https://redux-saga.js.org/\"\u003eRedux Sagas\u003c/a\u003e into the mix usually compounds this issue. As an alternative, you can often use the features in recent versions of React to manage state effectively without an additional framework. However, we want to highlight that when you reach the point at which your simple state management solution starts to become complex, it might be worth reaching for Redux after all or perhaps even Facebook’s recently published \u003ca href\u003d\"/radar/languages-and-frameworks/recoil\"\u003eRecoil\u003c/a\u003e.\u003c/p\u003e","blip_status":"move_out","theta":"303","volume":"2020-10"},{"name":"Rust","id":"771","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"81","display_name":"Rust","radius":"185","description":"\u003cp\u003eThe \u003cstrong\u003e\u003ca href\u003d\"http://www.rust-lang.org/\"\u003eRust\u003c/a\u003e\u003c/strong\u003e programming language continues to grow in popularity and has been voted Stack Overflow\u0027s \"most loved\" language by developers five years in a row. We like it too. It\u0027s a fast, safe and expressive language that is increasing in utility as its ecosystem grows. For example, Rust is starting to be used for data science and machine learning and can give a \u003ca href\u003d\"https://www.lpalmieri.com/posts/2019-12-01-taking-ml-to-production-with-rust-a-25x-speedup/\"\u003esignificant performance boost\u003c/a\u003e. Also, \u003ca href\u003d\"/radar/platforms/materialize\"\u003eMaterialize\u003c/a\u003e is a streaming-oriented, low-latency database written in Rust.\u003c/p\u003e","blip_status":"c","theta":"315","volume":"2020-10"},{"name":"single-spa","id":"1174","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"82","display_name":"single-spa","radius":"220","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://single-spa.js.org/\"\u003esingle-spa\u003c/a\u003e\u003c/strong\u003e is a JavaScript framework for bringing together multiple \u003ca href\u003d\"/radar/techniques/micro-frontends\"\u003emicro frontends\u003c/a\u003e in a single front-end application. Although we advise against \u003ca href\u003d\"/radar/techniques/micro-frontend-anarchy\"\u003emicro frontend anarchy\u003c/a\u003e, the use of micro frontends as an excuse to mix and match multiple frameworks, single-spa supports just that. We understand that there are legitimate scenarios such as upgrading to a new revision of a framework across multiple micro frontends where integration across multiple frameworks is necessary. single-spa has been a go-to framework for micro frontend integration for our teams, and they\u0027re finding it to work well with \u003ca href\u003d\"https://github.com/systemjs/systemjs\"\u003eSystemJS\u003c/a\u003e and managing different versions of a single dependency.\u003c/p\u003e","blip_status":"move_in","theta":"326","volume":"2020-10"},{"name":"Strikt","id":"202010089","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"83","display_name":"Strikt","radius":"220","description":"\u003cp\u003eThe \u003ca href\u003d\"/radar/languages-and-frameworks/kotlin\"\u003eKotlin\u003c/a\u003e ecosystem keeps growing and more libraries are taking advantage of Kotlin language features to replace their Java alternatives. \u003cstrong\u003e\u003ca href\u003d\"https://strikt.io/\"\u003eStrikt\u003c/a\u003e\u003c/strong\u003e is an assertion library that allows you to write test assertions in a very fluent style. It uses Kotlin features such as blocks and lambdas to help make your tests less verbose while maintaining readability. Strikt also supports building custom assertions, which can make your tests more domain specific.\u003c/p\u003e","blip_status":"t","theta":"337","volume":"2020-10"},{"name":"XState","id":"202005067","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"84","display_name":"XState","radius":"240","description":"\u003cp\u003eWe\u0027ve featured several state management libraries in the Radar before, but \u003cstrong\u003e\u003ca href\u003d\"https://xstate.js.org/docs/\"\u003eXState\u003c/a\u003e\u003c/strong\u003e takes a slightly different approach. It\u0027s a simple JavaScript and \u003ca href\u003d\"/radar/languages-and-frameworks/typescript\"\u003eTypeScript\u003c/a\u003e framework for creating finite state machines and visualizing them as state charts. It integrates with the more popular reactive JavaScript frameworks (\u003ca href\u003d\"/radar/languages-and-frameworks/vue-js\"\u003eVue.js\u003c/a\u003e, \u003ca href\u003d\"/radar/languages-and-frameworks/ember-js\"\u003eEmber.js\u003c/a\u003e, \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e and \u003ca href\u003d\"https://rxjs.dev/\"\u003eRxJS\u003c/a\u003e) and is based on the W3C standard for finite state machines. Another notable feature is the serialization of machine definitions. One thing that we\u0027ve found helpful when creating finite state machines in other contexts (particularly when writing game logic) is the ability to visualize states and their possible transitions; we like that it\u0027s really easy to do this with XState\u0027s \u003ca href\u003d\"https://xstate.js.org/viz/\"\u003evisualizer\u003c/a\u003e.\u003c/p\u003e","blip_status":"move_in","theta":"348","volume":"2020-10"},{"name":"Babylon.js","id":"202010065","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"85","display_name":"Babylon.js","radius":"335","description":"\u003cp\u003eWhen we wrote about \u003ca href\u003d\"/radar/techniques/vr-beyond-gaming\"\u003eVR beyond gaming\u003c/a\u003e a few years ago we made no prediction on how quickly and to what extent VR solutions would be found in fields other than video gaming. In hindsight, we\u0027ve certainly seen interest and adoption grow but the uptake has been slower than some of us anticipated. One reason could be tooling. \u003ca href\u003d\"https://unity.com/\"\u003eUnity\u003c/a\u003e and \u003ca href\u003d\"https://www.unrealengine.com/\"\u003eUnreal\u003c/a\u003e are two very mature and capable engines for developing VR applications. We also highlighted \u003ca href\u003d\"/radar/platforms/godot\"\u003eGodot\u003c/a\u003e. However, these engines are quite unlike what most web and enterprise teams are familiar with. As we continued exploring, we realized that web-based VR solutions have come a long way and we\u0027ve had positive experience with \u003cstrong\u003e\u003ca href\u003d\"https://www.babylonjs.com/\"\u003eBabylon.js\u003c/a\u003e\u003c/strong\u003e. Written in TypeScript and rendering its applications in the browser, Babylon.js provides a familiar experience for many development teams. Additionally, Babylon.js is open-source software, mature and well-funded, which makes it even more attractive.\u003c/p\u003e","blip_status":"t","theta":"275","volume":"2020-10"},{"name":"Blazor","id":"202010022","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"86","display_name":"Blazor","radius":"330","description":"\u003cp\u003eAlthough JavaScript and its ecosystem is dominant in the web UI development space, new opportunities are opening up with the emergence of \u003ca href\u003d\"/radar/languages-and-frameworks/webassembly\"\u003eWebAssembly\u003c/a\u003e. We see \u003cstrong\u003e\u003ca href\u003d\"https://dotnet.microsoft.com/apps/aspnet/web-apps/blazor\"\u003eBlazor\u003c/a\u003e\u003c/strong\u003e as an interesting option for building interactive web UIs using C#. We especially like this open-source framework because it allows running C# code in the browser on top of WebAssembly, leveraging the .NET Standard runtime and ecosystem as well as custom libraries developed in this programming language. Additionally, it can interoperate bidirectionally with JavaScript code in the browser if needed.\u003c/p\u003e","blip_status":"t","theta":"281","volume":"2020-10"},{"name":"Flutter Driver","id":"202010075","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"87","display_name":"Flutter Driver","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://api.flutter.dev/flutter/flutter_driver/flutter_driver-library.html\"\u003eFlutter Driver\u003c/a\u003e\u003c/strong\u003e is an integration testing library for \u003ca href\u003d\"https://flutter.dev/\"\u003eFlutter\u003c/a\u003e applications. With Flutter Driver you can instrument and drive the test suite on either real devices or emulators. Our teams continue to write unit and widget tests to ensure most of the business functionality in Flutter apps is implemented. However, for testing the actual user interaction, we\u0027re assessing Flutter Driver, and you should too.\u003c/p\u003e","blip_status":"t","theta":"286","volume":"2020-10"},{"name":"HashiCorp Sentinel","id":"202010031","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"88","display_name":"HashiCorp Sentinel","radius":"310","description":"\u003cp\u003eAlthough we\u0027re big advocates of defining \u003ca href\u003d\"/radar/techniques/security-policy-as-code\"\u003esecurity policy as code\u003c/a\u003e, the tooling in this space has been fairly limited. If you\u0027re using HashiCorp products (such as \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e or \u003ca href\u003d\"/radar/tools/hashicorp-vault\"\u003eVault\u003c/a\u003e) and don\u0027t mind paying for the enterprise versions, you have the option of using \u003ca href\u003d\"https://www.hashicorp.com/sentinel\"\u003e\u003cstrong\u003eHashiCorp Sentinel\u003c/strong\u003e\u003c/a\u003e. Sentinel is, in effect, a complete programming language for defining and implementing context-based policy decisions. For example, in Terraform it can be used to test for policy violations before applying infrastructure changes. In Vault, Sentinel can be used to define fine-grained access control on the APIs. This approach has all the benefits of encapsulation, maintainability, readability and extensibility that high-level programming languages offer, creating an attractive alternative to traditional, declarative security policy. Sentinel is in the same class of tools as \u003ca href\u003d\"/radar/tools/open-policy-agent-opa\"\u003eOpen Policy Agent\u003c/a\u003e but is proprietary, closed-source and only works with HashiCorp products.\u003c/p\u003e","blip_status":"t","theta":"292","volume":"2020-10"},{"name":"Hermes","id":"202010035","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"89","display_name":"Hermes","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://hermesengine.dev/\"\u003eHermes\u003c/a\u003e\u003c/strong\u003e is a JavaScript engine optimized for fast start-up of \u003ca href\u003d\"/radar/languages-and-frameworks/react-native\"\u003eReact Native\u003c/a\u003e applications on Android. JavaScript engines such as \u003ca href\u003d\"https://v8.dev/\"\u003eV8\u003c/a\u003e have just-in-time (JIT) compilers that profile the code at run time to produce optimized instructions. Hermes, however, takes a different approach by compiling the JavaScript code ahead of time (AOT) into an optimized bytecode. As a result you get a smaller APK image size, lean memory consumption and faster startup time. We\u0027re carefully assessing Hermes in a few React Native apps and recommend you do the same.\u003c/p\u003e","blip_status":"t","theta":"298","volume":"2020-10"},{"name":"io-ts","id":"202010103","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"90","display_name":"io-ts","radius":"300","description":"\u003cp\u003eWe\u0027ve been really enjoying using \u003ca href\u003d\"/radar/languages-and-frameworks/typescript\"\u003eTypeScript\u003c/a\u003e for a while now and love the safety that the strong typing provides. However, getting data into the bounds of the type system, from say a call to a back-end service, can lead to run-time errors. One library that helps solve this problem is \u003cstrong\u003e\u003ca href\u003d\"https://gcanti.github.io/io-ts/\"\u003eio-ts\u003c/a\u003e\u003c/strong\u003e. It bridges the gap between compile-time type-checking and run-time consumption of external data by providing encode and decode functions. It can also be used as a custom type guard. According to our teams, it\u0027s an elegant solution to a rascal of a problem.\u003c/p\u003e","blip_status":"t","theta":"303","volume":"2020-10"},{"name":"Kedro","id":"202010040","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"91","display_name":"Kedro","radius":"310","description":"\u003cp\u003eIn the past we\u0027ve talked about the \u003ca href\u003d\"/radar/tools/experiment-tracking-tools-for-machine-learning\"\u003eimproving\u003c/a\u003e \u003ca href\u003d\"/radar/tools/dvc\"\u003etooling\u003c/a\u003e for applying \u003ca href\u003d\"/radar/techniques/continuous-delivery-for-machine-learning-cd4ml\"\u003egood engineering practices\u003c/a\u003e in data science projects. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/quantumblacklabs/kedro\"\u003eKedro\u003c/a\u003e\u003c/strong\u003e is another good addition in this space. It\u0027s a development workflow framework for data science projects that brings a standardized approach to building production-ready data and machine-learning pipelines. We like the focus on software engineering practices and good design with its emphasis on test-driven development, modularity, versioning and good hygiene practices such as keeping credentials out of the codebase.\u003c/p\u003e","blip_status":"t","theta":"309","volume":"2020-10"},{"name":"LitElement","id":"202010046","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"92","display_name":"LitElement","radius":"315","description":"\u003cp\u003eSteady progress has been made since we first wrote about \u003ca href\u003d\"/radar/platforms/web-components-standard\"\u003eweb components\u003c/a\u003e in 2014. \u003cstrong\u003e\u003ca href\u003d\"https://lit-element.polymer-project.org/\"\u003eLitElement\u003c/a\u003e\u003c/strong\u003e, part of the \u003ca href\u003d\"https://www.polymer-project.org/\"\u003ePolymer Project\u003c/a\u003e, is a simple library that you can use to create lightweight web components. It\u0027s really just a base class that removes the need for a lot of the common boilerplate making writing web components a lot easier. We\u0027ve had early success using it on projects and are excited to see the technology maturing.\u003c/p\u003e","blip_status":"t","theta":"315","volume":"2020-10"},{"name":"Mock Service Worker","id":"202010050","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"93","display_name":"Mock Service Worker","radius":"325","description":"\u003cp\u003eWeb applications, especially those written for internal use in enterprises, are usually written in two parts. The user interface and some business logic run in the web browser while business logic, authorization and persistence run on a server. These two halves normally communicate via JSON over HTTP. The endpoints shouldn\u0027t be mistaken for a real API; they\u0027re simply an implementation detail of an application that is split across two run-time environments. At the same time, they provide a valid seam to test the pieces individually. When testing the JavaScript part, the server side can be stubbed and mocked at the network level by a tool such as \u003ca href\u003d\"/radar/tools/mountebank\"\u003eMountebank\u003c/a\u003e. An alternative approach is to intercept the requests in the browser. We like the approach taken by \u003cstrong\u003e\u003ca href\u003d\"https://mswjs.io/\"\u003eMock Service Worker\u003c/a\u003e\u003c/strong\u003e because with service workers it uses an abstraction familiar to developers. This approach results in a simpler setup and faster test execution. However, because these tests don\u0027t test the actual network layer, you want to implement some end-to-end tests as part of a healthy test pyramid.\u003c/p\u003e","blip_status":"t","theta":"320","volume":"2020-10"},{"name":"Recoil","id":"202010059","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"94","display_name":"Recoil","radius":"330","description":"\u003cp\u003eMore and more teams using \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e are reevaluating their options for state management, something we also mention in our reassessment of \u003ca href\u003d\"/radar/languages-and-frameworks/redux\"\u003eRedux\u003c/a\u003e. Now, Facebook — the creators of React — have published \u003cstrong\u003e\u003ca href\u003d\"https://recoiljs.org/\"\u003eRecoil\u003c/a\u003e\u003c/strong\u003e, a new framework for managing state, which came out of an internal application that had to deal with large amounts of data. Even though we currently do not have much practical experience with Recoil, we see its potential and promise. The API is simple and easy to learn; it feels like idiomatic React. Unlike other approaches, Recoil provides an efficient and flexible way to have state shared across an application: it supports dynamically created state by derived data and queries as well as app-wide state observation without impairing code splitting.\u003c/p\u003e","blip_status":"t","theta":"326","volume":"2020-10"},{"name":"Snorkel","id":"202010087","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"95","display_name":"Snorkel","radius":"310","description":"\u003cp\u003eModern ML models are very complex and require massive amounts of labeled training data sets to learn from. \u003cstrong\u003e\u003ca href\u003d\"https://www.snorkel.org/\"\u003eSnorkel\u003c/a\u003e\u003c/strong\u003e started at the Stanford AI lab with the realization that manually labeling data is very expensive and often not feasible. Snorkel allows us to label training data programmatically via the creation of labeling functions. Snorkel employs supervised learning techniques to assess the accuracies and correlations of these labeling functions, and then reweighs and combines their output labels, leading to high-quality training labels. The creators of Snorkel have since come out with a commercial platform called \u003ca href\u003d\"https://www.snorkel.ai/\"\u003eSnorkel Flow\u003c/a\u003e. While Snorkel itself is no longer actively developed, it\u0027s still significant for its ideas on the use of weakly supervised methods to label data.\u003c/p\u003e","blip_status":"t","theta":"331","volume":"2020-10"},{"name":"Streamlit","id":"202010088","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"96","display_name":"Streamlit","radius":"300","description":"\u003cp\u003e\u003ca href\u003d\"https://www.streamlit.io/\"\u003e\u003cstrong\u003eStreamlit\u003c/strong\u003e\u003c/a\u003e is an open-source application framework in Python used by data scientists for building good-looking data visualization applications. Streamlit stands out from competitors such as Dash with its focus on rapid prototyping and support for a wide range of visualization libraries, including \u003ca href\u003d\"https://plotly.com/\"\u003ePlotly\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/bokeh\"\u003eBokeh\u003c/a\u003e. For data scientists who need quick showcases during the experimentation cycle, Streamlit is a solid choice. We\u0027re using it in a few projects and like how we can put together interactive visualizations with very little effort.\u003c/p\u003e","blip_status":"t","theta":"337","volume":"2020-10"},{"name":"Svelte","id":"202010061","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"97","display_name":"Svelte","radius":"330","description":"\u003cp\u003eWe continue to see new front-end JavaScript frameworks, and \u003cstrong\u003e\u003ca href\u003d\"https://svelte.dev/\"\u003eSvelte\u003c/a\u003e\u003c/strong\u003e stands out as a promising new component framework. Unlike other frameworks that leverage the virtual DOM, Svelte compiles your code into vanilla framework-less JavaScript code that surgically updates the DOM directly. However, it\u0027s only a component framework; if you\u0027re planning to build feature-rich applications, consider assessing \u003ca href\u003d\"https://sapper.svelte.dev/\"\u003eSapper\u003c/a\u003e together with Svelte.\u003c/p\u003e","blip_status":"t","theta":"343","volume":"2020-10"},{"name":"SWR","id":"202010091","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"98","display_name":"SWR","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/vercel/swr\"\u003eSWR\u003c/a\u003e\u003c/strong\u003e is a \u003ca href\u003d\"/radar/languages-and-frameworks/react-hooks\"\u003eReact Hooks\u003c/a\u003e library for fetching remote data. It implements the \u003ca href\u003d\"https://tools.ietf.org/html/rfc5861\"\u003estale-while-revalidate\u003c/a\u003e HTTP caching strategy. SWR first returns data from cache (stale), then sends the fetch request (revalidate) and finally refreshes the values with the up-to-date response. Components receive a stream of data, first stale and then fresh, constantly and automatically. Our developers have had a good experience using SWR, dramatically improving the user experience with always having data on the screen. However, we caution teams to only use SWR caching strategy when appropriate for an application to return stale data. Note that \u003ca href\u003d\"https://tools.ietf.org/html/rfc2616\"\u003eHTTP\u003c/a\u003e requires that caches respond to a request with the most up-to-date response held that is appropriate to the request, and only in \u003cem\u003ecarefully considered circumstances\u003c/em\u003e is a stale response allowed to be returned.\u003c/p\u003e","blip_status":"t","theta":"348","volume":"2020-10"},{"name":"Testing Library","id":"202010018","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"99","display_name":"Testing Library","radius":"295","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://testing-library.com/\"\u003eTesting Library\u003c/a\u003e\u003c/strong\u003e is a family of packages for testing applications in numerous frameworks such as \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e, \u003ca href\u003d\"/radar/languages-and-frameworks/vue-js\"\u003eVue\u003c/a\u003e, \u003ca href\u003d\"/radar/languages-and-frameworks/react-native\"\u003eReact Native\u003c/a\u003e and \u003ca href\u003d\"/radar/languages-and-frameworks/angular\"\u003eAngular\u003c/a\u003e among others. This set of libraries helps you test UI components in a user-centric way by encouraging you to test user behavior rather than implementation details, such as the presence of elements in the UI at a certain moment in time. One of the benefits of this mindset is more reliable tests, and this is what we call out as its main differentiator. We recommend you assess this family of libraries when testing your web applications in any framework. Although our direct experience is limited to \u003ca href\u003d\"/radar/languages-and-frameworks/react-testing-library\"\u003eReact Testing Library\u003c/a\u003e and Angular Testing Library, we\u0027ve been impressed with what we\u0027ve seen.\u003c/p\u003e","blip_status":"t","theta":"354","volume":"2020-10"}],"date":"2020-10"},{"blips":[{"name":"API expand-contract","id":"202104022","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"1","display_name":"API expand-contract","radius":"70","description":"\u003cp\u003eThe \u003cstrong\u003eAPI expand-contract\u003c/strong\u003e pattern, sometimes called \u003ca href\u003d\"https://www.martinfowler.com/bliki/ParallelChange.html\"\u003eparallel change\u003c/a\u003e, will be familiar to many, especially when used with databases or code; however, we only see low levels of adoption with APIs. Specifically, we\u0027re seeing complex versioning schemes and breaking changes used in scenarios where a simple expand and then contract would suffice. For example, first adding to an API while deprecating an existing element, and then only later removing the deprecated elements once consumers are switched to the newer schema. This approach does require some coordination and visibility of the API consumers, perhaps through a technique such as \u003ca href\u003d\"https://martinfowler.com/articles/consumerDrivenContracts.html\"\u003econsumer-driven contract\u003c/a\u003e testing.\u003c/p\u003e","blip_status":"t","theta":"160","volume":"2021-04"},{"name":"Continuous delivery for machine learning (CD4ML)","id":"201904066","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"2","display_name":"Continuous delivery for machine learning (CD4ML)","radius":"100","description":"\u003cp\u003eWe see \u003cstrong\u003e\u003ca href\u003d\"https://martinfowler.com/articles/cd4ml.html\"\u003econtinuous delivery for machine learning (CD4ML)\u003c/a\u003e\u003c/strong\u003e as a good default starting point for any ML solution that is being deployed into production. Many organizations are becoming more reliant on ML solutions for both customer offerings and internal operations so it makes sound business sense to apply the lessons and good practice captured by \u003ca href\u003d\"/radar/techniques/continuous-delivery-cd\"\u003econtinuous delivery (CD)\u003c/a\u003e to ML solutions.\u003c/p\u003e","blip_status":"move_in","theta":"150","volume":"2021-04"},{"name":"Design systems","id":"201911040","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"3","display_name":"Design systems","radius":"125","description":"\u003cp\u003eAs application development becomes increasingly dynamic and complex, it\u0027s a challenge to deliver accessible and usable products with consistent style. This is particularly true in larger organizations with multiple teams working on different products. \u003cstrong\u003eDesign systems\u003c/strong\u003e define a collection of design patterns, component libraries and good design and engineering practices that ensure consistent digital products. Built on the corporate style guides of the past, design systems offer shared libraries and documents that are easy to find and use. Generally, guidance is written down as code and kept under version control so that the guide is less ambiguous and easier to maintain than simple documents. Design systems have become a standard approach when working across teams and disciplines in product development because they allow teams to focus. They can address strategic challenges around the product itself without reinventing the wheel every time a new visual component is needed.\u003c/p\u003e","blip_status":"move_in","theta":"135","volume":"2021-04"},{"name":"Platform engineering product teams","id":"1101","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"4","display_name":"Platform engineering product teams","radius":"100","description":"\u003cp\u003eAs noted in one of the themes for this edition, the industry is increasingly gaining experience with \u003cstrong\u003eplatform engineering product teams\u003c/strong\u003e that create and support internal platforms. These platforms are used by teams across an organization and accelerate application development, reduce operational complexity and improve time to market. With increasing adoption we\u0027re also clearer on both good and bad patterns for this approach. When creating a platform, it’s critical to have clearly defined customers and products that will benefit from it rather than building in a vacuum. We caution against \u003ca href\u003d\"/radar/techniques/layered-platform-teams\"\u003elayered platform teams\u003c/a\u003e that simply preserve existing technology silos but apply the \"platform team\" label as well as against ticket-driven platform operating models. We\u0027re still big fans of using concepts from \u003ca href\u003d\"https://teamtopologies.com/\"\u003eTeam Topologies\u003c/a\u003e as we think about how best to organize platform teams. We consider platform engineering product teams to be a standard approach and a significant enabler for high-performing IT.\u003c/p\u003e","blip_status":"move_in","theta":"120","volume":"2021-04"},{"name":"Service account rotation approach","id":"202104054","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"5","display_name":"Service account rotation approach","radius":"108","description":"\u003cp\u003eWe strongly advise organizations to make sure, when they really need to use cloud service accounts, that they are rotating the credentials. Rotation is one of \u003ca href\u003d\"/radar/techniques/the-three-rs-of-security\"\u003ethe three R\u0027s of security\u003c/a\u003e. It is far too easy for organizations to forget about these accounts unless an incident occurs. This is leading to accounts with unnecessarily broad permissions remaining in use for long periods alongside a lack of planning for how to replace or rotate them. Regularly applying a cloud \u003cstrong\u003eservice account rotation approach\u003c/strong\u003e also provides a chance to exercise the principle of least privilege.\u003c/p\u003e","blip_status":"t","theta":"105","volume":"2021-04"},{"name":"Cloud sandboxes","id":"202104009","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"6","display_name":"Cloud sandboxes","radius":"250","description":"\u003cp\u003eAs the cloud is becoming more and more a commodity and being able to spin up \u003cstrong\u003ecloud sandboxes\u003c/strong\u003e is easier and available at scale, our teams prefer cloud-only (as opposed to local) development environments to reduce maintenance complexity. We\u0027re seeing that the tooling to do local simulation of cloud-native services limits the confidence in developer build and test cycles; therefore, we\u0027re looking to focus on standardizing cloud sandboxes over running cloud-native components on a developer machine. This will drive good \u003ca href\u003d\"/radar/techniques/infrastructure-as-code\"\u003einfrastructure-as-code\u003c/a\u003e practices as a forcing function and good onboarding processes for provisioning sandbox environments for developers. There are risks associated with this transition, as it assumes that developers will have an absolute dependency on cloud environment availability, and it may slow down the developer feedback loop. We strongly recommend you adopt some lean governance practices regarding standardization of these sandbox environments, especially with regard to security, IAM and regional deployments.\u003c/p\u003e","blip_status":"t","theta":"173","volume":"2021-04"},{"name":"Contextual bandits","id":"202104093","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"7","display_name":"Contextual bandits","radius":"220","description":"\u003cp\u003e\u003ca href\u003d\"https://towardsdatascience.com/contextual-bandits-and-reinforcement-learning-6bdfeaece72a\"\u003e\u003cstrong\u003eContextual bandits\u003c/strong\u003e\u003c/a\u003e is a type of reinforcement learning that is well suited for problems with exploration/exploitation trade-offs. Named after \"bandits,\" or slot machines, in casinos, the algorithm explores different options to learn more about expected outcomes and balances it by exploiting the options that perform well. We\u0027ve successfully used this technique in scenarios where we\u0027ve had little data to train and deploy other machine-learning models. The fact that we can add context to this explore/exploit trade-off makes it suitable for a wide variety of use cases including A/B testing, recommendations and layout optimizations.\u003c/p\u003e","blip_status":"t","theta":"165","volume":"2021-04"},{"name":"Distroless Docker images","id":"1330","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"8","display_name":"Distroless Docker images","radius":"180","description":"\u003cp\u003eWhen building \u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e images for our applications, we\u0027re often concerned with two things: the security and the size of the image. Traditionally, we\u0027ve used \u003ca href\u003d\"/radar/techniques/container-security-scanning\"\u003econtainer security scanning\u003c/a\u003e tools to detect and patch \u003ca href\u003d\"https://cve.mitre.org/\"\u003ecommon vulnerabilities and exposures\u003c/a\u003e and small distributions such as \u003ca href\u003d\"https://alpinelinux.org/\"\u003eAlpine Linux\u003c/a\u003e to address the image size and distribution performance. But with rising security threats, eliminating all possible attack vectors is more important than ever. That\u0027s why \u003cstrong\u003edistroless Docker images\u003c/strong\u003e are becoming the default choice for deployment containers. Distroless Docker images reduce the footprint and dependencies by doing away with a full operating system distribution. This technique reduces security scan noise and the application attack surface. Moreover, fewer vulnerabilities need to be patched and as a bonus, these smaller images are more efficient. Google has published a set of \u003ca href\u003d\"https://github.com/GoogleContainerTools/distroless\"\u003edistroless container images\u003c/a\u003e for different languages. You can create distroless application images using the Google build tool \u003ca href\u003d\"https://bazel.build/\"\u003eBazel\u003c/a\u003e or simply use multistage Dockerfiles. Note that distroless containers by default don\u0027t have a shell for debugging. However, you can easily find debug versions of distroless containers online, including a \u003ca href\u003d\"https://busybox.net/downloads/BusyBox.html\"\u003eBusyBox shell\u003c/a\u003e. Distroless Docker images is a technique pioneered by Google and, in our experience, is still largely confined to Google-generated images. We would be more comfortable if there were more than one provider to choose from. Also, use caution when applying  \u003ca href\u003d\"/radar/tools/trivy\"\u003eTrivy\u003c/a\u003e or similar vulnerability scanners since distroless containers are only supported in more recent versions.\u003c/p\u003e","blip_status":"c","theta":"158","volume":"2021-04"},{"name":"Ethical Explorer","id":"202104086","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"9","display_name":"Ethical Explorer","radius":"220","description":"\u003cp\u003eThe group behind \u003ca href\u003d\"/radar/techniques/ethical-os\"\u003eEthical OS\u003c/a\u003e — the Omidyar Network, a self-described social change venture created by eBay founder Pierre Omidyar — has released a new iteration called \u003cstrong\u003e\u003ca href\u003d\"https://ethicalexplorer.org/\"\u003eEthical Explorer\u003c/a\u003e\u003c/strong\u003e. The new Ethical Explorer pack draws on lessons learned from using Ethical OS and adds further questions for product teams to consider. The kit, which can be \u003ca href\u003d\"https://ethicalexplorer.org/download/\"\u003edownloaded for free\u003c/a\u003e and folded into cards to trigger discussion, has open-ended question prompts for several technical \"risk zones,\" including surveillance (\"can someone use our product or service to track or identify other users?\"), disinformation, exclusion, algorithmic bias, addiction, data control, bad actors and outsized power. The included field guide has activities and workshops, ideas for starting conversations and tips for gaining organizational buy-in. While we\u0027ve a long way to go as an industry to better represent the ethical externalities of our digital society, we\u0027ve had some productive conversations using Ethical Explorer, and we\u0027re encouraged by the broadening awareness of the importance of product decisions in addressing societal issues.\u003c/p\u003e","blip_status":"t","theta":"150","volume":"2021-04"},{"name":"Hypothesis-driven legacy renovation","id":"202104008","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"10","display_name":"Hypothesis-driven legacy renovation","radius":"250","description":"\u003cp\u003eWe\u0027re often asked to refresh, update or remediate legacy systems that we didn\u0027t originally build. Sometimes, technical issues need our attention such as improving performance or reliability. One common approach to address these issues is to create \"technical stories\" using the same format as a user story but with a technical outcome rather than a business one. But these technical tasks are often difficult to estimate, take longer than anticipated or don\u0027t end up having the desired outcome. An alternative, more successful method is to apply \u003cstrong\u003ehypothesis-driven legacy renovation\u003c/strong\u003e. Rather than working toward a standard backlog, the team takes ownership of a measurable technical outcome and collectively establishes a set of hypotheses about the problem. They then conduct iterative, time-boxed experiments to verify or disprove each hypothesis in order of priority. The resulting workflow is optimized for reducing uncertainty rather than following a plan toward a predictable outcome.\u003c/p\u003e","blip_status":"t","theta":"143","volume":"2021-04"},{"name":"Lightweight approach to RFCs","id":"202104044","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"11","display_name":"Lightweight approach to RFCs","radius":"250","description":"\u003cp\u003eAs organizations drive toward \u003ca href\u003d\"/radar/techniques/evolutionary-architecture\"\u003eevolutionary architecture\u003c/a\u003e, it\u0027s important to capture decisions around design, architecture, techniques and teams\u0027 ways of workings. The process of collecting and aggregating feedback that will lead to these decisions begin with Request for Comments (RfCs). RfCs are a technique for collecting context, design and architectural ideas and collaborating with teams to ultimately come to decisions along with their context and consequences. We recommend that organizations take a \u003cstrong\u003elightweight approach to RFCs\u003c/strong\u003e by using a simple standardized template across many teams as well as version control to capture RfCs.\u003c/p\u003e\n\n\u003cp\u003eIt\u0027s important to capture these in an audit of these decisions to benefit future team members and to capture the technical and business evolution of an organization. Mature organizations have used RfCs in autonomous teams to drive better communication and collaboration especially in cross-team relevant decisions.\u003c/p\u003e","blip_status":"t","theta":"135","volume":"2021-04"},{"name":"Simplest possible ML","id":"202104070","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"12","display_name":"Simplest possible ML","radius":"250","description":"\u003cp\u003eAll major cloud providers offer a dazzling array of machine-learning (ML) solutions. These powerful tools can provide a lot of value, but come at a cost. There is the pure run cost for these services charged by the cloud provider. In addition, there is a kind of operations tax. These complex tools need to be understood and operated, and with each new tool added to the architecture this tax burden increases. In our experience, teams often choose complex tools because they underestimate the power of simpler tools such as linear regression. Many ML problems don\u0027t require a GPU or neural networks. For that reason we advocate for the \u003cstrong\u003esimplest possible ML\u003c/strong\u003e, using simple tools and models and a few hundred lines of Python on the compute platform you have at hand. Only reach for the complex tools when you can demonstrate the need for them.\u003c/p\u003e","blip_status":"t","theta":"128","volume":"2021-04"},{"name":"SPA injection","id":"202104012","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"13","display_name":"SPA injection","radius":"220","description":"\u003cp\u003eThe \u003ca href\u003d\"https://martinfowler.com/bliki/StranglerFigApplication.html\"\u003estrangler fig pattern\u003c/a\u003e is often the default strategy for legacy modernization, where the new code wraps around the old and slowly absorbs the ability to handle all the needed functionality. That sort of \"outside-in\" approach works well for a number of legacy systems, but now that we\u0027ve had enough experience with single-page applications (SPA) for them to become legacy systems themselves, we\u0027re seeing the opposite \"inside-out\" approach used to replace them. Instead of wrapping the legacy system, we instead embed the beginning of the new SPA into the HTML document containing the old one and let it slowly expand in functionality. The SPA frameworks don\u0027t even need to be the same as long as users can tolerate the performance hit of the increased page size (e.g., embedding a new \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e app inside an old \u003ca href\u003d\"/radar/languages-and-frameworks/angularjs\"\u003eAngularJS\u003c/a\u003e one). \u003cstrong\u003eSPA injection\u003c/strong\u003e allows you to iteratively remove the old SPA until the new one completely takes over. Whereas a strangler fig can be viewed as a type of parasite that uses the host tree\u0027s stable external surface to support itself until it takes root and the host itself dies, this approach is more like injecting an outside agent into the host, relying on functionality of the original SPA until it can completely take over.\u003c/p\u003e","blip_status":"t","theta":"120","volume":"2021-04"},{"name":"Team cognitive load","id":"202104127","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"14","display_name":"Team cognitive load","radius":"180","description":"\u003cp\u003eA system\u0027s architecture mimics organizational structure and its communication. It\u0027s not big news that we should be intentional about how teams interact — see, for instance, the \u003ca href\u003d\"/radar/techniques/inverse-conway-maneuver\"\u003eInverse Conway Maneuver\u003c/a\u003e. Team interaction is one of the variables for how fast and how easily teams can deliver value to their customers. We were happy to find a way to measure these interactions; we used the \u003ca href\u003d\"https://teamtopologies.com/book\"\u003eTeam Topologies\u003c/a\u003e author\u0027s \u003ca href\u003d\"https://github.com/TeamTopologies/Team-Cognitive-Load-Assessment\"\u003eassessment\u003c/a\u003e which gives you an understanding of how easy or difficult the teams find it to build, test and maintain their services. By measuring \u003cstrong\u003eteam cognitive load\u003c/strong\u003e, we could better advise our clients on how to change their teams\u0027 structure and evolve their interactions.\u003c/p\u003e","blip_status":"t","theta":"113","volume":"2021-04"},{"name":"Tool-managed Xcodeproj","id":"202104060","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"15","display_name":"Tool-managed Xcodeproj","radius":"220","description":"\u003cp\u003eMany of our developers coding iOS in Xcode often get headaches because the Xcodeproj file changes with every project change. The Xcodeproj file format is not human-readable, hence trying to handle merge conflicts is quite complicated and can lead to productivity loss and risk of messing up the entire project — if anything goes wrong with the file, Xcode won\u0027t work properly and developers will very likely be blocked. Instead of trying to merge and fix the file manually or version it, we recommend you use a \u003cstrong\u003etool-managed Xcodeproj\u003c/strong\u003e approach: Define your Xcode project configuration in YAML (\u003ca href\u003d\"https://github.com/yonaskolb/XcodeGen\"\u003eXcodeGen\u003c/a\u003e, \u003ca href\u003d\"https://github.com/lyptt/struct\"\u003eStruct\u003c/a\u003e), Ruby (\u003ca href\u003d\"https://github.com/igor-makarov/xcake\"\u003eXcake\u003c/a\u003e) or Swift (\u003ca href\u003d\"https://github.com/tuist/tuist\"\u003eTuist\u003c/a\u003e). These tools generate the Xcodeproj file based on a configuration file and the project structure. As a result, merge conflicts in the Xcodeproj file will be a thing of the past, and when they do happen in the configuration file, they\u0027re much easier to handle.\u003c/p\u003e","blip_status":"t","theta":"105","volume":"2021-04"},{"name":"UI/BFF shared types","id":"202104013","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"16","display_name":"UI/BFF shared types","radius":"220","description":"\u003cp\u003eWith \u003ca href\u003d\"/radar/languages-and-frameworks/typescript\"\u003eTypeScript\u003c/a\u003e becoming a common language for front-end development and \u003ca href\u003d\"/radar/platforms/node-js\"\u003eNode.js\u003c/a\u003e becoming the preferred \u003ca href\u003d\"/radar/techniques/bff-backend-for-frontends\"\u003eBFF\u003c/a\u003e technology, we\u0027re seeing increasing use of \u003cstrong\u003eUI/BFF shared types\u003c/strong\u003e. In this technique, a single set of type definitions is used to define both the data objects returned by front-end queries and the data served to satisfy those queries by the back-end server. Ordinarily, we would be cautious about this practice because of the unnecessarily tight coupling it creates across process boundaries. However, many teams are finding that the benefits of this approach outweigh any risks of tight coupling. Since the BFF pattern works best when the same team owns both the UI code and the BFF, often storing both components in the same repository, the UI/BFF pair can be viewed as a single cohesive system. When the BFF offers strongly typed queries, the results can be tailored to the specific needs of the frontend rather than reusing a single, general-purpose entity that must serve the needs of many consumers and contain more fields than actually required. This reduces the risk of accidentally exposing data that the user shouldn\u0027t see, prevents incorrect interpretation of the returned data object and makes the query more expressive. This practice is particularly useful when implemented with \u003ca href\u003d\"/radar/languages-and-frameworks/io-ts\"\u003eio-ts\u003c/a\u003e to enforce the run-time type safety.\u003c/p\u003e","blip_status":"t","theta":"98","volume":"2021-04"},{"name":"Bounded low-code platforms","id":"202010004","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"17","display_name":"Bounded low-code platforms","radius":"290","description":"\u003cp\u003eOne of the most nuanced decisions facing companies at the moment is the adoption of low-code or no-code platforms, that is, platforms that solve very specific problems in very limited domains. Many vendors are pushing aggressively into this space. The problems we see with these platforms typically relate to an inability to apply good engineering practices such as versioning. Testing too is typically really hard. However, we noticed some interesting new entrants to the market — including \u003ca href\u003d\"https://www.honeycode.aws/\"\u003eAmazon Honeycode\u003c/a\u003e, which makes it easy to create simple task or event management apps, and \u003ca href\u003d\"https://parabola.io/\"\u003eParabola\u003c/a\u003e for IFTTT-like cloud workflows — which is why we\u0027re once again including \u003cstrong\u003ebounded low-code platforms\u003c/strong\u003e in this volume. Nevertheless, we remain deeply skeptical about their wider applicability since these tools, like Japanese Knotweed, have a knack of escaping their bounds and tangling everything together. That\u0027s why we still strongly advise caution in their adoption.\u003c/p\u003e","blip_status":"c","theta":"172","volume":"2021-04"},{"name":"Decentralized identity","id":"202005083","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"18","display_name":"Decentralized identity","radius":"290","description":"\u003cp\u003eIn 2016, Christopher Allen, a key contributor to \u003ca href\u003d\"https://en.wikipedia.org/wiki/Transport_Layer_Security\"\u003eSSL/TLS\u003c/a\u003e, inspired us with an introduction of 10 principles underpinning a new form of digital identity and a path to get there, \u003ca href\u003d\"http://www.lifewithalacrity.com/2016/04/the-path-to-self-soverereign-identity.html\"\u003ethe path to self-sovereign identity\u003c/a\u003e. Self-sovereign identity, also known as \u003cstrong\u003edecentralized identity\u003c/strong\u003e, is a “lifetime portable identity for any person, organization, or thing that does not depend on any centralized authority and can never be taken away,” according to the \u003ca href\u003d\"/radar/platforms/trust-over-ip-stack\"\u003eTrust over IP\u003c/a\u003e standard. Adopting and implementing decentralized identity is gaining momentum and becoming attainable. We see its adoption in privacy-respecting \u003ca href\u003d\"https://www.civic.com/healthkey/\"\u003ecustomer health applications\u003c/a\u003e, \u003ca href\u003d\"https://www.truu.id/\"\u003egovernment healthcare infrastructure\u003c/a\u003e and \u003ca href\u003d\"https://id-bulletin.com/2020/06/04/news-gleif-and-evernym-demo-organization-wallets-to-deliver-trust-and-transparency-in-digital-business/\"\u003ecorporate legal identity\u003c/a\u003e. If you want to rapidly get started with decentralized identity, you can assess \u003ca href\u003d\"https://sovrin.org/\"\u003eSovrin Network\u003c/a\u003e, \u003ca href\u003d\"https://github.com/hyperledger/aries\"\u003eHyperledger Aries\u003c/a\u003e and \u003ca href\u003d\"https://github.com/hyperledger/indy-node\"\u003eIndy\u003c/a\u003e OSS, as well as \u003ca href\u003d\"https://www.w3.org/TR/did-core/\"\u003edecentralized identifiers\u003c/a\u003e and \u003ca href\u003d\"/radar/techniques/verifiable-credentials\"\u003everifiable credentials\u003c/a\u003e standards. We\u0027re watching this space closely as we help our clients with their strategic positioning in the new era of digital trust.\u003c/p\u003e","blip_status":"c","theta":"164","volume":"2021-04"},{"name":"Deployment drift radiator","id":"202104026","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"19","display_name":"Deployment drift radiator","radius":"295","description":"\u003cp\u003eA \u003cstrong\u003edeployment drift radiator\u003c/strong\u003e makes version drift visible for deployed software across multiple environments. Organizations using automated deployments may require manual approvals for environments that get closer to production, meaning the code in these environments might well be lagging several versions behind current development. This technique makes this lag visible via a simple dashboard showing how far behind each deployed component is for each environment. This helps to highlight the opportunity cost of completed software not yet in production while drawing attention to related risks such as security fixes not yet deployed.\u003c/p\u003e","blip_status":"t","theta":"156","volume":"2021-04"},{"name":"Homomorphic encryption","id":"202104035","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"20","display_name":"Homomorphic encryption","radius":"310","description":"\u003cp\u003eFully \u003cstrong\u003e\u003ca href\u003d\"https://en.wikipedia.org/wiki/Homomorphic_encryption\"\u003ehomomorphic encryption\u003c/a\u003e\u003c/strong\u003e (HE) refers to a class of encryption methods that allow computations (such as search and arithmetic) to be performed directly on encrypted data. The result of such a computation remains in encrypted form, which at a later point can be decrypted and revealed. Although the HE problem was first proposed in 1978, a solution wasn\u0027t constructed until 2009. With advances in computing power and the availability of easy-to-use open-source libraries — including \u003ca href\u003d\"https://github.com/microsoft/SEAL#introduction\"\u003eSEAL\u003c/a\u003e, \u003ca href\u003d\"https://github.com/ldsec/lattigo\"\u003eLattigo\u003c/a\u003e, \u003ca href\u003d\"https://github.com/homenc/HElib\"\u003eHElib\u003c/a\u003e and \u003ca href\u003d\"https://github.com/data61/python-paillier\"\u003epartially homomorphic encryption in Python\u003c/a\u003e — HE is becoming feasible in real-world applications. The motivating scenarios include privacy-preserving use cases, where computation can be outsourced to an untrusted party, for example, running computation on encrypted data in the cloud, or enabling a third party to aggregate homomorphically encrypted intermediate \u003ca href\u003d\"https://en.wikipedia.org/wiki/Federated_learning\"\u003efederated machine learning\u003c/a\u003e results. Moreover, most HE schemes are considered to be \u003ca href\u003d\"https://csrc.nist.gov/Projects/Post-Quantum-Cryptography\"\u003esecure against quantum computers\u003c/a\u003e, and efforts are underway to \u003ca href\u003d\"https://homomorphicencryption.org/standard/\"\u003estandardize\u003c/a\u003e HE. Despite its current limitations, namely performance and feasibility of the types of computations, HE is worth your attention.\u003c/p\u003e","blip_status":"t","theta":"148","volume":"2021-04"},{"name":"Hotwire","id":"202104066","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"21","display_name":"Hotwire","radius":"330","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://hotwire.dev/\"\u003eHotwire\u003c/a\u003e\u003c/strong\u003e (HTML over the wire) is a technique to build web applications. Pages are constructed out of components, but unlike modern SPAs the HTML for the components is generated on the server side and then sent \"over the wire\" to the browser. The application has only a small amount of JavaScript code in the browser to stitch the HTML fragments together. Our teams, and doubtlessly others too, experimented with this technique after asynchronous web requests gained cross-browser support around 2005, but for various reasons it never gained much traction.\u003c/p\u003e\n\n\u003cp\u003eToday, Hotwire uses modern web browser and HTTP capabilities to achieve the speed, responsiveness and dynamic nature of single-page apps (SPAs). It embraces simpler web application design by localizing the logic to the server and keeping the client-side code simple. The team at Basecamp has released a few Hotwire frameworks that power their own \u003ca href\u003d\"https://hey.com/\"\u003eapplication\u003c/a\u003e, including \u003ca href\u003d\"https://turbo.hotwired.dev/\"\u003eTurbo\u003c/a\u003e and \u003ca href\u003d\"https://stimulus.hotwire.dev/\"\u003eStimulus\u003c/a\u003e. Turbo includes a set of techniques and frameworks to speed up the application responsiveness by preventing whole page reloading, page preview from cache and decomposing the page into fragments with progressive enhancements on request. Stimulus is designed to enhance static HTML in the browser by connecting JavaScript objects to the page elements on the HTML.\u003c/p\u003e","blip_status":"t","theta":"140","volume":"2021-04"},{"name":"Import maps for micro frontends","id":"202104023","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"22","display_name":"Import maps for micro frontends","radius":"310","description":"\u003cp\u003eWhen composing an application out of several \u003ca href\u003d\"/radar/techniques/micro-frontends\"\u003emicro frontends\u003c/a\u003e, some part of the system needs to decide which micro frontends to load and where to load them from. So far, we\u0027ve either built custom solutions or relied on a broader framework like \u003ca href\u003d\"/radar/languages-and-frameworks/single-spa\"\u003esingle-spa\u003c/a\u003e. Now there is a new standard, \u003ca href\u003d\"https://github.com/WICG/import-maps\"\u003eimport maps\u003c/a\u003e, that helps in both cases. Our first experiences show that using \u003cstrong\u003eimport maps for micro frontends\u003c/strong\u003e allows for a neat separation of concerns. The JavaScript code states what to import and a small script tag in the initial HTML response specifies where to load the frontends from. That HTML is obviously generated on the server side, which makes it possible to use some dynamic configuration during its rendering. In many ways this technique reminds us of linker/loader paths for dynamic Unix libraries. At the moment import maps are only supported by Chrome, but with the \u003ca href\u003d\"https://github.com/systemjs/systemjs\"\u003eSystemJS\u003c/a\u003e polyfill they\u0027re ready for wider use.\u003c/p\u003e","blip_status":"t","theta":"131","volume":"2021-04"},{"name":"Open Application Model (OAM)","id":"202010032","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"23","display_name":"Open Application Model (OAM)","radius":"330","description":"\u003cp\u003eThe \u003cstrong\u003e\u003ca href\u003d\"https://oam.dev/\"\u003eOpen Application Model (OAM)\u003c/a\u003e\u003c/strong\u003e is an attempt to bring some standardization to the space of shaping infrastructure platforms as products. Using the abstractions of components, application configurations, scopes and traits, developers can describe their applications in a platform-agnostic way, while platform implementers define their platform in terms of workload, trait and scope. Since we last talked about the OAM, we\u0027ve followed one of its first implementations with interest, \u003ca href\u003d\"https://kubevela.io/\"\u003eKubeVela\u003c/a\u003e. KubeVela is close to release 1.0, and we\u0027re curious to see if implementations like this can substantiate the promise of the OAM idea.\u003c/p\u003e","blip_status":"c","theta":"123","volume":"2021-04"},{"name":"Privacy-focused web analytics","id":"202104120","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"24","display_name":"Privacy-focused web analytics","radius":"330","description":"\u003cp\u003e\u003cstrong\u003ePrivacy-focused web analytics\u003c/strong\u003e is a technique for gathering web analytics without compromising end user privacy by keeping the end users truly anonymous. One surprising consequence of General Data Protection Regulation (GDPR) compliance is the decision taken by many organizations to degrade the user experience with complex cookie consent processes, especially when the user doesn\u0027t immediately consent to the \"all the cookies\" default settings. Privacy-focused web analytics has the dual benefit of both observing the spirit and letter of GDPR while also avoiding the need to introduce intrusive cookie consent forms. One implementation of this approach is \u003ca href\u003d\"https://plausible.io/\"\u003ePlausible\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"115","volume":"2021-04"},{"name":"Remote mob programming","id":"202104052","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"25","display_name":"Remote mob programming","radius":"330","description":"\u003cp\u003eMob programming is one of those techniques that our teams have found to be easier when done remotely. \u003cstrong\u003eRemote mob programming\u003c/strong\u003e is allowing teams to quickly \"mob\" around an issue or piece of code without the physical constraints of only being able to fit so many people around a pairing station. Teams can quickly collaborate on an issue or piece of code without having to connect to a big display, book a physical meeting room or find a whiteboard.\u003c/p\u003e","blip_status":"t","theta":"107","volume":"2021-04"},{"name":"Secure multiparty computing","id":"202104053","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"26","display_name":"Secure multiparty computing","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://en.wikipedia.org/wiki/Secure_multi-party_computation\"\u003eSecure multiparty computing\u003c/a\u003e\u003c/strong\u003e (MPC) solves the problem of collaborative computing that protects privacy between parties that do not trust each other. It\u0027s aim is to safely calculate an agreed-upon problem without a trusted third party, while each participant is required to partake in the calculation result and can\u0027t be obtained by other entities. A simple illustration for MPC is the \u003ca href\u003d\"https://en.wikipedia.org/wiki/Yao%27s_Millionaires%27_problem\"\u003emillionaires\u0027 problem\u003c/a\u003e: two millionaires want to understand who is the richest, but neither want to share their actual net worth with each other nor trust a third party. The implementation approaches of MPC vary; scenarios may include secret sharing, oblivious transfer, garbled circuits or \u003ca href\u003d\"/radar/techniques/homomorphic-encryption\"\u003ehomomorphic encryption\u003c/a\u003e. Some commercial MPC solutions that have recently appeared (e.g., \u003ca href\u003d\"https://www.antchain.net/solutions/morse\"\u003eAntchain Morse\u003c/a\u003e) claim to help solve the problems of secret sharing and secure machine learning in scenarios such as multiparty joint credit investigation and medical records data exchange. Although these platforms are attractive from a marketing perspective, we\u0027ve yet to see whether they\u0027re really useful.\u003c/p\u003e","blip_status":"t","theta":"99","volume":"2021-04"},{"name":"GitOps","id":"202104006","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"27","display_name":"GitOps","radius":"375","description":"\u003cp\u003eWe suggest approaching \u003cstrong\u003eGitOps\u003c/strong\u003e with a degree of care, especially with regard to branching strategies. GitOps can be seen as a way of implementing \u003ca href\u003d\"/radar/techniques/infrastructure-as-code\"\u003einfrastructure as code\u003c/a\u003e that involves continuously synchronizing and applying infrastructure code from \u003ca href\u003d\"/radar/tools/git\"\u003eGit\u003c/a\u003e into various environments. When used with a \"branch per environment\" infrastructure, changes are promoted from one environment to the next by merging code. While treating code as the single source of truth is clearly a sound approach, we\u0027re seeing branch per environment lead to environmental drift and eventually environment-specific configs as code merges become problematic or even stop entirely. This is very similar to what we\u0027ve seen in the past with \u003ca href\u003d\"/radar/techniques/long-lived-branches-with-gitflow\"\u003elong-lived branches with GitFlow\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"169","volume":"2021-04"},{"name":"Layered platform teams","id":"202104043","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"28","display_name":"Layered platform teams","radius":"385","description":"\u003cp\u003eThe explosion of interest around software platforms has created a lot of value for organizations, but the path to building a platform-based delivery model is fraught with potential dead ends. It\u0027s common in the excitement of new paradigms to see a resurgence of older techniques rebranded with the new vernacular, making it easy to lose sight of the reasons we moved past those techniques in the first place. For an example of this rebranding, see our blip on traditional \u003ca href\u003d\"/radar/techniques/esbs-in-api-gateway-s-clothing\"\u003eESBs make a comeback as API gateways\u003c/a\u003e in the previous Radar. Another example we\u0027re seeing is rehashing the approach of dividing teams by technology layer but calling them platforms. In the context of building an application, it used to be common to have a front-end team separate from the business logic team separate from the data team, and we see analogs to that model when organizations segregate platform capabilities among teams dedicated to a business or data layer. Thanks to \u003ca href\u003d\"https://www.thoughtworks.com/insights/articles/demystifying-conways-law\"\u003eConway\u0027s Law\u003c/a\u003e, we know that organizing platform capability teams around \u003ca href\u003d\"https://martinfowler.com/articles/microservices.html#OrganizedAroundBusinessCapabilities\"\u003ebusiness capabilities\u003c/a\u003e is a more effective model, giving the team end-to-end ownership of the capability, including data ownership. This helps to avoid the dependency management headaches of \u003cstrong\u003elayered platform teams\u003c/strong\u003e, with the front-end team waiting on the business logic team waiting on the data team to get anything done.\u003c/p\u003e","blip_status":"t","theta":"158","volume":"2021-04"},{"name":"Naive password complexity requirements","id":"202104105","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"29","display_name":"Naive password complexity requirements","radius":"375","description":"\u003cp\u003ePassword policies are a standard default for many organizations today. However, we\u0027re still seeing organizations requiring passwords to include a variety of symbols, numbers, uppercase and lowercase letters as well as inclusion of special characters. These are \u003cstrong\u003enaive password complexity requirements\u003c/strong\u003e that lead to a false sense of security as users will opt for more insecure passwords because the alternative is difficult to remember and type. According to \u003ca href\u003d\"https://pages.nist.gov/800-63-3/sp800-63b.html\"\u003eNIST recommendations\u003c/a\u003e, the primary factor in password strength is password length, and therefore users should choose long passphrases with a maximum requirement of 64 characters (including spaces). These passphrases are more secure and memorable.\u003c/p\u003e","blip_status":"t","theta":"147","volume":"2021-04"},{"name":"Peer review equals pull request","id":"202104068","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"30","display_name":"Peer review equals pull request","radius":"375","description":"\u003cp\u003eSome organizations seem to think \u003cstrong\u003epeer review equals pull request\u003c/strong\u003e; they\u0027ve taken the view that the only way to achieve a peer review of code is via a pull request. We\u0027ve seen this approach create significant team bottlenecks as well as significantly degrade the quality of feedback as overloaded reviewers begin to simply reject requests. Although the argument could be made that this is one way to demonstrate code review \"regulatory compliance\" one of our clients was told this was invalid since there was no evidence the code was actually read by anyone prior to acceptance. Pull requests are only one way to manage the code review workflow; we urge people to consider other approaches, especially where there is a need to coach and pass on feedback carefully.\u003c/p\u003e","blip_status":"t","theta":"135","volume":"2021-04"},{"name":"SAFe™","id":"793","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"31","display_name":"SAFe™","radius":"388","description":"\u003cp\u003eOur positioning regarding \"being agile before doing agile\" and our opinions around this topic shouldn\u0027t come as a surprise; but since \u003cstrong\u003e\u003ca href\u003d\"http://www.scaledagileframework.com/\"\u003eSAFe™\u003c/a\u003e\u003c/strong\u003e (Scaled Agile Framework®), per Gartner’s May 2019\u003ca href\u003d\"http://go.scaledagile.com/Gartner-a.html\"\u003e report\u003c/a\u003e, is the most considered and most used enterprise agile framework, and since we\u0027re seeing more and more enterprises going through organizational changes, we thought it was time to raise awareness on this topic again. We\u0027ve come across organizations struggling with SAFe\u0027s over-standardized, phase-gated processes. Those processes create friction in the organizational structure and its operating model. It can also promote silos in the organization, preventing platforms from becoming real business capabilities enablers. The top-down control generates waste in the value stream and discourages engineering talent creativity, while limiting autonomy and experimentation in the teams. Rather than measuring effort and focusing on standardized ceremonies, we recommend a leaner, value-driven approach and governance to help eliminate organizational friction such as \u003ca href\u003d\"https://www.thoughtworks.com/books/edge\"\u003eEDGE\u003c/a\u003e, as well as a \u003ca href\u003d\"/radar/techniques/team-cognitive-load\"\u003eteam cognitive load\u003c/a\u003e assessment to identify types of teams and determine how they should better interact with each other.\u003c/p\u003e\n\n\u003cp\u003eScaled Agile Framework® and SAFe™ are trademarks of Scaled Agile, Inc.\u003c/p\u003e","blip_status":"c","theta":"124","volume":"2021-04"},{"name":"Separate code and pipeline ownership","id":"202104110","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"32","display_name":"Separate code and pipeline ownership","radius":"375","description":"\u003cp\u003eIdeally, but especially when teams are practicing DevOps, the deployment pipeline and the code being deployed should be owned by the same team. Unfortunately, we still see organizations where there is \u003cstrong\u003eseparate code and pipeline ownership\u003c/strong\u003e, with the deployment pipeline configuration owned by the infrastructure team; this results in delays to changes, barriers to improvements and a lack of development team ownership and involvement in deployments. One cause of this can clearly be the separate team, another can be the desire to retain “gatekeeper” processes and roles. Although there can be legitimate reasons for using this approach (e.g., regulatory control), in general we find it painful and unhelpful.\u003c/p\u003e","blip_status":"t","theta":"113","volume":"2021-04"},{"name":"Ticket-driven platform operating models","id":"202104025","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"33","display_name":"Ticket-driven platform operating models","radius":"380","description":"\u003cp\u003eOne of the ultimate goals of a platform should be to reduce ticket-based processes to an absolute minimum, as they create queues in the value stream. Sadly, we still see organizations not pushing forcefully enough toward this important goal, resulting in a \u003cstrong\u003eticket-driven platform operating model\u003c/strong\u003e. This is particularly frustrating when ticket-based processes are put in front of platforms that are built on top of the self-service and API-driven features of public cloud vendors. It\u0027s hard and not necessary to achieve self-service with very few tickets right from the start, but it needs to be the destination.\u003c/p\u003e\n\n\u003cp\u003eOver-reliance on bureaucracy and lack of trust are among the causes of this reluctance to move away from ticket-based processes. Baking more automated checks and alerts into your platform is one way to help cut the cord from approval processes with tickets. For example, \u003ca href\u003d\"/radar/techniques/run-cost-as-architecture-fitness-function\"\u003eprovide teams with visibility into their run costs\u003c/a\u003e and put in automated guardrails to avoid accidental explosion of costs. Implement \u003ca href\u003d\"/radar/techniques/security-policy-as-code\"\u003esecurity policy as code\u003c/a\u003e and use \u003ca href\u003d\"/radar/techniques/infrastructure-configuration-scanner\"\u003econfiguration scanners\u003c/a\u003e or analyzers like \u003ca href\u003d\"/radar/tools/recommender\"\u003eRecommender\u003c/a\u003e to help teams do the right thing.\u003c/p\u003e","blip_status":"t","theta":"102","volume":"2021-04"},{"name":"AWS Cloud Development Kit","id":"201911007","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"34","display_name":"AWS Cloud Development Kit","radius":"200","description":"\u003cp\u003eMany of our teams who are already on AWS have found \u003cstrong\u003e\u003ca href\u003d\"https://docs.aws.amazon.com/cdk/latest/guide/home.html\"\u003eAWS Cloud Development Kit\u003c/a\u003e\u003c/strong\u003e (AWS CDK) to be a sensible AWS default for enabling infrastructure provisioning. In particular, they like the use of first-class programming languages instead of configuration files which allows them to use existing tools, test approaches and skills. Like similar tools, care is still needed to ensure deployments remain easy to understand and maintain. The development kit currently supports \u003ca href\u003d\"/radar/languages-and-frameworks/typescript\"\u003eTypeScript\u003c/a\u003e, JavaScript, Python, Java, C# and .NET. New providers are being added to the CDK core. We\u0027ve also used both AWS Cloud Development Kit and HashiCorp\u0027s \u003ca href\u003d\"https://learn.hashicorp.com/tutorials/terraform/cdktf\"\u003eCloud Development Kit for Terraform\u003c/a\u003e to generate Terraform configurations and enable provisioning with the Terraform platform with success.\u003c/p\u003e","blip_status":"move_in","theta":"192","volume":"2021-04"},{"name":"Backstage","id":"202010066","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"35","display_name":"Backstage","radius":"240","description":"\u003cp\u003eWe continue to see interest in and use of \u003cstrong\u003e\u003ca href\u003d\"https://backstage.io/\"\u003eBackstage\u003c/a\u003e\u003c/strong\u003e grow, alongside the adoption of developer portals, as organizations look to support and streamline their development environments. As the number of tools and technologies increases, some form of standardization is becoming increasingly important for consistency so that developers are able to focus on innovation and product development instead of getting bogged down with reinventing the wheel. Backstage is an open-source developer portal platform created by Spotify, it\u0027s based upon software templates, unifying infrastructure tooling and consistent and centralized technical documentation. The plugin architecture allows for extensibility and adaptability into an organization’s infrastructure ecosystem.\u003c/p\u003e","blip_status":"move_in","theta":"205","volume":"2021-04"},{"name":"Delta Lake","id":"201911008","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"36","display_name":"Delta Lake","radius":"200","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://delta.io/\"\u003eDelta Lake\u003c/a\u003e\u003c/strong\u003e is an \u003ca href\u003d\"https://github.com/delta-io/delta\"\u003eopen-source storage layer\u003c/a\u003e, implemented by Databricks, that attempts to bring ACID transactions to big data processing. In our Databricks-enabled \u003ca href\u003d\"/radar/techniques/data-lake\"\u003edata lake\u003c/a\u003e or \u003ca href\u003d\"/radar/techniques/data-mesh\"\u003edata mesh\u003c/a\u003e projects, our teams continue to prefer using Delta Lake storage over the direct use of file storage types such \u003ca href\u003d\"https://aws.amazon.com/s3/\"\u003eS3\u003c/a\u003e or \u003ca href\u003d\"https://azure.microsoft.com/en-au/services/storage/data-lake-storage/\"\u003eADLS\u003c/a\u003e. Of course this is limited to projects that use storage platforms that support \u003ca href\u003d\"https://docs.delta.io/latest/delta-storage.html\"\u003eDelta Lake\u003c/a\u003e when using \u003ca href\u003d\"https://parquet.apache.org/\"\u003eParquet\u003c/a\u003e file formats. Delta Lake facilitates concurrent data read/write use cases where file-level transactionality is required. We find Delta Lake\u0027s seamless integration with Apache Spark \u003ca href\u003d\"https://docs.databricks.com/delta/delta-batch.html\"\u003ebatch\u003c/a\u003e and \u003ca href\u003d\"https://docs.databricks.com/delta/delta-streaming.html\"\u003emicro-batch\u003c/a\u003e APIs greatly helpful, particularly features such as \u003ca href\u003d\"https://databricks.com/blog/2019/02/04/introducing-delta-time-travel-for-large-scale-data-lakes.html\"\u003etime travel\u003c/a\u003e — accessing data at a particular point in time or commit reversion — as well as \u003ca href\u003d\"https://databricks.com/blog/2019/09/24/diving-into-delta-lake-schema-enforcement-evolution.html\"\u003eschema evolution\u003c/a\u003e support on write; though there are some limitations on these features.\u003c/p\u003e","blip_status":"move_in","theta":"218","volume":"2021-04"},{"name":"Materialize","id":"202010048","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"37","display_name":"Materialize","radius":"250","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://materialize.io/\"\u003eMaterialize\u003c/a\u003e\u003c/strong\u003e is a streaming database that enables you to do incremental computation without complicated data pipelines. Just describe your computations via standard SQL views and connect Materialize to the data stream. The underlying differential data flow engine performs incremental computation to provide consistent and correct output with minimal latency. Unlike traditional databases, there are no restrictions in defining these materialized views, and the computations are executed in real time. We\u0027ve used Materialize, together with Spring Cloud Stream and Kafka, to query over streams of events for insights in a distributed event-driven system, and we quite like the setup.\u003c/p\u003e","blip_status":"move_in","theta":"231","volume":"2021-04"},{"name":"Snowflake","id":"201911005","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"38","display_name":"Snowflake","radius":"210","description":"\u003cp\u003eSince we last mentioned \u003cstrong\u003e\u003ca href\u003d\"https://www.snowflake.com/\"\u003eSnowflake\u003c/a\u003e\u003c/strong\u003e in the Radar, we\u0027ve gained more experience with it as well as with \u003ca href\u003d\"/radar/techniques/data-mesh\"\u003edata mesh\u003c/a\u003e as an alternative to data warehouses and lakes. Snowflake continues to impress with features like time travel, zero-copy cloning, data sharing and its marketplace. We also haven\u0027t found anything we don\u0027t like about it, all of which has led to our consultants generally preferring it over the alternatives. Redshift is moving toward storage and compute separation, which has been a strong point of Snowflake, but even with Redshift Spectrum it isn\u0027t as convenient and flexible to use, partly because it is bound by its Postgres heritage (we do still like \u003ca href\u003d\"/radar/platforms/postgresql-for-nosql\"\u003ePostgres\u003c/a\u003e, by the way). Federated queries can be a reason to go with Redshift. When it comes to operations, Snowflake is much simpler to run. \u003ca href\u003d\"/radar/platforms/bigquery\"\u003eBigQuery\u003c/a\u003e, which is another alternative, is very easy to operate, but in a multicloud setup Snowflake is a better choice. We can also report that we\u0027ve used Snowflake successfully with \u003ca href\u003d\"/radar/platforms/google-cloud-platform\"\u003eGCP\u003c/a\u003e, \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e, and \u003ca href\u003d\"/radar/platforms/azure\"\u003eAzure\u003c/a\u003e.\u003c/p\u003e","blip_status":"c","theta":"244","volume":"2021-04"},{"name":"Variable fonts","id":"202104014","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"39","display_name":"Variable fonts","radius":"240","description":"\u003cp\u003e\u003cstrong\u003eVariable fonts\u003c/strong\u003e are a way of avoiding the need to find and include separate font files for different weights and styles. Everything is in one font file, and you can use properties to select which style and weight you need. While not new, we still see sites and projects that could benefit from this simple approach. If you have pages that are including many variations of the same font, we suggest trying out variable fonts.\u003c/p\u003e","blip_status":"t","theta":"257","volume":"2021-04"},{"name":"Apache Pinot","id":"202104075","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"40","display_name":"Apache Pinot","radius":"330","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://pinot.apache.org/\"\u003eApache Pinot\u003c/a\u003e\u003c/strong\u003e is a distributed OLAP data store, built to deliver real-time analytics with low latency. It can ingest from batch data sources (such as Hadoop HDFS, Amazon S3, Azure ADLS or Google Cloud Storage) as well as stream data sources (such as Apache Kafka). If the need is user-facing, low-latency analytics, SQL-on-Hadoop solutions don\u0027t offer the low latency that is needed. Modern OLAP engines like Apache Pinot (or \u003ca href\u003d\"https://druid.apache.org/\"\u003eApache Druid\u003c/a\u003e and \u003ca href\u003d\"https://clickhouse.tech/\"\u003eClickhouse\u003c/a\u003e among others) can achieve much lower latency and are particularly suited in contexts where fast analytics, such as aggregations, are needed on immutable data, possibly, with real-time data ingestion. Originally built by LinkedIn, Apache Pinot entered Apache incubation in late 2018 and has since added a plugin architecture and SQL support among other key capabilities. Apache Pinot can be fairly complex to operate and has many moving parts, but if your data volumes are large enough and you need low-latency query capability, we recommend you assess Apache Pinot.\u003c/p\u003e","blip_status":"t","theta":"188","volume":"2021-04"},{"name":"Bit.dev","id":"202104028","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"41","display_name":"Bit.dev","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://bit.dev/\"\u003eBit.dev\u003c/a\u003e\u003c/strong\u003e is a cloud-hosted collaborative platform for UI components extracted, modularized and reused with \u003ca href\u003d\"https://github.com/teambit/bit\"\u003eBit\u003c/a\u003e. \u003ca href\u003d\"/radar/platforms/web-components-standard\"\u003eWeb components\u003c/a\u003e have been around for a while, but building a modern front-end application by assembling small, independent components extracted from other projects has never been easy. Bit was designed to let you do exactly that: extract a component from an existing library or project. You can either build your own service on top of Bit for component collaboration or use Bit.dev.\u003c/p\u003e","blip_status":"t","theta":"196","volume":"2021-04"},{"name":"DataHub","id":"202104084","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"42","display_name":"DataHub","radius":"330","description":"\u003cp\u003eSince we first mentioned \u003ca href\u003d\"/radar/techniques/data-discoverability\"\u003edata discoverability\u003c/a\u003e in the Radar, LinkedIn has evolved \u003ca href\u003d\"https://engineering.linkedin.com/blog/2016/03/open-sourcing-wherehows--a-data-discovery-and-lineage-portal\"\u003eWhereHows\u003c/a\u003e to \u003cstrong\u003e\u003ca href\u003d\"https://github.com/linkedin/datahub\"\u003eDataHub\u003c/a\u003e\u003c/strong\u003e, the next generation platform that addresses data discoverability via an extensible metadata system. Instead of crawling and pulling metadata, DataHub adopts a push-based model where individual components of the data ecosystem publish metadata via an API or a stream to the central platform. This push-based integration shifts the ownership from the central entity to individual teams making them accountable for their metadata. As more and more companies are trying to become data driven, having a system that helps with data discovery and understanding data quality and lineage is critical, and we recommend you assess DataHub in that capacity.\u003c/p\u003e","blip_status":"t","theta":"204","volume":"2021-04"},{"name":"Feature Store","id":"202104088","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"43","display_name":"Feature Store","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.featurestore.org/\"\u003eFeature Store\u003c/a\u003e\u003c/strong\u003e is an ML-specific data platform that addresses some of the key challenges we face today in feature engineering with three fundamental capabilities: (1) it uses managed data pipelines to remove struggles with pipelines as new data arrives; (2) catalogs and stores feature data to promote discoverability and collaboration of features across models; and (3) consistently serves feature data during training and interference. \u003c/p\u003e\n\n\u003cp\u003eSince Uber revealed their \u003ca href\u003d\"https://eng.uber.com/michelangelo-machine-learning-platform/\"\u003eMichelangelo platform\u003c/a\u003e, many organizations and startups have built their own versions of a feature store; examples include \u003ca href\u003d\"https://github.com/logicalclocks/hopsworks\"\u003eHopsworks\u003c/a\u003e, \u003ca href\u003d\"https://github.com/feast-dev/feast\"\u003eFeast\u003c/a\u003e and \u003ca href\u003d\"https://www.tecton.ai/\"\u003eTecton\u003c/a\u003e. We see potential in Feature Store and recommend you carefully assess it.\u003c/p\u003e","blip_status":"t","theta":"212","volume":"2021-04"},{"name":"JuiceFS","id":"202104039","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"44","display_name":"JuiceFS","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/juicedata/juicefs\"\u003eJuiceFS\u003c/a\u003e\u003c/strong\u003e is an open-source, distributed POSIX file system built on top of \u003ca href\u003d\"https://www.thoughtworks.com/radar/platforms/redis\"\u003eRedis\u003c/a\u003e and an object store service (for example, Amazon S3). If you\u0027re building new applications, then our recommendation has always been to interact directly with the object store without going through another abstraction layer. However, JuiceFS can be an option if you\u0027re migrating legacy applications that depend on traditional POSIX file systems to the cloud.\u003c/p\u003e","blip_status":"t","theta":"220","volume":"2021-04"},{"name":"Kafka API without Kafka","id":"202104096","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"45","display_name":"Kafka API without Kafka","radius":"300","description":"\u003cp\u003eAs more businesses turn to events as a way to share data among microservices, collect analytics or feed data lakes, \u003ca href\u003d\"/radar/tools/apache-kafka\"\u003eApache Kafka\u003c/a\u003e has become a favorite platform to support an event-driven architectural style. Although Kafka was a revolutionary concept in scalable persistent messaging, a lot of moving parts are required to make it work, including ZooKeeper, brokers, partitions, and mirrors. While these can be particularly tricky to implement and operate, they do offer great flexibility and power when needed, especially at an industrial enterprise scale. Because of the high barrier to entry presented by the full Kafka ecosystem, we welcome the recent explosion of platforms offering the \u003cstrong\u003eKafka API without Kafka\u003c/strong\u003e. Recent entries such as \u003ca href\u003d\"https://github.com/streamnative/kop\"\u003eKafka on Pulsar\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/redpanda\"\u003eRedpanda\u003c/a\u003e offer alternative architectures, and \u003ca href\u003d\"https://github.com/Azure/azure-event-hubs-for-kafka\"\u003eAzure Event Hubs for Kafka\u003c/a\u003e provides some compatibility with Kafka producer and consumer APIs. Some features of Kafka, like the streams client library, are not compatible with these alternative brokers, so there are still reasons to choose Kafka over alternative brokers. It remains to be seen, however, if developers actually adopt this strategy or if it is merely an attempt by competitors to lure users away from the Kafka platform. Ultimately, perhaps Kafka\u0027s most enduring impact could be the convenient protocol and API provided to clients.\u003c/p\u003e","blip_status":"t","theta":"229","volume":"2021-04"},{"name":"NATS","id":"202104100","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"46","display_name":"NATS","radius":"320","description":"\u003cp\u003e\u003ca href\u003d\"https://nats.io/about/\"\u003e\u003cstrong\u003eNATS\u003c/strong\u003e\u003c/a\u003e is a fast, secure message queueing system with an unusually wide range of features and potential deployment targets. At first glance, you would be forgiven for asking why the world needs another message queueing system. Message queues have been around in various forms for nearly as long as businesses have been using computers and have undergone years of refinement and optimization for various tasks. But NATS has several interesting characteristics and is unique in its ability to scale from embedded controllers to global, cloud-hosted superclusters. We\u0027re particularly intrigued by NATS\u0027s intent to support a continuous streaming flow of data from mobile devices and IoT and through a network of interconnected systems. However, some tricky issues need to be addressed, not the least of which is ensuring consumers see only the messages and topics to which they\u0027re allowed access, especially when the network spans organizational boundaries. NATS 2.0 introduced a security and access control framework that supports multitenant clusters where accounts restrict a user\u0027s access to queues and topics. Written in Go, NATS has primarily been embraced by the Go language community. Although clients exist for pretty much all widely used programming languages, the Go client is by far the most popular. However, some of our developers have found that all the language client libraries tend to reflect the Go origins of codebase. Increasing bandwidth and processing power on small, wireless devices means that the volume of data businesses must consume in real time will only increase. Assess NATS as a possible platform for streaming that data within and among businesses.\u003c/p\u003e","blip_status":"t","theta":"237","volume":"2021-04"},{"name":"Opstrace","id":"202104104","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"47","display_name":"Opstrace","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://opstrace.com/\"\u003eOpstrace\u003c/a\u003e\u003c/strong\u003e is an open-source observability platform intended to be deployed in the user\u0027s own network. If we don\u0027t use commercial solutions like Datadog (for example, because of cost or data residency concerns), the only solution is to build your own platform composed of open-source tools. This can take a lot of effort — Opstrace is intended to fill this gap. It uses open-source APIs and interfaces such as \u003ca href\u003d\"/radar/tools/prometheus\"\u003ePrometheus\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/grafana\"\u003eGrafana\u003c/a\u003e and adds additional features on top like TLS and authentication. At the heart of Opstrace runs a \u003ca href\u003d\"https://github.com/cortexproject/cortex\"\u003eCortex\u003c/a\u003e cluster to provide the scalable Prometheus API as well as a \u003ca href\u003d\"https://github.com/grafana/loki\"\u003eLoki\u003c/a\u003e cluster for the logs. It\u0027s fairly new and \u003ca href\u003d\"https://opstrace.com/docs/references/roadmap#opstrace-roadmap\"\u003estill misses features\u003c/a\u003e when compared to solutions like Datadog or SignalFX. Still, it\u0027s a promising addition to this space and worth keeping an eye on.\u003c/p\u003e","blip_status":"t","theta":"245","volume":"2021-04"},{"name":"Pulumi","id":"1283","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"48","display_name":"Pulumi","radius":"300","description":"\u003cp\u003eWe\u0027ve seen interest in \u003cstrong\u003e\u003ca href\u003d\"https://pulumi.io/\"\u003ePulumi\u003c/a\u003e\u003c/strong\u003e slowly but steadily rising. Pulumi fills a gaping hole in the infrastructure coding world where \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e maintains a firm hold. While Terraform is a tried-and-true standby, its declarative nature suffers from inadequate abstraction facilities and limited testability. Terraform is adequate when the infrastructure is entirely static, but dynamic infrastructure definitions call for a real programming language. Pulumi distinguishes itself by allowing configurations to be written in \u003ca href\u003d\"/radar/languages-and-frameworks/typescript\"\u003eTypeScript\u003c/a\u003e/JavaScript, \u003ca href\u003d\"/radar/languages-and-frameworks/python-3\"\u003ePython\u003c/a\u003e and \u003ca href\u003d\"/radar/languages-and-frameworks/go-language\"\u003eGo\u003c/a\u003e — no markup language or templating required. Pulumi is tightly focused on cloud-native architectures — including containers, serverless functions and data services — and provides good support for \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e. Recently, \u003ca href\u003d\"/radar/platforms/aws-cloud-development-kit\"\u003eAWS CDK\u003c/a\u003e has mounted a challenge, but Pulumi remains the only cloud-neutral tool in this area. We\u0027re anticipating wider Pulumi adoption in the future and looking forward to a viable tool and knowledge ecosystem emerging to support it.\u003c/p\u003e","blip_status":"c","theta":"253","volume":"2021-04"},{"name":"Redpanda","id":"202104108","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"49","display_name":"Redpanda","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/vectorizedio/redpanda\"\u003eRedpanda\u003c/a\u003e\u003c/strong\u003e is a streaming platform that provides a \u003ca href\u003d\"/radar/tools/apache-kafka\"\u003eKafka\u003c/a\u003e-compatible API, allowing it to benefit from the Kafka ecosystem without having to deal with the complexities of a Kafka installation. For example, Redpanda simplifies operations by shipping as a single binary and avoiding the need for an external dependency such as ZooKeeper. Instead, it implements the Raft protocol and performs comprehensive tests to validate it\u0027s been \u003ca href\u003d\"https://vectorized.io/blog/validating-consistency/\"\u003eimplemented correctly\u003c/a\u003e. One of Redpanda’s capabilities (available for enterprise customers only) is inline \u003ca href\u003d\"/radar/languages-and-frameworks/webassembly\"\u003eWebAssembly (WASM)\u003c/a\u003e transformations, using an embedded WASM engine. This allows developers to create event transformers in their language of choice and compile it to WASM. Redpanda also offers much reduced tail latencies and increased throughput due to a \u003ca href\u003d\"https://vectorized.io/blog/tpc-buffers/\"\u003eseries of optimizations\u003c/a\u003e. Redpanda is an exciting alternative to Kafka and is worth assessing.\u003c/p\u003e","blip_status":"t","theta":"261","volume":"2021-04"},{"name":"Azure Machine Learning","id":"202104003","quadrant":"Platforms","ring":"Hold","movement":"t","radarId":"50","display_name":"Azure Machine Learning","radius":"375","description":"\u003cp\u003eWe\u0027ve observed before that the cloud providers push more and more services onto the market. We\u0027ve also documented our concerns that sometimes the services are made available when they\u0027re not quite ready for prime time. Unfortunately, in our experience, \u003cstrong\u003e\u003ca href\u003d\"https://azure.microsoft.com/en-us/services/machine-learning/\"\u003eAzure Machine Learning\u003c/a\u003e\u003c/strong\u003e falls into the latter category. One of several \u003ca href\u003d\"https://towardsdatascience.com/top-8-no-code-machine-learning-platforms-you-should-use-in-2020-1d1801300dd0\"\u003erecent entrants\u003c/a\u003e in the field of \u003ca href\u003d\"/radar/techniques/bounded-low-code-platforms\"\u003ebounded low-code platforms\u003c/a\u003e, Azure ML promises more convenience for data scientists. Ultimately, however, it doesn\u0027t live up to its promise; in fact, it still feels easier for our data scientists to work in Python. Despite significant efforts, we struggled to make it scale and lack of adequate documentation proved to be another issue which is why we moved it to the Hold ring.\u003c/p\u003e","blip_status":"t","theta":"210","volume":"2021-04"},{"name":"Homemade infrastructure-as-code (IaC) products","id":"202104007","quadrant":"Platforms","ring":"Hold","movement":"t","radarId":"51","display_name":"Homemade infrastructure-as-code (IaC) products","radius":"375","description":"\u003cp\u003eProducts supported by companies or communities are in constant evolution, at least the ones that get traction in the industry. Sometimes organizations tend to build frameworks or abstractions on top of the existing external products to cover very specific needs, thinking that the adaptation will provide more benefits than the existing ones. We\u0027re seeing organizations trying to create \u003cstrong\u003ehomemade infrastructure-as-code (IaC) products\u003c/strong\u003e on top of the existing ones; they underestimate the required effort to keep those solutions evolving according to their needs, and after a short period of time, they realize that the original version is in much better shape than their own; there are even cases where the abstraction on top of the external product reduces the original capabilities. Although we\u0027ve seen success stories of organizations building homemade solutions, we want to caution about this approach as the effort required to do so isn\u0027t negligible, and a long-term product vision is required to have the expected outcomes.\u003c/p\u003e","blip_status":"t","theta":"240","volume":"2021-04"},{"name":"Sentry","id":"1232","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"52","display_name":"Sentry","radius":"80","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://sentry.io/\"\u003eSentry\u003c/a\u003e\u003c/strong\u003e has become the default choice for many of our teams when it comes to front-end error reporting. The convenience of features like the grouping of errors or defining patterns for discarding errors with certain parameters helps deal with the flood of errors coming from many end user devices. Integrating Sentry in your CD pipeline allows you to upload source maps for more efficient error debugging, and it helps easily trace back which errors occurred in which version of the software. We also appreciate that while Sentry is primarily a SaaS offering, its source code is publicly available and it can be used for free for smaller use cases and \u003ca href\u003d\"https://develop.sentry.dev/self-hosted/\"\u003eself-hosting\u003c/a\u003e.\u003c/p\u003e","blip_status":"move_in","theta":"45","volume":"2021-04"},{"name":"axe-core","id":"202104015","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"53","display_name":"axe-core","radius":"205","description":"\u003cp\u003eMaking the web inclusive requires serious attention to ensure accessibility is considered \u003cem\u003eand\u003c/em\u003e validated at all stages of software delivery. Many of the popular accessibility testing tools are designed for testing after a web application is complete; as a result, issues are detected late and often are harder to fix, accumulating as debt. In our recent internal work on ThoughtWorks websites, we included the open-source accessibility (a11y) testing engine \u003cstrong\u003e\u003ca href\u003d\"https://github.com/dequelabs/axe-core\"\u003eaxe-core\u003c/a\u003e\u003c/strong\u003e as part of our build processes. It provided team members with early feedback on adherence to accessibility rules, even during early increments. Not every issue can be found through automated inspection, though. Extending the functionality of axe-core is the commercially available \u003ca href\u003d\"https://www.deque.com/axe/devtools/\"\u003eaxe DevTools\u003c/a\u003e, including functionality that guides team members through exploratory testing for a majority of accessibility issues.\u003c/p\u003e","blip_status":"t","theta":"85","volume":"2021-04"},{"name":"dbt","id":"201911076","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"54","display_name":"dbt","radius":"225","description":"\u003cp\u003eSince we last wrote about \u003cstrong\u003e\u003ca href\u003d\"https://www.getdbt.com/\"\u003edbt\u003c/a\u003e\u003c/strong\u003e, we\u0027ve used it in a few projects and like what we\u0027ve seen. For example, we like that dbt makes the transformation part of ELT pipelines more accessible to consumers of the data as opposed to just the data engineers building the pipelines. It does this while encouraging good engineering practices such as versioning, automated testing and deployment. SQL continues to be the lingua franca of the data world (including databases, warehouses, query engines, data lakes and analytical platforms) and most of these systems support it to some extent. This allows dbt to be used against these systems for transformations by just building adaptors. The number of native connectors has grown to include \u003ca href\u003d\"/radar/platforms/snowflake\"\u003eSnowflake\u003c/a\u003e, \u003ca href\u003d\"/radar/platforms/bigquery\"\u003eBigQuery\u003c/a\u003e, Redshift and Postgres, as has the range of \u003ca href\u003d\"https://docs.getdbt.com/docs/available-adapters\"\u003ecommunity plugins\u003c/a\u003e. We see tools like dbt helping data platforms become more \"self service\" capable.\u003c/p\u003e","blip_status":"move_in","theta":"79","volume":"2021-04"},{"name":"esbuild","id":"202104033","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"55","display_name":"esbuild","radius":"200","description":"\u003cp\u003eWe\u0027ve always been keen to find tools that can shorten the software development feedback cycle; \u003cstrong\u003e\u003ca href\u003d\"https://github.com/evanw/esbuild\"\u003eesbuild\u003c/a\u003e\u003c/strong\u003e is such an example. As the front-end codebase grows larger, we usually face a packaging time of minutes. As a JavaScript bundler optimized for speed, esbuild can reduce this time by a factor of 10 to 100. It is written in Golang and uses a more efficient approach in the process of parsing, printing and source map generation which significantly surpasses build tools such as \u003ca href\u003d\"/radar/tools/webpack\"\u003eWebpack\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/parcel\"\u003eParcel\u003c/a\u003e in building time. esbuild may not be as comprehensive as those tools in JavaScript syntax transformation; however, this doesn\u0027t stop many of our teams from switching to esbuild as their default.\u003c/p\u003e","blip_status":"t","theta":"74","volume":"2021-04"},{"name":"Flipper","id":"202104089","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"56","display_name":"Flipper","radius":"220","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/facebook/flipper\"\u003eFlipper\u003c/a\u003e\u003c/strong\u003e is an extensible mobile application debugger. Out of the box it supports profiling, interactive layout inspection, log viewer and a network inspector for iOS, Android and \u003ca href\u003d\"/radar/languages-and-frameworks/react-native\"\u003eReact Native\u003c/a\u003e applications. Compared to other debugging tools for mobile apps, we find Flipper to be lightweight, feature rich and easy to set up.\u003c/p\u003e","blip_status":"t","theta":"68","volume":"2021-04"},{"name":"Great Expectations","id":"202010076","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"57","display_name":"Great Expectations","radius":"240","description":"\u003cp\u003eWe wrote about \u003cstrong\u003e\u003ca href\u003d\"https://docs.greatexpectations.io/en/latest/\"\u003eGreat Expectations\u003c/a\u003e\u003c/strong\u003e in the previous edition of the Radar. We continue to like it and have moved it to Trial in this edition. Great Expectations is a framework that enables you to craft built-in controls that flag anomalies or quality issues in data pipelines. Just as unit tests run in a build pipeline, Great Expectations makes assertions during execution of a data pipeline. We like its simplicity and ease of use — the rules stored in JSON can be modified by our data domain experts without necessarily needing data engineering skills.\u003c/p\u003e","blip_status":"move_in","theta":"62","volume":"2021-04"},{"name":"k6","id":"202010078","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"58","display_name":"k6","radius":"250","description":"\u003cp\u003eWe\u0027ve had a bit more experience performance testing with \u003ca href\u003d\"https://k6.io/\"\u003e\u003cstrong\u003ek6\u003c/strong\u003e\u003c/a\u003e since we first covered it in the Radar, and with good results. Our teams have enjoyed the focus on the developer experience and flexibility of the tool. Although it\u0027s easy to get started with k6 all on its own, it really shines with its ease of integration into a developer ecosystem. For example, using the \u003ca href\u003d\"https://k6.io/docs/results-visualization/datadog\"\u003eDatadog adapter\u003c/a\u003e, one team was quickly able to visualize performance in a distributed system and identify significant concerns before releasing the system to production. Another team, with the commercial version of k6, was able to use the \u003ca href\u003d\"https://marketplace.visualstudio.com/items?itemName\u003dk6.k6-load-test\u0026ssr\u003dfalse\"\u003eAzure pipelines marketplace extension\u003c/a\u003e to wire performance tests into their CD pipeline and get Azure DevOps reporting with little effort. Since k6 supports thresholds that allow for automated testing assertions out of the box, it\u0027s relatively easy to add a stage to your pipeline that detects performance degradation of new changes, adding a powerful feedback mechanism for developers.\u003c/p\u003e","blip_status":"move_in","theta":"55","volume":"2021-04"},{"name":"MLflow","id":"202010082","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"59","display_name":"MLflow","radius":"195","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://mlflow.org/\"\u003eMLflow\u003c/a\u003e\u003c/strong\u003e is an open-source tool for \u003ca href\u003d\"/radar/tools/experiment-tracking-tools-for-machine-learning\"\u003emachine-learning experiment tracking\u003c/a\u003e and lifecycle management. The workflow to develop and continuously evolve a machine-learning model includes a series of experiments (a collection of runs), tracking the performance of these experiments (a collection of metrics) and tracking and tweaking models (projects). MLflow facilitates this workflow nicely by supporting existing open standards and integrates well with many other tools in the ecosystem. \u003ca href\u003d\"https://databricks.com/product/managed-mlflow\"\u003eMLflow as a managed service by Databricks\u003c/a\u003e on the cloud, available in \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/azure\"\u003eAzure\u003c/a\u003e, is rapidly maturing, and we\u0027ve used it successfully in our projects. We find MLflow a great tool for model management and tracking, supporting both UI-based and API-based interaction models. Our only growing concern is that MLflow is attempting to deliver too many conflating concerns as a single platform, such as model serving and scoring.\u003c/p\u003e","blip_status":"c","theta":"54","volume":"2021-04"},{"name":"OR-Tools","id":"202104109","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"60","display_name":"OR-Tools","radius":"215","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://developers.google.com/optimization\"\u003eOR-Tools\u003c/a\u003e\u003c/strong\u003e is an open-source software suite for solving combinatorial optimization problems. These optimization problems have a very large set of possible solutions, and tools like OR-Tools are quite helpful in seeking the best solution. You can model the problem in any one of the supported languages — Python, Java, C# or C++ — and choose the solvers from several supported open-source or commercial solvers. We\u0027ve successfully used OR-Tools in multiple optimization projects with integer and mixed-integer programming.\u003c/p\u003e","blip_status":"t","theta":"47","volume":"2021-04"},{"name":"Playwright","id":"202010056","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"61","display_name":"Playwright","radius":"220","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://playwright.dev/\"\u003ePlaywright\u003c/a\u003e\u003c/strong\u003e allows you to write Web UI tests for Chromium and Firefox as well as WebKit, all through the same API. The tool has gained some attention for its support of all the major browser engines which it achieves by including patched versions of Firefox and Webkit. We continue to hear positive experience reports with Playwright, in particular its stability. Teams have also found it easy to migrate from \u003ca href\u003d\"/radar/languages-and-frameworks/puppeteer\"\u003ePuppeteer\u003c/a\u003e, which has a very similar API.\u003c/p\u003e","blip_status":"move_in","theta":"39","volume":"2021-04"},{"name":"Prowler","id":"202104107","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"62","display_name":"Prowler","radius":"190","description":"\u003cp\u003eWe welcome the increased availability and maturity of \u003ca href\u003d\"/radar/techniques/infrastructure-configuration-scanner\"\u003einfrastructure configuration scanning\u003c/a\u003e tools: \u003cstrong\u003e\u003ca href\u003d\"https://github.com/toniblyx/prowler\"\u003eProwler\u003c/a\u003e\u003c/strong\u003e helps teams scan their AWS infrastructure setups and improve security based on the results. Although Prowler has been around for a while, it has evolved a lot over the past few years, and we\u0027ve found it very valuable to enable teams to take responsibility for proper security with a short feedback loop. Prowler categorizes \u003ca href\u003d\"https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf\"\u003eAWS CIS benchmarking\u003c/a\u003e checks into different groups (Identity and Access Management, Logging, Monitoring, Networking, CIS Level 1, CIS Level 2, EKS-CIS), and it includes many checks that help you gain insights into your PCI DSS and GDPR compliance.\u003c/p\u003e","blip_status":"t","theta":"34","volume":"2021-04"},{"name":"Pyright","id":"202104069","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"63","display_name":"Pyright","radius":"222","description":"\u003cp\u003eWhile \u003ca href\u003d\"https://en.wikipedia.org/wiki/Duck_typing\"\u003educk typing\u003c/a\u003e is certainly seen as a feature by many Python programmers, sometimes — especially for larger codebases — type checking can be useful, too. For that reason a number of type annotations are proposed as Python Enhancement Proposals (PEPs), and \u003cstrong\u003e\u003ca href\u003d\"https://github.com/Microsoft/pyright\"\u003ePyright\u003c/a\u003e\u003c/strong\u003e is a type checker that works with these annotations. In addition, it provides some type inference and guards that understand conditional code flow constructs. Designed with large codebases in mind, Pyright is fast, and its watch mode checks happen incrementally as files are changed to further shorten the feedback cycle. Pyright can be used directly on the command line, but integrations for VS Code, Emacs, vim, Sublime, and possibly other editors are available, too. In our experience, Pyright is preferable to alternatives like mypy.\u003c/p\u003e","blip_status":"t","theta":"29","volume":"2021-04"},{"name":"Redash","id":"202104051","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"64","display_name":"Redash","radius":"215","description":"\u003cp\u003eAdopting a \"you build it, you run it\" DevOps philosophy means teams have increased attention on both technical and business metrics that can be extracted from the systems they deploy. Often we find that analytics tooling is difficult to access for most developers, so the work to capture and present metrics is left to other teams — long after features are shipped to end users. Our teams have found \u003cstrong\u003e\u003ca href\u003d\"https://redash.io/\"\u003eRedash\u003c/a\u003e\u003c/strong\u003e to be very useful for querying product metrics and creating dashboards in a way that can be self-served by general developers, shortening feedback cycles and focusing the whole team on the business outcomes.\u003c/p\u003e","blip_status":"t","theta":"22","volume":"2021-04"},{"name":"Terratest","id":"201904011","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"65","display_name":"Terratest","radius":"175","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/gruntwork-io/terratest\"\u003eTerratest\u003c/a\u003e\u003c/strong\u003e caught our attention in the past as an interesting option for infrastructure testing. Since then, our teams have been using it, and they\u0027re very excited about it because of its stability and the experience it provides. Terratest is a Golang library that makes it easier to write automated tests for infrastructure code. Using infrastructure-as-code tools such as \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e, you can create real infrastructure components (such as servers, firewalls, or load balancers) to deploy applications on them and then validate the expected behavior using Terratest. At the end of the test, Terratest can undeploy the apps and clean up resources. This makes it largely useful for end-to-end tests of your infrastructure in a real environment.\u003c/p\u003e","blip_status":"move_in","theta":"17","volume":"2021-04"},{"name":"Tuple","id":"202104027","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"66","display_name":"Tuple","radius":"215","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://tuple.app/\"\u003eTuple\u003c/a\u003e\u003c/strong\u003e is a relatively new tool optimized for remote paired programming, designed to fill the gap Slack left in the marketplace after abandoning Screenhero. Although it still exhibits some growing pains — platform availability is limited to Mac OS for now (with Linux support coming soon), and it has some UI quirks to work through — we\u0027ve had good experience using it within those constraints. Unlike general-purpose video- and screen-sharing tools like Zoom, Tuple supports dual control with two mouse cursors, and unlike options such as \u003ca href\u003d\"/radar/tools/visual-studio-live-share\"\u003eVisual Studio Live Share\u003c/a\u003e, it isn\u0027t tied to an IDE. Tuple supports voice and video calls, clipboard sharing, and lower latency than general-purpose tools; and its ability to let you draw and erase in your pair\u0027s screen with ease makes Tuple a very intuitive and developer-friendly tool.\u003c/p\u003e","blip_status":"t","theta":"14","volume":"2021-04"},{"name":"Why Did You Render","id":"202104117","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"67","display_name":"Why Did You Render","radius":"205","description":"\u003cp\u003eWhen working with \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e, we often encounter situations where our page is very slow because some components are re-rendering when they shouldn\u0027t be. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/welldone-software/why-did-you-render\"\u003eWhy Did You Render\u003c/a\u003e\u003c/strong\u003e is a library that helps detect why a component is re-rendering. It does this by monkey patching React. We\u0027ve used it in a few of our projects to debug performance issues with great effect.\u003c/p\u003e","blip_status":"t","theta":"7","volume":"2021-04"},{"name":"Buildah and Podman","id":"202104064","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"68","display_name":"Buildah and Podman","radius":"315","description":"\u003cp\u003eEven though \u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e has become the sensible default for containerization, we\u0027re seeing new players in this space that are catching our attention. That is the case for \u003cstrong\u003e\u003ca href\u003d\"https://github.com/containers/buildah\"\u003eBuildah\u003c/a\u003e and \u003ca href\u003d\"https://github.com/containers/podman\"\u003ePodman\u003c/a\u003e\u003c/strong\u003e, which are complementary projects to build images (Buildah) and run containers (Podman) using a \u003ca href\u003d\"/radar/platforms/rootless-containers\"\u003erootless\u003c/a\u003e approach in multiple Linux distributions. Podman introduces a daemonless engine for managing and running containers which is an interesting approach in comparison to what Docker does. The fact that Podman can use either \u003ca href\u003d\"https://opencontainers.org/\"\u003eOpen Container Initiative (OCI)\u003c/a\u003e images built by Buildah or Docker images makes this tool even more attractive and easy to use.\u003c/p\u003e","blip_status":"t","theta":"84","volume":"2021-04"},{"name":"GitHub Actions","id":"202104005","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"69","display_name":"GitHub Actions","radius":"305","description":"\u003cp\u003eCI servers and build tools are some of the oldest and most widely used in our kit. They run the gamut from simple cloud-hosted services to complex, code-defined pipeline servers that support fleets of build machines. Given our experience and the wide range of options already available, we were initially skeptical when \u003cstrong\u003e\u003ca href\u003d\"https://docs.github.com/en/actions\"\u003eGitHub Actions\u003c/a\u003e\u003c/strong\u003e were introduced as another mechanism to manage the build and integration workflow. But the opportunity for developers to start small and easily customize behavior means that GitHub Actions are moving toward the default category for smaller projects. It\u0027s hard to argue with the convenience of having the build tool integrated directly into the source code repository. An enthusiastic community has emerged around this feature and that means a wide range of user-contributed tools and workflows are available to get started. Tools vendors are also getting on board via the \u003ca href\u003d\"https://github.com/marketplace?type\u003dactions\"\u003eGitHub Marketplace\u003c/a\u003e. However, we still recommend you proceed with caution. Although code and \u003ca href\u003d\"/radar/tools/git\"\u003eGit\u003c/a\u003e history can be exported into alternative hosts, a development workflow based on GitHub Actions can\u0027t. Also, use your best judgment to determine when a project is large or complex enough to warrant an independently supported pipeline tool. But for getting up and running quickly on smaller projects, it\u0027s worth considering GitHub Actions and the ecosystem that is growing around them.\u003c/p\u003e","blip_status":"t","theta":"77","volume":"2021-04"},{"name":"Graal Native Image","id":"202104122","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"70","display_name":"Graal Native Image","radius":"315","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.graalvm.org/reference-manual/native-image/\"\u003eGraal Native Image\u003c/a\u003e\u003c/strong\u003e is a technology that compiles Java code into an operating system\u0027s native binary — in the form of a statically linked executable or a shared library. A native image is optimized to reduce the memory footprint and startup time of an application. Our teams have successfully used Graal native images, executed as small Docker containers, in the \u003ca href\u003d\"/radar/techniques/serverless-architecture\"\u003eserverless architecture\u003c/a\u003e where reducing start time matters. Although designed for use with programming languages such as \u003ca href\u003d\"/radar/languages-and-frameworks/go-language\"\u003eGo\u003c/a\u003e or \u003ca href\u003d\"/radar/languages-and-frameworks/rust\"\u003eRust\u003c/a\u003e that natively compile and require smaller binary sizes and shorter start times, Graal Native Image can be equally useful to teams that have other requirements and want to use JVM-based languages.\u003c/p\u003e\n\n\u003cp\u003eGraal Native Image Builder, \u003cem\u003enative-image\u003c/em\u003e, supports JVM-based languages — such as Java, Scala, Clojure and Kotlin — and builds executables on multiple operating systems including Mac OS, Windows and multiple distributions of Linux. Since it requires a closed-world assumption, where all code is known at compile time, additional configuration is needed for features such as \u003cem\u003ereflection\u003c/em\u003e or \u003cem\u003edynamic class loading\u003c/em\u003e where types can\u0027t be deduced at build time from the code alone.\u003c/p\u003e","blip_status":"t","theta":"70","volume":"2021-04"},{"name":"HashiCorp Boundary","id":"202104092","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"71","display_name":"HashiCorp Boundary","radius":"335","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.boundaryproject.io/\"\u003eHashiCorp Boundary\u003c/a\u003e\u003c/strong\u003e combines the secure networking and identity management capabilities needed for brokering access to your hosts and services in one place and across a mix of cloud and on-premise resources if needed. Key management can be done by integrating the key management service of your choice, be it from a cloud vendor or something like \u003ca href\u003d\"/radar/tools/hashicorp-vault\"\u003eHashiCorp Vault\u003c/a\u003e. HashiCorp Boundary supports a growing number of identity providers and can be integrated with parts of your service landscape to help define permissions, not just on host but also on a service level. For example, it enables you to control fine-grained access to a Kubernetes cluster, and dynamically pulling in service catalogs from various sources is on the roadmap. All of this stays out of the way of the engineering end users who get the shell experience they\u0027re used to, securely connected through Boundary\u0027s network management layer.\u003c/p\u003e","blip_status":"t","theta":"63","volume":"2021-04"},{"name":"imgcook","id":"202104017","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"72","display_name":"imgcook","radius":"305","description":"\u003cp\u003eRemember the research project \u003ca href\u003d\"https://github.com/tonybeltramelli/pix2code\"\u003epix2code\u003c/a\u003e that showed how to automatically generate code from GUI screenshots? Now there is a productized version of this technique — \u003cstrong\u003e\u003ca href\u003d\"https://www.imgcook.com/\"\u003eimgcook\u003c/a\u003e\u003c/strong\u003e is a SaaS product from Alibaba that can intelligently transform various design files (Sketch/PSD/static images) into front-end code. Alibaba needs to customize a large number of campaign pages during the Double Eleven shopping festival. These are usually one-time pages that need to be developed quickly. Through the deep-learning method, the UX\u0027s design is initially processed into front-end code and then adjusted by the developer. Our team is evaluating this tech: although the image processing takes place on the server side while the main interface is on the web, imgcook provides \u003ca href\u003d\"https://github.com/imgcook\"\u003etools\u003c/a\u003e that could integrate with the software design and development lifecycle. imgcook can generate static code as well as some data-binding component code if you define a DSL. The technology is not perfect yet; designers need to refer to certain specifications to improve the accuracy of code generation (which still needs to be adjusted by developers afterward). We\u0027ve always been cautious about magic code generation, because the generated code is usually difficult to maintain in the long run, and imgcook is no exception. But if you limit the usage to a specific context, such as one-time campaign pages, it\u0027s worth a try.\u003c/p\u003e","blip_status":"t","theta":"56","volume":"2021-04"},{"name":"Longhorn","id":"202104019","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"73","display_name":"Longhorn","radius":"315","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://longhorn.io/\"\u003eLonghorn\u003c/a\u003e\u003c/strong\u003e is a distributed block storage system for \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e. There are many \u003ca href\u003d\"https://kubernetes-csi.github.io/docs/drivers.html\"\u003epersistent storage options\u003c/a\u003e for Kubernetes; unlike most, however, Longhorn is built from the ground up to provide incremental snapshots and backups, thereby easing the pain of running a replicated storage for non–cloud-hosted Kubernetes. With the recent \u003ca href\u003d\"https://longhorn.io/blog/longhorn-v1.1.0/\"\u003eexperimental support for ReadWriteMany (RWX)\u003c/a\u003e you can even mount the same volume for read and write access across many nodes. Choosing the right storage system for Kubernetes is a nontrivial task, and we recommend you assess Longhorn based on your needs.\u003c/p\u003e","blip_status":"t","theta":"49","volume":"2021-04"},{"name":"Operator Framework","id":"202104048","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"74","display_name":"Operator Framework","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://operatorframework.io/\"\u003eOperator Framework\u003c/a\u003e\u003c/strong\u003e is a set of open-source tools that simplifies building and managing the lifecycle of \u003ca href\u003d\"https://kubernetes.io/docs/concepts/extend-kubernetes/operator/\"\u003eKubernetes operators\u003c/a\u003e. The Kubernetes operator pattern, originally \u003ca href\u003d\"https://web.archive.org/web/20170129131616/https://coreos.com/blog/introducing-operators.html\"\u003eintroduced by CoreOS\u003c/a\u003e, is an approach to encapsulate the knowledge of operating an application using Kubernetes native capabilities; it includes \u003cem\u003eresources\u003c/em\u003e to be managed and \u003cem\u003econtroller code\u003c/em\u003e that ensures the resources are matching their target state. This approach has been used to extend Kubernetes to manage \u003ca href\u003d\"https://operatorhub.io/\"\u003emany applications\u003c/a\u003e, particularly the stateful ones, natively. Operator Framework has three components: \u003ca href\u003d\"https://sdk.operatorframework.io/\"\u003eOperator SDK\u003c/a\u003e, which simplifies building, testing and packaging Kubernetes operators; \u003ca href\u003d\"https://github.com/operator-framework/operator-lifecycle-manager/\"\u003eOperator lifecycle manager\u003c/a\u003e to install, manage and upgrade the operators; and a \u003ca href\u003d\"https://operatorhub.io/\"\u003ecatalog\u003c/a\u003e to publish and share third-party operators. Our teams have found Operator SDK particularly powerful in rapidly developing Kubernetes-native applications.\u003c/p\u003e","blip_status":"t","theta":"42","volume":"2021-04"},{"name":"Recommender","id":"202104073","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"75","display_name":"Recommender","radius":"300","description":"\u003cp\u003eThe number of services offered by the big cloud providers keeps growing, but so does the convenience and maturity of tools that help you use them securely and efficiently. \u003ca href\u003d\"https://cloud.google.com/recommender\"\u003e\u003cstrong\u003eRecommender\u003c/strong\u003e\u003c/a\u003e is a service on Google Cloud that analyzes your resources and gives you recommendations on how to optimize them based on your actual usage. The service consists of a range of \"recommenders\" in areas such as security, compute usage or cost savings. For example, the \u003ca href\u003d\"https://cloud.google.com/iam/docs/role-recommendations\"\u003eIAM Recommender\u003c/a\u003e helps you better implement the principle of least privilege by pointing out permissions that are never actually used and therefore are potentially too broad.\u003c/p\u003e","blip_status":"t","theta":"35","volume":"2021-04"},{"name":"Remote - WSL","id":"202104126","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"76","display_name":"Remote - WSL","radius":"307","description":"\u003cp\u003eOver the past few years \u003ca href\u003d\"https://docs.microsoft.com/en-us/windows/wsl/\"\u003eWindows Subsystem for Linux (WSL)\u003c/a\u003e has come up a few times in our discussions. Although we liked what we saw, including the improvements in WSL 2, it never made it into the Radar. In this edition we want to highlight an extension for Visual Studio Code that greatly improves the experience working with WSL. Although Windows-based editors could always access files on a WSL file system, they were unaware of the isolated Linux environment. With the \u003cstrong\u003e\u003ca href\u003d\"https://marketplace.visualstudio.com/items?itemName\u003dms-vscode-remote.remote-wsl\"\u003eRemote - WSL\u003c/a\u003e\u003c/strong\u003e extension, Visual Studio Code becomes aware of WSL, allowing developers to launch a Linux shell. This also enables debugging of binaries running inside WSL from Windows. Jetbrains\u0027 IntelliJ too has seen steady improvement in its \u003ca href\u003d\"https://youtrack.jetbrains.com/issue/IDEA-171510#focus\u003dComments-27-4155034.0-0\"\u003esupport for WSL\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"28","volume":"2021-04"},{"name":"Spectral","id":"202104055","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"77","display_name":"Spectral","radius":"315","description":"\u003cp\u003eOne of the patterns we\u0027ve seen repeat itself in this publication is that static error- and style-checking tools emerge quickly after a new language gains popularity. These tools are generically known as linters — after the classic and beloved Unix utility \u003cem\u003elint\u003c/em\u003e, which statically analyzes C code. We like these tools because they catch errors early, before code even gets compiled. The latest instance of this pattern is \u003cstrong\u003e\u003ca href\u003d\"https://stoplight.io/open-source/spectral/\"\u003eSpectral\u003c/a\u003e\u003c/strong\u003e, a linter for YAML and JSON. Although Spectral is a generic tool for these formats, its main target is OpenAPI (the evolution of \u003ca href\u003d\"/radar/tools/swagger\"\u003eSwagger\u003c/a\u003e) and \u003ca href\u003d\"/radar/tools/asyncapi\"\u003eAsyncAPI\u003c/a\u003e. Spectral ships with a comprehensive set of out-of-the-box rules for these specs that can save developers headaches when designing and implementing APIs or event-driven collaboration. These rules check for proper API parameter specifications or the existence of a license statement in the spec, among other things. While this tool is a welcome addition to the API development workflow, it does raise the question of whether a non-executable specification should be so complex as to require an error-checking technique designed for programming languages. Perhaps developers should be writing code instead of specs?\u003c/p\u003e","blip_status":"t","theta":"21","volume":"2021-04"},{"name":"Yelp detect-secrets","id":"202104057","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"78","display_name":"Yelp detect-secrets","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/Yelp/detect-secrets\"\u003eYelp detect-secrets\u003c/a\u003e\u003c/strong\u003e is a Python module for detecting secrets within a codebase; it scans files within a directory looking for secrets. It can be used as a \u003ca href\u003d\"/radar/tools/git\"\u003eGit\u003c/a\u003e pre-commit hook or to perform a scan in multiple places within the CI/CD pipeline. It comes with a default configuration that makes it very easy to use but can be modified to suit your needs. You can also install custom plugins to add to its default heuristic searches. Compared to similar offerings, we found that this tool detects more types of secrets with its out-of-the-box configuration.\u003c/p\u003e","blip_status":"t","theta":"14","volume":"2021-04"},{"name":"Zally","id":"202104058","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"79","display_name":"Zally","radius":"315","description":"\u003cp\u003eAs the API specification ecosystem matures, we\u0027re seeing more tools built to automate style checks. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/zalando/zally\"\u003eZally\u003c/a\u003e\u003c/strong\u003e is a minimalist OpenAPI linter that helps to ensure an API conforms to the team\u0027s API style guide. Out of the box, it will validate against a rule set developed for \u003ca href\u003d\"https://opensource.zalando.com/restful-api-guidelines/\"\u003eZalando\u0027s API style guide\u003c/a\u003e, but it also supports a Kotlin extension mechanism to develop custom rules. Zally includes a web UI that provides an intuitive interface for understanding style violations and includes a CLI that makes it easy to plug into your CD pipeline.\u003c/p\u003e","blip_status":"t","theta":"7","volume":"2021-04"},{"name":"AWS CodePipeline","id":"202104002","quadrant":"Tools","ring":"Hold","movement":"t","radarId":"80","display_name":"AWS CodePipeline","radius":"385","description":"\u003cp\u003eBased on the experiences of multiple ThoughtWorks teams we suggest approaching \u003cstrong\u003e\u003ca href\u003d\"https://aws.amazon.com/codepipeline/\"\u003eAWS CodePipeline\u003c/a\u003e\u003c/strong\u003e with caution. Specifically, we\u0027ve found that once teams move beyond simple pipelines, this tool can become hard to work with. While it may seem like a \"quick win\" when first starting out with \u003ca href\u003d\"/radar/platforms/aws\"\u003eAWS\u003c/a\u003e, we suggest taking a step back and checking whether AWS CodePipeline will meet your longer-term needs, for example, pipeline fan-out and fan-in or more complex deployment and testing scenarios featuring nontrivial dependencies and triggers.\u003c/p\u003e","blip_status":"t","theta":"45","volume":"2021-04"},{"name":"Combine","id":"202104031","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"81","display_name":"Combine","radius":"75","description":"\u003cp\u003eA long time ago we placed \u003ca href\u003d\"/radar/languages-and-frameworks/reactivex\"\u003eReactiveX\u003c/a\u003e — a family of open-source frameworks for reactive programming — into the Adopt ring of the Radar. In 2017, we mentioned the addition of \u003ca href\u003d\"https://github.com/ReactiveX/RxSwift\"\u003eRxSwift\u003c/a\u003e, which brought reactive programming to iOS development using Swift. Since then, Apple has introduced its own take on reactive programming in the form of the \u003ca href\u003d\"https://developer.apple.com/documentation/combine\"\u003e\u003cstrong\u003eCombine\u003c/strong\u003e\u003c/a\u003e framework. Combine has become our default choice for apps that support iOS 13 as an acceptable deployment target. It\u0027s easier to learn than RxSwift and integrates really well with \u003ca href\u003d\"/radar/languages-and-frameworks/swiftui\"\u003eSwiftUI\u003c/a\u003e. If you\u0027re planning to convert an existing application from RxSwift to Combine or work with both in the same project, you might want to look at \u003ca href\u003d\"https://github.com/CombineCommunity/RxCombine\"\u003eRxCombine\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"300","volume":"2021-04"},{"name":"LeakCanary","id":"1173","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"82","display_name":"LeakCanary","radius":"100","description":"\u003cp\u003eOur mobile teams now view \u003cstrong\u003e\u003ca href\u003d\"http://github.com/square/leakcanary\"\u003eLeakCanary\u003c/a\u003e\u003c/strong\u003e as a good default choice for Android development. It detects annoying memory leaks in Android apps, is extremely simple to hook up and provides notifications with a clear trace-back to the cause of the leak. LeakCanary can save you tedious hours troubleshooting out-of-memory errors on multiple devices, and we recommend you add it to your toolkit.\u003c/p\u003e","blip_status":"move_in","theta":"330","volume":"2021-04"},{"name":"Angular Testing Library","id":"202104118","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"83","display_name":"Angular Testing Library","radius":"210","description":"\u003cp\u003eAs we continue developing web applications in JavaScript, we continue enjoying the \u003ca href\u003d\"/radar/languages-and-frameworks/testing-library\"\u003eTesting Library\u003c/a\u003e approach of testing applications; and carry on exploring and gaining experience with its packages — beyond that of \u003ca href\u003d\"/radar/languages-and-frameworks/react-testing-library\"\u003eReact Testing Library\u003c/a\u003e. \u003cstrong\u003e\u003ca href\u003d\"https://testing-library.com/docs/angular-testing-library/intro/\"\u003eAngular Testing Library\u003c/a\u003e\u003c/strong\u003e brings all the benefits of its family when testing UI components in a user-centric way, pushing for more maintainable tests focused primarily on behavior rather than testing UI implementation details. Although it falls short in documentation, Angular Testing Library does provide \u003ca href\u003d\"https://github.com/testing-library/angular-testing-library/tree/main/apps/example-app/src/app/examples\"\u003egood sample tests\u003c/a\u003e that helped us in getting started faster for various cases. We\u0027ve had great success with this testing library in our \u003ca href\u003d\"/radar/languages-and-frameworks/angular\"\u003eAngular\u003c/a\u003e projects and advise you to trial this solid testing approach.\u003c/p\u003e","blip_status":"t","theta":"276","volume":"2021-04"},{"name":"AWS Data Wrangler","id":"202104077","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"84","display_name":"AWS Data Wrangler","radius":"240","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/awslabs/aws-data-wrangler\"\u003eAWS Data Wrangler\u003c/a\u003e\u003c/strong\u003e is an open-source library that extends the capabilities of \u003ca href\u003d\"https://github.com/pandas-dev/pandas\"\u003ePandas\u003c/a\u003e to AWS by connecting data frames to AWS data-related services. In addition to Pandas, this library leverages \u003ca href\u003d\"https://github.com/apache/arrow\"\u003eApache Arrow\u003c/a\u003e and \u003ca href\u003d\"https://github.com/boto/boto3\"\u003eBoto3\u003c/a\u003e to expose \u003ca href\u003d\"https://aws-data-wrangler.readthedocs.io/en/2.5.0/api.html\"\u003eseveral APIs\u003c/a\u003e to load, transform and save data from data lakes and data warehouses. An important limitation is that you can\u0027t do large distributed data pipelines with this library. However, you can leverage the native data services — like Athena, Redshift and Timestream — to do the heavy lifting and pull data in order to express complex transformations that are well suited for data frames. We\u0027ve used AWS Data Wrangler in production and like that it lets you focus on writing transformations without spending too much time on the connectivity to AWS data services.\u003c/p\u003e","blip_status":"t","theta":"283","volume":"2021-04"},{"name":"Blazor","id":"202010022","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"85","display_name":"Blazor","radius":"210","description":"\u003cp\u003eAlthough JavaScript and its ecosystem is dominant in the web UI development space, new opportunities are opening up with the emergence of \u003ca href\u003d\"/radar/languages-and-frameworks/webassembly\"\u003eWebAssembly\u003c/a\u003e. \u003cstrong\u003e\u003ca href\u003d\"https://dotnet.microsoft.com/apps/aspnet/web-apps/blazor\"\u003eBlazor\u003c/a\u003e\u003c/strong\u003e continues to demand our attention; it\u0027s producing good results with our teams building interactive rich user interfaces using C# on top of WebAssembly. The fact that our teams can use C# on the frontend too allows them to share code and reuse existing libraries. That, along with the existing tooling for debugging and testing, such as \u003ca href\u003d\"/radar/languages-and-frameworks/bunit\"\u003ebUnit\u003c/a\u003e, make this open-source framework worth trying.\u003c/p\u003e","blip_status":"move_in","theta":"290","volume":"2021-04"},{"name":"FastAPI","id":"202104087","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"86","display_name":"FastAPI","radius":"180","description":"\u003cp\u003eWe\u0027re seeing more teams adopting Python as the preferred language to build solutions, not just for data science but for back-end services too. In these scenarios, we\u0027re having good experiences with \u003cstrong\u003e\u003ca href\u003d\"https://fastapi.tiangolo.com/\"\u003eFastAPI\u003c/a\u003e\u003c/strong\u003e — a modern, fast (high-performance), web framework for building APIs with Python 3.6 or later. Additionally, this framework and its ecosystem include features such as API documentation using OpenAPI that allow our teams to focus on the business functionalities and quickly create REST APIs, which makes FastAPI a good alternative to existing solutions in this space.\u003c/p\u003e","blip_status":"t","theta":"297","volume":"2021-04"},{"name":"io-ts","id":"202010103","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"87","display_name":"io-ts","radius":"185","description":"\u003cp\u003eWe\u0027ve really enjoyed using \u003ca href\u003d\"/radar/languages-and-frameworks/typescript\"\u003eTypeScript\u003c/a\u003e for a while now and love the safety that the strong typing provides. However, getting data into the bounds of the type system — from, for example, a call to a back-end service — can lead to run-time errors. One library that helps solve this problem is \u003cstrong\u003e\u003ca href\u003d\"https://gcanti.github.io/io-ts/\"\u003eio-ts\u003c/a\u003e\u003c/strong\u003e. It bridges the gap between compile-time type-checking and run-time consumption of external data by providing encode and decode functions. It can also be used as a custom type guard. As we gain more experience with io-ts in our work, our initially positive impressions are confirmed, and we still like the elegance of its approach.\u003c/p\u003e","blip_status":"move_in","theta":"306","volume":"2021-04"},{"name":"Kotlin Flow","id":"202104041","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"88","display_name":"Kotlin Flow","radius":"180","description":"\u003cp\u003eThe introduction of \u003ca href\u003d\"https://kotlinlang.org/docs/coroutines-overview.html\"\u003ecoroutines to Kotlin\u003c/a\u003e opened the door for several innovations — \u003cstrong\u003e\u003ca href\u003d\"https://kotlinlang.org/docs/flow.html\"\u003eKotlin Flow\u003c/a\u003e\u003c/strong\u003e is one of them, directly integrated into the coroutines library. It\u0027s an implementation of Reactive Streams on top of coroutines. Unlike \u003ca href\u003d\"https://github.com/ReactiveX/RxJava\"\u003eRxJava\u003c/a\u003e, flows are a native Kotlin API similar to the familiar sequence API with methods that include \u003ccode\u003emap\u003c/code\u003e and \u003ccode\u003efilter\u003c/code\u003e. Like sequences, flows are \u003cem\u003ecold\u003c/em\u003e, meaning that the values of the sequence are only constructed when needed. All of this makes writing multithreaded code much simpler and easier to understand than other approaches. The \u003ccode\u003etoList\u003c/code\u003e method, predictably, converts a flow into a list which is a common pattern in tests.\u003c/p\u003e","blip_status":"t","theta":"318","volume":"2021-04"},{"name":"LitElement","id":"202010046","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"89","display_name":"LitElement","radius":"240","description":"\u003cp\u003eSteady progress has been made since we first wrote about \u003ca href\u003d\"/radar/platforms/web-components-standard\"\u003eWeb Components\u003c/a\u003e in 2014. \u003cstrong\u003e\u003ca href\u003d\"https://lit-element.polymer-project.org/\"\u003eLitElement\u003c/a\u003e\u003c/strong\u003e, part of the \u003ca href\u003d\"https://www.polymer-project.org/\"\u003ePolymer Project\u003c/a\u003e, is a simple library that you can use to create lightweight web components. It\u0027s really just a base class that removes the need for a lot of the common boilerplate, making writing web components a lot easier. We\u0027ve had success using it on projects, and as we see the technology maturing and the library being well liked, LitElement is becoming more commonly used in our Web Components-based projects.\u003c/p\u003e","blip_status":"move_in","theta":"318","volume":"2021-04"},{"name":"Next.js","id":"201904030","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"90","display_name":"Next.js","radius":"210","description":"\u003cp\u003eWe\u0027ve had a bit more experience using \u003cstrong\u003e\u003ca href\u003d\"https://nextjs.org/\"\u003eNext.js\u003c/a\u003e\u003c/strong\u003e for \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e codebases since the last time we wrote about it. Next.js is an opinionated, zero-configuration framework that includes simplified routing, automatic compilation and bundling with \u003ca href\u003d\"/radar/tools/webpack\"\u003eWebpack\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/babel\"\u003eBabel\u003c/a\u003e, fast hot reloading for a convenient developer workflow among other features. It provides server-side rendering by default, improves search engine optimization and the initial load time and supports incremental static generation. We\u0027ve had positive experience reports from teams using Next.js and, given its large community, continue to be excited about the evolution of the framework.\u003c/p\u003e","blip_status":"move_in","theta":"325","volume":"2021-04"},{"name":"On-demand modules","id":"202104047","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"91","display_name":"On-demand modules","radius":"260","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://developer.android.com/codelabs/on-demand-dynamic-delivery#0\"\u003eOn-demand modules\u003c/a\u003e\u003c/strong\u003e for Android is a framework that allows tailored APKs containing only required functionality to be downloaded and installed for a suitably structured app. This could be worth trialing for larger apps where download speed might be an issue, or if a user is likely only to use some functionality on initial installation. It can also simplify the handling of multiple devices without requiring different APKs. A similar framework is available for \u003ca href\u003d\"https://developer.apple.com/app-clips/\"\u003eiOS\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"332","volume":"2021-04"},{"name":"Streamlit","id":"202010088","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"92","display_name":"Streamlit","radius":"210","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.streamlit.io/\"\u003eStreamlit\u003c/a\u003e\u003c/strong\u003e is an open-source application framework in Python used by data scientists for building interactive data applications. Tuning machine-learning models takes time; instead of going back and forth on the main application (the one that uses these models), we\u0027ve found value in quickly building standalone prototypes in Streamlit and gathering feedback during experimentation cycles. Streamlit stands out from competitors such as \u003ca href\u003d\"/radar/tools/dash\"\u003eDash\u003c/a\u003e because of its focus on rapid prototyping and support for a wide range of visualization libraries, including \u003ca href\u003d\"https://plotly.com/\"\u003ePlotly\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/bokeh\"\u003eBokeh\u003c/a\u003e. We\u0027re using it in a few projects and like how we can put together interactive visualizations with very little effort.\u003c/p\u003e","blip_status":"move_in","theta":"339","volume":"2021-04"},{"name":"SWR","id":"202010091","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"93","display_name":"SWR","radius":"210","description":"\u003cp\u003eWhen used in appropriate circumstances, our teams have found that the \u003ca href\u003d\"/radar/languages-and-frameworks/react-hooks\"\u003eReact Hooks\u003c/a\u003e library \u003cstrong\u003e\u003ca href\u003d\"https://github.com/vercel/swr\"\u003eSWR\u003c/a\u003e\u003c/strong\u003e can result in cleaner code and much improved performance. SWR implements the \u003ca href\u003d\"https://tools.ietf.org/html/rfc5861\"\u003estale-while-revalidate\u003c/a\u003e HTTP caching strategy, first returning data from cache (stale), then sending the fetch request (revalidate) and finally refreshing the values with the up-to-date response. We caution teams to only use the SWR caching strategy when an application is supposed to return stale data. Note that \u003ca href\u003d\"https://tools.ietf.org/html/rfc2616\"\u003eHTTP\u003c/a\u003e requires that caches respond to a request with the most up-to-date response; only in \u003cem\u003ecarefully considered circumstances\u003c/em\u003e is a stale response allowed to be returned.\u003c/p\u003e","blip_status":"move_in","theta":"346","volume":"2021-04"},{"name":"TrustKit","id":"202104115","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"94","display_name":"TrustKit","radius":"260","description":"\u003cp\u003e\u003ca href\u003d\"https://owasp.org/www-community/controls/Certificate_and_Public_Key_Pinning\"\u003eSSL public key pinning\u003c/a\u003e is tricky. If you select the wrong policy or don\u0027t have a backup pin, your application will stop working unexpectedly. This is where \u003cstrong\u003e\u003ca href\u003d\"https://github.com/datatheorem/TrustKit\"\u003eTrustKit\u003c/a\u003e\u003c/strong\u003e is useful — it\u0027s an open-source framework that makes SSL public key pinning easier for iOS applications. There is an equivalent \u003ca href\u003d\"https://github.com/datatheorem/TrustKit-Android\"\u003eframework for Android\u003c/a\u003e as well. Picking the correct pinning strategy is a nuanced topic, and you can find more details about it in the TrustKit \u003ca href\u003d\"https://github.com/datatheorem/TrustKit/blob/master/docs/getting-started.md\"\u003eGetting Started guide\u003c/a\u003e. We\u0027ve used TrustKit in several projects in production, and it has worked out well.\u003c/p\u003e","blip_status":"t","theta":"353","volume":"2021-04"},{"name":".NET 5","id":"202104021","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"95","display_name":".NET 5","radius":"320","description":"\u003cp\u003eWe don\u0027t call out every new .NET version in the Radar, but \u003cstrong\u003e.NET 5\u003c/strong\u003e represents a significant step forward in bringing .NET Core and .NET Framework into a single platform. Organizations should start to develop a strategy to migrate their development environments — a fragmented mix of frameworks depending on the deployment target — to a single version of .NET 5 or 6 when it becomes available. The advantage of this approach will be a common development platform regardless of the intended environment: Windows, Linux, cross-platform mobile devices (via \u003ca href\u003d\"/radar/tools/xamarin\"\u003eXamarin\u003c/a\u003e) or the browser (using \u003ca href\u003d\"/radar/languages-and-frameworks/blazor\"\u003eBlazor\u003c/a\u003e). While polyglot development will remain the preferred approach for companies with the engineering culture to support it, others will find it more efficient to standardize on a single platform for .NET development. For now, we want to keep this in the Assess ring to see how well the final unified framework performs in .NET 6.\u003c/p\u003e","blip_status":"t","theta":"278","volume":"2021-04"},{"name":"bUnit","id":"202104029","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"96","display_name":"bUnit","radius":"295","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://bunit.egilhansen.com/\"\u003ebUnit\u003c/a\u003e\u003c/strong\u003e is a testing library for \u003ca href\u003d\"/radar/languages-and-frameworks/blazor\"\u003eBlazor\u003c/a\u003e that makes it easy to create tests for Blazor components in existing unit testing frameworks such as NUnit, xUnit or MSUnit. It provides a facade around the component allowing it to be run and tested within the familiar unit test paradigm, thus allowing very fast feedback and testing of the component in isolation. If you\u0027re developing for Blazor, we recommend that you add bUnit to your list of tools to try out.\u003c/p\u003e","blip_status":"t","theta":"286","volume":"2021-04"},{"name":"Dagster","id":"202104083","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"97","display_name":"Dagster","radius":"315","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/dagster-io/dagster\"\u003eDagster\u003c/a\u003e\u003c/strong\u003e is an open-source data orchestration framework for machine learning, analytics and plain ETL data pipelines. Unlike other task-driven frameworks, Dagster is aware of data flowing through the pipeline and can provide type-safety. With this unified view of pipelines and assets produced, Dagster can schedule and orchestrate Pandas, \u003ca href\u003d\"/radar/platforms/apache-spark\"\u003eSpark\u003c/a\u003e, SQL or anything else that Python can invoke. The framework is relatively new, and we recommend that you assess its capabilities for your data pipelines.\u003c/p\u003e","blip_status":"t","theta":"294","volume":"2021-04"},{"name":"Flutter for Web","id":"202104128","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"98","display_name":"Flutter for Web","radius":"320","description":"\u003cp\u003eSo far, \u003ca href\u003d\"/radar/languages-and-frameworks/flutter\"\u003eFlutter\u003c/a\u003e has primarily supported native iOS and Android applications. However, the Flutter team\u0027s vision is to support building applications on every platform. \u003cstrong\u003eFlutter for Web\u003c/strong\u003e is one step in that direction — it allows us to build apps for iOS, Android and the browser from the same codebase. It has been available for over a year now on the \"Beta\" channel, but with the recent Flutter 2.0 release, Flutter for Web has hit the stable milestone. In the initial release of web support, the Flutter team is focusing on \u003ca href\u003d\"https://web.dev/what-are-pwas/\"\u003eprogressive web apps\u003c/a\u003e, \u003ca href\u003d\"https://en.wikipedia.org/wiki/Single-page_application\"\u003esingle-page apps\u003c/a\u003e and expanding existing mobile apps to the web. The application and framework code (all in \u003ca href\u003d\"/radar/languages-and-frameworks/google-dart\"\u003eDart\u003c/a\u003e) are compiled to JavaScript instead of ARM machine code, which is used for mobile applications. Flutter’s web engine offers a choice of two renderers: an HTML renderer, which uses HTML, CSS, Canvas and SVG, and a CanvasKit renderer that uses \u003ca href\u003d\"/radar/languages-and-frameworks/webassembly\"\u003eWebAssembly\u003c/a\u003e and WebGL to render Skia paint commands to the browser canvas. A few of our teams have started using Flutter for Web and like the initial results.\u003c/p\u003e","blip_status":"t","theta":"302","volume":"2021-04"},{"name":"Jotai and Zustand","id":"202104119","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"99","display_name":"Jotai and Zustand","radius":"340","description":"\u003cp\u003eIn the previous Radar, we commented on the beginning of a phase of experimentation with state management in \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e applications. We moved \u003ca href\u003d\"/radar/languages-and-frameworks/redux\"\u003eRedux\u003c/a\u003e back into the Trial ring, documenting that it is no longer our default choice, and we mentioned Facebook\u0027s \u003ca href\u003d\"/radar/languages-and-frameworks/recoil\"\u003eRecoil\u003c/a\u003e. In this volume we want to highlight \u003cstrong\u003e\u003ca href\u003d\"https://github.com/pmndrs/jotai\"\u003eJotai\u003c/a\u003e and \u003ca href\u003d\"https://github.com/pmndrs/zustand\"\u003eZustand\u003c/a\u003e\u003c/strong\u003e: Both are state management libraries for React; both aim to be small and simple to use; and, perhaps not by complete coincidence, both names are translations of the word \u003cem\u003estate\u003c/em\u003e into Japanese and German, respectively. Beyond these similarities, however, they differ in their design. Jotai\u0027s design is closer to that of Recoil in that state consists of atoms stored within the React component tree, whereas Zustand stores the state outside of React in a single state object, much like the approach taken by Redux. The authors of Jotai provide a helpful \u003ca href\u003d\"https://github.com/pmndrs/jotai/blob/master/docs/introduction/comparison.md\"\u003echecklist\u003c/a\u003e to decide when to use which.\u003c/p\u003e","blip_status":"t","theta":"310","volume":"2021-04"},{"name":"Kotlin Multiplatform Mobile","id":"202104042","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"100","display_name":"Kotlin Multiplatform Mobile","radius":"335","description":"\u003cp\u003eFollowing the trend of cross-platform mobile development, \u003cstrong\u003e\u003ca href\u003d\"https://kotlinlang.org/docs/mobile/home.html\"\u003eKotlin Multiplatform Mobile\u003c/a\u003e\u003c/strong\u003e (KMM) is a new entry in this space. KMM is an SDK provided by JetBrains that leverages the \u003ca href\u003d\"https://kotlinlang.org/docs/multiplatform.html\"\u003emultiplatform capabilities\u003c/a\u003e in \u003ca href\u003d\"/radar/languages-and-frameworks/kotlin\"\u003eKotlin\u003c/a\u003e and includes tools and features designed to make the end-to-end experience of building mobile cross-platform applications more enjoyable and efficient. With KMM you write code once for business logic and the app core in Kotlin and then  share it with both Android and iOS applications. Write platform-specific code only when necessary, for example, to take advantage of native UI elements; and the specific code is kept in different views for each platform. Although still in Alpha, Kotlin Multiplatform Mobile is \u003ca href\u003d\"https://kotlinlang.org/docs/mobile/kmm-evolution.html\"\u003eevolving rapidly\u003c/a\u003e. We\u0027ll certainly keep an eye on it, and you should too.\u003c/p\u003e","blip_status":"t","theta":"315","volume":"2021-04"},{"name":"LVGL","id":"202104045","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"101","display_name":"LVGL","radius":"295","description":"\u003cp\u003eWith the increasing popularity of smart home and wearable devices, demand for intuitive graphical user interfaces (GUIs)is increasing. However, if you\u0027re engaged in embedded device development, rather than Android/iOS, GUI development may take a lot of effort. As an open-source embedded graphics library, \u003cstrong\u003e\u003ca href\u003d\"https://github.com/lvgl/lvgl\"\u003eLVGL\u003c/a\u003e\u003c/strong\u003e has become increasingly popular. LVGL has been adapted to mainstream embedded platforms such as NXP, STM32, PIC, Arduino, and ESP32. It has a very small memory footprint: 64 kB flash and 8 kB RAM is enough to make it work, and it can run smoothly on various Cortex-M0 low-power MCUs. LVGL supports input types such as touchscreen, mouse and buttons and contains more than 30 controls, including TileView suitable for smart watches. The MIT license it chose doesn’t restrict enterprise and commercial use. Our teams’ feedback on this tool has been positive and one of our projects using LVGL is already in production, more specifically in small batch manufacturing.\u003c/p\u003e","blip_status":"t","theta":"327","volume":"2021-04"},{"name":"React Hook Form","id":"202104050","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"102","display_name":"React Hook Form","radius":"335","description":"\u003cp\u003eBuilding forms for the web remains one of the perennial challenges of front-end development, in particular with \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact\u003c/a\u003e. Many of our teams working with React have been using \u003ca href\u003d\"/radar/languages-and-frameworks/formik\"\u003eFormik\u003c/a\u003e to make this easier, but some are now assessing \u003cstrong\u003e\u003ca href\u003d\"https://react-hook-form.com/\"\u003eReact Hook Form\u003c/a\u003e\u003c/strong\u003e as a potential alternative. \u003ca href\u003d\"/radar/languages-and-frameworks/react-hooks\"\u003eReact Hooks\u003c/a\u003e already existed when React Hook Form was created, so it could use them as a first-class concept: the framework is registering and tracking form elements as uncontrolled components via a hook, thereby significantly reducing the need for re-rendering. It\u0027s also quite lightweight in size and in the amount of boilerplate code needed.\u003c/p\u003e","blip_status":"t","theta":"335","volume":"2021-04"},{"name":"River","id":"202104011","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"103","display_name":"River","radius":"335","description":"\u003cp\u003eAt the heart of many approaches to machine learning lies the creation of a model from a set of training data. Once a model is created, it can be used over and over again. However, the world isn\u0027t stationary, and often the model needs to change as new data becomes available. Simply re-running the model creation step can be slow and \u003ca href\u003d\"https://medium.com/syncedreview/the-staggering-cost-of-training-sota-ai-models-e329e80fa82\"\u003ecostly\u003c/a\u003e. Incremental learning addresses this issue, making it possible to learn from streams of data incrementally to react to change faster. As a bonus the compute and memory requirements are lower and predictable. In our implementations we\u0027ve had good experience with the \u003cstrong\u003e\u003ca href\u003d\"https://riverml.xyz/dev/\"\u003eRiver\u003c/a\u003e\u003c/strong\u003e framework, but so far we\u0027ve added checks, sometimes manual, after updates to the model.\u003c/p\u003e","blip_status":"t","theta":"343","volume":"2021-04"},{"name":"Webpack 5 Module Federation","id":"202104116","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"104","display_name":"Webpack 5 Module Federation","radius":"320","description":"\u003cp\u003eThe release of the \u003cstrong\u003e\u003ca href\u003d\"https://webpack.js.org/concepts/module-federation/\"\u003eWebpack 5 Module Federation\u003c/a\u003e\u003c/strong\u003e feature has been highly anticipated by developers of \u003ca href\u003d\"/radar/techniques/micro-frontends\"\u003emicro frontend\u003c/a\u003e architectures. The feature introduces a more standardized way to optimize how module dependencies and shared code are managed and loaded. Module federation allows for the specification of shared modules, which helps with the deduplication of dependencies across micro frontends by loading code used by multiple modules only once. It also lets you distinguish between local and remote modules, where the remote modules are not actually part of the build itself but loaded asynchronously. Compared to build-time dependencies like npm packages, this can significantly simplify the deployment of a module update with many downstream dependencies. Be aware, though, that this requires you to bundle all of your micro frontends with Webpack, as opposed to approaches such as \u003ca href\u003d\"/radar/techniques/import-maps-for-micro-frontends\"\u003eimport maps\u003c/a\u003e, which might eventually become part of the W3C standard.\u003c/p\u003e","blip_status":"t","theta":"351","volume":"2021-04"}],"date":"2021-04"},{"blips":[{"name":"Four key metrics","id":"1298","quadrant":"Techniques","ring":"Adopt","movement":"c","radarId":"1","display_name":"Four key metrics","radius":"75","description":"\u003cp\u003eTo measure software delivery performance, more and more organizations are turning to the \u003cstrong\u003efour key metrics\u003c/strong\u003e as defined by the \u003ca href\u003d\"https://www.devops-research.com/\"\u003eDORA research\u003c/a\u003e program: change lead time, deployment frequency, mean time to restore (MTTR) and change fail percentage. This research and its statistical analysis have shown a clear link between high delivery performance and these metrics; they provide a great leading indicator for how a team, or even a whole delivery organization, is doing.\u003c/p\u003e\n\n\u003cp\u003eWe\u0027re still big proponents of these metrics, but we\u0027ve also learned some lessons since we first started monitoring them. And we\u0027re increasingly seeing misguided measurement approaches with tools that help teams measure these metrics based purely on their continuous delivery (CD) pipelines. In particular when it comes to the stability metrics (MTTR and change fail percentage), CD pipeline data alone doesn\u0027t provide enough information to determine what a deployment failure with real user impact is. Stability metrics only make sense if they include data about real incidents that degrade service for the users.\u003c/p\u003e\n\n\u003cp\u003eAnd as with all metrics, we recommend to always keep in mind the ultimate intention behind a measurement and use them to reflect and learn. For example, before spending weeks to build up sophisticated dashboard tooling, consider just regularly taking the \u003ca href\u003d\"https://www.devops-research.com/quickcheck.html\"\u003eDORA quick check\u003c/a\u003e in team retrospectives. This gives the team the opportunity to reflect on which \u003ca href\u003d\"https://www.devops-research.com/research.html#capabilities\"\u003ecapabilities\u003c/a\u003e they could work on to improve their metrics, which can be much more effective than overdetailed out-of-the-box tooling.\u003c/p\u003e","blip_status":"c","theta":"158","volume":"2021-10"},{"name":"Platform engineering product teams","id":"1101","quadrant":"Techniques","ring":"Adopt","movement":"c","radarId":"2","display_name":"Platform engineering product teams","radius":"75","description":"\u003cp\u003eWe continue to see \u003cstrong\u003eplatform engineering product teams\u003c/strong\u003e as a sensible default with the key insight being that they\u0027re just another \u003ca href\u003d\"https://martinfowler.com/articles/products-over-projects.html\"\u003eproduct team\u003c/a\u003e, albeit one focused on internal platform customers. Thus it is critical to have clearly defined customers and products while using the same engineering disciplines and ways of working as any other (externally focused) product team; platform teams aren\u0027t special in this regard. We strongly caution against just renaming existing internal teams \"platform teams\" while leaving ways of working and organizational structures unchanged. We\u0027re still big fans of using concepts from \u003ca href\u003d\"https://teamtopologies.com/\"\u003eTeam Topologies\u003c/a\u003e as we think about how best to organize platform teams. We consider platform engineering product teams to be a standard approach and a significant enabler for high-performing IT.\u003c/p\u003e","blip_status":"c","theta":"135","volume":"2021-10"},{"name":"Zero trust architecture","id":"202005092","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"3","display_name":"Zero trust architecture","radius":"75","description":"\u003cp\u003eWe keep hearing about enterprises finding their security badly compromised due to an overreliance on the \"secure\" network perimeter. Once this external perimeter is breached, internal systems prove to be poorly protected with attackers quickly and easily able to deploy automated data extraction tools and ransomware attacks that all too often remain undetected for long periods. This leads us to recommend \u003cstrong\u003ezero trust architecture\u003c/strong\u003e (ZTA) as a now sensible default.\u003c/p\u003e\n\n\u003cp\u003eZTA is a paradigm shift in security architecture and strategy. It’s based on the assumption that a network perimeter is no longer representative of a secure boundary and no implicit trust should be granted to users or services based solely on their physical or network location. The number of resources, tools and platforms available to implement aspects of ZTA keeps growing and includes enforcing \u003ca href\u003d\"/radar/techniques/security-policy-as-code\"\u003epolicies as code\u003c/a\u003e based on the least privilege and as-granular-as-possible principles and continuous monitoring and automated mitigation of threats; using \u003ca href\u003d\"/radar/techniques/service-mesh\"\u003eservice mesh\u003c/a\u003e to enforce security control application-to-service and service-to-service; implementing \u003ca href\u003d\"/radar/techniques/binary-attestation\"\u003ebinary attestation\u003c/a\u003e to verify the origin of the binaries; and including \u003ca href\u003d\"/radar/techniques/secure-enclaves\"\u003esecure enclaves\u003c/a\u003e in addition to traditional encryption to enforce the three pillars of data security: in transit, at rest and in memory. For introductions to the topic, consult the \u003ca href\u003d\"https://csrc.nist.gov/publications/detail/sp/800-207/final\"\u003eNIST ZTA\u003c/a\u003e publication and Google\u0027s white paper on \u003ca href\u003d\"https://cloud.google.com/security/beyondprod\"\u003eBeyondProd\u003c/a\u003e.\u003c/p\u003e","blip_status":"move_in","theta":"113","volume":"2021-10"},{"name":"CBOR/JSON bilingual protocols","id":"202110012","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"4","display_name":"CBOR/JSON bilingual protocols","radius":"250","description":"\u003cp\u003eAlthough it’s been around for a while, we\u0027re seeing more and more use cases where using the \u003ca href\u003d\"http://cbor.io/\"\u003eCBOR\u003c/a\u003e specification for data interchange makes sense — especially in environments containing multiple types of applications communicating with one another: service to service, browser to service, and so on. One thing we\u0027ve found useful with \u003ca href\u003d\"https://github.com/sirthias/borer\"\u003eBorer\u003c/a\u003e, a Scala implementation of a CBOR encoder/decoder, is the ability for clients to negotiate content between the binary representation and plain old JSON format. It\u0027s quite useful to have a text version viewable in a browser as well as the concise binary format. We foresee \u003cstrong\u003eCBOR/JSON bilingual protocols\u003c/strong\u003e picking up in popularity with the continuing rise of IoT and edge computing and other situations where the environment is tightly constrained.\u003c/p\u003e","blip_status":"t","theta":"169","volume":"2021-10"},{"name":"Data mesh","id":"201911051","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"5","display_name":"Data mesh","radius":"170","description":"\u003cp\u003eIncreasingly, we see a mismatch between what data-driven organizations want to achieve and what the current data architectures and organizational structures allow. Organizations want to embed data-driven decision-making, machine learning and analytics into many aspects of their products and services and how they operate internally; essentially they want to augment every aspect of their operational landscape with data-driven intelligence. Yet, we still have a ways to go before we can embed analytical data, access to it and how it is managed into the business domains and operations. Today, every aspect of managing analytical data is externalized outside of the operational business domains to the data team and to the data management monoliths: data lakes and data warehouses. \u003cstrong\u003e\u003ca href\u003d\"https://martinfowler.com/articles/data-monolith-to-mesh.html\"\u003eData mesh\u003c/a\u003e\u003c/strong\u003e is a decentralized sociotechnical approach to remove the dichotomy of analytical data and business operation. Its objective is to embed sharing and using analytical data into each operational business domain and close the gap between the operational and analytical planes. It\u0027s founded on four principles: domain data ownership, data as a product, self-serve data platform and computational federated governance.\u003c/p\u003e\n\n\u003cp\u003eOur teams have been implementing the \u003ca href\u003d\"https://martinfowler.com/articles/data-mesh-principles.html\"\u003edata mesh architecture\u003c/a\u003e; they\u0027ve created new architectural abstractions such as the data product quantum to encapsulate the code, data and policy as an autonomous unit of analytical data sharing embedded into operational domains; and they\u0027ve built self-serve data platform capabilities to manage the lifecycle of data product quanta in a declarative manner as described in \u003cem\u003e\u003ca href\u003d\"https://www.oreilly.com/library/view/data-mesh/9781492092384/\"\u003eData Mesh\u003c/a\u003e\u003c/em\u003e. Despite our technical advances, we\u0027re still experiencing friction using the existing technologies in a data mesh topology, not to mention the resistance of business domains to embrace sharing and using data as a first-class responsibility in some organizations.\u003c/p\u003e","blip_status":"c","theta":"158","volume":"2021-10"},{"name":"Living documentation in legacy systems","id":"202110020","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"6","display_name":"Living documentation in legacy systems","radius":"200","description":"\u003cp\u003e\u003ca href\u003d\"https://livebook.manning.com/book/specification-by-example/chapter-3/\"\u003eLiving documentation\u003c/a\u003e, which comes from the behavior-driven development (BDD) community, is often considered a privilege for those well-maintained codebases with executable specifications. We found that this technique can also be applied to legacy systems. Lack of business knowledge is a common obstacle encountered by teams when doing system modernization. Code is usually the only trustworthy source of truth because staff turnover and existing documentation are outdated. Therefore it\u0027s very important to reestablish the association between the documentation and the code and spread the business knowledge among the team when we take over a legacy system. In practice, we would first try to go to the codebase and deepen our understanding of the business through simple cleanup and safe refactoring. During the process, we\u0027ll need to add annotations to the code so that we\u0027re able to automatically generate living documentation later. This is very different from doing BDD in green-field projects, but it\u0027s a good start in legacy systems. Based on the generated documentation, we would try to convert some of the specs into executable high-level automation tests. Do this iteratively, and eventually you could get \u003cstrong\u003eliving documentation in legacy systems\u003c/strong\u003e that is closely associated with the code and partially executable.\u003c/p\u003e","blip_status":"t","theta":"147","volume":"2021-10"},{"name":"Micro frontends for mobile","id":"202005013","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"7","display_name":"Micro frontends for mobile","radius":"200","description":"\u003cp\u003eSince introducing them in the Radar in 2016, we\u0027ve seen widespread adoption of \u003ca href\u003d\"/radar/techniques/micro-frontends\"\u003emicro frontends\u003c/a\u003e for web UIs. Recently, however, we\u0027ve seen projects extend this architectural style to include \u003cstrong\u003emicro frontends for mobile\u003c/strong\u003e applications as well. When the application becomes sufficiently large and complex, it becomes necessary to distribute the development over multiple teams. This presents the challenge of maintaining team autonomy while integrating their work into a single app. Some teams write their own frameworks to enable this development style, and in the past we\u0027ve mentioned \u003ca href\u003d\"/radar/languages-and-frameworks/atlas-and-beehive\"\u003eAtlas and Beehive\u003c/a\u003e as possible ways to simplify the problem of integrating multiteam app development. More recently, we\u0027ve seen teams using \u003ca href\u003d\"/radar/languages-and-frameworks/react-native\"\u003eReact Native\u003c/a\u003e to accomplish the same thing. Each React Native micro frontend is kept in its own repository where it can be built, tested and deployed separately. The team responsible for the overall application can then aggregate those micro frontends built by different teams into a single released app.\u003c/p\u003e","blip_status":"c","theta":"135","volume":"2021-10"},{"name":"Remote mob programming","id":"202104052","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"8","display_name":"Remote mob programming","radius":"250","description":"\u003cp\u003eWe continue to see many teams working and collaborating remotely; for these teams \u003cstrong\u003eremote mob programming\u003c/strong\u003e is a technique that is well worth trying. Remote mob programming allows teams to quickly \"mob\" around an issue or piece of code without the physical constraints of only being able to fit so many people around a pairing station. Teams can quickly collaborate on an issue or piece of code using their video conferencing tool of choice without having to connect to a big display, book a physical meeting room or find a whiteboard.\u003c/p\u003e","blip_status":"move_in","theta":"124","volume":"2021-10"},{"name":"Single team remote wall","id":"202110040","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"9","display_name":"Single team remote wall","radius":"240","description":"\u003cp\u003eWith the increased use of remote distributed teams, one of the things we hear people have missed having is the physical team wall. This is a single place where all the various story cards, tasks, status and progress can be displayed, acting as an information radiator and hub for the team. Often the wall was an integration point with the actual data being stored in different systems. As teams have become remote, they\u0027ve had to revert to looking into the individual source systems and getting an \"at a glance\" view of a project has become very difficult. A \u003cstrong\u003esingle team remote wall\u003c/strong\u003e is a simple technique to reintroduce the team wall virtually. While there might be some overhead in keeping this up-to-date, we feel the benefits to the team are worth it. For some teams, updating the physical wall formed part of the daily \"ceremonies\" the team did together, and the same can be done with a remote wall.\u003c/p\u003e","blip_status":"t","theta":"113","volume":"2021-10"},{"name":"Team cognitive load","id":"202104127","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"10","display_name":"Team cognitive load","radius":"170","description":"\u003cp\u003eA system\u0027s architecture mimics organizational structure and its communication. It\u0027s not big news that we should be intentional about how teams interact — see, for instance, the \u003ca href\u003d\"/radar/techniques/inverse-conway-maneuver\"\u003eInverse Conway Maneuver\u003c/a\u003e. Team interaction is one of the variables for how fast and how easily teams can deliver value to their customers. We were happy to find a way to measure these interactions; we used the \u003ca href\u003d\"https://teamtopologies.com/book\"\u003eTeam Topologies\u003c/a\u003e author\u0027s \u003ca href\u003d\"https://github.com/TeamTopologies/Team-Cognitive-Load-Assessment\"\u003eassessment\u003c/a\u003e which gives you an understanding of how easy or difficult the teams find it to build, test and maintain their services. By measuring \u003cstrong\u003eteam cognitive load\u003c/strong\u003e, we could better advise our clients on how to change their teams\u0027 structure and evolve their interactions.\u003c/p\u003e","blip_status":"c","theta":"102","volume":"2021-10"},{"name":"AR spatial anchors","id":"202110070","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"11","display_name":"AR spatial anchors","radius":"320","description":"\u003cp\u003eMany augmented reality (AR) applications depend on knowing the location and orientation of the user\u0027s device. The default is to use GPS-based solutions, but \u003cstrong\u003espatial anchors\u003c/strong\u003e, a newer technique to address this requirement, are also worth considering. Spatial anchors work with the image recorded by the device\u0027s camera, using image features and their relative position in 3D space to recognize a real-world location. For this location a corresponding anchor is created in the AR space. Although spatial anchors can\u0027t replace all GPS and marker-based anchors, they do provide more accuracy than most GPS-based solutions and are more resilient to different viewing angles than marker-based anchors. Our experience is currently limited to Google\u0027s \u003ca href\u003d\"https://developers.google.com/ar/develop/java/cloud-anchors/overview-android\"\u003eCloud Anchors for Android\u003c/a\u003e, which worked well for us. Somewhat uncharacteristically Google also offers \u003ca href\u003d\"https://developers.google.com/ar/develop/ios/cloud-anchors/quickstart\"\u003eCloud Anchors for iOS\u003c/a\u003e and with \u003ca href\u003d\"https://docs.microsoft.com/en-us/azure/spatial-anchors/overview\"\u003eAzure Spatial Anchors\u003c/a\u003e Microsoft supports even more platforms.\u003c/p\u003e","blip_status":"t","theta":"165","volume":"2021-10"},{"name":"Hotwire","id":"202104066","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"12","display_name":"Hotwire","radius":"320","description":"\u003cp\u003eAfter successfully launching their email application \u003ca href\u003d\"https://hey.com/\"\u003eHEY\u003c/a\u003e as a server-side application, Basecamp \u003ca href\u003d\"https://world.hey.com/dhh/bringing-hotwire-to-basecamp-91a442d6\"\u003ereported\u003c/a\u003e migrating its flagship product, \u003ca href\u003d\"https://basecamp.com/\"\u003eBasecamp 3\u003c/a\u003e, to \u003cstrong\u003e\u003ca href\u003d\"https://hotwire.dev/\"\u003eHotwire\u003c/a\u003e\u003c/strong\u003e this summer. As organizations increasingly default to single-page applications (SPAs) for new web development, we continue to be excited by Hotwire swimming against the stream. Unlike SPAs, Hotwire applications keep most of the logic and navigation on the server, relying on a minimal amount of browser JavaScript. Hotwire modularizes HTML pages into a set of components (called \u003ca href\u003d\"https://turbo.hotwired.dev/\"\u003eTurbo Frames\u003c/a\u003e) that can be lazy loaded, provide independent contexts and send HTML updates to those contexts based on user actions. SPAs offer undeniable user responsiveness, but the simplicity of traditional server-side web programming combined with modern browser tooling provides a refreshing take on balancing developer effectiveness and user responsiveness.\u003c/p\u003e","blip_status":"c","theta":"150","volume":"2021-10"},{"name":"Operator pattern for nonclustered resources","id":"202110008","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"13","display_name":"Operator pattern for nonclustered resources","radius":"310","description":"\u003cp\u003eWe\u0027re seeing increasing use of the \u003ca href\u003d\"/radar/tools/kubernetes-operators\"\u003eKubernetes Operator\u003c/a\u003e pattern for purposes other than managing applications deployed on the cluster. Using the \u003cstrong\u003eoperator pattern for nonclustered resources\u003c/strong\u003e takes advantage of custom resource definitions and the event-driven scheduling mechanism implemented in the Kubernetes control plane to manage activities that are related to yet outside of the cluster. This technique builds on the idea of \u003ca href\u003d\"/radar/techniques/kube-managed-cloud-services\"\u003eKube-managed cloud services\u003c/a\u003e and extends it to other activities, such as continuous deployment or reacting to changes in external repositories. One advantage of this technique over a purpose-built tool is that it opens up a wide range of tools that either come with Kubernetes or are part of the wider ecosystem. You can use commands such as \u003ccode\u003ediff\u003c/code\u003e, \u003ccode\u003edry-run\u003c/code\u003e or \u003ccode\u003eapply\u003c/code\u003e to interact with the operator\u0027s custom resources. Kube\u0027s scheduling mechanism makes development easier by eliminating the need to orchestrate activities in the proper order. Open-source tools such as \u003ca href\u003d\"/radar/tools/crossplane\"\u003eCrossplane\u003c/a\u003e, \u003ca href\u003d\"https://fluxcd.io/\"\u003eFlux\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/argo-cd\"\u003eArgoCD\u003c/a\u003e take advantage of this technique and we expect to see more of these emerge over time.\u003c/p\u003e","blip_status":"t","theta":"135","volume":"2021-10"},{"name":"Remote spontaneous huddling","id":"202110021","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"14","display_name":"Remote spontaneous huddling","radius":"300","description":"\u003cp\u003eWe\u0027re seeing continued innovation in remote collaboration tools. The new \u003ca href\u003d\"https://slack.com/help/articles/4402059015315-Start-a-huddle-in-a-channel-or-direct-message\"\u003eHuddles\u003c/a\u003e feature in Slack provides a Discord-like experience of persistent audio calls that users can jump in and out of at any time. \u003ca href\u003d\"https://www.gather.town/\"\u003eGather\u003c/a\u003e provides a creative way to emulate a virtual office with avatars and video. IDEs provide direct collaboration features for pairing and debugging: we\u0027ve previously blipped \u003ca href\u003d\"/radar/tools/visual-studio-live-share\"\u003eVisual Studio Live Share\u003c/a\u003e and included \u003ca href\u003d\"/radar/tools/code-with-me\"\u003eJetBrains Code With Me\u003c/a\u003e to the list in this edition. As tools continue to evolve modalities for collaboration in addition to video conferencing, we\u0027re increasingly seeing teams participating in \u003cstrong\u003eremote spontaneous huddling\u003c/strong\u003e, recreating the spontaneity of informal conversations over the intentionality of scheduling a Zoom or Microsoft Teams meeting. We don\u0027t expect to ever fully recreate the richness of face-to-face communication through digital tools, but we do see improved remote team effectiveness by giving teams multiple channels of collaboration rather than relying on one toolchain for everything.\u003c/p\u003e","blip_status":"t","theta":"120","volume":"2021-10"},{"name":"Software Bill of Materials","id":"202110076","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"15","display_name":"Software Bill of Materials","radius":"300","description":"\u003cp\u003eIn May 2021, the U.S. White House published its \u003ca href\u003d\"https://www.whitehouse.gov/briefing-room/presidential-actions/2021/05/12/executive-order-on-improving-the-nations-cybersecurity/\"\u003eExecutive Order on Improving the Nation\u0027s Cybersecurity\u003c/a\u003e. The document puts forward several technical mandates that relate to items we\u0027ve featured in past Radars, such as \u003ca href\u003d\"/radar/techniques/zero-trust-architecture\"\u003ezero trust architecture\u003c/a\u003e and automated compliance scanning using \u003ca href\u003d\"/radar/techniques/security-policy-as-code\"\u003esecurity policy as code\u003c/a\u003e. Much of the document is devoted to improving the security of the software supply chain. One item in particular that caught our attention was the requirement that government software should contain a machine-readable \u003cstrong\u003eSoftware Bill of Materials (SBOM)\u003c/strong\u003e, defined as \"a formal record containing the details and supply chain relationships of various components used in building software.\" In other words, it should detail not just the components shipped but also the tools and frameworks used to deliver the software. This order has the potential to usher in a new era of transparency and openness in software development. This will undoubtedly have an impact on those of us who produce software for a living. Many, if not all software products produced today contain open-source components or employ them in the build process. Often, the consumer has no way of knowing which version of which package might have an impact on the security of their product. Instead they must rely on the security alerts and patches provided by the retail vendor. This executive order will ensure that an explicit description of all components is made available to consumers, empowering them to implement their own security controls. And since the SBOM is machine-readable, those controls can be automated. We sense that this move also represents a shift toward embracing open-source software and practically addressing both the security risks and benefits that it provides.\u003c/p\u003e","blip_status":"t","theta":"105","volume":"2021-10"},{"name":"Peer review equals pull request","id":"202104068","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"16","display_name":"Peer review equals pull request","radius":"385","description":"\u003cp\u003eSome organizations seem to think \u003cstrong\u003epeer review equals pull request\u003c/strong\u003e; they\u0027ve taken the view that the only way to achieve a peer review of code is via a pull request. We\u0027ve seen this approach create significant team bottlenecks as well as significantly degrade the quality of feedback as overloaded reviewers begin to simply reject requests. Although the argument could be made that this is one way to demonstrate code review \"regulatory compliance,\" one of our clients was told this was invalid since there was no evidence the code was actually read by anyone prior to acceptance. Pull requests are only one way to manage the code review workflow; we urge people to consider other approaches, especially where there is a need to coach and pass on feedback carefully.\u003c/p\u003e","blip_status":"c","theta":"150","volume":"2021-10"},{"name":"Production data in test environments","id":"202110036","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"17","display_name":"Production data in test environments","radius":"385","description":"\u003cp\u003eWe continue to perceive \u003cstrong\u003eproduction data in test environments\u003c/strong\u003e as an area for concern. Firstly, many examples of this have resulted in reputational damage, for example, where an incorrect alert has been sent from a test system to an entire client population. Secondly, the level of security, specifically around protection of private data, tends to be less for test systems. There is little point in having elaborate controls around access to production data if that data is copied to a test database that can be accessed by every developer and QA. Although you \u003cem\u003ecan\u003c/em\u003e obfuscate the data, this tends to be applied only to specific fields, for example, credit card numbers. Finally, copying production data to test systems can break privacy laws, for example, where test systems are hosted or accessed from a different country or region. This last scenario is especially problematic with complex cloud deployments. Fake data is a safer approach, and tools exist to help in its creation. We do recognize there are reasons for \u003cem\u003especific\u003c/em\u003e elements of production data to be copied, for example, in the reproduction of bugs or for training of specific ML models. Here our advice is to proceed with caution.\u003c/p\u003e","blip_status":"t","theta":"120","volume":"2021-10"},{"name":"Backstage","id":"202010066","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"18","display_name":"Backstage","radius":"180","description":"\u003cp\u003eAs the focus on improving the developer experience and efficiency increases across organizations, we\u0027re seeing \u003cstrong\u003e\u003ca href\u003d\"https://backstage.io/\"\u003eBackstage\u003c/a\u003e\u003c/strong\u003e rise in popularity, alongside the adoption of developer portals. These organizations are looking to support and streamline their development environments. As the number of tools and technologies increases, some form of standardization is becoming increasingly important for consistency so that developers can focus on innovation and product development instead of getting bogged down with reinventing the wheel. Backstage is an open-source developer portal platform created by Spotify. It\u0027s based on software templates, unifying infrastructure tooling and consistent and centralized technical documentation. The plugin architecture allows for extensibility and adaptability into an organization\u0027s infrastructure ecosystem. We\u0027ll be watching the new \u003ca href\u003d\"https://backstage.io/docs/features/software-catalog/software-catalog-overview\"\u003eBackstage Service Catalog\u003c/a\u003e, currently in alpha, which keeps track of ownership and metadata for all the software in an organization\u0027s ecosystem.\u003c/p\u003e","blip_status":"c","theta":"186","volume":"2021-10"},{"name":"ClickHouse","id":"202110002","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"19","display_name":"ClickHouse","radius":"240","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://clickhouse.com/\"\u003eClickHouse\u003c/a\u003e\u003c/strong\u003e is an open-source, columnar online analytical processing (OLAP) database for real-time analytics. It started as an experimental project in 2009 and since has matured into a highly performant and linearly scalable analytical database. It\u0027s efficient query processing engine together with data compression makes it suitable to run interactive queries without pre-aggregation. We\u0027ve used ClickHouse and are quite impressed with its performance.\u003c/p\u003e","blip_status":"t","theta":"193","volume":"2021-10"},{"name":"Confluent Kafka REST Proxy","id":"202110003","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"20","display_name":"Confluent Kafka REST Proxy","radius":"200","description":"\u003cp\u003eKafka is a common default for event-driven architectures, but adapting it to legacy environments introduces an impedance mismatch. In a few cases, we\u0027ve had success minimizing the legacy complexity using \u003ca href\u003d\"https://docs.confluent.io/3.0.0/kafka-rest/docs/index.html\"\u003e\u003cstrong\u003eConfluent Kafka REST Proxy\u003c/strong\u003e\u003c/a\u003e. The proxy allows developers to access Kafka through an HTTP interface, which is useful in environments that make using the native Kafka protocol difficult. For example, we were able to consume events emitted through SAP simply by having the SAP team invoke an HTTP POST command through a preconfigured SAP remote function call, avoiding the need to spin up a Java abstraction around SAP (and a team to manage it). The proxy is quite full-featured, although, as with any such adapter tool, we recommend caution and a clear-eyed view of the trade-offs involved. We believe the proxy is valuable when it enables legacy producers to send events, but would be careful creating event consumers through the proxy as the abstraction gets more complex. The proxy doesn\u0027t change the fact that Kafka consumers are stateful, which means that consumer instances created through the REST API are tied to a specific proxy, and the need to make an HTTP call to consume messages from a topic changes the standard semantics of Kafka eventing.\u003c/p\u003e","blip_status":"t","theta":"200","volume":"2021-10"},{"name":"GitHub Actions","id":"202104005","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"21","display_name":"GitHub Actions","radius":"240","description":"\u003cp\u003eDespite our cautionary advice when we last blipped it, we\u0027ve seen continued enthusiasm for \u003cstrong\u003e\u003ca href\u003d\"https://docs.github.com/en/actions\"\u003eGitHub Actions\u003c/a\u003e\u003c/strong\u003e. What we said before still holds true: GitHub Actions is not yet a full-fledged CI/CD replacement for complex workflows. It cannot, for example, re-trigger a single job of a workflow, call other actions inside a composite action or support a shared library. Furthermore, while the ecosystem in the \u003ca href\u003d\"https://github.com/marketplace?type\u003dactions\"\u003eGitHub Marketplace\u003c/a\u003e offers obvious advantages, giving third-party GitHub Actions access to your build pipeline risks sharing secrets in insecure ways (we recommend following GitHub\u0027s advice on \u003ca href\u003d\"https://docs.github.com/en/actions/security-guides/security-hardening-for-github-actions\"\u003esecurity hardening\u003c/a\u003e). Despite those concerns, the convenience of creating your build workflow directly in GitHub next to your source code is a compelling option for some teams, and \u003ca href\u003d\"https://github.com/nektos/act\"\u003eact\u003c/a\u003e helps you run GitHub Actions locally. As always, we recommend a clear-eyed assessment of the trade-offs, but some of our teams are happy with the simplicity of GitHub Actions.\u003c/p\u003e","blip_status":"move_in","theta":"207","volume":"2021-10"},{"name":"K3s","id":"202010039","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"22","display_name":"K3s","radius":"255","description":"\u003cp\u003e\u003ca href\u003d\"https://k3s.io/\"\u003e\u003cstrong\u003eK3s\u003c/strong\u003e\u003c/a\u003e is a lightweight Kubernetes distribution built for IoT and edge computing. You get the benefits of a fully compliant Kubernetes but with reduced operational overhead. Its enhancements include lightweight storage backends (\u003ca href\u003d\"https://docs.python.org/3/library/sqlite3.html\"\u003esqlite3\u003c/a\u003e as default instead of \u003ca href\u003d\"https://etcd.io/\"\u003eetcd\u003c/a\u003e), a single binary package with minimal OS dependencies and reduced memory footprint, all of which make K3s suitable for resource-constrained environments. We\u0027ve used K3s in point-of-sale machines, and we\u0027re quite happy with our decision.\u003c/p\u003e","blip_status":"move_in","theta":"214","volume":"2021-10"},{"name":"Mambu","id":"202110028","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"23","display_name":"Mambu","radius":"210","description":"\u003cp\u003e\u003ca href\u003d\"https://www.mambu.com/\"\u003e\u003cstrong\u003eMambu\u003c/strong\u003e\u003c/a\u003e is a SaaS cloud banking platform. It empowers customers to easily and flexibly build and change their banking and lending products. Unlike other out-of-box core banking platforms that you can only adapt with hard-coded integration, Mambu is designed for constantly changing financial offerings. It comes with an opinionated workflow, while also providing an API-driven approach to customize business logic, process and integrations. We currently have several projects using Mambu. With its cloud-based scalability and highly customizable capabilities, it\u0027s becoming one of the sensible default domain systems when building financial products.\u003c/p\u003e","blip_status":"t","theta":"221","volume":"2021-10"},{"name":"MirrorMaker 2.0","id":"202110018","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"24","display_name":"MirrorMaker 2.0","radius":"230","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-382%3A+MirrorMaker+2.0\"\u003eMirrorMaker 2.0\u003c/a\u003e\u003c/strong\u003e (also known as MM2), built using the Kafka Connect framework, solves many tool shortcomings of previous Kafka replication approaches. It can successfully \u003ca href\u003d\"https://kafka.apache.org/documentation/#georeplication\"\u003egeo-replicate\u003c/a\u003e topic data and metadata across clusters, including offsets, consumer groups and authorization command lines (ACLs). MM2 preserves partitioning and detects new topics and partitions. We appreciated the ability to stage a cluster migration over time, an approach that can be useful in migrating from an on-prem cluster to a cloud cluster. After synchronizing the topics and consumer groups, we first migrated the clients to the new cluster location, then we migrated the producers to the new location and finally turned off MM2 and decommissioned the old cluster. We\u0027ve also seen MM2 used in disaster recovery and high-availability scenarios.\u003c/p\u003e","blip_status":"t","theta":"228","volume":"2021-10"},{"name":"OPA Gatekeeper for Kubernetes","id":"202110025","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"25","display_name":"OPA Gatekeeper for Kubernetes","radius":"190","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://kubernetes.io/blog/2019/08/06/opa-gatekeeper-policy-and-governance-for-kubernetes/\"\u003eOPA Gatekeeper for Kubernetes\u003c/a\u003e\u003c/strong\u003e is a customizable admission webhook for \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e that enforces policies executed by the \u003ca href\u003d\"/radar/tools/open-policy-agent-opa\"\u003eOpen Policy Agent (OPA)\u003c/a\u003e. We\u0027re using this extension of the Kubernetes platform to add a security layer to clusters, providing automated governance mechanisms that ensure applications are compliant with defined policies. Our teams like it because of its customization capability; using CustomResourceDefinitions (CRD) allows us to define ConstraintTemplates and Constraints which make defining rules and the objects (e.g., deployments, jobs, cron jobs) and namespaces under evaluation an easy task.\u003c/p\u003e","blip_status":"t","theta":"233","volume":"2021-10"},{"name":"Pulumi","id":"1283","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"26","display_name":"Pulumi","radius":"180","description":"\u003cp\u003eWe\u0027ve been seeing an increase in teams using \u003cstrong\u003e\u003ca href\u003d\"https://pulumi.io/\"\u003ePulumi\u003c/a\u003e\u003c/strong\u003e in various organizations. Pulumi fills a gaping hole in the infrastructure coding world where \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e maintains a firm hold. While Terraform is a tried-and-true standby, its declarative nature suffers from inadequate abstraction facilities and limited testability. Terraform is adequate when the infrastructure is entirely static, but dynamic infrastructure definitions call for a real programming language. Pulumi distinguishes itself by allowing configurations to be written in \u003ca href\u003d\"/radar/languages-and-frameworks/typescript\"\u003eTypeScript\u003c/a\u003e/JavaScript, \u003ca href\u003d\"/radar/languages-and-frameworks/python-3\"\u003ePython\u003c/a\u003e and \u003ca href\u003d\"/radar/languages-and-frameworks/go-language\"\u003eGo\u003c/a\u003e — no markup language or templating required. Pulumi is tightly focused on cloud-native architectures — including containers, serverless functions and data services — and provides good support for \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e. Recently, \u003ca href\u003d\"/radar/platforms/aws-cloud-development-kit\"\u003eAWS CDK\u003c/a\u003e has mounted a challenge, but Pulumi remains the only cloud-neutral tool in this area.\u003c/p\u003e","blip_status":"move_in","theta":"242","volume":"2021-10"},{"name":"Sealed Secrets","id":"202110092","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"27","display_name":"Sealed Secrets","radius":"200","description":"\u003cp\u003e\u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e natively supports a key-value object known as a secret. However, by default, Kubernetes secrets aren\u0027t really secret. They\u0027re handled separately from other key-value data so that precautions or access control can be applied separately. There is support for encrypting secrets before they are stored in \u003ca href\u003d\"https://etcd.io/\"\u003eetcd\u003c/a\u003e, but the secrets start out as plain text fields in configuration files. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/bitnami-labs/sealed-secrets\"\u003eSealed Secrets\u003c/a\u003e\u003c/strong\u003e is a combination operator and command-line utility that uses asymmetric keys to encrypt secrets so that they can only be decrypted by the controller in the cluster. This process ensures that the secrets won\u0027t be compromised while they sit in the configuration files that define a Kubernetes deployment. Once encrypted, these files can be safely shared or stored alongside other deployment artifacts.\u003c/p\u003e","blip_status":"t","theta":"249","volume":"2021-10"},{"name":"Vercel","id":"202110041","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"28","display_name":"Vercel","radius":"220","description":"\u003cp\u003eSince we first evaluated \u003ca href\u003d\"/radar/techniques/jamstack\"\u003eJAMstack\u003c/a\u003e, we\u0027ve seen more and more web applications of this style. However, when the infrastructure for building traditional dynamic websites and back-end services is too heavy for JAMstack, our teams choose \u003ca href\u003d\"https://vercel.com/\"\u003e\u003cstrong\u003eVercel\u003c/strong\u003e\u003c/a\u003e. Vercel is a cloud platform for static site hosting. More importantly, it provides a seamless workflow for developing, previewing and shipping JAMstack sites. The configuration for the deployment is quite simple. By integrating with GitHub, each code commit or pull request could trigger a new website deployment that has a URL for preview, which greatly accelerates development feedback. Vercel also uses CDN to scale and speed up production sites. It\u0027s worth mentioning that the team behind Vercel also supports another popular framework, \u003ca href\u003d\"/radar/languages-and-frameworks/next-js\"\u003eNext.js\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"256","volume":"2021-10"},{"name":"Weights \u0026 Biases","id":"202110042","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"29","display_name":"Weights \u0026 Biases","radius":"230","description":"\u003cp\u003e\u003ca href\u003d\"https://wandb.ai/\"\u003e\u003cstrong\u003eWeights \u0026 Biases\u003c/strong\u003e\u003c/a\u003e is a machine learning (ML) platform for building models faster through experiment tracking, data set versioning, visualizing model performance and model management. You can integrate it with existing ML code and quickly get live metrics, terminal logs and system statistics streamed to the dashboard for further analysis. Our teams have used Weights \u0026 Biases, and we like its collaborative approach to model building.\u003c/p\u003e","blip_status":"t","theta":"263","volume":"2021-10"},{"name":"Azure Cognitive Search","id":"202110024","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"30","display_name":"Azure Cognitive Search","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://docs.microsoft.com/en-us/azure/search/\"\u003eAzure Cognitive Search\u003c/a\u003e\u003c/strong\u003e provides search as a service for applications that require text search over heterogeneous content. It provides push or pull-based APIs to upload and index images, unstructured text or structured document content, with \u003ca href\u003d\"https://docs.microsoft.com/en-us/rest/api/searchservice/create-data-source\"\u003elimitations on supported pull-based data source types\u003c/a\u003e. It provides APIs over REST and .NET SDK to execute search queries, either using a simple query language or more powerful \u003ca href\u003d\"https://lucene.apache.org/\"\u003eApache Lucene\u003c/a\u003e queries with field-scoped queries, fuzzy search, infix and suffix wildcard search and regular expression search, among other features. We\u0027ve successfully used Azure Cognitive Search alongside other Azure services, including searching content uploaded from \u003ca href\u003d\"https://azure.microsoft.com/en-us/services/cosmos-db/\"\u003eCosmos DB\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"191","volume":"2021-10"},{"name":"Babashka","id":"202110080","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"31","display_name":"Babashka","radius":"330","description":"\u003cp\u003eEven today, considering all the development and infrastructure tools at our disposal, we often reach a point where we need a script to glue several things together or to automate a recurring task. Current favorites for writing these scripts are bash and Python, but we\u0027re happy to report that there\u0027s a new, exciting option: Clojure. This is made possible with \u003cstrong\u003e\u003ca href\u003d\"https://babashka.org/\"\u003eBabashka\u003c/a\u003e\u003c/strong\u003e, a complete Clojure run time implemented with \u003ca href\u003d\"/radar/platforms/graalvm\"\u003eGraalVM\u003c/a\u003e. Babashka ships with libraries that cover most of the use cases for which you\u0027d use a scripting tool, and loading of further libraries is possible, too. The use of GraalVM brings startup times within range of native tools, and it also makes Babashka one of the few options for a multithreaded scripting environment, for those rare cases when it\u0027s needed.\u003c/p\u003e","blip_status":"t","theta":"202","volume":"2021-10"},{"name":"ExternalDNS","id":"202110045","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"32","display_name":"ExternalDNS","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/kubernetes-sigs/external-dns\"\u003eExternalDNS\u003c/a\u003e\u003c/strong\u003e synchronizes Kubernetes ingresses and services with external DNS providers, filling a hole previously filled by \u003ca href\u003d\"https://github.com/kubernetes/kops/tree/HEAD/dns-controller\"\u003ekops dns-controller\u003c/a\u003e, \u003ca href\u003d\"https://github.com/linki/mate\"\u003eZalando\u0027s Mate\u003c/a\u003e or \u003ca href\u003d\"https://github.com/wearemolecule/route53-kubernetes\"\u003eroute53-kubernetes\u003c/a\u003e — the last two of which have been deprecated in favor of ExternalDNS. The tool makes internal Kubernetes resources discoverable via public DNS servers, removing a sometimes manual step to update DNS records when an ingress host or service\u0027s IP address changes. It supports a huge list of DNS service providers out of the box with more being added via community support. As the old joke goes, \u003ca href\u003d\"https://imgur.com/YKvOiA4\"\u003eit\u0027s always DNS\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"213","volume":"2021-10"},{"name":"Konga","id":"202110019","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"33","display_name":"Konga","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"https://pantsel.github.io/konga/\"\u003e\u003cstrong\u003eKonga\u003c/strong\u003e\u003c/a\u003e is an open-source UI for administering the \u003ca href\u003d\"/radar/tools/kong-api-gateway\"\u003eKong API Gateway\u003c/a\u003e, previously featured in the Radar in Trial. Our teams liked the quick setup and rich feature set that allowed them to experiment with and try out configurations easily. And the fact it\u0027s open-source software eases concerns about licensing costs.\u003c/p\u003e","blip_status":"t","theta":"225","volume":"2021-10"},{"name":"Milvus 2.0","id":"202110086","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"34","display_name":"Milvus 2.0","radius":"320","description":"\u003cp\u003e\u003ca href\u003d\"https://github.com/milvus-io/milvus\"\u003e\u003cstrong\u003eMilvus 2.0\u003c/strong\u003e\u003c/a\u003e is a cloud-native, open-source vector database built to search and manage embedding vectors generated by machine-learning models and neural networks. It supports several \u003ca href\u003d\"https://milvus.io/docs/index_selection.md\"\u003evector indexes\u003c/a\u003e for approximate nearest neighbors (ANN) search across embedding vectors of audio, video, image or any unstructured data. Milvus 2.0 is a relatively new database, and we recommend you assess it for your similarity search needs.\u003c/p\u003e","blip_status":"t","theta":"236","volume":"2021-10"},{"name":"Thought Machine Vault","id":"202110078","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"35","display_name":"Thought Machine Vault","radius":"300","description":"\u003cp\u003eIt\u0027s rare for us to feature commercial, off-the-shelf software in the Radar, much less a core banking platform. However, \u003cstrong\u003e\u003ca href\u003d\"https://thoughtmachine.net/vault\"\u003eThought Machine Vault\u003c/a\u003e\u003c/strong\u003e (no connection to Thoughtworks) is an example of a product in this class designed to support good software engineering practices such as test-driven development, continuous delivery and infrastructure as code. Developers define banking products in Vault by writing smart contracts in Python code. This is distinctly different from the standard no-code approach where customization is done through graphical interfaces or proprietary configuration files or both. Because products are defined in regular Python code, developers have access to a range of tools such as test frameworks and version control to ensure that their work is safe and accurate. We wish more financial services platforms were designed with developer effectiveness in mind.\u003c/p\u003e","blip_status":"t","theta":"247","volume":"2021-10"},{"name":"XTDB","id":"201911009","quadrant":"Platforms","ring":"Assess","movement":"c","radarId":"36","display_name":"XTDB","radius":"310","description":"\u003cp\u003e\u003ca href\u003d\"https://www.xtdb.com/main/index.html\"\u003e\u003cstrong\u003eXTDB\u003c/strong\u003e\u003c/a\u003e is an open-source document database with bitemporal graph queries. It natively supports two time axes for each record: \u003cem\u003evalid\u003c/em\u003e time, when a fact occurs, and \u003cem\u003etransaction\u003c/em\u003e time, when a fact is processed and recorded by the database. Support for bitemporality is beneficial in numerous scenarios, including analytical use cases executing time-aware queries; auditing historical changes to facts; supporting distributed data architectures that must guarantee globally consistent point-in-time queries such as \u003ca href\u003d\"/radar/techniques/data-mesh\"\u003edata mesh\u003c/a\u003e; and preserving data immutability. XTDB takes information in document form, expressed in the Extensible Data Notation (EDN) format, a subset of the Clojure language. XTDB supports graph as well as SQL queries and is extensible through a REST API layer and Kafka Connect, among other modules. We\u0027re excited to see a growth in adoption of XTDB and the addition of features such as support for transactions and SQL.\u003c/p\u003e","blip_status":"c","theta":"258","volume":"2021-10"},{"name":"fastlane","id":"1018","quadrant":"Tools","ring":"Adopt","movement":"c","radarId":"37","display_name":"fastlane","radius":"85","description":"\u003cp\u003eReleasing applications for iOS involves a code-signing step. Although supported by Apple\u0027s toolchain, the process can be cumbersome, error prone and full of unexpected surprises. We\u0027re happy to report that \u003ca href\u003d\"https://fastlane.tools/\"\u003e\u003cstrong\u003efastlane\u003c/strong\u003e\u003c/a\u003e, already our tool of choice for automating the release process of mobile applications, provides a better solution: \u003ca href\u003d\"https://docs.fastlane.tools/actions/match\"\u003ematch\u003c/a\u003e is integrated into fastlane\u0027s smooth process, and it implements a \u003ca href\u003d\"https://codesigning.guide/\"\u003enew approach\u003c/a\u003e to manage code signing for teams. Instead of storing the signing keys in the developer\u0027s macOS keychain — the default approach — the new approach revolves around storing the keys and certificates in a Git repository. This not only makes it easier to on-board new team members and set up new development machines; in our experience, it also is the easiest method to integrate signing into continuous delivery pipelines.\u003c/p\u003e","blip_status":"c","theta":"45","volume":"2021-10"},{"name":"Airflow","id":"1125","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"38","display_name":"Airflow","radius":"160","description":"\u003cp\u003eIn recent years we\u0027ve seen the rise of generic and domain-specific workflow management tools. The drivers behind this rise include the increased usage of data-processing pipelines and the automation of the machine-learning (ML) model development process. \u003cstrong\u003e\u003ca href\u003d\"https://airflow.apache.org/\"\u003eAirflow\u003c/a\u003e\u003c/strong\u003e is one of the early open-source task orchestration tools that popularized the definition of directed acyclic graphs (DAGs) as code, an improvement over an XML/YAML pipeline configuration. Although Airflow remains one of the most widely adopted orchestration tools, we encourage you to evaluate other tools based on your unique situation. For example, you may want to choose \u003ca href\u003d\"/radar/tools/prefect\"\u003ePrefect\u003c/a\u003e, which supports dynamic data-processing tasks as a first-class concern with generic Python functions as tasks; or \u003ca href\u003d\"https://argoproj.github.io/\"\u003eArgo\u003c/a\u003e if you prefer a tight integration with Kubernetes; or \u003ca href\u003d\"/radar/tools/kubeflow\"\u003eKubeflow\u003c/a\u003e or \u003ca href\u003d\"/radar/tools/mlflow\"\u003eMLflow\u003c/a\u003e for ML-specific workflows. Given the rise of new tools, combined with some of the shortfalls of Airflow (such as lack of native support for dynamic workflows and its centralized approach to scheduling pipelines), we no longer recommend Airflow as the default orchestration tool.\u003c/p\u003e\n\n\u003cp\u003eWe believe that with the increased usage of streaming in analytics and data pipelines, as well as managing data through a \u003ca href\u003d\"/radar/techniques/data-mesh\"\u003edecentralized data mesh\u003c/a\u003e, the need for orchestration tools to define and manage complex data-processing pipelines is reduced.\u003c/p\u003e","blip_status":"move_out","theta":"76","volume":"2021-10"},{"name":"Batect","id":"201904061","quadrant":"Tools","ring":"Trial","movement":"c","radarId":"39","display_name":"Batect","radius":"200","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://batect.dev/\"\u003eBatect\u003c/a\u003e\u003c/strong\u003e continues to gain traction among our developers and is considered by many to be a default approach for configuring local development and test environments. This open-source tool (which happens to be developed by a Thoughtworker) makes it easy to set up and share a build environment based on \u003ca href\u003d\"/radar/techniques/docker-for-builds\"\u003eDocker\u003c/a\u003e. Batect then becomes the entry point for your build system, replacing the ubiquitous go script as the basis for a “\u003ca href\u003d\"https://www.thoughtworks.com/insights/blog/praise-go-script-part-i\"\u003echeck out and go\u003c/a\u003e” approach. Batect continues to evolve in response to developer feedback and recently added support for Docker\u0027s BuildKit and shell tab completion.\u003c/p\u003e","blip_status":"c","theta":"70","volume":"2021-10"},{"name":"Berglas","id":"202110011","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"40","display_name":"Berglas","radius":"220","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/GoogleCloudPlatform/berglas\"\u003eBerglas\u003c/a\u003e\u003c/strong\u003e is a tool for managing secrets on \u003ca href\u003d\"/radar/platforms/google-cloud-platform\"\u003eGoogle Cloud Platform (GCP)\u003c/a\u003e. We\u0027ve recommended \u003ca href\u003d\"/radar/techniques/secrets-as-a-service\"\u003esecrets as a service\u003c/a\u003e as a technique to store and share secrets in modern distributed architectures in the past, and GCP offers \u003ca href\u003d\"https://cloud.google.com/secret-manager\"\u003eSecret Manager\u003c/a\u003e for that purpose, and Berglas works well with Secret Manager. This is especially useful for those GCP services that don\u0027t have direct integration with Secret Manager yet; the alternative in such cases would be to write custom code or scripts. Berglas ships as a command-line tool and as a library, and both also come in handy in use cases beyond secrets as a service. The author of Berglas, who also happens to be the original author of \u003ca href\u003d\"/radar/tools/hashicorp-vault\"\u003eHashiCorp Vault\u003c/a\u003e, now works at Google; however, Berglass is not an official Google product.\u003c/p\u003e","blip_status":"t","theta":"60","volume":"2021-10"},{"name":"Contrast Security","id":"202110015","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"41","display_name":"Contrast Security","radius":"190","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.contrastsecurity.com/\"\u003eContrast Security\u003c/a\u003e\u003c/strong\u003e offers a security platform with multiple components, including static application security testing (SAST), interactive application security testing (IAST), open-source scanning and runtime application self-protection (RASP). It\u0027s been around for a few years now, and we\u0027ve used it in multiple projects. One of the things we quite like about the Contrast platform is its run-time analysis of libraries; it helps identify libraries that are not used, which in turn helps our teams prioritize vulnerabilities and potentially get rid of unused libraries. This is particularly relevant given the increased importance of \u003ca href\u003d\"/radar/techniques/software-bill-of-materials\"\u003esecuring the software supply chain\u003c/a\u003e. We also quite like its IAST component; we\u0027ve found it effective in our continuous delivery (CD) pipeline with reduced false positives, and it manages to catch a good range of vulnerabilities.\u003c/p\u003e","blip_status":"t","theta":"50","volume":"2021-10"},{"name":"Dive","id":"202110082","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"42","display_name":"Dive","radius":"210","description":"\u003cp\u003e\u003ca href\u003d\"https://github.com/wagoodman/dive\"\u003e\u003cstrong\u003eDive\u003c/strong\u003e\u003c/a\u003e is a tool for analyzing Docker images; it helps explore each layer in the image and identify what\u0027s changed in each layer. Dive estimates \u003cem\u003eimage efficiency\u003c/em\u003e and \u003cem\u003ewasted space\u003c/em\u003e in an image and can be integrated into the continuous integration (CI) pipeline to fail the build based on the efficiency score or amount of wasted space. We\u0027ve used it in a few projects, and it has proven to be a useful tool — particularly if you\u0027re building images with a very low tolerance for additional tools or space consumption.\u003c/p\u003e","blip_status":"t","theta":"40","volume":"2021-10"},{"name":"Lens","id":"202005050","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"43","display_name":"Lens","radius":"220","description":"\u003cp\u003eOur teams continue to report good results when using \u003cstrong\u003e\u003ca href\u003d\"https://k8slens.dev/\"\u003eLens\u003c/a\u003e\u003c/strong\u003e to visualize and manage their \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e clusters. Billed as an \"IDE for Kubernetes,\" Lens makes it possible to interact with the cluster without having to memorize commands or manifest file structures. Kubernetes can be complex, and we understand that a tool for visualizing cluster metrics and deployed workloads can save time and reduce some of the toil involved in maintaining a Kubernetes cluster. Instead of hiding complexity behind a simple point-and-click interface, Lens brings together the tools an administrator would run from the command line. But be cautious about interactively making changes to a running cluster via any mechanism. We generally prefer that infrastructure changes be \u003ca href\u003d\"/radar/techniques/infrastructure-as-code\"\u003eimplemented in code\u003c/a\u003e so they are repeatable, testable and less prone to human error. However, Lens does excel as a one-stop tool to interactively navigate through and comprehend your cluster status.\u003c/p\u003e","blip_status":"move_in","theta":"30","volume":"2021-10"},{"name":"Nx","id":"202110073","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"44","display_name":"Nx","radius":"220","description":"\u003cp\u003eOver the years we\u0027ve debated several times whether to feature monorepos in the Radar. Each time we ended up concluding that the trade-offs introduced by monorepos require a nuanced discussion and the technique is \"too complex to blip.\" Now we\u0027re seeing increased interest in monorepos in the JavaScript community, for example, for building applications composed of micro frontends, as discussed in this \u003ca href\u003d\"https://semaphoreci.com/blog/monorepo-micro-frontends-jonathan-creamer\"\u003epodcast episode\u003c/a\u003e. Whether this is a good idea depends a lot on your situation, and we certainly don\u0027t want to give a general recommendation. What we do want to comment on is the tooling. In our teams we see a shift away from \u003ca href\u003d\"https://lerna.js.org/\"\u003eLerna\u003c/a\u003e and a strong preference to use \u003ca href\u003d\"https://nx.dev/\"\u003e\u003cstrong\u003eNx\u003c/strong\u003e\u003c/a\u003e for managing JavaScript-based monorepos.\u003c/p\u003e","blip_status":"t","theta":"20","volume":"2021-10"},{"name":"Wav2Vec 2.0","id":"202110100","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"45","display_name":"Wav2Vec 2.0","radius":"220","description":"\u003cp\u003e\u003ca href\u003d\"https://github.com/pytorch/fairseq/tree/main/examples/wav2vec\"\u003e\u003cstrong\u003eWav2Vec 2.0\u003c/strong\u003e\u003c/a\u003e is a self-supervised learning framework for speech recognition. With this framework the model is trained in two phases. First, it begins in self-supervised mode using unlabeled data and tries to achieve the best possible speech representation. Then it uses supervised fine-tuning, during which labeled data teaches the model to predict particular words or phonemes. We\u0027ve used Wav2Vec and find its approach quite powerful for building automatic speech recognition models for regional languages with limited availability of labeled data.\u003c/p\u003e","blip_status":"t","theta":"10","volume":"2021-10"},{"name":"cert-manager","id":"202110044","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"46","display_name":"cert-manager","radius":"315","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://cert-manager.io/\"\u003ecert-manager\u003c/a\u003e\u003c/strong\u003e is a tool to manage your X.509 certificates within your \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e cluster. It models certificates and issuers as first-class resource types and provides certificates as a service securely to developers and applications working within the Kubernetes cluster. With built-in support for \u003ca href\u003d\"/radar/tools/let-s-encrypt\"\u003eLet\u0027s Encrypt\u003c/a\u003e, \u003ca href\u003d\"/radar/tools/hashicorp-vault\"\u003eHashiCorp Vault\u003c/a\u003e and Venafi, cert-manager is an interesting tool to assess for certificate management.\u003c/p\u003e","blip_status":"t","theta":"86","volume":"2021-10"},{"name":"Cloud Carbon Footprint","id":"202110016","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"47","display_name":"Cloud Carbon Footprint","radius":"295","description":"\u003cp\u003eStakeholders increasingly expect businesses to account for the environmental externalities of their decisions, as evidenced by the rise of environmental, social and corporate governance (ESG) investing and employee activism around climate change. Migrating to the cloud offers the potential for more efficient energy usage — the cloud providers have much more scale to justify investment in green energy sources and R\u0026D — but the downside of software abstractions for cloud users is that those abstractions also hide the energy impact as the actual data centers are hidden from view and financed by another company. \u003cstrong\u003e\u003ca href\u003d\"https://www.cloudcarbonfootprint.org/\"\u003eCloud Carbon Footprint\u003c/a\u003e\u003c/strong\u003e, a new open-source tool, takes advantage of cloud APIs to provide visualizations of estimated carbon emissions based on usage across AWS, GCP and Azure. It uses heuristics like Etsy\u0027s \u003ca href\u003d\"https://codeascraft.com/2020/04/23/cloud-jewels-estimating-kwh-in-the-cloud/\"\u003eCloud Jewels\u003c/a\u003e to estimate energy usage and public data sources to convert energy usage into emissions based on the carbon intensity of the cloud region\u0027s underlying energy grid (GCP \u003ca href\u003d\"https://cloud.google.com/sustainability/region-carbon\"\u003epublishes\u003c/a\u003e this data already). The tool\u0027s dashboards act as information radiators, allowing decision makers to modify setups to cut costs and emissions at the same time. The linkage of cloud regions to carbon intensity of the underlying grid provides a nudge to switch dirty workloads to regions with greener energy sources.\u003c/p\u003e","blip_status":"t","theta":"82","volume":"2021-10"},{"name":"Code With Me","id":"202110013","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"48","display_name":"Code With Me","radius":"305","description":"\u003cp\u003eJetBrains\u0027 collaborative coding tool, \u003cstrong\u003e\u003ca href\u003d\"https://www.jetbrains.com/code-with-me/\"\u003eCode With Me\u003c/a\u003e\u003c/strong\u003e, has been increasing in popularity as many teams use various JetBrains tools in this remote-first world. Along with other remote collaboration tools such as VSCode\u0027s \u003ca href\u003d\"/radar/tools/visual-studio-live-share\"\u003eVisual Studio Live Share\u003c/a\u003e, Code With Me gives development teams an improved experience with remote pairing and collaboration. Code With Me\u0027s abilities to invite teammates into the IDE projects and collaborate in real time are worth exploring. However, we\u0027ve seen some limitations with regard to refactoring seamlessly and some issues in high-latency environments. We\u0027ll continue to watch this tool in this space.\u003c/p\u003e","blip_status":"t","theta":"77","volume":"2021-10"},{"name":"Comby","id":"202110071","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"49","display_name":"Comby","radius":"317","description":"\u003cp\u003eThis edition of the Radar introduces two tools that search and replace code using an abstract syntax tree (AST) representation. They occupy a similar space as \u003ca href\u003d\"/radar/tools/jscodeshift\"\u003ejscodeshift\u003c/a\u003e but contain parsers for a wide range of programming languages. Although they share some similarities, they also differ in several ways. One of these tools, \u003cstrong\u003e\u003ca href\u003d\"https://comby.dev/\"\u003eComby\u003c/a\u003e\u003c/strong\u003e, is unique in its simple, command-line interface designed in the spirit of Unix tools such as \u003ccode\u003eawk\u003c/code\u003e and \u003ccode\u003esed\u003c/code\u003e. While the Unix commands are based on regular expressions operating matching text, Comby employs a pattern syntax that is specific to programming language constructs and parses the code before searching. This helps developers search large code bases for structural patterns. Like \u003ccode\u003esed\u003c/code\u003e, Comby can replace the patterns it matches with new structures. This is useful for automating wholesale changes to large codebases or for making repetitive changes across a suite of microservice repositories. Since these tools are fairly new, we expect to see a range of creative uses that have yet to be discovered.\u003c/p\u003e","blip_status":"t","theta":"72","volume":"2021-10"},{"name":"Conftest","id":"202110014","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"50","display_name":"Conftest","radius":"335","description":"\u003cp\u003e\u003ca href\u003d\"https://github.com/open-policy-agent/conftest\"\u003e\u003cstrong\u003eConftest\u003c/strong\u003e\u003c/a\u003e is a tool for writing tests against structured configuration data. It relies on the \u003ca href\u003d\"https://www.openpolicyagent.org/docs/latest/policy-language/#what-is-rego\"\u003eRego language\u003c/a\u003e from \u003ca href\u003d\"/radar/tools/open-policy-agent-opa\"\u003eOpen Policy Agent\u003c/a\u003e to write tests for \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e configurations, \u003ca href\u003d\"/radar/platforms/tekton\"\u003eTekton\u003c/a\u003e pipeline definitions or even \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e plans. Configurations are a critical part of the infrastructure, and we encourage you to assess Conftest to verify assumptions and get quick feedback.\u003c/p\u003e","blip_status":"t","theta":"68","volume":"2021-10"},{"name":"Cosign","id":"202110093","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"51","display_name":"Cosign","radius":"318","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/sigstore/cosign\"\u003eCosign\u003c/a\u003e\u003c/strong\u003e is a container signing and verification tool. Part of Sigstore — a project under the Cloud Native Computing Foundation (CNCF) umbrella aimed at simplifying software signing and transparency — Cosign supports not only Docker and Open Container Initiative (OCI) images but also other artifacts that can be stored in a container registry. We previously talked about \u003ca href\u003d\"/radar/tools/docker-notary\"\u003eDocker Notary\u003c/a\u003e, which also operates in this space; Notary v1, however, has some disadvantages: it\u0027s not registry native and needs a separate Notary server. Cosign avoids this problem and stores the signatures in the registry next to an image. It currently has integrations with \u003ca href\u003d\"https://github.com/marketplace/actions/install-cosign\"\u003eGitHub actions\u003c/a\u003e and \u003ca href\u003d\"https://github.com/sigstore/helm-charts/tree/main/charts/cosigned\"\u003eKubernetes\u003c/a\u003e using a Webhook with further integrations in the pipeline. We\u0027ve used Cosign in some of our projects and it looks quite promising.\u003c/p\u003e","blip_status":"t","theta":"64","volume":"2021-10"},{"name":"Crossplane","id":"202110081","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"52","display_name":"Crossplane","radius":"320","description":"\u003cp\u003e\u003ca href\u003d\"https://crossplane.io/\"\u003e\u003cstrong\u003eCrossplane\u003c/strong\u003e\u003c/a\u003e is another entry in the class of tools implemented by the \u003ca href\u003d\"/radar/tools/kubernetes-operators\"\u003eKubernetes Operator pattern\u003c/a\u003e but with side effects that extend beyond the Kubernetes cluster. In our last Radar we mentioned \u003ca href\u003d\"/radar/techniques/kube-managed-cloud-services\"\u003eKube-managed cloud services\u003c/a\u003e as a technique, and Crossplane does just that. The idea is to leverage the Kubernetes control plane to provision cloud services on which your deployment is dependent, even if they aren\u0027t deployed on the cluster itself. Examples include managed database instances, load balancers or access control policies. This tool is noteworthy for two reasons. First, it demonstrates the powerful and flexible execution environment of the underlying Kubernetes control plane. There is no real limit to the range of supported custom resources. Second, Crossplane provides an alternative to the usual options of \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e, \u003ca href\u003d\"/radar/platforms/aws-cloud-development-kit\"\u003eCDK\u003c/a\u003e or \u003ca href\u003d\"/radar/platforms/pulumi\"\u003ePulumi\u003c/a\u003e. Crossplane comes with a set of predefined providers for the major cloud services that cover the most commonly provisioned services. It isn\u0027t trying to be a general-purpose infrastructure-as-code (IaC) tool but rather a companion to workloads being deployed in Kubernetes. Often associated with the practice of \u003ca href\u003d\"/radar/techniques/gitops\"\u003eGitOps\u003c/a\u003e, Crossplane stands on its own and allows you to stay within the Kubernetes ecosystem when it\u0027s necessary to manage external cloud resources. However, Crossplane doesn\u0027t help with provisioning Kubernetes itself; you\u0027ll need at least one other IaC tool to bootstrap the cluster.\u003c/p\u003e","blip_status":"t","theta":"59","volume":"2021-10"},{"name":"gopass","id":"1145","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"53","display_name":"gopass","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.gopass.pw/\"\u003egopass\u003c/a\u003e\u003c/strong\u003e is a password manager for teams, built on GPG and Git. It\u0027s a descendant of \u003ca href\u003d\"http://www.passwordstore.org/\"\u003epass\u003c/a\u003e and adds several features, including interactive search and multiple password stores in a single tree. Since we first mentioned gopass, our teams have used it on several projects, sometimes stretching it beyond its limits. A sorely missed feature was the ability to deprecate secrets. Discoverability was already an issue, but not being able to mark secrets as no longer in use compounded this problem. The biggest issue, though, was scale. When you have teams with 50+ people using the same repository for several years, we found that the repository could grow to multiple gigabytes in size. Re-encrypting the secrets when onboarding new members could take more than half an hour. The underlying issue seems to be that in our teams everything changes all the time: people come and go, secrets are rotated, the architecture evolves, new secrets are added, old ones are no longer needed. gopass seems to work well, even for large numbers of users, when there\u0027s less change.\u003c/p\u003e","blip_status":"move_out","theta":"56","volume":"2021-10"},{"name":"Micoo","id":"202110030","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"54","display_name":"Micoo","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/Mikuu/Micoo\"\u003eMicoo\u003c/a\u003e\u003c/strong\u003e is a new entrant into the crowded space of \u003ca href\u003d\"/radar/tools/visual-regression-testing-tools\"\u003evisual regression tools\u003c/a\u003e; it\u0027s an open-source solution and is self-contained, providing Docker images to enable an easy and quick environment setup. It also provides different clients for Node.js, Java and Python as well as a Cypress plugin so it can be easily integrated with most of the common frontend UI automation testing frameworks or solutions. Although Micoo doesn\u0027t provide all the functionality of some of the SaaS-based or other commercial solutions, our teams have been using it extensively and have had positive experiences. They\u0027ve especially called out that it works for mobile and desktop apps as well as the web.\u003c/p\u003e","blip_status":"t","theta":"53","volume":"2021-10"},{"name":"mob","id":"202110031","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"55","display_name":"mob","radius":"290","description":"\u003cp\u003eSometimes you come across a tool that you didn\u0027t realize you needed until you do; \u003cstrong\u003e\u003ca href\u003d\"https://github.com/remotemobprogramming/mob\"\u003emob\u003c/a\u003e\u003c/strong\u003e is just such a tool. Living as we do in a world where remote pair programming has become the norm for many teams, having a tool that allows for seamless handover either between pairs or a wider group as part of a \u003ca href\u003d\"/radar/techniques/remote-mob-programming\"\u003emob programming\u003c/a\u003e session is super useful. mob hides all the version control paraphernalia behind a command-line interface that makes participating in mob programming sessions simpler. It also provides specific advice around how to participate remotely, for example, to \"steal the screenshare\" in Zoom rather than ending a screenshare, ensuring the video layout doesn\u0027t change for participants. A useful tool and thoughtful advice, what\u0027s not to like?\u003c/p\u003e","blip_status":"t","theta":"48","volume":"2021-10"},{"name":"Modern Unix commands","id":"202110032","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"56","display_name":"Modern Unix commands","radius":"310","description":"\u003cp\u003eThere are many reasons to love Unix, but the one that has profoundly affected our industry is the Unix philosophy of building applications that \"do one thing and do it well.\" Unix commands embody this philosophy. A set of small functions that can be piped together to create more complex solutions. In recent years, programmers have contributed to a growing set of \u003cstrong\u003emodern Unix commands\u003c/strong\u003e. These modern versions attempt to be smaller and faster, often written in \u003ca href\u003d\"/radar/languages-and-frameworks/rust\"\u003eRust\u003c/a\u003e. They include additional features such as syntax highlighting and utilize features of modern terminals. They aim to support programmers natively by integrating nicely with \u003ccode\u003egit\u003c/code\u003e and recognizing source code files. For example, \u003ccode\u003e\u003ca href\u003d\"https://github.com/sharkdp/bat\"\u003ebat\u003c/a\u003e\u003c/code\u003e is a replacement for \u003ccode\u003ecat\u003c/code\u003e with paging and syntax highlighting; \u003ccode\u003e\u003ca href\u003d\"https://github.com/ogham/exa\"\u003eexa\u003c/a\u003e\u003c/code\u003e is a replacement for \u003ccode\u003els\u003c/code\u003e with extended file information and \u003ccode\u003e\u003ca href\u003d\"https://github.com/BurntSushi/ripgrep#quick-examples-comparing-tools\"\u003eripgrep\u003c/a\u003e\u003c/code\u003e is a faster \u003ccode\u003egrep\u003c/code\u003e replacement that by default ignores gitignore, binary and hidden files. The \u003ca href\u003d\"https://github.com/ibraheemdev/modern-Unix\"\u003eModern Unix\u003c/a\u003e repository has a reference to some of these commands. We\u0027ve been enjoying using these Unix commands. You should try them in improving your command-line experience. However, we caution against using them in scripts as replacements for the standard command-line utilities that are shipped in default OS distributions, because they reduce the scripts\u0027 portability running on other machines.\u003c/p\u003e","blip_status":"t","theta":"43","volume":"2021-10"},{"name":"Mozilla Sops","id":"202110033","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"57","display_name":"Mozilla Sops","radius":"335","description":"\u003cp\u003ePlaintext secrets checked into source control (usually Github) are one of the most pervasive security mistakes developers make. For this reason we thought it useful to feature \u003cstrong\u003e\u003ca href\u003d\"https://github.com/mozilla/sops\"\u003eMozilla Sops\u003c/a\u003e\u003c/strong\u003e, a tool for encrypting secrets in text files that our developers find useful in situations where it is impossible to remove secrets from legacy code repositories. We\u0027ve mentioned many tools of this type before (\u003ca href\u003d\"/radar/tools/blackbox\"\u003eBlackbox\u003c/a\u003e, \u003ca href\u003d\"https://github.com/AGWA/git-crypt\"\u003egit-crypt\u003c/a\u003e), but Sops has several features that set it apart. For example, Sops integrates with cloud-managed keystores such as AWS and GCP Key Management Service (KMS) or Azure Key Vault as sources of encryption keys. It also works cross-platform and supports PGP keys. This enables fine-grained access control to secrets on a file-by-file basis. Sops leaves the identifying key in plain text so that secrets can still be located and diffed by git. We\u0027re always supportive of anything that makes it easier for developers to be secure; however, remember that you don\u0027t have to keep secrets in source control to begin with. See \u003ca href\u003d\"/radar/techniques/decoupling-secret-management-from-source-code\"\u003eDecoupling secret management from source code\u003c/a\u003e in our November 2017 issue.\u003c/p\u003e","blip_status":"t","theta":"40","volume":"2021-10"},{"name":"Operator Framework","id":"202104048","quadrant":"Tools","ring":"Assess","movement":"c","radarId":"58","display_name":"Operator Framework","radius":"290","description":"\u003cp\u003eWe continue to see the adoption of Kubernetes in new and novel scenarios. For example, we see Kubernetes is being extended to \u003ca href\u003d\"/radar/techniques/operator-pattern-for-nonclustered-resources\"\u003emanage resources running outside of its cluster\u003c/a\u003e or \u003ca href\u003d\"/radar/tools/crossplane\"\u003eacross multiple infrastructure providers\u003c/a\u003e, or it is used in managing stateful applications beyond Kubernetes\u0027s original scope. These extensions are possible using the \u003ca href\u003d\"https://kubernetes.io/docs/concepts/extend-kubernetes/operator/\"\u003eKubernetes Operator\u003c/a\u003e pattern: building Kubernetes controllers that have the domain-specific knowledge of the custom resource they manage. For example, an operator that manages a stateful application can use the Kubernetes primitives to automate an application\u0027s specific tasks beyond its deployment, such as restore, backup and upgrade its database.\u003c/p\u003e\n\n\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://operatorframework.io/\"\u003eOperator Framework\u003c/a\u003e\u003c/strong\u003e is a set of open-source tools that simplifies building and managing the lifecycle of \u003ca href\u003d\"https://kubernetes.io/docs/concepts/extend-kubernetes/operator/\"\u003eKubernetes operators\u003c/a\u003e. Although there are \u003ca href\u003d\"https://github.com/cncf/tag-app-delivery/blob/eece8f7307f2970f46f100f51932db106db46968/operator-wg/whitepaper/Operator-WhitePaper_v1-0.md#operator-frameworks-for-kubernetes\"\u003emultiple frameworks\u003c/a\u003e to help you build Kubernetes operators, Operator Framework remains a good choice. It supports rich operator lifecycle management using its \u003ca href\u003d\"https://github.com/operator-framework/operator-lifecycle-manager/\"\u003eOperator Lifecycle Manager\u003c/a\u003e module; it supports multiple languages to build the operator code itself using its \u003ca href\u003d\"https://sdk.operatorframework.io/\"\u003eOperator SDK\u003c/a\u003e; and it provides a \u003ca href\u003d\"https://operatorhub.io/\"\u003ecatalog\u003c/a\u003e for publishing and sharing the operators. If you\u0027re planning to build Kubernetes operators, we recommend giving the Operator Framework a try to accelerate your development reliably.\u003c/p\u003e","blip_status":"c","theta":"35","volume":"2021-10"},{"name":"Pactflow","id":"202110074","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"59","display_name":"Pactflow","radius":"320","description":"\u003cp\u003eFor organizations with larger and more complex API ecosystems, especially those who are already using \u003ca href\u003d\"https://github.com/pact-foundation\"\u003ePact\u003c/a\u003e, we think it\u0027s worth assessing whether \u003cstrong\u003e\u003ca href\u003d\"https://pactflow.io/\"\u003ePactflow\u003c/a\u003e\u003c/strong\u003e could be useful. Pactflow manages the workflow and continuous deployment of tests written in Pact, lowering the barrier to \u003ca href\u003d\"/radar/techniques/consumer-driven-contract-testing\"\u003econsumer-driven contract testing\u003c/a\u003e. The complexity of coordination between multiple producers and various disparate consumers can become prohibitive. We\u0027ve seen some teams invest significant effort in hand-crafting solutions to this problem and think it\u0027s worth assessing whether Pactflow can look after this for you.\u003c/p\u003e","blip_status":"t","theta":"32","volume":"2021-10"},{"name":"Prefect","id":"202110035","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"60","display_name":"Prefect","radius":"295","description":"\u003cp\u003e\u003ca href\u003d\"https://github.com/prefecthq/prefect\"\u003e\u003cstrong\u003ePrefect\u003c/strong\u003e\u003c/a\u003e is a data workflow management tool that makes it easy to add semantics such as retries, dynamic mapping, caching and failure notifications to data pipelines. You can mark Python functions as tasks and chain them together through function calls to build the data flow. The Python API combined with a collection of predefined tasks for common data operations makes Prefect a noteworthy option to assess for your data pipeline needs.\u003c/p\u003e","blip_status":"t","theta":"28","volume":"2021-10"},{"name":"Proxyman","id":"202110037","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"61","display_name":"Proxyman","radius":"335","description":"\u003cp\u003eIt may not be a tool that you need everyday, but when you\u0027re in the weeds trying to diagnose a nasty network problem, it\u0027s very useful to be able to reach for a feature-rich HTTP debugging proxy. \u003cstrong\u003e\u003ca href\u003d\"https://proxyman.io/\"\u003eProxyman\u003c/a\u003e\u003c/strong\u003e is just such a tool. Quite a few of our teams have been using it for a while now as a macOS-specific drop-in replacement for \u003ca href\u003d\"https://www.charlesproxy.com/\"\u003eCharles\u003c/a\u003e and really like its streamlined interface and cert management.\u003c/p\u003e","blip_status":"t","theta":"22","volume":"2021-10"},{"name":"Regula","id":"202110091","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"62","display_name":"Regula","radius":"290","description":"\u003cp\u003eOne of the key tenets of infrastructure as code (IaC) is automated testing. If we have a solid test pyramid with good code-level coverage at the bottom, we can produce a better and more secure infrastructure. Unfortunately, tools to assist in this space have been sparse. \u003ca href\u003d\"/radar/tools/conftest\"\u003eConftest\u003c/a\u003e is frequently used to test Terraform JSON and HCL code, but it is a general-purpose tool. \u003cstrong\u003e\u003ca href\u003d\"https://regula.dev/\"\u003eRegula\u003c/a\u003e\u003c/strong\u003e is an attractive alternative. Similar to Conftest, Regula checks for compliance of infrastructure code by applying rules written in Open Policy Agent\u0027s Rego language, but it also provides a set of primitives specifically for validating infrastructure configurations. Because both tools are based on the Rego language, Regula rules can be run by Conftest. However, Regula comes with its own command-line tool for running tests as part of a pipeline with no dependence on Conftest or OPA. Our developers have found that Regula saves time and produces much more readable, maintainable and succinct test code. Still, both tools only validate the infrastructure code. A complete suite should also test the infrastructure to ensure the code is being accurately interpreted.\u003c/p\u003e","blip_status":"t","theta":"19","volume":"2021-10"},{"name":"Sourcegraph","id":"202110077","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"63","display_name":"Sourcegraph","radius":"300","description":"\u003cp\u003eAnother abstract syntax tree–based code search tool that received our attention is \u003cstrong\u003e\u003ca href\u003d\"https://about.sourcegraph.com/\"\u003eSourcegraph\u003c/a\u003e\u003c/strong\u003e. In contrast to \u003ca href\u003d\"/radar/tools/comby\"\u003eComby\u003c/a\u003e, which is open source, Sourcegraph is a commercial tool (with a 10-user free tier). Sourcegraph is particularly suited for searching, navigating or cross-referencing in large codebases. The cloud-hosted version can be accessed through Sourcegraph\u0027s website and is designed to search publicly available open-source repositories. Whereas Comby is a lightweight command-line tool for automating repetitive tasks, Sourcegraph\u0027s emphasis is on interactive developer tools for understanding and navigating large code bases. Unlike Comby\u0027s \u003ccode\u003esed\u003c/code\u003e-like interface, Sourcegraph\u0027s automated code rewriting capability is driven from a UI, allowing users to review changes before they\u0027re made. Because Sourcegraph is a hosted service, it also has the ability to continuously monitor code bases and send alerts when a match occurs.\u003c/p\u003e","blip_status":"t","theta":"13","volume":"2021-10"},{"name":"Telepresence","id":"202110095","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"64","display_name":"Telepresence","radius":"322","description":"\u003cp\u003e\u003ca href\u003d\"https://www.telepresence.io/\"\u003e\u003cstrong\u003eTelepresence\u003c/strong\u003e\u003c/a\u003e is a tool that helps shorten the feedback loop of changes that usually require a deployment for proper testing. Developers can use it to plug a process that is running on their local machines into a remote Kubernetes cluster. This gives the local process access to the remote cluster\u0027s services and features, and the local service can also temporarily replace one of the cluster services.\u003c/p\u003e\n\n\u003cp\u003eIn situations where the service integration setup has become somewhat unwieldy, Telepresence can boost developer productivity and enable more effective local testing. However, if you get into the habit of using a clever tool like this, you may have bigger problems. For example, if you use Telepresence because it has become impossible to set up all necessary dependencies for local development, you may want to investigate the complexity of your setup and architecture. If it becomes the only way for you to do service integration tests, consider looking into \u003ca href\u003d\"/radar/techniques/consumer-driven-contract-testing\"\u003econsumer-driven contract testing\u003c/a\u003e or other automated ways of integration testing.\u003c/p\u003e","blip_status":"t","theta":"9","volume":"2021-10"},{"name":"Vite","id":"202110099","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"65","display_name":"Vite","radius":"300","description":"\u003cp\u003eFast feedback is crucial for a good developer experience. Nothing breaks the flow of development more than having to wait a minute or two before getting feedback on the last code changes. Unfortunately, with applications growing in size and complexity, the popular build tools for front-end pipelines are often not fast enough anymore. Previously, we featured \u003ca href\u003d\"/radar/tools/esbuild\"\u003eesbuild\u003c/a\u003e, which offers a significant performance improvement, because it\u0027s implemented in a compile-to-native language rather than JavaScript. \u003cstrong\u003e\u003ca href\u003d\"https://vitejs.dev/\"\u003eVite\u003c/a\u003e\u003c/strong\u003e, which is built on top of esbuild, delivers \u003ca href\u003d\"https://vitejs.dev/guide/why.html\"\u003esignificant improvements\u003c/a\u003e over other tools. It consists of two major parts: a dev server that provides rich feature enhancements over native ES modules, such as extremely fast Hot Module Replacement (HMR), and a build command that bundles your code with Rollup. Vite relies on ES modules, and unlike most older tools, it doesn\u0027t provide shimming or polyfills, which means it\u0027s not compatible with older browsers that don\u0027t support ES modules. In cases where older browsers had to be supported, some of our teams used Vite during development and other tools for production builds.\u003c/p\u003e","blip_status":"t","theta":"5","volume":"2021-10"},{"name":"Jetpack Compose","id":"202110072","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"66","display_name":"Jetpack Compose","radius":"90","description":"\u003cp\u003eIn a move that mirrors Apple\u0027s introduction of \u003ca href\u003d\"/radar/languages-and-frameworks/swiftui\"\u003eSwiftUI\u003c/a\u003e, Google introduced \u003ca href\u003d\"https://developer.android.com/jetpack/compose\"\u003e\u003cstrong\u003eJetpack Compose\u003c/strong\u003e\u003c/a\u003e as a new and quite different approach to building user interfaces for modern Android applications. Compose brings more powerful tools and an intuitive Kotlin API. In most cases less code is needed, and it has become easier to create user interfaces at runtime rather than defining a static UI that can be filled with data. With \u003ca href\u003d\"https://blog.jetbrains.com/kotlin/2021/08/compose-multiplatform-goes-alpha\"\u003eCompose Multiplatform\u003c/a\u003e and \u003ca href\u003d\"https://kotlinlang.org/docs/multiplatform.html\"\u003eKotlin Multiplatform\u003c/a\u003e developers now have a unified toolkit to build desktop, web and native Android apps. Wear OS 3.0+ is included, too, and with support for iOS already present in \u003ca href\u003d\"/radar/languages-and-frameworks/kotlin-multiplatform-mobile\"\u003eKotlin Multiplatform Mobile\u003c/a\u003e, it\u0027s likely that iOS will be supported by Compose in the future.\u003c/p\u003e","blip_status":"t","theta":"300","volume":"2021-10"},{"name":"React Hooks","id":"201911020","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"c","radarId":"67","display_name":"React Hooks","radius":"100","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://reactjs.org/docs/hooks-intro.html\"\u003eReact Hooks\u003c/a\u003e\u003c/strong\u003e have introduced a new approach to managing stateful logic; given React components have always been closer to functions than classes, Hooks have embraced this and brought state to the functions, instead of using classes to take function to the state with methods. Another staple of state management in React applications is \u003ca href\u003d\"/radar/languages-and-frameworks/redux\"\u003eRedux\u003c/a\u003e, and we\u0027ve already noted that it has come under scrutiny, suggesting that sometimes the complexity of Redux isn\u0027t worth it and in such cases a simple approach using Hooks is preferable. Rolling this completely on your own can quickly become tricky; therefore we recommend considering a combination of \u003ca href\u003d\"https://reactjs.org/docs/context.html\"\u003eReact Context\u003c/a\u003e and the useContext and useReducer hooks, along the lines explained in this \u003ca href\u003d\"https://blog.logrocket.com/guide-to-react-usereducer-hook/\"\u003eblog post\u003c/a\u003e.\u003c/p\u003e","blip_status":"c","theta":"330","volume":"2021-10"},{"name":"Arium","id":"202110022","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"68","display_name":"Arium","radius":"190","description":"\u003cp\u003e\u003ca href\u003d\"https://github.com/thoughtworks/Arium\"\u003e\u003cstrong\u003eArium\u003c/strong\u003e\u003c/a\u003e is an automated testing framework for 3D applications written in Unity. Functional tests are an important part of a healthy test pyramid. Arium, which is built as a wrapper on the \u003ca href\u003d\"https://docs.unity3d.com/Packages/com.unity.test-framework@1.1/manual/index.html\"\u003eUnity Test framework\u003c/a\u003e, lets you write functional tests for 3D apps on multiple platforms. We\u0027ve used it successfully in a few of our projects.\u003c/p\u003e","blip_status":"t","theta":"274","volume":"2021-10"},{"name":"Chakra UI","id":"202110023","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"69","display_name":"Chakra UI","radius":"260","description":"\u003cp\u003e\u003ca href\u003d\"https://chakra-ui.com/\"\u003e\u003cstrong\u003eChakra UI\u003c/strong\u003e\u003c/a\u003e is a UI component library for \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e that is designed for accessibility. We like it, especially for its accessibility features, including dark mode and compatibility with the Web Accessibility Initiative – Accessible Rich Internet Applications (WAI-ARIA) guidelines. Moreover, it is easy to test and customize which makes for a good development experience, accelerating the development process of UI solutions in production environments.\u003c/p\u003e","blip_status":"t","theta":"279","volume":"2021-10"},{"name":"DoWhy","id":"202110083","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"70","display_name":"DoWhy","radius":"185","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/Microsoft/dowhy\"\u003eDoWhy\u003c/a\u003e\u003c/strong\u003e is a Python library to perform end-to-end causal inference and analysis. Although machine-learning models can make predictions based on factual data, exploiting the correlation of variables that were present at the time, they\u0027re insufficient in scenarios where we need to ask \u003cem\u003eWhat if\u003c/em\u003e and \u003cem\u003eWhy\u003c/em\u003e questions: \u003cem\u003eWhat if a variable changed? What would be the impact on the outcome?\u003c/em\u003e Causal inference is an approach to answer such questions. It estimates the causal effect, that is, the magnitude by which an outcome would change, if we changed one of the causal variables. This approach is applied when we can\u0027t arrive at the answer through observations and collecting data from A/B testing — due to the cost of experiments or limitations. The DoWhy library estimates the causal effect based on a process that uses the past collected facts and data as well as assumptions one can make knowing the domain. It uses a four-step process of modeling the causal relationships graph based on assumptions, identifying a cause for an outcome, estimating the causal effect and finally challenging those assumptions by refuting the result. We\u0027ve used this library successfully in production, and it\u0027s one of the commonly used libraries in causal estimation use cases.\u003c/p\u003e","blip_status":"t","theta":"283","volume":"2021-10"},{"name":"Gatsby.js","id":"201911025","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"71","display_name":"Gatsby.js","radius":"200","description":"\u003cp\u003eAlthough several frameworks promise the same ease of development and scalability typical of static site generators, we continue to have good experiences with \u003ca href\u003d\"https://www.gatsbyjs.org/\"\u003e\u003cstrong\u003eGatsby.js\u003c/strong\u003e\u003c/a\u003e. In particular we\u0027ve used it to build and deploy websites that scale to very large numbers of users without having to worry about capacity planning or deployment infrastructure. Our developers have also been impressed by the focus on accessibility and support for old browsers and that they could reuse their \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e experience. All in all, we feel Gatsby has matured well and is a solid choice in this space.\u003c/p\u003e","blip_status":"move_in","theta":"291","volume":"2021-10"},{"name":"Jetpack Hilt","id":"202110005","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"72","display_name":"Jetpack Hilt","radius":"240","description":"\u003cp\u003e\u003ca href\u003d\"https://developer.android.com/jetpack/androidx/releases/hilt\"\u003e\u003cstrong\u003eJetpack Hilt\u003c/strong\u003e\u003c/a\u003e has recently reached version 1.0, and we can report that we\u0027ve had good experiences with it. Jetpack Hilt offers extensions for integrating Hilt with various other AndroidX libraries, such as WorkManager and Navigation. It further expands the reach of Hilt, to provide developers with a standard way of incorporating \u003ca href\u003d\"/radar/languages-and-frameworks/dagger\"\u003eDagger\u003c/a\u003e dependency injection into Android applications. We\u0027ve featured \u003ca href\u003d\"/radar/languages-and-frameworks/koin\"\u003eKoin\u003c/a\u003e as a Kotlin-native dependency injection framework in the Radar before, and we would advise against attempting to replace Koin in a large existing codebase. However, when starting a new project, Hilt, it seems, is now the way to go.\u003c/p\u003e","blip_status":"t","theta":"292","volume":"2021-10"},{"name":"Kotlin Multiplatform Mobile","id":"202104042","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"73","display_name":"Kotlin Multiplatform Mobile","radius":"190","description":"\u003cp\u003eFor many organizations, cross-platform mobile development is becoming a strong option especially as the end-to-end experience of building mobile cross-platform applications becomes more enjoyable and efficient. \u003cstrong\u003e\u003ca href\u003d\"https://kotlinlang.org/docs/mobile/home.html\"\u003eKotlin Multiplatform Mobile\u003c/a\u003e\u003c/strong\u003e (KMM) is an SDK provided by JetBrains that leverages the \u003ca href\u003d\"https://kotlinlang.org/docs/multiplatform.html\"\u003emultiplatform capabilities\u003c/a\u003e in \u003ca href\u003d\"/radar/languages-and-frameworks/kotlin\"\u003eKotlin\u003c/a\u003e and includes tools and features designed to streamline the developer experience. With KMM you write code once for business logic and the app core in Kotlin and then share it with both Android and iOS applications. You write platform-specific code only when necessary, for example, to take advantage of native UI elements; and the specific code is kept in different views for each platform. We\u0027re moving KMM to Trial as it is \u003ca href\u003d\"https://kotlinlang.org/docs/mobile/kmm-evolution.html\"\u003eevolving rapidly\u003c/a\u003e and we\u0027re seeing a few organizations use this as their default.\u003c/p\u003e","blip_status":"move_in","theta":"297","volume":"2021-10"},{"name":"lifelines","id":"202110027","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"74","display_name":"lifelines","radius":"220","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://lifelines.readthedocs.io/en/latest/\"\u003elifelines\u003c/a\u003e\u003c/strong\u003e is a library for survival analysis in Python. Originally developed for birth and death events, it has evolved into a complete survival analysis library to predict any duration of time. Beyond medical use cases (such as answering, \u003cem\u003eHow long does this population live for?\u003c/em\u003e), we\u0027ve used it in retail and manufacturing to answer questions like \u003cem\u003eHow long users are subscribed to a service?\u003c/em\u003e or \u003cem\u003eWhen should we do the next preventive maintenance?\u003c/em\u003e\u003c/p\u003e","blip_status":"t","theta":"301","volume":"2021-10"},{"name":"Mock Service Worker","id":"202010050","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"75","display_name":"Mock Service Worker","radius":"230","description":"\u003cp\u003eWeb applications, especially those for internal use in enterprises, are usually written in two parts. The user interface and some business logic run in the web browser while business logic, authorization and persistence run on a server. These two halves normally communicate via JSON over HTTP. The endpoints shouldn\u0027t be mistaken for a real API; they\u0027re simply an implementation detail of an application that is split across two run-time environments. At the same time, they provide a valid seam to test the pieces individually. When testing the JavaScript part, the server side can be stubbed and mocked at the network level by a tool such as \u003ca href\u003d\"/radar/tools/mountebank\"\u003eMountebank\u003c/a\u003e. \u003cstrong\u003e\u003ca href\u003d\"https://mswjs.io/\"\u003eMock Service Worker\u003c/a\u003e\u003c/strong\u003e offers an alternative approach of intercepting requests in the browser. This simplifies manual tests as well. Like Mountebank, Mock Service Worker is run outside the browser as a Node.js process for testing network interactions. In addition to REST interactions, it mocks GraphQL APIs — a bonus because GraphQL can be complex to mock manually at the network level.\u003c/p\u003e","blip_status":"move_in","theta":"311","volume":"2021-10"},{"name":"NgRx","id":"202110034","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"76","display_name":"NgRx","radius":"180","description":"\u003cp\u003eState management in React applications has been a recurring topic in the Radar, and we\u0027ve recently clarified our position on \u003ca href\u003d\"/radar/languages-and-frameworks/redux\"\u003eRedux\u003c/a\u003e, a popular framework in this space. \u003ca href\u003d\"https://ngrx.io/\"\u003e\u003cstrong\u003eNgRx\u003c/strong\u003e\u003c/a\u003e is, in essence, Redux for \u003ca href\u003d\"/radar/languages-and-frameworks/angular\"\u003eAngular\u003c/a\u003e. It\u0027s a framework for building reactive applications with Angular, providing ways to manage state and to isolate side effects. Our teams report that picking up NgRx was straightforward, not the least because it is built with \u003ca href\u003d\"https://rxjs.dev/\"\u003eRxJS\u003c/a\u003e, and they highlight a trade-off similar to the one we know from Redux: adding reactive state management comes with added complexity that only pays off in larger applications. The developer experience is enhanced by schematics, a scaffolding library and a set of tools that enable visual tracking of state and time-travel debugging.\u003c/p\u003e","blip_status":"t","theta":"309","volume":"2021-10"},{"name":"pydantic","id":"202110075","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"77","display_name":"pydantic","radius":"200","description":"\u003cp\u003eOriginally type annotations were added to Python to support static analysis. However, considering how widely type annotations, and annotations in general, are used in other programming languages, it was only a matter of time before developers would begin to use Python\u0027s type annotations for other purposes. \u003cstrong\u003e\u003ca href\u003d\"https://pydantic-docs.helpmanual.io/\"\u003epydantic\u003c/a\u003e\u003c/strong\u003e falls into this category. It allows you to use type annotations for data validation and settings management at run time. When data arrives as, say, a JSON document and needs to be parsed into a complex Python structure, pydantic ensures that the incoming data matches the expected types or reports an error if it doesn\u0027t. Although you can use pydantic directly, many developers have used it as part of \u003ca href\u003d\"/radar/languages-and-frameworks/fastapi\"\u003eFastAPI\u003c/a\u003e, one of the most popular Python web frameworks. In fact, using pydantic in FastAPI is considered so indispensable that a recently proposed change to Python, aimed at reducing the cost of loading annotated code into memory, was \u003ca href\u003d\"https://mail.python.org/archives/list/python-dev@python.org/thread/CLVXXPQ2T2LQ5MP2Y53VVQFCXYWQJHKZ/\"\u003ereconsidered\u003c/a\u003e because it would have broken the use of type annotations at run time.\u003c/p\u003e","blip_status":"t","theta":"315","volume":"2021-10"},{"name":"Quarkus","id":"201911026","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"78","display_name":"Quarkus","radius":"165","description":"\u003cp\u003eWe assessed \u003cstrong\u003e\u003ca href\u003d\"https://quarkus.io/\"\u003eQuarkus\u003c/a\u003e\u003c/strong\u003e two years ago, and now our teams have more experience with it. Quarkus is a Kubernetes-native Java stack tailored for OpenJDK HotSpot and \u003ca href\u003d\"/radar/platforms/graalvm\"\u003eGraalVM\u003c/a\u003e. Over the past two years, Quarkus has wired those best-of-breed libraries in the Java world and streamlined the code configuration, giving our teams a pretty good developer experience. Quarkus has a very fast boot time (tens of milliseconds) and a low RSS memory footprint; this is because of its \u003ca href\u003d\"https://quarkus.io/vision/container-first\"\u003econtainer-first\u003c/a\u003e building approach: it uses ahead-of-time compilation techniques to do dependency injection at compile time and thus avoids the run-time costs of reflection. Our team has also had to endure the trade-offs: it takes nearly 10 minutes for Quarkus to build on our pipeline; some features that rely on annotations and reflection (such as ORM and serializer) are also limited. Part of these trade-offs are the result of using GraalVM. So if your application is not running for FaaS, using Quarkus with HotSpot is also a good choice.\u003c/p\u003e","blip_status":"move_in","theta":"319","volume":"2021-10"},{"name":"React Native Reanimated 2.0","id":"202110039","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"79","display_name":"React Native Reanimated 2.0","radius":"200","description":"\u003cp\u003eIf we want animations in \u003ca href\u003d\"/radar/languages-and-frameworks/react-native\"\u003eReact Native\u003c/a\u003e applications, \u003cstrong\u003e\u003ca href\u003d\"https://docs.swmansion.com/react-native-reanimated/\"\u003eReact Native Reanimated 2.0\u003c/a\u003e\u003c/strong\u003e is the way to go. We previously had Reanimated 1.x, but it had issues related to the complexity of the Reanimated declarative language and also had some additional performance costs related to initialization and communication between the React Native JavaScript thread and the UI thread. Reanimated 2.0 is an attempt at reimagining how to run animations in the UI thread; it allows us to code the animations in JavaScript and run them on the UI thread using a new API called \u003ca href\u003d\"https://docs.swmansion.com/react-native-reanimated/docs/2.2.0/worklets/\"\u003eanimation worklets\u003c/a\u003e. It does this by spawning a secondary JavaScript context on the UI thread that then is able to run JavaScript functions. We\u0027re using it in our React Native projects which need animations and like it a lot.\u003c/p\u003e","blip_status":"t","theta":"324","volume":"2021-10"},{"name":"React Query","id":"202110089","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"80","display_name":"React Query","radius":"242","description":"\u003cp\u003e\u003ca href\u003d\"https://react-query.tanstack.com/\"\u003e\u003cstrong\u003eReact Query\u003c/strong\u003e\u003c/a\u003e is often described as the missing data-fetching library for React. Fetching, caching, synchronizing and updating server state is a common requirement in many React applications, and although the requirements are well-understood, getting the implementation right is notoriously difficult. React Query provides a straightforward solution using hooks. As an application developer you simply pass a function that resolves your data and leave everything else to the framework. We like that it works out-of-the-box but still offers a lot of configuration when needed. The developer tools, unfortunately not yet available for React Native, do help with understanding of how the framework works, which benefits developers new to it. In our experience, version 3 of the framework brought the stability needed to be used in production with our clients.\u003c/p\u003e","blip_status":"t","theta":"328","volume":"2021-10"},{"name":"Tailwind CSS","id":"202005054","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"81","display_name":"Tailwind CSS","radius":"225","description":"\u003cp\u003eOur developers have continued to be productive with \u003cstrong\u003e\u003ca href\u003d\"https://tailwindcss.com/\"\u003eTailwind CSS\u003c/a\u003e\u003c/strong\u003e and are impressed with its ability to scale with large teams and codebases. Tailwind CSS offers an alternative approach to CSS tools and frameworks that reduces complexity through lower-level utility CSS classes. The Tailwind CSS classes can easily be customized to suit any customer\u0027s visual identity. We\u0027ve also found that it pairs particularly well with \u003ca href\u003d\"/radar/languages-and-frameworks/headless-ui\"\u003eHeadless UI\u003c/a\u003e. Tailwind CSS allows you to avoid writing any classes or CSS on your own which leads to a more maintainable codebase in the long term. It seems that Tailwind CSS offers the right balance between reusability and customization to create visual components.\u003c/p\u003e","blip_status":"move_in","theta":"333","volume":"2021-10"},{"name":"TensorFlow Lite","id":"1244","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"82","display_name":"TensorFlow Lite","radius":"175","description":"\u003cp\u003eSince we first mentioned \u003ca href\u003d\"https://www.tensorflow.org/lite/\"\u003e\u003cstrong\u003eTensorFlow Lite\u003c/strong\u003e\u003c/a\u003e in the Radar in 2018, we\u0027ve used it in several products and are happy to report that it works as advertised. The standard use case is to integrate pretrained models into mobile apps, but TensorFlow Lite also supports on-device learning which opens further areas of application. Numerous examples on the website showcase many common areas of application, such as image classification and object detection, but also hint at new ways of interaction using, for example, pose estimation and gesture recognition.\u003c/p\u003e","blip_status":"move_in","theta":"337","volume":"2021-10"},{"name":"Three.js","id":"1060","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"83","display_name":"Three.js","radius":"200","description":"\u003cp\u003eWe first mentioned \u003cstrong\u003e\u003ca href\u003d\"https://threejs.org/\"\u003eThree.js\u003c/a\u003e\u003c/strong\u003e in the Radar in Assess back in 2017. Since then, this 3D rendering library for the web has evolved and improved rapidly. The standard WebGL APIs have improved, and Three.js has added support for WebXR, turning it into a viable tool for creating immersive experiences. At the same time, browser support for 3D rendering and WebXR device APIs has improved, making the web an increasingly attractive platform for 3D content. Although there are other 3D rendering libraries, our teams have come to prefer Three.js, especially when paired with \u003ca href\u003d\"/radar/languages-and-frameworks/react-three-fiber\"\u003eReact Three Fiber\u003c/a\u003e to abstract away some of the low-level details. We\u0027ve found that developers still need to be conscious of performance issues and will sometimes need to restructure data to optimize rendering speed.\u003c/p\u003e","blip_status":"move_in","theta":"342","volume":"2021-10"},{"name":"ViewInspector","id":"202110098","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"84","display_name":"ViewInspector","radius":"250","description":"\u003cp\u003eWhen creating a user interface with \u003ca href\u003d\"/radar/languages-and-frameworks/swiftui\"\u003eSwiftUI\u003c/a\u003e, the idea is to build a view model that can be mapped easily to the elements of the user interface. In such cases, most of the testing can be done on the model, using the standard unit testing frameworks which makes these tests straightforward to write and fast to run. To test the bindings between the model and the views, developers usually reach for \u003ca href\u003d\"https://developer.apple.com/documentation/xctest/user_interface_tests\"\u003eXCUITest\u003c/a\u003e, a test automation framework that launches the full application and remote controls the interface. It works, tests are reasonably stable, but they take a long time to run.\u003c/p\u003e\n\n\u003cp\u003eFor a faster approach to writing unit tests for SwiftUI, try \u003ca href\u003d\"https://github.com/nalexn/ViewInspector\"\u003e\u003cstrong\u003eViewInspector\u003c/strong\u003e\u003c/a\u003e, an open-source framework that uses Swift\u0027s public reflection API to access the underlying views created by SwiftUI. With ViewInspector, a test simply instantiates a SwiftUI view, locates the interface elements that need to be tested and then makes assertions against them. Basic interactions such as taps can be tested, too. Like many UI testing frameworks, it provides an API to locate interface elements, either by specifying a path through the view hierarchy or by using a set of finder methods. These tests are usually simpler than XCUITests, and they run much faster. As a word of caution, though, given the ease with which tests can be written using ViewInspector, you might be tempted to over-test the interface. Testing simple one-to-one mappings is just double-entry bookkeeping. And even though ViewInspector makes it easier to test the SwiftUI code, remember to keep most of the logic in the model.\u003c/p\u003e","blip_status":"t","theta":"344","volume":"2021-10"},{"name":"Vowpal Wabbit","id":"202110010","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"85","display_name":"Vowpal Wabbit","radius":"256","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://vowpalwabbit.org/\"\u003eVowpal Wabbit\u003c/a\u003e\u003c/strong\u003e is a general-purpose machine-learning library. Even though it was originally created at Yahoo! Research over a decade ago, we still want to mention it to highlight that it continues to be the place where many of the newest machine-learning techniques get added first. If you\u0027re interested in machine learning, you may want to keep an eye on the innovations in Vowpal Wabbit. Note also that Microsoft has shown a deeper interest in Vowpal Wabbit in recent years, employing a main contributor and integrating it into their Azure offerings, for example in their \u003ca href\u003d\"https://docs.microsoft.com/en-us/azure/machine-learning/algorithm-module-reference/train-vowpal-wabbit-model\"\u003emachine-learning designer\u003c/a\u003e and in \u003ca href\u003d\"https://azure.microsoft.com/en-us/services/cognitive-services/personalizer/\"\u003ePersonalizer\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"351","volume":"2021-10"},{"name":"Zap","id":"202110043","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"86","display_name":"Zap","radius":"190","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/uber-go/zap\"\u003eZap\u003c/a\u003e\u003c/strong\u003e is a super performant structured logging library for GoLang which is faster than the standard Log implementation and other logging libraries. Zap has both a \"pretty\" logger, providing a structured and \u003ccode\u003eprintf\u003c/code\u003e-style interface, as well as an (even) faster implementation with just the structured interface. Our teams have used it extensively at scale and are happy to recommend it as their go-to solution.\u003c/p\u003e","blip_status":"t","theta":"353","volume":"2021-10"},{"name":"Headless UI","id":"202110084","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"87","display_name":"Headless UI","radius":"295","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://headlessui.dev/\"\u003eHeadless UI\u003c/a\u003e\u003c/strong\u003e is an unstyled component library for either \u003ca href\u003d\"/radar/languages-and-frameworks/react-js\"\u003eReact.js\u003c/a\u003e or \u003ca href\u003d\"/radar/languages-and-frameworks/vue-js\"\u003eVue.js\u003c/a\u003e from the same people that created \u003ca href\u003d\"/radar/languages-and-frameworks/tailwind-css\"\u003eTailwind CSS\u003c/a\u003e. Our developers like that they don\u0027t have to customize or work around the default styles that other component libraries come with. The components\u0027 rich functionality and full accessibility, combined with the frictionless styling, allows developers to focus more productively on the business problem and user experience. Unsurprisingly, Headless UI also pairs well with Tailwind CSS classes.\u003c/p\u003e","blip_status":"t","theta":"278","volume":"2021-10"},{"name":"InsightFace","id":"202110079","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"88","display_name":"InsightFace","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/deepinsight/insightface\"\u003eInsightFace\u003c/a\u003e\u003c/strong\u003e is an open source 2D and 3D deep face analysis toolbox, mainly based on \u003ca href\u003d\"/radar/languages-and-frameworks/pytorch\"\u003ePyTorch\u003c/a\u003e and MXNet. InsightFace uses some of the most recent and accurate methods for face detection, face recognition and face alignment. We\u0027re particularly interested in it, because it has one of the best implementations for ArcFace, a cutting-edge machine-learning model that detects the similarities of two images. InsightFace with ArcFace received a 99.83% accuracy score on the \u003ca href\u003d\"http://vis-www.cs.umass.edu/lfw/\"\u003eLabeled Faces in the Wild (LFW)\u003c/a\u003e data set. We\u0027re experimenting with it in the context of facial deduplication and have seen promising results.\u003c/p\u003e","blip_status":"t","theta":"286","volume":"2021-10"},{"name":"Kats","id":"202110085","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"89","display_name":"Kats","radius":"330","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/facebookresearch/Kats\"\u003eKats\u003c/a\u003e\u003c/strong\u003e is a lightweight framework for performing time series analyses, recently released by Facebook Research. Time series analysis is an important area in data science; it encompasses the problem domains of forecasting, detection (including the detection of seasonalities, outliers and change points), feature extraction and multivariate analysis. Typically we tend to have different libraries for different techniques in a time series analysis. Kats though aims to be a one-stop shop for time series analyses and provides a set of algorithms and models for all the time series analysis problem domains. Previously we mentioned \u003ca href\u003d\"/radar/platforms/prophet\"\u003eProphet\u003c/a\u003e, also by Facebook Research,  which is one of the models Kats implements for forecasting. We\u0027re looking forward to trying Kats in problems involving time series analyses.\u003c/p\u003e","blip_status":"t","theta":"294","volume":"2021-10"},{"name":"ksqlDB","id":"202110006","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"90","display_name":"ksqlDB","radius":"305","description":"\u003cp\u003eIf you\u0027re using \u003ca href\u003d\"/radar/tools/apache-kafka\"\u003eApache Kafka\u003c/a\u003e and building stream-processing applications, \u003ca href\u003d\"https://ksqldb.io/\"\u003e\u003cstrong\u003eksqlDB\u003c/strong\u003e\u003c/a\u003e is a great framework for writing simple applications using SQL-like statements. ksqlDB is not a traditional SQL database. However, it allows you to use lightweight SQL-like statements to build new Kafka \u003ca href\u003d\"https://docs.ksqldb.io/en/latest/concepts/streams/\"\u003estreams\u003c/a\u003e or \u003ca href\u003d\"https://docs.ksqldb.io/en/latest/concepts/tables/\"\u003etables\u003c/a\u003e on top of the existing Kafka topics. The queries can pull data, similar to reading from a traditional database, or push results to the application when incremental changes occur. You can choose to run it as a \u003ca href\u003d\"https://ksqldb.io/quickstart.html#quickstart-content\"\u003estandalone server\u003c/a\u003e natively as part of your existing Apache Kafka installation or as a fully managed service on Confluent Cloud. We\u0027re using ksqlDB in simple data-processing use cases. In more complex use cases, where an application requires programming code beyond algebraic SQL queries, we continue to use data-processing frameworks such as \u003ca href\u003d\"/radar/platforms/apache-spark\"\u003eApache Spark\u003c/a\u003e or \u003ca href\u003d\"/radar/platforms/apache-flink\"\u003eApache Flink\u003c/a\u003e on top of Kafka. We recommend experimenting with ksqlDB in scenarios where the simplicity of the application allows it.\u003c/p\u003e","blip_status":"t","theta":"302","volume":"2021-10"},{"name":"Polars","id":"202110087","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"91","display_name":"Polars","radius":"325","description":"\u003cp\u003e\u003ca href\u003d\"https://github.com/pola-rs/polars\"\u003e\u003cstrong\u003ePolars\u003c/strong\u003e\u003c/a\u003e is an in-memory data frame library implemented in \u003ca href\u003d\"/radar/languages-and-frameworks/rust\"\u003eRust\u003c/a\u003e. Unlike other data frames (such as Pandas), Polars is multithreaded and safe for parallel operations. The in-memory data is organized in the \u003ca href\u003d\"https://arrow.apache.org/\"\u003eApache Arrow\u003c/a\u003e format for efficient analytic operations and to enable interoperability with other tools. If you\u0027re familiar with Pandas, you can quickly get started with Polars\u0027 Python bindings. We believe Polars, with Rust implementation and Python bindings, is a performant in-memory data frame to assess for your analytical needs.\u003c/p\u003e","blip_status":"t","theta":"310","volume":"2021-10"},{"name":"PyTorch Geometric","id":"202110088","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"92","display_name":"PyTorch Geometric","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://pytorch-geometric.readthedocs.io/en/latest/\"\u003ePyTorch Geometric\u003c/a\u003e\u003c/strong\u003e is a geometric deep learning extension library for \u003ca href\u003d\"/radar/languages-and-frameworks/pytorch\"\u003ePyTorch\u003c/a\u003e. Geometric deep learning aims to build neural networks that can learn from non-Euclidean data like graphs. Graph network-based machine-learning approaches have been of increasing interest in social network modeling and in biomedical fields, specifically in drug discovery. PyTorch Geometric provides an easy-to-use library to design complicated graph network problems like protein structure representation. It has GPU and CPU support and includes a good collection of graph-based machine-learning algorithms based on recent research.\u003c/p\u003e","blip_status":"t","theta":"319","volume":"2021-10"},{"name":"Qiankun","id":"202110038","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"93","display_name":"Qiankun","radius":"290","description":"\u003cp\u003e\u003ca href\u003d\"/radar/techniques/micro-frontends\"\u003eMicro frontends\u003c/a\u003e have continued to gain in popularity since they were first introduced. However, it\u0027s easy to fall into \u003ca href\u003d\"/radar/techniques/micro-frontend-anarchy\"\u003emicro frontend anarchy\u003c/a\u003e if teams fail to maintain consistency across an application, from styling technique to state management. \u003ca href\u003d\"https://github.com/umijs/qiankun\"\u003e\u003cstrong\u003eQiankun\u003c/strong\u003e\u003c/a\u003e, which means heaven and earth in Chinese, is a JavaScript library built to provide an out-of-the-box solution for this. Qiankun is based on \u003ca href\u003d\"/radar/languages-and-frameworks/single-spa\"\u003esingle-spa\u003c/a\u003e, so it allows different frameworks to coexist in a single application. It also provides style isolation and JavaScript sandbox to ensure the style or state of microapplications do not interfere with each other. Qiankun has received some attention in the community; our teams are also assessing it, hoping that it can support more friendly debugging.\u003c/p\u003e","blip_status":"t","theta":"327","volume":"2021-10"},{"name":"React Three Fiber","id":"202110090","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"94","display_name":"React Three Fiber","radius":"335","description":"\u003cp\u003eWith the rising interest in — and viability of — 3D and extended reality (XR) applications in web browsers, our teams have been experimenting with \u003ca href\u003d\"https://github.com/pmndrs/react-three-fiber\"\u003e\u003cstrong\u003eReact Three Fiber\u003c/strong\u003e\u003c/a\u003e for developing 3D experiences on the web. React Three Fiber is a library that takes the React.js component and state model and translates it to 3D objects rendered with the \u003ca href\u003d\"/radar/languages-and-frameworks/three-js\"\u003eThree.js\u003c/a\u003e library. This approach opens up 3D web programming to the wider group of developers already familiar with React.js and the rich ecosystem of tools and libraries surrounding it. However, when developing applications with React Three Fiber, our teams often have to manipulate the 3D scene imperatively. This doesn\u0027t mix well with the reactive component paradigm provided by React. There is no escaping the need to understand the basic 3D rendering mechanisms. The jury is still out on whether React Three Fiber offers enough abstraction to warrant learning its idiosyncrasies or if it\u0027s better just to work with Three.js directly.\u003c/p\u003e","blip_status":"t","theta":"335","volume":"2021-10"},{"name":"Tauri","id":"202110094","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"95","display_name":"Tauri","radius":"330","description":"\u003cp\u003e\u003ca href\u003d\"https://github.com/tauri-apps/tauri\"\u003e\u003cstrong\u003eTauri\u003c/strong\u003e\u003c/a\u003e is an \u003ca href\u003d\"https://www.electronjs.org/\"\u003eElectron\u003c/a\u003e alternative for building desktop applications using a combination of \u003ca href\u003d\"/radar/languages-and-frameworks/rust\"\u003eRust\u003c/a\u003e tools and HTML, CSS, and JavaScript rendered in System\u0027s WebView. Unlike Electron which bundles Chromium, the applications built with Tauri leverage the underlying WebView, that is, WebKit on macOS, WebView2 on Windows and WebKitGTK on Linux. This approach has interesting trade-offs — on one hand you get small and fast application binaries; on the other hand, you need to verify compatibility quirks across WebViews of different systems.\u003c/p\u003e","blip_status":"t","theta":"343","volume":"2021-10"},{"name":"Transloco","id":"202110097","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"96","display_name":"Transloco","radius":"335","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://ngneat.github.io/transloco/\"\u003eTransloco\u003c/a\u003e\u003c/strong\u003e is a library for Angular to build multilingual applications. It can be used in templates and offers a function to cover more complex use cases. Because the translations are loaded on-demand at run time, Transloco makes it easy to implement language switching in the web browser. It also covers localization of numbers, dates and more using template pipes.\u003c/p\u003e","blip_status":"t","theta":"351","volume":"2021-10"}],"date":"2021-10"},{"blips":[{"name":"Four key metrics","id":"1298","quadrant":"Techniques","ring":"Adopt","movement":"c","radarId":"1","display_name":"Four key metrics","radius":"65","description":"\u003cp\u003eTo measure software delivery performance, more and more organizations are defaulting to the \u003cstrong\u003efour key metrics\u003c/strong\u003e as defined by the \u003ca href\u003d\"https://www.devops-research.com/\"\u003eDORA research\u003c/a\u003e program: change lead time, deployment frequency, mean time to restore (MTTR) and change fail percentage. This research and its statistical analysis have shown a clear link between high-delivery performance and these metrics; they provide a great leading indicator for how a delivery organization as a whole is doing.\u003c/p\u003e\n\n\u003cp\u003eWe\u0027re still big proponents of these metrics, but we\u0027ve also learned some lessons. We\u0027re still observing misguided approaches with tools that help teams measure these metrics based purely on their continuous delivery (CD) pipelines. In particular when it comes to the stability metrics (MTTR and change fail percentage), CD pipeline data alone doesn\u0027t provide enough information to determine what a deployment failure with real user impact is. Stability metrics only make sense if they include data about real incidents that degrade service for the users.\u003c/p\u003e\n\n\u003cp\u003eWe recommend always to keep in mind the ultimate intention behind a measurement and use it to reflect and learn. For example, before spending weeks building up sophisticated dashboard tooling, consider just regularly taking the \u003ca href\u003d\"https://www.devops-research.com/quickcheck.html\"\u003eDORA quick check\u003c/a\u003e in team retrospectives. This gives the team the opportunity to reflect on which \u003ca href\u003d\"https://www.devops-research.com/research.html#capabilities\"\u003ecapabilities\u003c/a\u003e they could work on to improve their metrics, which can be much more effective than overdetailed out-of-the-box tooling. Keep in mind that these four key metrics originated out of the organization-level research of high-performing teams, and the use of these metrics at a team level should be a way to reflect on their own behaviors, not just another set of metrics to add to the dashboard.\u003c/p\u003e","blip_status":"c","theta":"150","volume":"2022-03"},{"name":"Single team remote wall","id":"202110040","quadrant":"Techniques","ring":"Adopt","movement":"t","radarId":"2","display_name":"Single team remote wall","radius":"110","description":"\u003cp\u003eA \u003cstrong\u003esingle team remote wall\u003c/strong\u003e is a simple technique to reintroduce the team wall virtually. We recommend that distributed teams adopt this approach; one of the things we hear from teams who moved to remote working is that they miss having the physical team wall. This was a single place where all the various story cards, tasks, status and progress could be displayed, acting as an information radiator and hub for the team. The wall acted as an integration point with the actual data being stored in different systems. As teams have become remote, they\u0027ve had to revert to looking into the individual source systems and getting an \"at a glance\" view of a project has become very difficult. While there might be some overhead in keeping this up-to-date, we feel the benefits to the team are worth it. For some teams, updating the physical wall formed part of the daily \"ceremonies\" the team did together, and the same can be done with a remote wall.\u003c/p\u003e","blip_status":"move_in","theta":"120","volume":"2022-03"},{"name":"Data mesh","id":"201911051","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"3","display_name":"Data mesh","radius":"180","description":"\u003cp\u003e\u003ca href\u003d\"https://martinfowler.com/articles/data-monolith-to-mesh.html\"\u003e\u003cstrong\u003eData mesh\u003c/strong\u003e\u003c/a\u003e is a \u003cem\u003edecentralized\u003c/em\u003e organizational and technical approach in sharing, accessing and managing data for analytics and ML. Its objective is to create a \u003cem\u003esociotechnical\u003c/em\u003e approach that scales out getting value from data as the organization\u0027s complexity grows and as the use cases for data proliferate and the sources of data diversify. Essentially, it creates a \u003cem\u003eresponsible\u003c/em\u003e data-sharing model that is in step with organizational growth and continuous change. In our experience, interest in the application of data mesh has grown tremendously. The approach has inspired many organizations to embrace its adoption and technology providers to repurpose their existing technologies for a mesh deployment. Despite the great interest and growing experience in data mesh, its implementations face high cost of integration. Moreover, its adoption remains limited to sections of larger organizations and technology vendors are distracting the organizations from the hard \u003cem\u003esocio\u003c/em\u003e aspects of data mesh — decentralized data ownership and a federated governance operating model.\u003c/p\u003e\n\n\u003cp\u003eThese ideas are explored in \u003cem\u003e\u003ca href\u003d\"https://www.amazon.com/Data-Mesh-Delivering-Data-Driven-Value/dp/1492092398\"\u003eData Mesh, Delivering Data-Driven Value at Scale\u003c/a\u003e\u003c/em\u003e, which guides practitioners, architects, technical leaders and decision makers on their journeys from traditional big data architecture to data mesh. It provides a complete introduction to data mesh principles and its constituents; it covers how to design a data mesh architecture, guide and execute a data mesh strategy and navigate organizational design to a decentralized data ownership model. The goal of the book is to create a new framework for deeper conversations and lead to the next phase in maturity of data mesh.\u003c/p\u003e","blip_status":"c","theta":"171","volume":"2022-03"},{"name":"Definition of production readiness","id":"202203026","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"4","display_name":"Definition of production readiness","radius":"170","description":"\u003cp\u003eIn an organization that practices the \"you build it, you run it\" principle, a \u003cstrong\u003edefinition of production readiness\u003c/strong\u003e (DPR) is a useful technique to support teams in assessing and preparing the operational readiness of new services. Implemented as a checklist or a template, a DPR gives teams guidance on what to think about and consider before they bring a new service into production. While DPRs do not define specific service-level objectives (SLOs) to fulfill (those would be hard to define one-size-fits-all), they remind teams what categories of SLOs to think of, what organizational standards to comply with and what documentation is required. DPRs provide a source of input that teams turn into respective product-specific requirements around, for example, observability and reliability, to feed into their product backlogs.\u003c/p\u003e\n\n\u003cp\u003eDPRs are closely related to Google\u0027s concept of a \u003ca href\u003d\"https://sre.google/sre-book/evolving-sre-engagement-model/#:%7E:text\u003dThe%20most%20typical,of%20a%20service\"\u003eproduction readiness review (PRR)\u003c/a\u003e. In organizations that are too small to have a dedicated site reliability engineering team, or who are concerned that a review board process could negatively impact a team\u0027s flow to go live, having a DPR can at least provide some guidance and document the agreed-upon criteria for the organization. For highly critical new services, extra scrutiny on fulfilling the DPR can be added via a PRR when needed.\u003c/p\u003e","blip_status":"t","theta":"162","volume":"2022-03"},{"name":"Documentation quadrants","id":"202203016","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"5","display_name":"Documentation quadrants","radius":"200","description":"\u003cp\u003eWriting good documentation is an overlooked aspect of software development that is often left to the last minute and done in a haphazard way. Some of our teams have found \u003cstrong\u003e\u003ca href\u003d\"https://documentation.divio.com/\"\u003edocumentation quadrants\u003c/a\u003e\u003c/strong\u003e a handy way to ensure the right artifacts are being produced. This technique classifies artifacts along two axes: The first axis relates to the nature of the information, practical or theoretical; the second axis describes the context in which the artifact is used, studying or working. This defines four quadrants in which artifacts such as tutorials, how-to guides or reference pages can be placed and understood. This classification system not only ensures that critical artifacts aren\u0027t overlooked but also guides the presentation of the content. We\u0027ve found this particularly useful for creating onboarding documentation that brings developers up to speed quickly when they join a new team.\u003c/p\u003e","blip_status":"t","theta":"153","volume":"2022-03"},{"name":"Rethinking remote standups","id":"202203099","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"6","display_name":"Rethinking remote standups","radius":"240","description":"\u003cp\u003eThe term \u003cem\u003estandup\u003c/em\u003e originated from the idea of standing up during this daily sync meeting, with the goal of making it short. It\u0027s a common principle many teams try to abide by in their standups: keep it crisp and to the point. But we\u0027re now seeing teams challenge that principle and \u003cstrong\u003erethinking remote standups\u003c/strong\u003e. When co-located, there are lots of opportunities during the rest of the day to sync up with each other spontaneously, as a complement to the short standup. Remotely, some of our teams are now experimenting with a longer meeting format, similar to what the folks at Honeycomb call a “\u003ca href\u003d\"https://www.honeycomb.io/blog/standup-meetings-are-dead/\"\u003emeandering team sync\u003c/a\u003e.”\u003c/p\u003e\n\n\u003cp\u003eIt\u0027s not about getting rid of a daily sync altogether; we still find that very important and valuable, especially in a remote setup. Instead, it\u0027s about extending the time blocked in everybody\u0027s calendars for the daily sync to up to an hour, and use it in a way that makes some of the other team meetings obsolete and brings the team closer together. Activities can still include the well-tried walkthrough of the team board but are then extended by more detailed clarification discussions, quick decisions, and taking time to socialize. The technique is considered successful if it reduces the overall meeting load and improves team bonding.\u003c/p\u003e","blip_status":"t","theta":"144","volume":"2022-03"},{"name":"Server-driven UI","id":"202203029","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"7","display_name":"Server-driven UI","radius":"230","description":"\u003cp\u003eWhen putting together a new volume of the Radar, we\u0027re often overcome by a sense of déjà vu, and the technique of \u003cstrong\u003eserver-driven UI\u003c/strong\u003e sparks a particularly strong case with the advent of frameworks that allow mobile developers to take advantage of faster change cycles while not falling foul of an app store\u0027s policies around revalidation of the mobile app itself. We\u0027ve blipped about this before from the perspective of enabling mobile development to \u003ca href\u003d\"/radar/techniques/micro-frontends-for-mobile\"\u003escale across teams\u003c/a\u003e. Server-driven UI separates the rendering into a generic container in the mobile app while the structure and data for each view is provided by the server. This means that changes that once required a round trip to an app store can now be accomplished via simple changes to the responses the server sends. Note, we\u0027re not recommending this approach for all UI development, indeed we\u0027ve experienced some horrendous, overly configurable messes, but with the backing of behemoths such as AirBnB and Lyft, we suspect it\u0027s not only us at Thoughtworks getting tired of \u003ca href\u003d\"/radar/techniques/spa-by-default\"\u003eeverything being done client side\u003c/a\u003e. Watch this space.\u003c/p\u003e","blip_status":"t","theta":"135","volume":"2022-03"},{"name":"Software Bill of Materials","id":"202110076","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"8","display_name":"Software Bill of Materials","radius":"200","description":"\u003cp\u003eWith continued pressure to keep systems secure and no reduction in the general threat landscape, a machine-readable \u003cstrong\u003eSoftware Bill of Materials\u003c/strong\u003e (SBOM) may help teams stay on top of security problems in the libraries that they rely on. The recent \u003ca href\u003d\"https://en.wikipedia.org/wiki/Log4Shell\"\u003eLog4Shell\u003c/a\u003e zero-day remote exploit was critical and widespread, and if teams had had an SBOM ready, it could have been scanned for and fixed quickly. We\u0027ve now had production experience using SBOMs on projects ranging from small companies to large multinationals and even government departments, and we\u0027re convinced they provide a benefit. Tools such as \u003ca href\u003d\"/radar/tools/syft\"\u003eSyft\u003c/a\u003e make it easy to use an SBOM for vulnerability detection.\u003c/p\u003e","blip_status":"move_in","theta":"126","volume":"2022-03"},{"name":"Tactical forking","id":"202203098","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"9","display_name":"Tactical forking","radius":"220","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://faustodelatog.wordpress.com/2020/10/16/tactical-forking/\"\u003eTactical forking\u003c/a\u003e\u003c/strong\u003e is a technique that can assist with restructuring or migrating from monolithic codebases to microservices. Specifically, this technique offers one possible alternative to the more common approach of fully modularizing the codebase first, which in many circumstances can take a very long time or be very challenging to achieve. With tactical forking a team can create a new fork of the codebase and use that to address and extract one particular concern or area while deleting the unnecessary code. Use of this technique would likely be just one part of a longer-term plan for the overall monolith.\u003c/p\u003e","blip_status":"t","theta":"117","volume":"2022-03"},{"name":"Team cognitive load","id":"202104127","quadrant":"Techniques","ring":"Trial","movement":"c","radarId":"10","display_name":"Team cognitive load","radius":"170","description":"\u003cp\u003eA system\u0027s architecture mimics an organizational structure and its communication. It\u0027s not big news that we should be intentional about how teams interact — see, for instance, the \u003ca href\u003d\"/radar/techniques/inverse-conway-maneuver\"\u003eInverse Conway Maneuver\u003c/a\u003e. Team interaction is one of the variables for how fast and how easily teams can deliver value to their customers. We were happy to find a way to measure these interactions; we used the \u003ca href\u003d\"https://teamtopologies.com/book\"\u003eTeam Topologies\u003c/a\u003e author\u0027s \u003ca href\u003d\"https://github.com/TeamTopologies/Team-Cognitive-Load-Assessment\"\u003eassessment\u003c/a\u003e which gives you an understanding of how easy or difficult the teams find it to build, test and maintain their services. By measuring \u003cstrong\u003eteam cognitive load\u003c/strong\u003e, we could better advise our clients on how to change their teams\u0027 structure and evolve their interactions.\u003c/p\u003e","blip_status":"c","theta":"108","volume":"2022-03"},{"name":"Transitional architecture","id":"202203071","quadrant":"Techniques","ring":"Trial","movement":"t","radarId":"11","display_name":"Transitional architecture","radius":"210","description":"\u003cp\u003eA \u003cstrong\u003e\u003ca href\u003d\"https://martinfowler.com/articles/patterns-legacy-displacement/transitional-architecture.html\"\u003etransitional architecture\u003c/a\u003e\u003c/strong\u003e is a useful practice used when replacing legacy systems. Much like scaffolding might be built, reconfigured and finally removed during construction or renovation of a building, you often need interim architectural steps during legacy displacement. Transitional architectures will be removed or replaced later on, but they\u0027re not just throwaway work given the important role they play in reducing risk and allowing a difficult problem to be broken into smaller steps. Thus they help with avoiding the trap of defaulting to a \"big bang\" legacy replacement approach, because you cannot make smaller interim steps line up with a final architectural vision. Care is needed to make sure the architectural \"scaffolding\" is eventually removed, lest it just become technical debt later on.\u003c/p\u003e","blip_status":"t","theta":"99","volume":"2022-03"},{"name":"CUPID","id":"202203050","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"12","display_name":"CUPID","radius":"310","description":"\u003cp\u003eHow do you approach writing good code? How do you judge if you\u0027ve written good code? As software developers, we\u0027re always looking for catchy rules, principles and patterns that we can use to share a language and values with each other when it comes to writing simple, easy-to-change code.\u003c/p\u003e\n\n\u003cp\u003eDaniel Terhorst-North has recently made a new attempt at creating such a checklist for good code. He argues that instead of sticking to a set of rules like \u003ca href\u003d\"https://en.wikipedia.org/wiki/SOLID\"\u003eSOLID\u003c/a\u003e, using a set of properties to aim for is more generally applicable. He came up with what he calls the \u003cstrong\u003e\u003ca href\u003d\"https://dannorth.net/2022/02/10/cupid-for-joyful-coding/\"\u003eCUPID\u003c/a\u003e\u003c/strong\u003e properties to describe what we should strive for to achieve \"joyful\" code: Code should be composable, follow the Unix philosophy and be predictable, idiomatic and domain based.\u003c/p\u003e","blip_status":"t","theta":"169","volume":"2022-03"},{"name":"Inclusive design","id":"202203054","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"13","display_name":"Inclusive design","radius":"302","description":"\u003cp\u003eWe recommend organizations assess \u003ca href\u003d\"https://www.microsoft.com/design/inclusive/\"\u003e\u003cstrong\u003einclusive design\u003c/strong\u003e\u003c/a\u003e as a way of making sure accessibility is treated as a first-class requirement. All too often requirements around accessibility and inclusivity are ignored until just before, if not just after, the release of software. The cheapest and simplest way to accommodate these requirements, while also providing early feedback to teams, is to incorporate them fully into the development process. In the past, we\u0027ve highlighted techniques that perform a \"shift-left\" for security and cross-functional requirements; one perspective on this technique is that it achieves the same goal for accessibility.\u003c/p\u003e","blip_status":"t","theta":"158","volume":"2022-03"},{"name":"Operator pattern for nonclustered resources","id":"202110008","quadrant":"Techniques","ring":"Assess","movement":"c","radarId":"14","display_name":"Operator pattern for nonclustered resources","radius":"302","description":"\u003cp\u003eWe\u0027re continuing to see increasing use of the \u003ca href\u003d\"/radar/tools/kubernetes-operators\"\u003eKubernetes Operator\u003c/a\u003e pattern for purposes other than managing applications deployed on the cluster. Using the \u003cstrong\u003eOperator pattern for nonclustered resources\u003c/strong\u003e takes advantage of custom resource definitions and the event-driven scheduling mechanism implemented in the Kubernetes control plane to manage activities that are related to yet outside of the cluster. This technique builds on the idea of \u003ca href\u003d\"/radar/techniques/kube-managed-cloud-services\"\u003eKube-managed cloud services\u003c/a\u003e and extends it to other activities, such as continuous deployment or reacting to changes in external repositories. One advantage of this technique over a purpose-built tool is that it opens up a wide range of tools that either come with Kubernetes or are part of the wider ecosystem. You can use commands such as diff, dry-run or apply to interact with the operator\u0027s custom resources. Kube\u0027s scheduling mechanism makes development easier by eliminating the need to orchestrate activities in the proper order. Open-source tools such as \u003ca href\u003d\"/radar/tools/crossplane\"\u003eCrossplane\u003c/a\u003e, \u003ca href\u003d\"https://fluxcd.io/\"\u003eFlux\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/argo-cd\"\u003eArgo CD\u003c/a\u003e take advantage of this technique, and we expect to see more of these emerge over time. Although these tools have their use cases, we\u0027re also starting to see the inevitable misuse and overuse of this technique and need to repeat some old advice: Just because you \u003cem\u003ecan\u003c/em\u003e do something with a tool doesn\u0027t mean you \u003cem\u003eshould\u003c/em\u003e. Be sure to rule out simpler, conventional approaches before creating a custom resource definition and taking on the complexity that comes with this approach.\u003c/p\u003e","blip_status":"c","theta":"147","volume":"2022-03"},{"name":"Service mesh without sidecar","id":"202203060","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"15","display_name":"Service mesh without sidecar","radius":"320","description":"\u003cp\u003e\u003ca href\u003d\"/radar/techniques/service-mesh\"\u003eService mesh\u003c/a\u003e is usually implemented as a reverse-proxy process, aka sidecar, deployed alongside each service instance. Although these sidecars are lightweight processes, the overall cost and operational complexity of adopting service mesh increases with every new instance of the service requiring another sidecar. However, with the advancements in \u003ca href\u003d\"/radar/platforms/ebpf\"\u003eeBPF\u003c/a\u003e, we\u0027re observing a new \u003ca href\u003d\"https://isovalent.com/blog/post/2021-12-08-ebpf-servicemesh\"\u003e\u003cstrong\u003eservice mesh without sidecar\u003c/strong\u003e\u003c/a\u003e approach where the functionalities of the mesh are safely pushed down to the OS kernel, thereby enabling services in the same node to communicate transparently via sockets without the need of additional proxies. You can try this with \u003ca href\u003d\"https://github.com/cilium/cilium-service-mesh-beta\"\u003eCilium service mesh\u003c/a\u003e and simplify the deployment from one proxy-per-service to one proxy-per-node. We\u0027re intrigued by the capabilities of eBPF and find this evolution of service mesh to be important to assess.\u003c/p\u003e","blip_status":"t","theta":"135","volume":"2022-03"},{"name":"SLSA","id":"202203063","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"16","display_name":"SLSA","radius":"300","description":"\u003cp\u003eAs software continues to grow in complexity, the threat vector of software dependencies becomes increasingly challenging to guard against. The recent Log4J vulnerability showed how difficult it can be to even \u003cem\u003eknow\u003c/em\u003e those dependencies — many companies who didn\u0027t use Log4J directly were unknowingly vulnerable simply because other software in their ecosystem relied on it. Supply chain Levels for Software Artifacts, or \u003cstrong\u003e\u003ca href\u003d\"https://slsa.dev\"\u003eSLSA\u003c/a\u003e\u003c/strong\u003e (pronounced \"salsa\"), is a consortium-curated set of guidance for organizations to protect against supply chain attacks, evolved from internal guidance Google has been using for years. We appreciate that SLSA doesn\u0027t promise a \"silver bullet,\" tools-only approach to securing the supply chain but instead provides a checklist of concrete threats and practices along a maturity model. The \u003ca href\u003d\"https://slsa.dev/spec/v0.1/threats\"\u003ethreat model\u003c/a\u003e is easy to follow with real-world examples of attacks, and the \u003ca href\u003d\"https://slsa.dev/spec/v0.1/requirements\"\u003erequirements\u003c/a\u003e provide guidance to help organizations prioritize actions based on levels of increasing robustness to improve their supply chain security posture. We think SLSA provides applicable advice and look forward to more organizations learning from it.\u003c/p\u003e","blip_status":"t","theta":"124","volume":"2022-03"},{"name":"The streaming data warehouse","id":"202203008","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"17","display_name":"The streaming data warehouse","radius":"320","description":"\u003cp\u003eThe need to respond quickly to customer insights has driven increasing adoption of event-driven architectures and stream processing. Frameworks such as \u003ca href\u003d\"/radar/platforms/apache-spark\"\u003eSpark\u003c/a\u003e, \u003ca href\u003d\"/radar/platforms/apache-flink\"\u003eFlink\u003c/a\u003e or \u003ca href\u003d\"/radar/platforms/kafka-streams\"\u003eKafka Streams\u003c/a\u003e offer a paradigm where simple event consumers and producers can cooperate in complex networks to deliver real-time insights. But this programming style takes time and effort to master and when implemented as single-point applications, it lacks interoperability. Making stream processing work universally on a large scale can require a significant engineering investment. Now, a new crop of tools is emerging that offers the benefits of stream processing to a wider, established group of developers who are comfortable using SQL to implement analytics. Standardizing on SQL as the universal streaming language lowers the barrier for implementing streaming data applications. Tools like \u003ca href\u003d\"/radar/languages-and-frameworks/ksqldb\"\u003eksqlDB\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/materialize\"\u003eMaterialize\u003c/a\u003e help transform these separate applications into unified platforms. Taken together, a collection of SQL-based streaming applications across an enterprise might constitute a \u003cstrong\u003estreaming data warehouse\u003c/strong\u003e.\u003c/p\u003e","blip_status":"t","theta":"113","volume":"2022-03"},{"name":"TinyML","id":"202203070","quadrant":"Techniques","ring":"Assess","movement":"t","radarId":"18","display_name":"TinyML","radius":"302","description":"\u003cp\u003eUntil recently, executing a machine-learning (ML) model was seen as computationally expensive and in some cases required special-purpose hardware. While creating the models still broadly sits within this classification, they can be created in a way that allows them to be run on small, low-cost and low-power consumption devices. This technique, called \u003cstrong\u003e\u003ca href\u003d\"https://towardsdatascience.com/an-introduction-to-tinyml-4617f314aa79\"\u003eTinyML\u003c/a\u003e\u003c/strong\u003e, has opened up the possibility of running ML models in situations many might assume infeasible. For example, on battery-powered devices, or in disconnected environments with limited or patchy connectivity, the model can be run locally without prohibitive cost. If you\u0027ve been considering using ML but thought it unrealistic because of compute or network constraints, then this technique is worth assessing.\u003c/p\u003e","blip_status":"t","theta":"102","volume":"2022-03"},{"name":"Azure Data Factory for orchestration","id":"201911058","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"19","display_name":"Azure Data Factory for orchestration","radius":"375","description":"\u003cp\u003eFor organizations using Azure as their primary cloud provider, \u003ca href\u003d\"https://azure.microsoft.com/en-us/services/data-factory/\"\u003eAzure Data Factory\u003c/a\u003e is currently the default for orchestrating data-processing pipelines. It supports data ingestion, copying data from and to different storage types on prem or on Azure and executing transformation logic. Although we\u0027ve had adequate experience with Azure Data Factory for simple migrations of data stores from on prem to the cloud, we discourage the use of \u003cstrong\u003eAzure Data Factory for orchestration\u003c/strong\u003e of complex data-processing pipelines and workflows. We\u0027ve had some success with Azure Data Factory when it\u0027s used primarily to move data between systems. For more complex data pipelines, it still has its challenges, including poor debuggability and error reporting; limited observability as Azure Data Factory logging capabilities don\u0027t integrate with other products such as Azure Data Lake Storage or Databricks, making it difficult to get an end-to-end observability in place; and availability of data source-triggering mechanisms only to certain regions. At this time, we encourage using other open-source orchestration tools (e.g., \u003ca href\u003d\"/radar/tools/airflow\"\u003eAirflow\u003c/a\u003e) for complex data pipelines and limiting Azure Data Factory for data copying or snapshotting. Our teams continue to use Data Factory to move and extract data, but for larger operations we recommend other, more well-rounded workflow tools.\u003c/p\u003e","blip_status":"c","theta":"162","volume":"2022-03"},{"name":"Miscellaneous platform teams","id":"202203003","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"20","display_name":"Miscellaneous platform teams","radius":"380","description":"\u003cp\u003eWe previously featured \u003ca href\u003d\"/radar/techniques/platform-engineering-product-teams\"\u003eplatform engineering product teams\u003c/a\u003e in Adopt as a good way for internal platform teams to operate, thus enabling delivery teams to self-service deploy and operate systems with reduced lead time and stack complexity. Unfortunately we\u0027re seeing the \"platform team\" label applied to teams dedicated to projects that don\u0027t have clear outcomes or a well-defined set of customers. As a result, these \u003cstrong\u003emiscellaneous platform teams\u003c/strong\u003e, as we call them, struggle to deliver due to high cognitive loads and a lack of clearly aligned priorities as they\u0027re dealing with a miscellaneous collection of unrelated systems. They effectively become just another general support team for things that don\u0027t fit or that are unwanted elsewhere. We continue to believe platform engineering product teams focused around a clear and well-defined (internal) product offer a better set of outcomes.\u003c/p\u003e","blip_status":"t","theta":"144","volume":"2022-03"},{"name":"Production data in test environments","id":"202110036","quadrant":"Techniques","ring":"Hold","movement":"c","radarId":"21","display_name":"Production data in test environments","radius":"375","description":"\u003cp\u003eWe continue to perceive \u003cstrong\u003eproduction data in test environments\u003c/strong\u003e as an area for concern. Firstly, many examples of this have resulted in reputational damage, for example, where an incorrect alert has been sent from a test system to an entire client population. Secondly, the level of security, specifically around protection of private data, tends to be less for test systems. There is little point in having elaborate controls around access to production data if that data is copied to a test database that can be accessed by every developer and QA. Although you \u003cem\u003ecan\u003c/em\u003e obfuscate the data, this tends to be applied only to specific fields, for example, credit card numbers. Finally, copying production data to test systems can break privacy laws, for example, where test systems are hosted or accessed from a different country or region. This last scenario is especially problematic with complex cloud deployments. Fake data is a safer approach, and tools exist to help in its creation. We do recognize there are reasons for \u003cem\u003especific\u003c/em\u003e elements of production data to be copied, for example, in the reproduction of bugs or for training of specific ML models. Here our advice is to proceed with caution.\u003c/p\u003e","blip_status":"c","theta":"126","volume":"2022-03"},{"name":"SPA by default","id":"202203006","quadrant":"Techniques","ring":"Hold","movement":"t","radarId":"22","display_name":"SPA by default","radius":"380","description":"\u003cp\u003eWe generally avoid putting blips in Hold when we consider that advice too obvious, including blindly following an architectural style without paying attention to trade-offs. However, the sheer prevalence of teams choosing a single-page application (SPA) by default when they need a website has us concerned that people aren\u0027t even recognizing SPAs as an architectural style to begin with, instead immediately jumping into framework selection. SPAs incur complexity that simply doesn\u0027t exist with traditional server-based websites: search engine optimization, browser history management, web analytics, first page load time, etc. That complexity is often warranted for user experience reasons, and tooling continues to evolve to make those concerns easier to address (although the churn in the React community around state management hints at how hard it can be to get a generally applicable solution). Too often, though, we don\u0027t see teams making that trade-off analysis, blindly accepting the complexity of \u003cstrong\u003eSPAs by default\u003c/strong\u003e even when the business needs don\u0027t justify it. Indeed, we\u0027ve started to notice that many newer developers aren\u0027t even aware of an alternative approach, as they\u0027ve spent their entire career in a framework like React. We believe that many websites will benefit from the simplicity of server-side logic, and we\u0027re encouraged by techniques like \u003ca href\u003d\"/radar/techniques/hotwire\"\u003eHotwire\u003c/a\u003e that help close the gap on user experience.\u003c/p\u003e","blip_status":"t","theta":"108","volume":"2022-03"},{"name":"Azure DevOps","id":"1329","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"23","display_name":"Azure DevOps","radius":"230","description":"\u003cp\u003eAs the \u003cstrong\u003e\u003ca href\u003d\"https://azure.microsoft.com/en-us/services/devops/\"\u003eAzure DevOps\u003c/a\u003e\u003c/strong\u003e ecosystem keeps growing, our teams are using it more with success. These services contain a set of managed services, including hosted Git repos, build and deployment pipelines, automated testing tooling, backlog management tooling and artifact repository. We\u0027ve seen our teams gaining experience in using this platform with good results, which means Azure DevOps is maturing. We particularly like its flexibility; it allows you to use the services you want even if they\u0027re from different providers. For instance, you could use an external Git repository while still using the Azure DevOps pipeline services. Our teams are especially excited about \u003ca href\u003d\"https://azure.microsoft.com/en-us/services/devops/pipelines/\"\u003eAzure DevOps Pipelines\u003c/a\u003e. As the ecosystem matures, we\u0027re seeing an uptick in onboarding teams that are already on the Azure stack as it easily integrates with the rest of the Microsoft world.\u003c/p\u003e","blip_status":"c","theta":"186","volume":"2022-03"},{"name":"Azure Pipeline templates","id":"202203044","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"24","display_name":"Azure Pipeline templates","radius":"250","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://docs.microsoft.com/en-us/azure/devops/pipelines/process/templates?view\u003dazure-devops\"\u003eAzure Pipeline templates\u003c/a\u003e\u003c/strong\u003e allow you to remove duplication in your Azure Pipeline definition through two mechanisms. With \"includes\" templates, you can reference a template such that it will expand inline like a parameterized C++ macro, allowing a simple way of factoring out common configuration across stages, jobs and steps. With \"extends\" templates, you can define an outer shell with common pipeline configuration, and with the \u003ca href\u003d\"https://docs.microsoft.com/en-us/azure/devops/pipelines/process/approvals?view\u003dazure-devops\u0026tabs\u003dcheck-pass#required-template\"\u003erequired template approval\u003c/a\u003e, you can fail the build if the pipeline doesn\u0027t extend certain templates, preventing malicious attacks against the pipeline configuration itself. Along with \u003ca href\u003d\"/radar/platforms/circleci\"\u003eCircleCI\u003c/a\u003e Orbs and the newer \u003ca href\u003d\"/radar/platforms/reusable-workflows-in-github-actions\"\u003eGitHub Actions Reusable Workflows\u003c/a\u003e, Azure Pipeline templates are part of the trend of creating modularity in pipeline design across multiple platforms, and several of our teams have been happy using them.\u003c/p\u003e","blip_status":"t","theta":"193","volume":"2022-03"},{"name":"CircleCI","id":"1147","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"25","display_name":"CircleCI","radius":"175","description":"\u003cp\u003eMany of our teams choose \u003cstrong\u003e\u003ca href\u003d\"http://circleci.com/\"\u003eCircleCI\u003c/a\u003e\u003c/strong\u003e for their continuous integration needs, and they appreciate its ability to run complex pipelines efficiently. The CircleCI developers continue to add new features with CircleCI, now in version 3.0. \u003ca href\u003d\"https://circleci.com/docs/2.0/concepts/#orbs\"\u003eOrbs\u003c/a\u003e and \u003ca href\u003d\"https://circleci.com/docs/2.0/executor-types/\"\u003eexecutors\u003c/a\u003e were called out by our teams as being particularly useful. Orbs are reusable snippets of code that automate repeated processes, speed up project setup and make it easy to integrate with third-party tools. The wide variety of executor types provides flexibility to set up jobs in Docker, Linux, macOS or Windows VMs.\u003c/p\u003e","blip_status":"c","theta":"200","volume":"2022-03"},{"name":"Couchbase","id":"513","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"26","display_name":"Couchbase","radius":"200","description":"\u003cp\u003eWhen we originally blipped \u003cstrong\u003e\u003ca href\u003d\"https://www.couchbase.com/\"\u003eCouchbase\u003c/a\u003e\u003c/strong\u003e in 2013, it was seen primarily as a persistent cache that evolved from a merger of \u003ca href\u003d\"https://github.com/membase\"\u003eMembase\u003c/a\u003e and \u003ca href\u003d\"https://couchdb.apache.org/\"\u003eCouchDB\u003c/a\u003e. Since then, it has undergone steady improvement and an ecosystem of related tools and commercial offerings has grown up around it. Among the additions to the product suite are Couchbase Mobile and the Couchbase Sync Gateway. These features work together to keep persistent data on edge devices up-to-date even when the device is offline for periods of time due to intermittent connectivity. As these devices proliferate, we see increasing need for embedded persistence that continues to work whether or not the device happens to be connected. Recently, one of our teams evaluated Couchbase for its offline sync capability and found that this off-the-shelf capability saved them considerable effort that they otherwise would have had to invest themselves.\u003c/p\u003e","blip_status":"c","theta":"207","volume":"2022-03"},{"name":"eBPF","id":"202005111","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"27","display_name":"eBPF","radius":"250","description":"\u003cp\u003eFor several years now, the Linux kernel has included the extended Berkeley Packet Filter (\u003cstrong\u003e\u003ca href\u003d\"https://ebpf.io/\"\u003eeBPF\u003c/a\u003e\u003c/strong\u003e), a virtual machine that provides the ability to attach filters to particular sockets. But eBPF goes far beyond packet filtering and allows custom scripts to be triggered at various points within the kernel with very little overhead. Although this technology isn\u0027t new, it\u0027s now coming into its own with the increasing use of microservices deployed as orchestrated containers. Kubernetes and service mesh technology such as \u003ca href\u003d\"/radar/platforms/istio\"\u003eIstio\u003c/a\u003e are commonly used, and they employ sidecars to implement control functionality. With new tools — \u003ca href\u003d\"https://github.com/solo-io/bumblebee\"\u003eBumblebee\u003c/a\u003e in particular makes building, running and distributing eBPF programs much easier — eBPF can be seen as an alternative to the traditional sidecar. A maintainer of \u003ca href\u003d\"/radar/tools/cilium\"\u003eCilium\u003c/a\u003e, a tool in this space, has even proclaimed the \u003ca href\u003d\"https://isovalent.com/blog/post/2021-12-08-ebpf-servicemesh\"\u003edemise of the sidecar\u003c/a\u003e. An approach based on eBPF reduces some overhead in performance and operation that comes with sidecars, but it doesn\u0027t support common features such as SSL termination.\u003c/p\u003e","blip_status":"c","theta":"214","volume":"2022-03"},{"name":"GitHub Actions","id":"202104005","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"28","display_name":"GitHub Actions","radius":"175","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://docs.github.com/en/actions\"\u003eGitHub Actions\u003c/a\u003e\u003c/strong\u003e has grown considerably last year. It has proven that it can take on more complex workflows and call other actions in composite actions among other things. It still has some shortcomings, though, such as its inability to re-trigger a single job of a workflow. Although the ecosystem in the \u003ca href\u003d\"https://github.com/marketplace?type\u003dactions\"\u003eGitHub Marketplace\u003c/a\u003e has its obvious advantages, giving third-party GitHub Actions access to your build pipeline risks sharing secrets in insecure ways (we recommend following GitHub\u0027s advice on \u003ca href\u003d\"https://docs.github.com/en/actions/security-guides/security-hardening-for-github-actions\"\u003esecurity hardening\u003c/a\u003e). However, the convenience of creating your build workflow directly in GitHub next to your source code combined with the ability to run GitHub Actions locally using open-source tools such as \u003ca href\u003d\"https://github.com/nektos/act\"\u003eact\u003c/a\u003e is a compelling option that has facilitated setup and onboarding of our teams.\u003c/p\u003e","blip_status":"c","theta":"221","volume":"2022-03"},{"name":"GitLab CI/CD","id":"202203001","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"29","display_name":"GitLab CI/CD","radius":"205","description":"\u003cp\u003eIf you\u0027re using \u003ca href\u003d\"https://gitlab.com/\"\u003eGitLab\u003c/a\u003e to manage your software delivery, you should also look at \u003cstrong\u003e\u003ca href\u003d\"https://docs.gitlab.com/ee/ci/\"\u003eGitLab CI/CD\u003c/a\u003e\u003c/strong\u003e for your continuous integration and continuous delivery needs. We\u0027ve found it especially useful when used with on-premise GitLab and self-hosted runners, as this combination gets around authorization headaches often caused by using a cloud-based solution. Self-hosted runners can be fully configured for your purposes with the right OS and dependencies installed, and as a result pipelines can run much faster than using a cloud-provisioned runner that needs to be configured each time.\u003c/p\u003e\n\n\u003cp\u003eApart from the basic build, test and deploy pipeline, GitLab\u0027s product supports Services, Auto Devops and ChatOps among other advanced features. Services are useful in running Docker services such as Postgres or \u003ca href\u003d\"/radar/languages-and-frameworks/testcontainers\"\u003eTestcontainer\u003c/a\u003e linked to a job for integration and end-to-end testing. Auto Devops creates pipelines with zero configuration which is very useful for teams that are new to continuous delivery or for organizations with many repositories that would otherwise need to create many pipelines manually.\u003c/p\u003e","blip_status":"t","theta":"227","volume":"2022-03"},{"name":"Google BigQuery ML","id":"202005040","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"30","display_name":"Google BigQuery ML","radius":"200","description":"\u003cp\u003eSince we last blipped about \u003cstrong\u003e\u003ca href\u003d\"https://cloud.google.com/bigquery-ml/docs\"\u003eGoogle BigQuery ML\u003c/a\u003e\u003c/strong\u003e, more sophisticated models such as Deep Neural Networks and AutoML Tables have been added by connecting BigQuery ML with TensorFlow and Vertex AI as its backend. BigQuery has also introduced support for time series forecasting. One of our concerns previously was \u003ca href\u003d\"/radar/techniques/explainability-as-a-first-class-model-selection-criterion\"\u003eexplainability\u003c/a\u003e. Earlier this year, \u003ca href\u003d\"https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-xai-overview\"\u003eBigQuery Explainable AI\u003c/a\u003e was announced for general availability, taking a step in addressing this. We can also export BigQuery ML models to Cloud Storage as a Tensorflow SavedModel and use them for online prediction. There remain trade-offs like ease of \"continuous delivery for machine learning\" but with its low barrier to entry, BigQuery ML remains an attractive option, particularly when the data already resides in BigQuery.\u003c/p\u003e","blip_status":"move_in","theta":"235","volume":"2022-03"},{"name":"Google Cloud Dataflow","id":"1336","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"31","display_name":"Google Cloud Dataflow","radius":"230","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://cloud.google.com/dataflow/\"\u003eGoogle Cloud Dataflow\u003c/a\u003e\u003c/strong\u003e is a cloud-based data-processing service for both batch and real-time data-streaming applications. Our teams are using Dataflow to create processing pipelines for integrating, preparing and analyzing large data sets, with \u003ca href\u003d\"https://beam.apache.org/\"\u003eApache Beam\u003c/a\u003e\u0027s unified programming model on top to ease manageability. We first featured Dataflow in 2018, and its stability, performance and rich feature set make us confident to move it to Trial in this edition of the Radar.\u003c/p\u003e","blip_status":"move_in","theta":"242","volume":"2022-03"},{"name":"Reusable workflows in Github Actions","id":"202203005","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"32","display_name":"Reusable workflows in Github Actions","radius":"200","description":"\u003cp\u003eWe\u0027ve seen increased interest in \u003ca href\u003d\"/radar/platforms/github-actions\"\u003eGitHub Actions\u003c/a\u003e since we first blipped it two Radars ago. With the release of \u003ca href\u003d\"https://docs.github.com/en/actions/using-workflows/reusing-workflows\"\u003ereusable workflows\u003c/a\u003e, GitHub continues to evolve the product in a way that addresses some of its early shortcomings. \u003cstrong\u003eReusable workflows in Github Actions\u003c/strong\u003e bring modularity to pipeline design, allowing parameterized reuse even across repositories (as long as the workflow repository is public). They support explicit passing of confidential values as secrets and can pass outputs to the calling job. With a few lines of YAML, GitHub Actions now gives you the type of flexibility you see with \u003ca href\u003d\"/radar/platforms/circleci\"\u003eCircleCI\u003c/a\u003e Orbs or \u003ca href\u003d\"/radar/platforms/azure-pipeline-templates\"\u003eAzure Pipeline Templates\u003c/a\u003e, but without having to leave GitHub as a platform.\u003c/p\u003e","blip_status":"t","theta":"249","volume":"2022-03"},{"name":"Sealed Secrets","id":"202110092","quadrant":"Platforms","ring":"Trial","movement":"c","radarId":"33","display_name":"Sealed Secrets","radius":"200","description":"\u003cp\u003e\u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e natively supports a key-value object known as a secret. However, by default, Kubernetes secrets aren\u0027t really secret. They\u0027re handled separately from other key-value data so that precautions or access control can be applied separately. There is support for encrypting secrets before they are stored in \u003ca href\u003d\"https://etcd.io/\"\u003eetcd\u003c/a\u003e, but the secrets start out as plain text fields in configuration files. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/bitnami-labs/sealed-secrets\"\u003eSealed Secrets\u003c/a\u003e\u003c/strong\u003e is a combination operator and command-line utility that uses asymmetric keys to encrypt secrets so that they can only be decrypted by the controller in the cluster. This process ensures that the secrets won\u0027t be compromised while they sit in the configuration files that define a Kubernetes deployment. Once encrypted, these files can be safely shared or stored alongside other deployment artifacts.\u003c/p\u003e","blip_status":"c","theta":"256","volume":"2022-03"},{"name":"VerneMQ","id":"202203009","quadrant":"Platforms","ring":"Trial","movement":"t","radarId":"34","display_name":"VerneMQ","radius":"250","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/vernemq/vernemq\"\u003eVerneMQ\u003c/a\u003e\u003c/strong\u003e is an open-source, high-performance, distributed MQTT broker. We\u0027ve blipped other MQTT brokers in the past like \u003ca href\u003d\"/radar/platforms/mosquitto\"\u003eMosquitto\u003c/a\u003e and \u003ca href\u003d\"/radar/platforms/emq\"\u003eEMQ\u003c/a\u003e. Like EMQ and RabbitMQ, VerneMQ is also based on Erlang/OTP which makes it highly scalable. It scales horizontally and vertically on commodity hardware to support a high number of concurrent publishers and consumers while maintaining low latency and fault tolerance. In our internal benchmarks, we\u0027ve been able to achieve a few million concurrent connections in a single cluster. While it\u0027s not new, we\u0027ve used it in production for some time now, and it has worked well for us.\u003c/p\u003e","blip_status":"t","theta":"263","volume":"2022-03"},{"name":"actions-runner-controller","id":"202203040","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"35","display_name":"actions-runner-controller","radius":"330","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/actions-runner-controller/actions-runner-controller\"\u003eactions-runner-controller\u003c/a\u003e\u003c/strong\u003e is a Kubernetes \u003ca href\u003d\"https://kubernetes.io/docs/concepts/architecture/controller/\"\u003econtroller\u003c/a\u003e that operates \u003ca href\u003d\"https://docs.github.com/en/actions/hosting-your-own-runners\"\u003eself-hosted runners\u003c/a\u003e for \u003ca href\u003d\"/radar/platforms/github-actions\"\u003eGitHub Actions\u003c/a\u003e on your Kubernetes cluster. With this tool you create a runner resource on Kubernetes, and it will run and operate the self-hosted runner. Self-hosted runners are helpful in scenarios where the job that your GitHub Actions runs needs to access resources that are either not accessible to GitHub cloud runners or have specific operating system and environmental requirements that are different from what GitHub provides. In those cases where you have a Kubernetes cluster, you can run your self-hosted runners as a Kubernetes pod, with the ability to scale up or down hooking into GitHub webhook events. actions-controller-runner is lightweight and scalable.\u003c/p\u003e","blip_status":"t","theta":"189","volume":"2022-03"},{"name":"Apache Iceberg","id":"202203012","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"36","display_name":"Apache Iceberg","radius":"330","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://iceberg.apache.org/\"\u003eApache Iceberg\u003c/a\u003e\u003c/strong\u003e is an open table format for very large analytic data sets. Iceberg supports modern analytical data operations such as record-level insert, update, delete, \u003ca href\u003d\"https://iceberg.apache.org/docs/latest/spark-queries/#time-travel\"\u003etime-travel queries\u003c/a\u003e, ACID transactions, \u003ca href\u003d\"https://iceberg.apache.org/docs/latest/partitioning/#icebergs-hidden-partitioning\"\u003ehidden partitioning\u003c/a\u003e and \u003ca href\u003d\"https://iceberg.apache.org/docs/latest/evolution/\"\u003efull schema evolution\u003c/a\u003e. It supports multiple underlying file storage formats such as \u003ca href\u003d\"https://parquet.apache.org/\"\u003eApache Parquet\u003c/a\u003e, \u003ca href\u003d\"https://orc.apache.org/\"\u003eApache ORC\u003c/a\u003e and \u003ca href\u003d\"https://avro.apache.org/docs/1.2.0/\"\u003eApache Avro\u003c/a\u003e. Many data-processing engines support Apache Iceberg, including SQL engines such as \u003ca href\u003d\"https://www.dremio.com/\"\u003eDremio\u003c/a\u003e and \u003ca href\u003d\"https://trino.io/\"\u003eTrino\u003c/a\u003e as well as (structured) streaming engines such as \u003ca href\u003d\"https://spark.apache.org/\"\u003eApache Spark\u003c/a\u003e and \u003ca href\u003d\"https://flink.apache.org/\"\u003eApache Flink\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eApache Iceberg falls in the same category as \u003ca href\u003d\"https://delta.io/\"\u003eDelta Lake\u003c/a\u003e and \u003ca href\u003d\"https://hudi.apache.org/\"\u003eApache Hudi\u003c/a\u003e. They all more or less support similar features, but each differs in the underlying implementations and detailed feature lists. Iceberg is an independent format and is not native to any specific processing engine, hence it\u0027s supported by an increasing number of platforms, including \u003ca href\u003d\"https://docs.aws.amazon.com/athena/latest/ug/querying-iceberg.html\"\u003eAWS Athena\u003c/a\u003e and \u003ca href\u003d\"https://www.snowflake.com/\"\u003eSnowflake\u003c/a\u003e. For the same reason, Apache Iceberg, unlike native formats such as Delta Lake, may not benefit from optimizations when used with Spark.\u003c/p\u003e","blip_status":"t","theta":"198","volume":"2022-03"},{"name":"Blueboat","id":"202203013","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"37","display_name":"Blueboat","radius":"330","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/losfair/blueboat\"\u003eBlueboat\u003c/a\u003e\u003c/strong\u003e is a multitenant platform for serverless web applications. It leverages the popular V8 JavaScript engine and implements commonly used web application libraries natively in \u003ca href\u003d\"/radar/languages-and-frameworks/rust\"\u003eRust\u003c/a\u003e for security and performance. You can think of Blueboat as an alternative to \u003ca href\u003d\"/radar/platforms/cloudflare-workers\"\u003eCloudFlare Workers\u003c/a\u003e or \u003ca href\u003d\"https://deno.com/deploy\"\u003eDeno Deploy\u003c/a\u003e but with an important distinction — you have to operate and manage the underlying infrastructure. That said, we recommend you carefully assess Blueboat for your on-prem serverless needs.\u003c/p\u003e","blip_status":"t","theta":"207","volume":"2022-03"},{"name":"Cloudflare Pages","id":"202203048","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"38","display_name":"Cloudflare Pages","radius":"300","description":"\u003cp\u003eWhen \u003ca href\u003d\"/radar/platforms/cloudflare-workers\"\u003eCloudflare Workers\u003c/a\u003e was released, we highlighted it as an early function as a service (FaaS) for edge computing with an interesting implementation. The release of \u003cstrong\u003e\u003ca href\u003d\"https://pages.cloudflare.com/\"\u003eCloudflare Pages\u003c/a\u003e\u003c/strong\u003e last April didn\u0027t feel as noteworthy, because Pages is just one in a class of many Git-backed site-hosting solutions. It did have continuous previews, a useful feature not found in most alternatives. Now, though, Cloudflare has more tightly \u003ca href\u003d\"https://blog.cloudflare.com/cloudflare-pages-goes-full-stack/\"\u003eintegrated Workers and Pages\u003c/a\u003e, creating a fully integrated \u003ca href\u003d\"/radar/techniques/jamstack\"\u003eJamstack\u003c/a\u003e solution running on the CDN. The inclusion of a key-value store and a strongly consistent coordination primitive further enhance the attractiveness of the new version of Cloudflare Pages.\u003c/p\u003e","blip_status":"t","theta":"216","volume":"2022-03"},{"name":"Colima","id":"202203015","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"39","display_name":"Colima","radius":"290","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/abiosoft/colima\"\u003eColima\u003c/a\u003e\u003c/strong\u003e is becoming a popular open alternative to Docker for Desktop. It provisions the Docker container runtime in a Lima VM, configures the Docker CLI on macOS and handles port-forwarding and volume mounts. Colima uses \u003ca href\u003d\"https://containerd.io/\"\u003econtainerd\u003c/a\u003e as runtime, which is also the runtime on most managed Kubernetes services (thus improved dev-prod parity). With Colima you can easily use and test the latest features of containerd, such as lazy loading for container images. With its good performance, we\u0027re watching Colima as a strong potential for the open-source choice alternative to Docker for Desktop.\u003c/p\u003e","blip_status":"t","theta":"225","volume":"2022-03"},{"name":"Collibra","id":"202203049","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"40","display_name":"Collibra","radius":"300","description":"\u003cp\u003eIn the increasingly crowded space that is the enterprise data catalog market, our teams have enjoyed working with \u003cstrong\u003e\u003ca href\u003d\"https://www.collibra.com/us/en\"\u003eCollibra\u003c/a\u003e\u003c/strong\u003e. They liked the deployment flexibility of either a SaaS or self-hosted instance, the wide range of functionality included out of the box, including data governance, lineage, quality and observability. Users also have the option to use a smaller subset of capabilities required by a more decentralized approach such as a \u003ca href\u003d\"/radar/techniques/data-mesh\"\u003edata mesh\u003c/a\u003e. The real feather in its cap has been their often overlooked customer support, which our people have found to be collaborative and supportive. Of course, there\u0027s a tension between simple data catalogs and more full featured enterprise platforms, but so far the teams using it are happy with how Collibra has supported their needs.\u003c/p\u003e","blip_status":"t","theta":"234","volume":"2022-03"},{"name":"CycloneDX","id":"202203034","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"41","display_name":"CycloneDX","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://cyclonedx.org/\"\u003eCycloneDX\u003c/a\u003e\u003c/strong\u003e is a standard for describing a machine-readable \u003ca href\u003d\"/radar/techniques/software-bill-of-materials\"\u003eSoftware Bill of Materials\u003c/a\u003e (SBOM). As software and compute fabrics increase in complexity, \u003cem\u003esoftware\u003c/em\u003e becomes harder to define. Originating with OWASP, CycloneDX improves on the older SPDX standard with a broader definition that extends beyond the local machine dependencies to include runtime service dependencies. You\u0027ll also find implementations in several languages, an \u003ca href\u003d\"https://cyclonedx.org/tool-center/\"\u003eecosystem\u003c/a\u003e of supporting integrations and a \u003ca href\u003d\"https://github.com/CycloneDX/cyclonedx-cli\"\u003eCLI tool\u003c/a\u003e that lets you analyze and change SBOMs with appropriate signing and verification.\u003c/p\u003e","blip_status":"t","theta":"243","volume":"2022-03"},{"name":"Embeddinghub","id":"202203017","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"42","display_name":"Embeddinghub","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/featureform/embeddinghub\"\u003eEmbeddinghub\u003c/a\u003e\u003c/strong\u003e is a vector database for machine-learning \u003ca href\u003d\"https://www.featureform.com/post/the-definitive-guide-to-embeddings\"\u003eembeddings\u003c/a\u003e, and quite similar to \u003ca href\u003d\"/radar/platforms/milvus-2-0\"\u003eMilvus\u003c/a\u003e. However, with out-of-the-box support for approximate nearest neighbor operations, partitioning, versioning and access control, we recommend you assess Embeddinghub for your embedding vector use cases.\u003c/p\u003e","blip_status":"t","theta":"252","volume":"2022-03"},{"name":"Temporal","id":"202203067","quadrant":"Platforms","ring":"Assess","movement":"t","radarId":"43","display_name":"Temporal","radius":"340","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://temporal.io/\"\u003eTemporal\u003c/a\u003e\u003c/strong\u003e is a platform for developing long-running workflows, particularly for microservice architectures. A fork of Uber’s previous OSS \u003ca href\u003d\"https://github.com/uber/cadence\"\u003eCadence\u003c/a\u003e project, it has an event-sourcing model for long-running workflows so they can survive process/machine crashes. Although we don’t recommend using distributed transactions in microservice architectures, if you do need to implement them or long-running \u003ca href\u003d\"https://microservices.io/patterns/data/saga.html\"\u003eSagas\u003c/a\u003e, you may want to look at Temporal.\u003c/p\u003e","blip_status":"t","theta":"261","volume":"2022-03"},{"name":"tfsec","id":"202005105","quadrant":"Tools","ring":"Adopt","movement":"t","radarId":"44","display_name":"tfsec","radius":"82","description":"\u003cp\u003eFor our projects using \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e, \u003cstrong\u003e\u003ca href\u003d\"https://github.com/liamg/tfsec\"\u003etfsec\u003c/a\u003e\u003c/strong\u003e has quickly become a default static analysis tool to detect potential security risks. It\u0027s easy to integrate into a CI pipeline and has a growing library of checks against all of the major cloud providers and platforms like Kubernetes. Given its ease of use, we believe tfsec could be a good addition to any Terraform project.\u003c/p\u003e","blip_status":"move_in","theta":"45","volume":"2022-03"},{"name":"AKHQ","id":"202203011","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"45","display_name":"AKHQ","radius":"175","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://akhq.io/docs/#installation\"\u003eAKHQ\u003c/a\u003e\u003c/strong\u003e is a GUI for Apache Kafka that lets you manage topics, topics data, consumer groups and more. Some of our teams have found AKHQ to be an effective tool to watch the real-time status of a Kafka cluster. You can, for example, browse the topics on a cluster. For each topic, you can visualize the name, the number of messages stored, the disk size used, the time of the last record, the number of partitions, the replication factor with the in-sync quantity and the consumer group. With options for Avro and Protobuf deserialization, AKHQ can help you understand the flow of data in your Kafka environment.\u003c/p\u003e","blip_status":"t","theta":"85","volume":"2022-03"},{"name":"cert-manager","id":"202110044","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"46","display_name":"cert-manager","radius":"200","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://cert-manager.io/\"\u003ecert-manager\u003c/a\u003e\u003c/strong\u003e is a tool to manage your X.509 certificates within your \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e cluster. It models certificates and issuers as first-class resource types and provides certificates as a service securely to developers and applications working within the Kubernetes cluster. The obvious choice when using the Kubernetes default ingress controller, it\u0027s also recommended for others and much preferred over hand-rolling your own certificate management. Several of our teams have been using cert-manager extensively, and we\u0027ve also found that its usability has much improved in the past few months.\u003c/p\u003e","blip_status":"move_in","theta":"79","volume":"2022-03"},{"name":"Cloud Carbon Footprint","id":"202110016","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"47","display_name":"Cloud Carbon Footprint","radius":"250","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://www.cloudcarbonfootprint.org/\"\u003eCloud Carbon Footprint\u003c/a\u003e\u003c/strong\u003e (CCF) is an open-source tool that uses cloud APIs to provide visualizations of estimated carbon emissions based on usage across AWS, GCP and Azure. The Thoughtworks team has \u003ca href\u003d\"https://www.thoughtworks.com/clients/Bringing-green-cloud-optimization-to-a-green-energy-business\"\u003esuccessfully used the tool\u003c/a\u003e with several organizations, including energy technology companies, retailers, digital service providers and companies that use AI. Cloud platform providers realize that it\u0027s important to help their customers understand the carbon impact of using their services, so they\u0027ve begun to build similar functionality themselves. Because CCF is cloud agnostic, it allows users to view energy usage and carbon emissions for multiple cloud providers in one place, while translating carbon footprints into real-world impact such as flights or trees planted.\u003c/p\u003e\n\n\u003cp\u003eIn recent releases, CCF has begun to include Google Cloud and AWS-sourced optimization recommendations alongside potential energy and CO2 savings, as well as to support more cloud instance types such as GPU instances. Given the traction the tool has received and the continued addition of new features, we feel confident moving it to Trial.\u003c/p\u003e","blip_status":"move_in","theta":"72","volume":"2022-03"},{"name":"Conftest","id":"202110014","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"48","display_name":"Conftest","radius":"187","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/open-policy-agent/conftest\"\u003eConftest\u003c/a\u003e\u003c/strong\u003e is a tool for writing tests against structured configuration data. It relies on the \u003ca href\u003d\"https://www.openpolicyagent.org/docs/latest/policy-language/#what-is-rego\"\u003eRego language\u003c/a\u003e from \u003ca href\u003d\"/radar/tools/open-policy-agent-opa\"\u003eOpen Policy Agent\u003c/a\u003e to write tests for \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e configurations, \u003ca href\u003d\"/radar/platforms/tekton\"\u003eTekton\u003c/a\u003e pipeline definitions or even \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e plans. We\u0027ve had great experiences with Conftest — and its shallow learning curve. With fast feedback from tests, our teams iterate quickly and safely on configuration changes to Kubernetes.\u003c/p\u003e","blip_status":"move_in","theta":"70","volume":"2022-03"},{"name":"kube-score","id":"202203022","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"49","display_name":"kube-score","radius":"189","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/zegl/kube-score\"\u003ekube-score\u003c/a\u003e\u003c/strong\u003e is a tool that does static code analysis of your Kubernetes object definitions. The output is a list of recommendations for what you can improve to make your application more secure and resilient. It has a list of \u003ca href\u003d\"https://github.com/zegl/kube-score/blob/master/README_CHECKS.md\"\u003epredefined checks\u003c/a\u003e which includes best practices such as running containers with non-root privileges and correctly specifying resource limits. It\u0027s been around for some time, and we\u0027ve used it in a few projects as part of a CD pipeline for Kubernetes manifests. A major drawback of kube-score is that you can\u0027t add custom policies. We typically supplement it with tools like \u003ca href\u003d\"/radar/tools/conftest\"\u003eConftest\u003c/a\u003e in these cases.\u003c/p\u003e","blip_status":"t","theta":"62","volume":"2022-03"},{"name":"Lighthouse","id":"1158","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"50","display_name":"Lighthouse","radius":"235","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://developers.google.com/web/tools/lighthouse/\"\u003eLighthouse\u003c/a\u003e\u003c/strong\u003e is a tool written by Google to assess web applications and web pages, collecting performance metrics and insights on good development practices. We\u0027ve long advocated for \u003ca href\u003d\"/radar/techniques/performance-testing-as-a-first-class-citizen\"\u003eperformance testing as a first-class citizen\u003c/a\u003e, and the additions to Lighthouse that we mentioned five years ago certainly helped with that. Our thinking around \u003ca href\u003d\"/radar/techniques/architectural-fitness-function\"\u003earchitectural fitness functions\u003c/a\u003e created strong motivation for tools such as Lighthouse to be run in build pipelines. With the introduction of \u003ca href\u003d\"https://github.com/GoogleChrome/lighthouse-ci\"\u003eLighthouse CI\u003c/a\u003e, it has become easier than ever to include Lighthouse in pipelines managed by \u003ca href\u003d\"https://github.com/GoogleChrome/lighthouse-ci/blob/main/docs/getting-started.md#configure-your-ci-provider\"\u003evarious tools\u003c/a\u003e.\u003c/p\u003e","blip_status":"move_in","theta":"57","volume":"2022-03"},{"name":"Metaflow","id":"202203023","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"51","display_name":"Metaflow","radius":"210","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/Netflix/metaflow\"\u003eMetaflow\u003c/a\u003e\u003c/strong\u003e is a user-friendly Python library and back-end service that helps data scientists and engineers build and manage production-ready data processing, ML training and inference workflows. Metaflow provides Python APIs that structure the code as a directed graph of steps. Each step can be decorated with flexible configurations such as the required compute and storage resources. Code and data artifacts for each step\u0027s run (aka task) are stored and can be retrieved either for future runs or the next steps in the flow, enabling you to recover from errors, repeat runs and track  versions of models and their dependencies across multiple runs.\u003c/p\u003e\n\n\u003cp\u003eThe value proposition of Metaflow is the simplicity of its idiomatic Python library: it fully integrates with the build and run-time infrastructure to enable running data engineering and science tasks in local and scaled production environments. At the time of writing, Metaflow is heavily integrated with AWS services such as S3 for its data store service and step functions for orchestration. Metaflow supports R in addition to Python. Its core features are open sourced.\u003c/p\u003e\n\n\u003cp\u003eIf you\u0027re building and deploying your production ML and data-processing pipelines on AWS, Metaflow is a lightweight full-stack alternative framework to more complex platforms such as \u003ca href\u003d\"/radar/tools/mlflow\"\u003eMLflow\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"51","volume":"2022-03"},{"name":"Micrometer","id":"202203024","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"52","display_name":"Micrometer","radius":"178","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://micrometer.io/\"\u003eMicrometer\u003c/a\u003e\u003c/strong\u003e is a platform-agnostic library for metrics instrumentation on the JVM that supports Graphite, New Relic, CloudWatch and many other integrations. We\u0027ve found that Micrometer has benefited both library authors and teams: library authors can include metrics instrumentation code in their libraries without needing to support each and every metrics system that their users are using;  and teams can support many different metrics on back-end registries which enables organizations to collect metrics in a consistent way.\u003c/p\u003e","blip_status":"t","theta":"45","volume":"2022-03"},{"name":"NUKE","id":"202203025","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"53","display_name":"NUKE","radius":"255","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://nuke.build/\"\u003eNUKE\u003c/a\u003e\u003c/strong\u003e is a build system for .NET and an alternative to either the traditional MSBuild or \u003ca href\u003d\"https://cakebuild.net/\"\u003eCake\u003c/a\u003e and \u003ca href\u003d\"https://fake.build/\"\u003eFake\u003c/a\u003e which we\u0027ve featured previously in the Radar. NUKE represents build instructions as a C# DSL, making it easy to learn and with good IDE support. In our experience, NUKE made it really simple to build automation for .NET projects. We like the accurate static code checks and hints. We also like that we can use any NuGet package seamlessly and that the automation code can be compiled to avoid problems at runtime. NUKE isn\u0027t new, but its novel approach — using a C# DSL — and our positive overall experience prompted us to include it here.\u003c/p\u003e","blip_status":"t","theta":"40","volume":"2022-03"},{"name":"Pactflow","id":"202110074","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"54","display_name":"Pactflow","radius":"167","description":"\u003cp\u003eWe\u0027ve used \u003ca href\u003d\"https://github.com/pact-foundation\"\u003ePact\u003c/a\u003e for contract testing long enough to see some of the complexity that comes with scale. Some of our teams have successfully used \u003cstrong\u003e\u003ca href\u003d\"https://pactflow.io/\"\u003ePactflow\u003c/a\u003e\u003c/strong\u003e to reduce that friction. Pactflow runs both as software as a service and as an on-prem deployment with the same features as the SaaS offering, and it adds improved usability, security and auditing on top of the open-source Pact Broker offering. We\u0027ve been pleased with our use so far and are happy to see continued effort to remove some of the overhead of managing contract testing at scale.\u003c/p\u003e","blip_status":"move_in","theta":"34","volume":"2022-03"},{"name":"Podman","id":"202104064","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"55","display_name":"Podman","radius":"220","description":"\u003cp\u003eAs an alternative to \u003ca href\u003d\"/radar/platforms/docker\"\u003eDocker\u003c/a\u003e, \u003cstrong\u003e\u003ca href\u003d\"https://github.com/containers/podman\"\u003ePodman\u003c/a\u003e\u003c/strong\u003e has been validated by many of our teams. Podman introduces a daemonless engine for managing and running containers which is an interesting approach in comparison to what Docker does. Additionally, Podman can be easily run as a normal user \u003ca href\u003d\"/radar/platforms/rootless-containers\"\u003ewithout requiring root privileges\u003c/a\u003e, which reduces the attack surface. By using either \u003ca href\u003d\"https://opencontainers.org/\"\u003eOpen Container Initiative\u003c/a\u003e (OCI) images built by \u003ca href\u003d\"https://github.com/containers/buildah\"\u003eBuildah\u003c/a\u003e or Docker images, Podman can be adapted to most container use cases. Apart from some compatibility issues with macOS, our team has had generally good experiences with Podman on Linux distributions.\u003c/p\u003e","blip_status":"move_in","theta":"29","volume":"2022-03"},{"name":"Sourcegraph","id":"202110077","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"56","display_name":"Sourcegraph","radius":"186","description":"\u003cp\u003eIn our previous Radar, we featured two tools that search and replace code using an abstract syntax tree (AST) representation, \u003ca href\u003d\"/radar/tools/comby\"\u003eComby\u003c/a\u003e and \u003cstrong\u003e\u003ca href\u003d\"https://about.sourcegraph.com/\"\u003eSourcegraph\u003c/a\u003e\u003c/strong\u003e. Although they share some similarities, they also differ in several ways. Sourcegraph is a commercial tool (with a 10-user free tier). It\u0027s particularly suited for searching, navigating or cross-referencing in large codebases, with an emphasis on an interactive developer experience. In contrast, Comby is a lightweight open-source command-line tool for automating repetitive tasks. Because Sourcegraph is a hosted service, it also has the ability to continuously monitor code bases and send alerts when a match occurs. Now that we\u0027ve gained more experience with Sourcegraph, we decided to move it into the Trial ring to reflect our positive experience — which doesn\u0027t mean that Sourcegraph is better than Comby. Each tool focuses on a different niche.\u003c/p\u003e","blip_status":"move_in","theta":"23","volume":"2022-03"},{"name":"Syft","id":"202203087","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"57","display_name":"Syft","radius":"218","description":"\u003cp\u003eOne of the key elements of improving \"supply chain security\" is using a \u003ca href\u003d\"/radar/techniques/software-bill-of-materials\"\u003eSoftware Bill of Materials (SBOM)\u003c/a\u003e, which is why publishing an SBOM along with the software artifact is increasingly important. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/anchore/syft\"\u003eSyft\u003c/a\u003e\u003c/strong\u003e is a CLI tool and Go library for generating an SBOM from container images and file systems. It can generate the SBOM output in multiple formats, including JSON, \u003ca href\u003d\"/radar/platforms/cyclonedx\"\u003eCycloneDX\u003c/a\u003e and SPDX. The SBOM output of Syft can be used by \u003ca href\u003d\"/radar/tools/grype\"\u003eGrype\u003c/a\u003e for vulnerability scanning. One way to publish the generated SBOM along with the image is to add it as an attestation using \u003ca href\u003d\"/radar/tools/cosign\"\u003eCosign\u003c/a\u003e. This allows consumers of the image to verify the SBOM and to use it for further analysis.\u003c/p\u003e","blip_status":"t","theta":"17","volume":"2022-03"},{"name":"Volta","id":"202203039","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"58","display_name":"Volta","radius":"250","description":"\u003cp\u003eWhen working on multiple JavaScript codebases at the same time, it\u0027s often necessary to use different versions of Node and other JavaScript tools. On developer machines, these tools are usually installed in the user account or the machine itself, which means a solution is needed to switch between multiple installations. For Node itself there\u0027s nvm, but we want to highlight \u003cstrong\u003e\u003ca href\u003d\"https://volta.sh/\"\u003eVolta\u003c/a\u003e\u003c/strong\u003e as an alternative that we\u0027re seeing in use with our teams. Volta has several advantages over using nvm: it can manage other JavaScript tools such as Yarn; it also has the notion of pinning a version of the toolchain on a project basis, which means that developers can simply use the tools in a given code directory without having to worry about manually switching between tool versions — Volta simply uses shims in the path to select the pinned version. Written in Rust, Volta is fast and ships as a single binary without dependencies.\u003c/p\u003e","blip_status":"t","theta":"12","volume":"2022-03"},{"name":"Web Test Runner","id":"202203038","quadrant":"Tools","ring":"Trial","movement":"t","radarId":"59","display_name":"Web Test Runner","radius":"220","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://modern-web.dev/docs/test-runner/overview/\"\u003eWeb Test Runner\u003c/a\u003e\u003c/strong\u003e is a package within the \u003ca href\u003d\"https://modern-web.dev/\"\u003eModern Web\u003c/a\u003e project, which provides several high-quality tools for modern web development with support for web standards like ES Modules. Web Test Runner is a test runner for web applications. One of its advantages compared to existing test runners is that it runs tests in the browser (which could be headless). It supports multiple browser launchers — including \u003ca href\u003d\"/radar/languages-and-frameworks/puppeteer\"\u003ePuppeteer\u003c/a\u003e, \u003ca href\u003d\"/radar/tools/playwright\"\u003ePlaywright\u003c/a\u003e, and Selenium — and uses Mocha by default for the test framework. The tests run pretty fast, and we like that we can open a browser window with devtools when debugging. Web Test Runner internally uses \u003ca href\u003d\"https://modern-web.dev/docs/dev-server/overview/\"\u003eWeb Dev Server\u003c/a\u003e which allows us to leverage its great plugin API for adding customized plugins for our test suite. Modern Web tools look like a very promising developer toolchain, and we\u0027re already using it in a few projects.\u003c/p\u003e","blip_status":"t","theta":"6","volume":"2022-03"},{"name":"CDKTF","id":"202203047","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"60","display_name":"CDKTF","radius":"320","description":"\u003cp\u003eBy now many organizations have created sprawling landscapes of services in the cloud. Of course, this is only possible when using \u003ca href\u003d\"/radar/techniques/infrastructure-as-code\"\u003einfrastructure as code\u003c/a\u003e and mature tooling. We still like \u003ca href\u003d\"/radar/tools/terraform\"\u003eTerraform\u003c/a\u003e, not the least because of its rich and growing ecosystem. However, the lack of abstractions in HCL, Terraform\u0027s default configuration language, effectively creates a glass ceiling. Using \u003ca href\u003d\"/radar/tools/terragrunt\"\u003eTerragrunt\u003c/a\u003e pushes that up a bit further, but more and more often our teams find themselves longing for the abstractions afforded by modern programming languages. \u003ca href\u003d\"https://www.terraform.io/cdktf\"\u003e\u003cstrong\u003eCloud Development Kit for Terraform (CDKTF)\u003c/strong\u003e\u003c/a\u003e, which resulted from a collaboration between AWS\u0027s \u003ca href\u003d\"/radar/platforms/aws-cloud-development-kit\"\u003eCDK\u003c/a\u003e team and Hashicorp, makes it possible for teams to use several programming languages, including TypeScript and Java, to define and provision infrastructure. With this approach it follows the lead of \u003ca href\u003d\"/radar/platforms/pulumi\"\u003ePulumi\u003c/a\u003e while remaining in the Terraform ecosystem. We\u0027ve had good experiences with CDKTF but have decided to keep it in the Assess ring until it moves out of beta.\u003c/p\u003e","blip_status":"t","theta":"84","volume":"2022-03"},{"name":"Chrome Recorder panel","id":"202203004","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"61","display_name":"Chrome Recorder panel","radius":"295","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://developer.chrome.com/docs/devtools/recorder/\"\u003eChrome Recorder panel\u003c/a\u003e\u003c/strong\u003e is a preview feature in Google Chrome 97 that allows for simple record and playback of user journeys. While this definitely isn\u0027t a new idea, the way in which it is integrated into Chrome allows for quick creation, editing and running of scripts. The panel also integrates nicely with the performance panel, which makes getting repeated consistent feedback on page performance easier. While record/playback style testing always needs to be used with care in order to avoid brittle tests, we think this preview feature is worth assessing, especially if you\u0027re already using the Chrome Performance panel to measure your pages.\u003c/p\u003e","blip_status":"t","theta":"77","volume":"2022-03"},{"name":"Excalidraw","id":"202203036","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"62","display_name":"Excalidraw","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://excalidraw.com/\"\u003eExcalidraw\u003c/a\u003e\u003c/strong\u003e is a simple but powerful online drawing tool that our teams enjoy using. Sometimes teams just need a quick picture instead of a formal diagram, for remote teams Excalidraw provides a quick way to create and share diagrams. Our teams also like the \"lo-fi\" look of the diagrams it can produce, which is reminiscent of the whiteboard diagrams they would have produced when co-located. One caveat: you need to pay attention to the default security — at the time of writing, anyone who has the link can see the diagram. A paid-for version provides further authentication.\u003c/p\u003e","blip_status":"t","theta":"70","volume":"2022-03"},{"name":"GitHub Codespaces","id":"202203053","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"63","display_name":"GitHub Codespaces","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/features/codespaces\"\u003eGitHub Codespaces\u003c/a\u003e\u003c/strong\u003e allows developers to create \u003ca href\u003d\"/radar/techniques/development-environments-in-the-cloud\"\u003edevelopment environments in the cloud\u003c/a\u003e and access them through an IDE as though the environment were local. GitHub isn\u0027t the first company to implement this idea; we previously blipped about \u003ca href\u003d\"/radar/tools/gitpod\"\u003eGitpod\u003c/a\u003e. We like that Codespaces allows environments to be standardized by using dotfiles configuration, making it quicker to onboard new team members, and that they offer VMs with up to 32 cores and 64GB memory. These VMs can be spun up in under ten seconds, potentially offering environments more powerful than a developer laptop.\u003c/p\u003e","blip_status":"t","theta":"63","volume":"2022-03"},{"name":"GoReleaser","id":"202203018","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"64","display_name":"GoReleaser","radius":"292","description":"\u003cp\u003e\u003ca href\u003d\"https://github.com/goreleaser/goreleaser\"\u003e\u003cstrong\u003eGoReleaser\u003c/strong\u003e\u003c/a\u003e is a tool that automates the process of building and releasing a Go project for different architectures via multiple repositories and channels, a common need for Go projects targeting different platforms. You run the tool either from your local machine or via CI, with the tool available via several CI services thus minimizing set-up and maintenance. GoReleaser takes care of build, packaging, publishing and announcement of each release and supports different combinations of package format, package repository and source control. Although it\u0027s been around for a few years, we\u0027re surprised that more teams are not using it. If you\u0027re regularly releasing a Go codebase, this tool is worth assessing.\u003c/p\u003e","blip_status":"t","theta":"56","volume":"2022-03"},{"name":"Grype","id":"202203019","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"65","display_name":"Grype","radius":"330","description":"\u003cp\u003eSecuring the software supply chain has become a commonplace concern among delivery teams, a concern that is reflected by the growing number of new tools in this space. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/anchore/grype\"\u003eGrype\u003c/a\u003e\u003c/strong\u003e is a new lightweight vulnerability scanning tool for Docker and OCI images. It can be installed as a binary, can scan images before they\u0027re pushed to a registry, and it doesn\u0027t require a Docker daemon to run on your build agents. Grype comes from the same team that is behind \u003ca href\u003d\"/radar/tools/syft\"\u003eSyft\u003c/a\u003e, which generates \u003ca href\u003d\"/radar/techniques/software-bill-of-materials\"\u003eSBOMs\u003c/a\u003e in various formats from container images. Grype can consume the SBOM output of Syft to scan for vulnerabilities.\u003c/p\u003e","blip_status":"t","theta":"49","volume":"2022-03"},{"name":"Infracost","id":"202203020","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"66","display_name":"Infracost","radius":"300","description":"\u003cp\u003eOne often-cited advantage of moving to the cloud is transparency around infrastructure spend. In our experience, this is often not the case. Teams don\u0027t always think about the decisions they make around infrastructure in terms of financial cost which is why we previously blipped about \u003ca href\u003d\"/radar/techniques/run-cost-as-architecture-fitness-function\"\u003erun cost as architecture fitness function\u003c/a\u003e. We\u0027re intrigued by the release of a new tool called \u003cstrong\u003e\u003ca href\u003d\"https://infracost.io/\"\u003eInfracost\u003c/a\u003e\u003c/strong\u003e which aims to make cost trade-offs visible in Terraform pull requests. It\u0027s open-source software and available for macOS, Linux, Windows and Docker and supports pricing for AWS, GCP and Microsoft Azure out of the box. It also provides a public API that can be queried for current cost data. Our teams are excited by its potential, especially when it comes to gaining better cost visibility in the IDE.\u003c/p\u003e","blip_status":"t","theta":"42","volume":"2022-03"},{"name":"jc","id":"202203056","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"67","display_name":"jc","radius":"330","description":"\u003cp\u003eIn our previous Radar, we placed \u003ca href\u003d\"/radar/tools/modern-unix-commands\"\u003emodern Unix commands\u003c/a\u003e in Assess. One of the commands featured in that collection of tools was jq, effectively a sed for JSON. \u003cstrong\u003e\u003ca href\u003d\"https://kellyjonbrazil.github.io/jc/docs/\"\u003ejc\u003c/a\u003e\u003c/strong\u003e performs a related task: it takes the output of common Unix commands and parses the output into JSON. The two commands together provide a bridge between the Unix CLI world and the raft of libraries and tools that operate on JSON. When writing \u003cem\u003esimple\u003c/em\u003e scripts, for example, for software deployment or gathering troubleshooting information, having the myriad of different Unix command output formats mapped into well-defined JSON can save a lot of time and effort. As with jq, you need to make sure the command is available. It can be installed from many of the well-known package repositories.\u003c/p\u003e","blip_status":"t","theta":"35","volume":"2022-03"},{"name":"skopeo","id":"202203084","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"68","display_name":"skopeo","radius":"330","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/containers/skopeo\"\u003eskopeo\u003c/a\u003e\u003c/strong\u003e is a command line utility that performs various operations on container images and image repositories. It doesn\u0027t require a user to be root to do most of its operations nor does it require a daemon to be running. It\u0027s a useful part of a CI pipeline; we\u0027ve used it to copy images from one registry to another as we promote the images. It\u0027s better than doing a pull and a push as we don\u0027t need to store the images locally. It\u0027s not a new tool, but it\u0027s useful enough and underutilized that we felt it\u0027s worth calling it out.\u003c/p\u003e","blip_status":"t","theta":"28","volume":"2022-03"},{"name":"SQLFluff","id":"202203065","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"69","display_name":"SQLFluff","radius":"289","description":"\u003cp\u003eWhile linting is an ancient practice in the software world, it\u0027s had slower adoption in the data world. \u003cstrong\u003e\u003ca href\u003d\"https://docs.sqlfluff.com/en/stable/\"\u003eSQLFluff\u003c/a\u003e\u003c/strong\u003e is a cross-dialect SQL linter written in Python that ships with a simple command line interface (CLI), making it easy to incorporate into a CI/CD pipeline. If you\u0027re comfortable with the default conventions, then SQLFluff works without any additional configuration after installing it and will enforce a strongly opinionated set of formatting standards; setting your own conventions involves adding a configuration dotfile. The CLI can automatically fix certain classes of violations that involve formatting concerns like whitespace or uppercasing of keywords. SQLFluff is still new, but we\u0027re excited to see SQL getting some attention in the linting world.\u003c/p\u003e","blip_status":"t","theta":"21","volume":"2022-03"},{"name":"Terraform Validator","id":"202203068","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"70","display_name":"Terraform Validator","radius":"300","description":"\u003cp\u003eOrganizations that have adopted \u003ca href\u003d\"/radar/techniques/infrastructure-as-code\"\u003einfrastructure as code\u003c/a\u003e and self-service infrastructure platforms are looking for ways to give teams a maximum of autonomy while still enforcing good security practices and organizational policies. We\u0027ve highlighted \u003ca href\u003d\"/radar/tools/tfsec\"\u003etfsec\u003c/a\u003e before and are moving it into the Adopt category in this Radar. For teams working on GCP, \u003ca href\u003d\"https://github.com/GoogleCloudPlatform/terraform-validator\"\u003e\u003cstrong\u003eTerraform Validator\u003c/strong\u003e\u003c/a\u003e could be an option when creating a policy library, a set of constraints that are checked against Terraform configurations.\u003c/p\u003e","blip_status":"t","theta":"14","volume":"2022-03"},{"name":"Typesense","id":"202203031","quadrant":"Tools","ring":"Assess","movement":"t","radarId":"71","display_name":"Typesense","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/typesense/typesense\"\u003eTypesense\u003c/a\u003e\u003c/strong\u003e is a fast, typo-tolerant text search engine. For use cases with large volumes of data, Elasticsearch might still be a good option as it provides a horizontally scalable disk-based search solution. However, if you\u0027re building a latency-sensitive search application with a search index size that can fit in memory, Typesense is a powerful alternative and another option to evaluate alongside tools such as \u003ca href\u003d\"/radar/platforms/meilisearch\"\u003eMeilisearch\u003c/a\u003e.\u003c/p\u003e","blip_status":"t","theta":"7","volume":"2022-03"},{"name":"SwiftUI","id":"201911018","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"72","display_name":"SwiftUI","radius":"95","description":"\u003cp\u003eWhen Apple introduced \u003cstrong\u003e\u003ca href\u003d\"https://developer.apple.com/xcode/swiftui/\"\u003eSwiftUI\u003c/a\u003e\u003c/strong\u003e a few years ago, it was a big step forward for implementing user interfaces on all kinds of devices made by Apple. From the beginning, we liked the declarative, code-centric approach and the reactive programming model provided by \u003ca href\u003d\"/radar/languages-and-frameworks/combine\"\u003eCombine\u003c/a\u003e. We did notice, though, that writing a lot of view tests, which you still need with a model—view—viewmodel (MVVM) pattern, was not really sensible with the XCUITest automation framework provided by Apple. This gap has been closed by \u003ca href\u003d\"/radar/languages-and-frameworks/viewinspector\"\u003eViewInspector\u003c/a\u003e. A final hurdle was the minimum OS version required. At the time of release, only the very latest versions of iOS and macOS could run applications written with SwiftUI, but because of Apple’s regular cadence of updates, SwiftUI apps can now run on practically all versions of macOS and iOS that receive security updates.\u003c/p\u003e","blip_status":"move_in","theta":"300","volume":"2022-03"},{"name":"Testcontainers","id":"201911027","quadrant":"languages-and-frameworks","ring":"Adopt","movement":"t","radarId":"73","display_name":"Testcontainers","radius":"85","description":"\u003cp\u003eWe\u0027ve had enough experience with \u003cstrong\u003e\u003ca href\u003d\"https://www.testcontainers.org/\"\u003eTestcontainers\u003c/a\u003e\u003c/strong\u003e that we think it\u0027s a useful default option for creating a reliable environment for running tests. It\u0027s a library, ported to \u003ca href\u003d\"https://github.com/testcontainers\"\u003emultiple languages\u003c/a\u003e, that Dockerizes common test dependencies — including various types of databases, queuing technologies, cloud services and UI testing dependencies like web browsers — with the ability to run custom Dockerfiles when needed. It works well with test frameworks like JUnit, is flexible enough to let users manage the container lifecycle and advanced networking and quickly sets up an integrated test environment. Our teams have consistently found this library of programmable, lightweight and disposable containers to make functional tests more reliable.\u003c/p\u003e","blip_status":"move_in","theta":"330","volume":"2022-03"},{"name":"Bob","id":"202203046","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"74","display_name":"Bob","radius":"220","description":"\u003cp\u003eWhen building an app with React Native you sometimes find yourself having to create your own modules. For example, we\u0027ve encountered this need when building a UI component library for a React Native app. Creating such a module project isn\u0027t straightforward, and our teams report success using \u003cstrong\u003e\u003ca href\u003d\"https://github.com/callstack/react-native-builder-bob\"\u003eBob\u003c/a\u003e\u003c/strong\u003e to automate this task. Bob provides a CLI to create the scaffolding for different targets. The scaffolding is not limited to core functionality but, optionally, can include example code, linters, build pipeline configuration and other features.\u003c/p\u003e","blip_status":"t","theta":"285","volume":"2022-03"},{"name":"Flutter-Unity widget","id":"202203077","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"75","display_name":"Flutter-Unity widget","radius":"250","description":"\u003cp\u003eFlutter is increasingly popular for building cross-platform mobile apps, and Unity is great for building AR/VR experiences. A key piece in the puzzle for integrating Unity and Flutter is the \u003cstrong\u003e\u003ca href\u003d\"https://github.com/juicycleff/flutter-unity-view-widget\"\u003eFlutter-Unity widget\u003c/a\u003e\u003c/strong\u003e, which allows embedding Unity apps inside Flutter widgets. One of the key capabilities the widget offers is bi-directional communication between Flutter and Unity. We\u0027ve found its performance to be pretty good as well, and we\u0027re looking forward to leveraging Unity in more Flutter apps.\u003c/p\u003e","blip_status":"t","theta":"300","volume":"2022-03"},{"name":"Kotest","id":"201911021","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"76","display_name":"Kotest","radius":"230","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://kotest.io/\"\u003eKotest\u003c/a\u003e\u003c/strong\u003e (previously KotlinTest) is a stand-alone testing tool for the \u003ca href\u003d\"/radar/languages-and-frameworks/kotlin\"\u003eKotlin\u003c/a\u003e ecosystem that is continuing to gain traction within our teams across various Kotlin implementations — native, JVM or JavaScript. Key advantages are that it offers a variety of testing styles in order to structure the test suites and that it comes with a comprehensive set of matchers, which allow for expressive tests in an elegant internal DSL. In addition to its support for \u003ca href\u003d\"/radar/techniques/property-based-unit-testing\"\u003eproperty-based testing\u003c/a\u003e — a technique we\u0027ve highlighted previously in the Radar — our teams like the solid IntelliJ plugin and the growing community of support.\u003c/p\u003e","blip_status":"move_in","theta":"315","volume":"2022-03"},{"name":"Swift Package Manager","id":"202203007","quadrant":"languages-and-frameworks","ring":"Trial","movement":"t","radarId":"77","display_name":"Swift Package Manager","radius":"220","description":"\u003cp\u003eSome programming languages, especially newer ones, have a package and dependency management solution built in. When it was introduced in 2014, Swift didn\u0027t come with a package manager, and so the macOS and iOS developer community simply kept using CocoaPods and \u003ca href\u003d\"/radar/tools/carthage\"\u003eCarthage\u003c/a\u003e, the third-party solutions that had been created for Objective-C. A couple of years later \u003cstrong\u003e\u003ca href\u003d\"https://github.com/apple/swift-package-manager\"\u003eSwift Package Manager\u003c/a\u003e\u003c/strong\u003e (SwiftPM) was started as an official Apple open-source project, and it then took another few  years before Apple added support for it to Xcode. Even at that point, though, many development teams continued to use CocoaPods and Carthage, mostly because many packages were simply not available via SwiftPM. Now that most packages can be included via SwiftPM and processes have been further streamlined for both creators and consumers of packages, our teams are increasingly relying on SwiftPM.\u003c/p\u003e","blip_status":"t","theta":"330","volume":"2022-03"},{"name":"Vowpal Wabbit","id":"202110010","quadrant":"languages-and-frameworks","ring":"Trial","movement":"c","radarId":"78","display_name":"Vowpal Wabbit","radius":"240","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://vowpalwabbit.org/\"\u003eVowpal Wabbit\u003c/a\u003e\u003c/strong\u003e is a general-purpose machine-learning library. Originally created at Yahoo! Research over a decade ago, Vowpal Wabbit continues to implement new algorithms in reinforcement learning. We want to highlight \u003ca href\u003d\"https://vowpalwabbit.org/blog/vowpalwabbit-9.0.0.html\"\u003eVowpal Wabbit 9.0\u003c/a\u003e, a major release after six years, and encourage you to plan the \u003ca href\u003d\"https://vowpalwabbit.org/docs/vowpal_wabbit/python/latest/reference/python_8110_900_migration_guide.html\"\u003emigration\u003c/a\u003e as it has several usability improvements, new reductions and bug fixes.\u003c/p\u003e","blip_status":"c","theta":"345","volume":"2022-03"},{"name":"Android Gradle plugin - Kotlin DSL","id":"202203041","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"79","display_name":"Android Gradle plugin - Kotlin DSL","radius":"300","description":"\u003cp\u003e\u003cstrong\u003eAndroid Gradle plugin Kotlin DSL\u003c/strong\u003e added support for Kotlin Script as an alternative to Groovy for Gradle build scripts. The goal of replacing Groovy with Kotlin is to provide better support for refactoring and simpler editing in IDEs as well as ultimately to produce code that is easier to read and maintain. For teams already using Kotlin it also means working on the build in a familiar language. We had a team with an at least seven-year-old 450-line build script \u003ca href\u003d\"https://developer.android.com/studio/build/migrate-to-kts\"\u003emigrate\u003c/a\u003e within a few days. If you have large or complex gradle build scripts, then it\u0027s worth assessing whether Kotlin Script will produce better outcomes for your teams.\u003c/p\u003e","blip_status":"t","theta":"275","volume":"2022-03"},{"name":"Azure Bicep","id":"202203042","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"80","display_name":"Azure Bicep","radius":"300","description":"\u003cp\u003eFor those who prefer a more natural language than JSON for infrastructure code, \u003cstrong\u003e\u003ca href\u003d\"https://docs.microsoft.com/en-us/azure/azure-resource-manager/bicep/overview?tabs\u003dbicep\"\u003eAzure Bicep\u003c/a\u003e\u003c/strong\u003e is a domain-specific language (DSL) that uses a declarative syntax. It supports reusable parameterized templates for modular resource definitions. A \u003ca href\u003d\"https://marketplace.visualstudio.com/items?itemName\u003dms-azuretools.vscode-bicep\"\u003eVisual Studio Code extension\u003c/a\u003e provides instant type-safety, intellisense and syntax checking, and the compiler allows bidirectional transpilation to and from ARM templates. Bicep\u0027s resource-oriented DSL and native integration with the Azure ecosystem make it a compelling choice for Azure infrastructure development.\u003c/p\u003e","blip_status":"t","theta":"281","volume":"2022-03"},{"name":"Capacitor","id":"202203014","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"81","display_name":"Capacitor","radius":"320","description":"\u003cp\u003eWe\u0027ve been debating the merits of cross-platform mobile development tools for nearly as long as we\u0027ve been publishing the Technology Radar. We first noted a new generation of tools in 2011 when blipping about \u003ca href\u003d\"/radar/tools/cross-mobile-platforms\"\u003ecross-mobile platforms\u003c/a\u003e. Although we were skeptical of them at first, these tools have been perfected and widely adopted over the years. And nobody can debate the enduring popularity and usefulness of \u003ca href\u003d\"/radar/languages-and-frameworks/react-native\"\u003eReact Native\u003c/a\u003e. \u003cstrong\u003e\u003ca href\u003d\"https://capacitorjs.com/\"\u003eCapacitor\u003c/a\u003e\u003c/strong\u003e is the latest generation of a line of tools starting with PhoneGap, then renamed to \u003ca href\u003d\"/radar/platforms/phonegap-apache-cordova\"\u003eApache Cordova\u003c/a\u003e. Capacitor is a complete rewrite from Ionic that embraces the \u003ca href\u003d\"/radar/techniques/progressive-web-applications\"\u003eprogressive web app\u003c/a\u003e style for stand-alone applications. So far, our developers like that they can address web, iOS and Android applications with a single code base and that they can manage the native platforms separately with access to the native APIs when necessary. Capacitor offers an alternative to React Native, which has many years of cross-platform experience behind it.\u003c/p\u003e","blip_status":"t","theta":"286","volume":"2022-03"},{"name":"Java 17","id":"202203055","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"82","display_name":"Java 17","radius":"300","description":"\u003cp\u003eWe don\u0027t routinely feature new versions of languages, but we wanted to highlight the new long-term support (LTS) version of Java, version 17. While there are promising new features, such as the preview of \u003ca href\u003d\"https://openjdk.java.net/jeps/406\"\u003epattern matching\u003c/a\u003e, it\u0027s the switch to the new LTS process that should interest many organizations. We recommend organizations assess new releases of Java as and when they become available, making sure they adopt new features and versions as appropriate. Surprisingly many organizations do not routinely adopt newer versions of languages even though regular updates help keep things small and manageable. Hopefully the new LTS process, alongside organizations moving to regular updates, will help avoid the \"too expensive to update\" trap that ends with production software running on an end-of-life version of Java.\u003c/p\u003e","blip_status":"t","theta":"292","volume":"2022-03"},{"name":"Jetpack Glance","id":"202203057","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"83","display_name":"Jetpack Glance","radius":"320","description":"\u003cp\u003eAndroid 12 brought significant changes to app widgets that have improved the user and developer experience. For writing regular Android apps, we\u0027ve expressed our preference for \u003ca href\u003d\"/radar/languages-and-frameworks/jetpack-compose\"\u003eJetpack Compose\u003c/a\u003e as a modern way of building native user interfaces. Now, with \u003cstrong\u003e\u003ca href\u003d\"https://developer.android.com/jetpack/androidx/releases/glance\"\u003eJetpack Glance\u003c/a\u003e\u003c/strong\u003e, which is built on top of the Compose runtime, developers can use similar declarative Kotlin APIs for writing widgets. Recently, Glance has been \u003ca href\u003d\"https://android-developers.googleblog.com/2022/01/announcing-glance-tiles-for-wear-os.html\"\u003eextended\u003c/a\u003e to support Tiles for Wear OS.\u003c/p\u003e","blip_status":"t","theta":"298","volume":"2022-03"},{"name":"Jetpack Media3","id":"202203002","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"84","display_name":"Jetpack Media3","radius":"310","description":"\u003cp\u003eAndroid today has several media APIs: Jetpack Media, also known as MediaCompat, Jetpack Media2 and ExoPlayer. Unfortunately, these libraries were developed independently, with different goals but overlapping functionality. Android developers not only had to choose which library to use, they also had to contend with writing adaptors or other connecting code when features from multiple APIs were needed. \u003ca href\u003d\"https://developer.android.com/jetpack/androidx/releases/media3\"\u003e\u003cstrong\u003eJetpack Media3\u003c/strong\u003e\u003c/a\u003e is an effort, currently in early access, to create a new API that takes common areas of functionality from the existing APIs — including UI, playback and media session handling — combining them into a merged and refined API. The player interface from ExoPlayer has also been updated, enhanced and streamlined to act as the common player interface for Media3.\u003c/p\u003e","blip_status":"t","theta":"303","volume":"2022-03"},{"name":"MistQL","id":"202203082","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"85","display_name":"MistQL","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/evinism/mistql\"\u003eMistQL\u003c/a\u003e\u003c/strong\u003e is a small domain-specific language for performing computations on JSON-like structures. Originally built for handcrafted feature extraction of machine-learning models on the frontend, MistQL currently supports a JavaScript implementation for browsers and a Python implementation for server-side use cases. We quite like its clean composable functional syntax, and we encourage you to assess it based on your needs.\u003c/p\u003e","blip_status":"t","theta":"309","volume":"2022-03"},{"name":"npm workspaces","id":"202203059","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"86","display_name":"npm workspaces","radius":"300","description":"\u003cp\u003eWhile many tools support multipackage development in the node.js world, npm 7 adds direct support with the addition of \u003cstrong\u003e\u003ca href\u003d\"https://docs.npmjs.com/cli/v8/using-npm/workspaces\"\u003enpm workspaces\u003c/a\u003e\u003c/strong\u003e. Managing related packages together facilitates development, allowing you, for example, to store multiple related libraries in a single repo. With npm workspaces, once you add a configuration in a top-level package.json file to refer to one or more nested package.json files, commands like \u003ccode\u003enpm install\u003c/code\u003e work across multiple packages, symlinking the dependent source packages into the root node_modules directory. Other npm commands are also now workspace aware, allowing you, for example, to execute \u003ccode\u003enpm run\u003c/code\u003e and \u003ccode\u003enpm test\u003c/code\u003e commands across multiple packages with a single command. Having that flexibility out of the box decreases the need for some teams to reach for another package manager.\u003c/p\u003e","blip_status":"t","theta":"315","volume":"2022-03"},{"name":"Remix","id":"202203027","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"87","display_name":"Remix","radius":"320","description":"\u003cp\u003eWe witnessed the migration from server-side rendering website to single-page application in the browser, now the pendulum of web development seems to swing back to the middle. \u003cstrong\u003e\u003ca href\u003d\"https://remix.run/\"\u003eRemix\u003c/a\u003e\u003c/strong\u003e is one such example. It\u0027s a full-stack JavaScript framework. It provides fast page loads by leveraging distributed systems and native browsers instead of clumsy static builds. It has made some optimizations on nested routing and page loading, which makes page rendering seem especially fast. Many people will compare Remix with \u003ca href\u003d\"/radar/languages-and-frameworks/next-js\"\u003eNext.js\u003c/a\u003e, which is similarly positioned. We\u0027re glad to see such frameworks cleverly combining the browser run time with the server run time to provide a better user experience.\u003c/p\u003e","blip_status":"t","theta":"320","volume":"2022-03"},{"name":"ShedLock","id":"202203061","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"88","display_name":"ShedLock","radius":"320","description":"\u003cp\u003eExecuting a scheduled task once and only once in a cluster of distributed processors is a relatively common requirement. For example, the situation might arise when ingesting a batch of data, sending a notification or performing some regular cleanup activity. But this is a notoriously difficult problem. How does a group of processes cooperate reliably over laggy and less reliable networks? Some kind of locking mechanism is required to coordinate actions across the cluster. Fortunately, a variety of distributed stores can implement a lock. Systems like \u003ca href\u003d\"https://zookeeper.apache.org/\"\u003eZooKeeper\u003c/a\u003e and \u003ca href\u003d\"/radar/tools/consul\"\u003eConsul\u003c/a\u003e as well as databases such as DynamoDB or \u003ca href\u003d\"/radar/platforms/couchbase\"\u003eCouchbase\u003c/a\u003e have the necessary underlying mechanisms to manage consensus across the cluster. \u003cstrong\u003e\u003ca href\u003d\"https://github.com/lukas-krecan/ShedLock\"\u003eShedLock\u003c/a\u003e\u003c/strong\u003e is a small library for taking advantage of these providers in your own Java code, if you\u0027re looking to implement your own scheduled tasks. It provides an API for acquiring and releasing locks as well as connectors to a wide variety of lock providers. If you\u0027re writing your own distributed tasks but don\u0027t want to take on the complexity of an entire orchestration platform like \u003ca href\u003d\"/radar/platforms/kubernetes\"\u003eKubernetes\u003c/a\u003e, ShedLock is worth a look.\u003c/p\u003e","blip_status":"t","theta":"326","volume":"2022-03"},{"name":"SpiceDB","id":"202203085","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"89","display_name":"SpiceDB","radius":"300","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/authzed/spicedb\"\u003eSpiceDB\u003c/a\u003e\u003c/strong\u003e is a database system, inspired by Google\u0027s \u003ca href\u003d\"https://research.google/pubs/pub48190\"\u003eZanzibar\u003c/a\u003e, for managing application permissions. With SpiceDB, you create a schema to model the permissions requirements and use the \u003ca href\u003d\"https://docs.authzed.com/reference/api#client-libraries\"\u003eclient library\u003c/a\u003e to apply the schema to one of the \u003ca href\u003d\"https://docs.authzed.com/spicedb/selecting-a-datastore\"\u003esupported databases\u003c/a\u003e, insert data and query to efficiently answer questions like \"Does this user have access to this resource?\" or even the inverse \"What are all the resources this user has access to?\" We usually advocate separating the authorization policies from code, but SpiceDB takes it a step further by separating data from the policy and storing it as a graph to efficiently answer authorization queries. Because of this separation, you have to ensure that the changes in your application\u0027s primary data store are reflected in SpiceDB. Among other Zanzibar-inspired implementations, we find SpiceDB to be an interesting framework to assess for your authorization needs.\u003c/p\u003e","blip_status":"t","theta":"331","volume":"2022-03"},{"name":"sqlc","id":"202203030","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"90","display_name":"sqlc","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://github.com/kyleconroy/sqlc\"\u003esqlc\u003c/a\u003e\u003c/strong\u003e is a compiler that generates type-safe idiomatic Go code from SQL. Unlike other approaches based on object-relational mapping (ORM), you continue to write plain SQL for your needs. Once invoked, sqlc checks the correctness of the SQL and generates performant Go code, which can be directly called from the rest of the application. With stable support for both PostgreSQL and MySQL, sqlc is worth a look, and we encourage you to assess it.\u003c/p\u003e","blip_status":"t","theta":"337","volume":"2022-03"},{"name":"The Composable Architecture","id":"202203066","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"91","display_name":"The Composable Architecture","radius":"300","description":"\u003cp\u003eDeveloping apps for iOS has become more streamlined over time, and \u003ca href\u003d\"https://www.thoughtworks.com/radar/languages-and-frameworks/swiftui\"\u003eSwiftUI\u003c/a\u003e moving into Adopt is a sign of that. Going beyond the general nature of SwiftUI and other common frameworks, \u003ca href\u003d\"https://github.com/pointfreeco/swift-composable-architecture#the-composable-architecture\"\u003e\u003cstrong\u003eThe Composable Architecture\u003c/strong\u003e\u003c/a\u003e (TCA) is both a library and an architectural style for building apps. It was designed over the course of a series of videos, and the authors state that they had composition, testing and ergonomics in mind, building on a foundation of ideas from The Elm Architecture and Redux. As expected, the narrow scope and opinionatedness is both a strength and a weakness of TCA. We feel that teams who don\u0027t have a lot of expertise in writing iOS apps, which are often teams who may be looking after multiple related codebases with different tech stacks, stand to benefit the most from using an opinionated framework like TCA, and we like the opinions expressed in TCA.\u003c/p\u003e","blip_status":"t","theta":"343","volume":"2022-03"},{"name":"WebAssembly","id":"1250","quadrant":"languages-and-frameworks","ring":"Assess","movement":"c","radarId":"92","display_name":"WebAssembly","radius":"310","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"http://webassembly.org/\"\u003eWebAssembly\u003c/a\u003e\u003c/strong\u003e (WASM) is the W3C standard that provides capabilities of executing code in the browser. Supported by all major browsers and backward compatible, it\u0027s a binary compilation format designed to run in the browser at near native speeds. It opens up the range of languages you can use to write front-end functionality, with early focus on C, C++ and Rust, and it\u0027s also an \u003ca href\u003d\"https://llvm.org/\"\u003eLLVM compilation\u003c/a\u003e target. When run in the sandbox, it can interact with JavaScript and shares the same permissions and security model. Portability and security are key capabilities that will enable most platforms, including mobile and IoT.\u003c/p\u003e","blip_status":"c","theta":"348","volume":"2022-03"},{"name":"Zig","id":"202203010","quadrant":"languages-and-frameworks","ring":"Assess","movement":"t","radarId":"93","display_name":"Zig","radius":"320","description":"\u003cp\u003e\u003cstrong\u003e\u003ca href\u003d\"https://ziglang.org/\"\u003eZig\u003c/a\u003e\u003c/strong\u003e is a new language that shares many attributes with C but with stronger typing, easier memory allocation, support for namespacing and a host of other features. Its syntax, however, is reminiscent of JavaScript rather than C, which some may hold against it. Zig\u0027s aim is to provide a very simple language with straightforward compilation that minimizes side-effects and delivers predictable, easy-to-trace execution. Zig also provides simplified access to LLVM\u0027s \u003ca href\u003d\"https://llvm.org/\"\u003ecross-compilation capability\u003c/a\u003e. Some of our developers have found this feature so viable, they\u0027re using Zig as a cross-compiler even though they aren\u0027t writing Zig code. Zig is a novel language and worth looking into  for applications where C is being considered or already in use as well as for low-level systems applications that require explicit memory manipulation.\u003c/p\u003e","blip_status":"t","theta":"354","volume":"2022-03"}],"date":"2022-03"}]